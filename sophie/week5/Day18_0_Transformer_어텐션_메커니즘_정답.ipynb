{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day18_0: Transformer ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ - ì •ë‹µ\n",
    "\n",
    "## ğŸ“š ì‹¤ìŠµ í€´ì¦ˆ ì •ë‹µ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³µí†µ ì„í¬íŠ¸\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q1. Attention Score ê³„ì‚° â­\n",
    "\n",
    "**ë¬¸ì œ**: Queryì™€ Keyê°€ ì£¼ì–´ì¡Œì„ ë•Œ, Attention Scoreë¥¼ ê³„ì‚°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# Queryì™€ Key ì •ì˜\n",
    "Q = torch.tensor([[1.0, 0.0], [0.0, 1.0]])  # (2, 2)\n",
    "K = torch.tensor([[1.0, 1.0], [0.0, 1.0]])  # (2, 2)\n",
    "\n",
    "# Attention Score ê³„ì‚°: Q @ K^T\n",
    "scores = torch.matmul(Q, K.transpose(-2, -1))\n",
    "\n",
    "print(\"Query Q:\")\n",
    "print(Q)\n",
    "print(\"\\nKey K:\")\n",
    "print(K)\n",
    "print(\"\\nAttention Score (Q @ K^T):\")\n",
    "print(scores)\n",
    "print(f\"\\nScore shape: {scores.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- Attention ScoreëŠ” Queryì™€ Keyì˜ ë‚´ì (dot product)ìœ¼ë¡œ ê³„ì‚°\n",
    "- Q @ K^Të¥¼ í†µí•´ ê° Queryê°€ ê° Keyì™€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ ì¸¡ì •\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- Score[i,j] = Q[i] dot K[j]\n",
    "- ë†’ì€ ì ìˆ˜ = Queryì™€ Keyê°€ ë¹„ìŠ·í•œ ë°©í–¥\n",
    "\n",
    "**ê³„ì‚° ê³¼ì •**:\n",
    "```\n",
    "Q[0] = [1, 0], K[0] = [1, 1] -> 1*1 + 0*1 = 1\n",
    "Q[0] = [1, 0], K[1] = [0, 1] -> 1*0 + 0*1 = 0\n",
    "Q[1] = [0, 1], K[0] = [1, 1] -> 0*1 + 1*1 = 1\n",
    "Q[1] = [0, 1], K[1] = [0, 1] -> 0*0 + 1*1 = 1\n",
    "```\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- transpose(-2, -1)ì€ ë§ˆì§€ë§‰ ë‘ ì°¨ì›ì„ êµí™˜\n",
    "- ë°°ì¹˜ ì²˜ë¦¬ ì‹œì—ë„ ë™ì¼í•˜ê²Œ ì‘ë™\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Scaled Dot-Product Attention â­\n",
    "\n",
    "**ë¬¸ì œ**: Scoreë¥¼ ìŠ¤ì¼€ì¼ë§í•˜ê³  softmaxë¥¼ ì ìš©í•˜ì—¬ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# ì´ì „ ë¬¸ì œì˜ Score ì‚¬ìš©\n",
    "Q = torch.tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "K = torch.tensor([[1.0, 1.0], [0.0, 1.0]])\n",
    "scores = torch.matmul(Q, K.transpose(-2, -1))\n",
    "\n",
    "# Key ì°¨ì›\n",
    "d_k = K.size(-1)  # 2\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§: Score / sqrt(d_k)\n",
    "scaled_scores = scores / math.sqrt(d_k)\n",
    "\n",
    "# Softmaxë¡œ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "attention_weights = F.softmax(scaled_scores, dim=-1)\n",
    "\n",
    "print(f\"Score:\\n{scores}\")\n",
    "print(f\"\\nd_k = {d_k}, sqrt(d_k) = {math.sqrt(d_k):.4f}\")\n",
    "print(f\"\\nScaled Score:\\n{scaled_scores}\")\n",
    "print(f\"\\nAttention Weights (softmax):\\n{attention_weights}\")\n",
    "print(f\"\\nê° í–‰ì˜ í•©: {attention_weights.sum(dim=-1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. Scoreë¥¼ sqrt(d_k)ë¡œ ë‚˜ëˆ  ìŠ¤ì¼€ì¼ë§\n",
    "2. Softmaxë¥¼ ì ìš©í•˜ì—¬ í™•ë¥  ë¶„í¬ ìƒì„±\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ìŠ¤ì¼€ì¼ë§: ê°’ì´ ë„ˆë¬´ í¬ë©´ softmaxê°€ ê·¹ë‹¨ì ì¸ ê°’ì„ ì¶œë ¥\n",
    "- sqrt(d_k)ë¡œ ë‚˜ëˆ  ë¶„ì‚°ì„ 1ë¡œ ìœ ì§€\n",
    "- Softmax: ê° í–‰ì˜ í•©ì´ 1ì´ ë˜ë„ë¡ ì •ê·œí™”\n",
    "\n",
    "**ì™œ ìŠ¤ì¼€ì¼ë§?**:\n",
    "- d_kê°€ í¬ë©´ ë‚´ì  ê°’ì´ ì»¤ì§ (ë¶„ì‚° ~ d_k)\n",
    "- í° ê°’ -> softmax í›„ 0 ë˜ëŠ” 1 -> ê¸°ìš¸ê¸° ì†Œì‹¤\n",
    "- sqrt(d_k)ë¡œ ë‚˜ëˆ  ë¶„ì‚° ì•ˆì •í™”\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- dim=-1: ë§ˆì§€ë§‰ ì°¨ì›(Key ë°©í–¥)ì— softmax ì ìš©\n",
    "- ê° Queryê°€ ëª¨ë“  Keyì— ëŒ€í•´ í•©ì´ 1ì¸ ê°€ì¤‘ì¹˜ ìƒì„±\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Query, Key, Value ìƒì„± â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì…ë ¥ í…ì„œ Xë¡œë¶€í„° Q, K, Vë¥¼ ìƒì„±í•˜ëŠ” ì„ í˜• ë ˆì´ì–´ë¥¼ ì •ì˜í•˜ê³  ì ìš©í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# ì„¤ì •\n",
    "batch_size = 1\n",
    "seq_len = 4\n",
    "embed_dim = 8\n",
    "\n",
    "# ì…ë ¥ í…ì„œ\n",
    "X = torch.randn(batch_size, seq_len, embed_dim)\n",
    "\n",
    "# Q, K, V ìƒì„±ì„ ìœ„í•œ ì„ í˜• ë ˆì´ì–´\n",
    "W_Q = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "W_K = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "W_V = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "\n",
    "# Q, K, V ìƒì„±\n",
    "Q = W_Q(X)\n",
    "K = W_K(X)\n",
    "V = W_V(X)\n",
    "\n",
    "print(f\"ì…ë ¥ X shape: {X.shape}\")\n",
    "print(f\"Query Q shape: {Q.shape}\")\n",
    "print(f\"Key K shape: {K.shape}\")\n",
    "print(f\"Value V shape: {V.shape}\")\n",
    "print(f\"\\nW_Q íŒŒë¼ë¯¸í„° shape: {W_Q.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- nn.Linearë¡œ Q, K, V ë³€í™˜ í–‰ë ¬ ì •ì˜\n",
    "- ê° í–‰ë ¬ì€ ë™ì¼í•œ ì…ë ¥ Xë¥¼ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- Q = X @ W_Q: \"ë‚´ê°€ ì°¾ëŠ” ì •ë³´\" í‘œí˜„\n",
    "- K = X @ W_K: \"ë‚´ê°€ ê°€ì§„ ì •ë³´ì˜ íŠ¹ì„±\" í‘œí˜„\n",
    "- V = X @ W_V: \"ì‹¤ì œ ì •ë³´ ë‚´ìš©\" í‘œí˜„\n",
    "\n",
    "**ì™œ ì„¸ ê°œë¡œ ë¶„ë¦¬?**:\n",
    "- ê°™ì€ ì…ë ¥ì´ì§€ë§Œ ë‹¤ë¥¸ \"ì—­í• \"ì„ ìˆ˜í–‰\n",
    "- Q-K ë‚´ì  = ìœ ì‚¬ë„ ê³„ì‚°\n",
    "- V = ì‹¤ì œ ì „ë‹¬ë  ì •ë³´\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- bias=False: ì› ë…¼ë¬¸ì—ì„œëŠ” bias ì‚¬ìš©, í•˜ì§€ë§Œ ì—†ì–´ë„ ì„±ëŠ¥ ìœ ì‚¬\n",
    "- íš¨ìœ¨ì„±ì„ ìœ„í•´ Q, K, Vë¥¼ í•œ ë²ˆì— ê³„ì‚°í•˜ê¸°ë„ í•¨\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Self-Attention ì „ì²´ ê³„ì‚° â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Q, K, Vê°€ ì£¼ì–´ì¡Œì„ ë•Œ, Self-Attentionì˜ ì „ì²´ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# Q, K, V ìƒì„± (ì´ì „ ë¬¸ì œì—ì„œ)\n",
    "batch_size, seq_len, embed_dim = 1, 4, 8\n",
    "X = torch.randn(batch_size, seq_len, embed_dim)\n",
    "\n",
    "W_Q = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "W_K = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "W_V = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "\n",
    "Q = W_Q(X)\n",
    "K = W_K(X)\n",
    "V = W_V(X)\n",
    "\n",
    "d_k = Q.size(-1)\n",
    "\n",
    "# 1. Score ê³„ì‚°: Q @ K^T\n",
    "scores = torch.matmul(Q, K.transpose(-2, -1))\n",
    "print(f\"1. Score shape: {scores.shape}\")\n",
    "\n",
    "# 2. ìŠ¤ì¼€ì¼ë§: / sqrt(d_k)\n",
    "scaled_scores = scores / math.sqrt(d_k)\n",
    "print(f\"2. Scaled Score shape: {scaled_scores.shape}\")\n",
    "\n",
    "# 3. Softmax\n",
    "attention_weights = F.softmax(scaled_scores, dim=-1)\n",
    "print(f\"3. Attention Weights shape: {attention_weights.shape}\")\n",
    "\n",
    "# 4. ê°€ì¤‘í•©: weights @ V\n",
    "output = torch.matmul(attention_weights, V)\n",
    "print(f\"4. Output shape: {output.shape}\")\n",
    "\n",
    "print(f\"\\nì…ë ¥ Xì™€ ì¶œë ¥ shape ë¹„êµ: {X.shape} -> {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "Scaled Dot-Product Attention ê³µì‹ ë‹¨ê³„ë³„ ì ìš©:\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "1. Score = Q @ K^T: (B, N, D) @ (B, D, N) = (B, N, N)\n",
    "2. ìŠ¤ì¼€ì¼ë§: ê°’ ì•ˆì •í™”\n",
    "3. Softmax: í™•ë¥  ë¶„í¬ ìƒì„± (ê° í–‰ í•© = 1)\n",
    "4. ê°€ì¤‘í•©: (B, N, N) @ (B, N, D) = (B, N, D)\n",
    "\n",
    "**ê²°ê³¼ í•´ì„**:\n",
    "- ì¶œë ¥ì˜ ê° ìœ„ì¹˜ëŠ” ëª¨ë“  ìœ„ì¹˜ì˜ Valueë¥¼ ê°€ì¤‘ í•©ì‚°\n",
    "- ê´€ë ¨ ìˆëŠ” ìœ„ì¹˜ì˜ ì •ë³´ê°€ ë” ë§ì´ ë°˜ì˜ë¨\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì…ë ¥ê³¼ ì¶œë ¥ì˜ shapeê°€ ë™ì¼ (B, N, D)\n",
    "- ì´ë¥¼ í†µí•´ ë ˆì´ì–´ ìŒ“ê¸° ê°€ëŠ¥\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ì‹œê°í™” â­â­\n",
    "\n",
    "**ë¬¸ì œ**: 5ê°œ ë‹¨ì–´ë¡œ êµ¬ì„±ëœ ë¬¸ì¥ì˜ Self-Attention ê°€ì¤‘ì¹˜ë¥¼ íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸\n",
    "words = [\"I\", \"love\", \"deep\", \"learning\", \"!\"]\n",
    "\n",
    "# Self-Attention í´ë˜ìŠ¤ ì •ì˜\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim)\n",
    "        self.embed_dim = embed_dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        Q = self.query(x)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "        \n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.embed_dim)\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        output = torch.matmul(weights, V)\n",
    "        \n",
    "        return output, weights\n",
    "\n",
    "# ëª¨ë¸ ë° ì…ë ¥ ìƒì„±\n",
    "embed_dim = 32\n",
    "attention = SelfAttention(embed_dim)\n",
    "x = torch.randn(1, len(words), embed_dim)\n",
    "\n",
    "# ì–´í…ì…˜ ê³„ì‚°\n",
    "_, attention_weights = attention(x)\n",
    "attn_matrix = attention_weights.squeeze().detach().numpy()\n",
    "\n",
    "# Plotly íˆíŠ¸ë§µ ì‹œê°í™”\n",
    "fig = px.imshow(\n",
    "    attn_matrix,\n",
    "    labels=dict(x=\"Key (ì°¸ì¡°ë˜ëŠ” ë‹¨ì–´)\", y=\"Query (ì£¼ëª©í•˜ëŠ” ë‹¨ì–´)\", color=\"ê°€ì¤‘ì¹˜\"),\n",
    "    x=words,\n",
    "    y=words,\n",
    "    color_continuous_scale=\"Blues\",\n",
    "    aspect=\"equal\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Self-Attention ê°€ì¤‘ì¹˜ íˆíŠ¸ë§µ\",\n",
    "    xaxis_title=\"Key (ì°¸ì¡°ë˜ëŠ” ë‹¨ì–´)\",\n",
    "    yaxis_title=\"Query (ì£¼ëª©í•˜ëŠ” ë‹¨ì–´)\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"ì–´í…ì…˜ ê°€ì¤‘ì¹˜ í–‰ë ¬:\")\n",
    "print(pd.DataFrame(attn_matrix, index=words, columns=words).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. Self-Attention í´ë˜ìŠ¤ ì •ì˜\n",
    "2. ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ì¶”ì¶œ\n",
    "3. px.imshowë¡œ íˆíŠ¸ë§µ ì‹œê°í™”\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- í–‰(Query): ì£¼ëª©í•˜ëŠ” ë‹¨ì–´\n",
    "- ì—´(Key): ì°¸ì¡°ë˜ëŠ” ë‹¨ì–´\n",
    "- ê°’: ì£¼ëª© ì •ë„ (0~1, í–‰ í•©=1)\n",
    "\n",
    "**í•´ì„ ë°©ë²•**:\n",
    "- ë°ì€ ìƒ‰: ë†’ì€ ì–´í…ì…˜ (ê°•í•œ ì—°ê´€ì„±)\n",
    "- ëŒ€ê°ì„ : ìê¸° ìì‹ ì— ëŒ€í•œ ì–´í…ì…˜\n",
    "- ë¹„ëŒ€ê°ì„ : ë‹¤ë¥¸ ë‹¨ì–´ì™€ì˜ ê´€ê³„\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì‹¤ì œ ëª¨ë¸ì—ì„œëŠ” í•™ìŠµ í›„ ì˜ë¯¸ ìˆëŠ” íŒ¨í„´ ë‚˜íƒ€ë‚¨\n",
    "- ì´ˆê¸°í™” ì§í›„ëŠ” ëœë¤ì— ê°€ê¹Œì›€\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Multi-Head Attention í—¤ë“œ ë¶„í•  â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: embed_dim=64, num_heads=4ì¼ ë•Œ, í…ì„œë¥¼ í—¤ë“œë³„ë¡œ ë¶„í• í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# ì„¤ì •\n",
    "batch_size = 2\n",
    "seq_len = 10\n",
    "embed_dim = 64\n",
    "num_heads = 4\n",
    "head_dim = embed_dim // num_heads  # 64 / 4 = 16\n",
    "\n",
    "# ì…ë ¥ í…ì„œ (ì˜ˆ: Q, K, ë˜ëŠ” V)\n",
    "x = torch.randn(batch_size, seq_len, embed_dim)\n",
    "print(f\"ì›ë³¸ shape: {x.shape}\")\n",
    "print(f\"(batch={batch_size}, seq_len={seq_len}, embed_dim={embed_dim})\")\n",
    "\n",
    "# í—¤ë“œë³„ ë¶„í• \n",
    "# Step 1: (B, N, D) -> (B, N, h, d_k)\n",
    "x_reshaped = x.view(batch_size, seq_len, num_heads, head_dim)\n",
    "print(f\"\\nreshape í›„: {x_reshaped.shape}\")\n",
    "\n",
    "# Step 2: (B, N, h, d_k) -> (B, h, N, d_k)\n",
    "x_heads = x_reshaped.transpose(1, 2)\n",
    "print(f\"transpose í›„: {x_heads.shape}\")\n",
    "print(f\"(batch={batch_size}, num_heads={num_heads}, seq_len={seq_len}, head_dim={head_dim})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. viewë¡œ ì„ë² ë”© ì°¨ì›ì„ (num_heads, head_dim)ìœ¼ë¡œ ë¶„í• \n",
    "2. transposeë¡œ í—¤ë“œ ì°¨ì›ì„ seq_len ì•ìœ¼ë¡œ ì´ë™\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ê° í—¤ë“œê°€ ë…ë¦½ì ìœ¼ë¡œ ì–´í…ì…˜ ìˆ˜í–‰\n",
    "- head_dim = embed_dim / num_heads\n",
    "- (B, N, D) -> (B, h, N, d_k)\n",
    "\n",
    "**ì™œ transpose?**:\n",
    "- ì–´í…ì…˜ ê³„ì‚°ì—ì„œ (N, d_k) í˜•íƒœ í•„ìš”\n",
    "- Q @ K^T ê³„ì‚° ì‹œ ë§ˆì§€ë§‰ ë‘ ì°¨ì› ì‚¬ìš©\n",
    "- ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ íš¨ìœ¨ì \n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- embed_dim % num_heads == 0 í•„ìˆ˜\n",
    "- contiguous() í˜¸ì¶œ í•„ìš”í•  ìˆ˜ ìˆìŒ (ë©”ëª¨ë¦¬ ì—°ì†ì„±)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Positional Encoding ìƒì„± â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: d_model=16, max_len=10ì¸ Positional Encodingì„ ìƒì„±í•˜ê³  ì‹œê°í™”í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# ì„¤ì •\n",
    "d_model = 16\n",
    "max_len = 10\n",
    "\n",
    "# Positional Encoding ìƒì„±\n",
    "pe = torch.zeros(max_len, d_model)\n",
    "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "# ì§ìˆ˜ ì¸ë±ìŠ¤: sin, í™€ìˆ˜ ì¸ë±ìŠ¤: cos\n",
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "print(f\"Positional Encoding shape: {pe.shape}\")\n",
    "print(f\"(max_len={max_len}, d_model={d_model})\")\n",
    "\n",
    "# íˆíŠ¸ë§µ ì‹œê°í™”\n",
    "fig = px.imshow(\n",
    "    pe.numpy(),\n",
    "    labels=dict(x=\"Dimension\", y=\"Position\", color=\"Value\"),\n",
    "    color_continuous_scale=\"RdBu\",\n",
    "    aspect=\"auto\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Positional Encoding (d_model={d_model}, max_len={max_len})\",\n",
    "    xaxis_title=\"Dimension\",\n",
    "    yaxis_title=\"Position\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì • ì°¨ì›ì˜ íŒ¨í„´ ì‹œê°í™”\n",
    "positions = list(range(max_len))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# ì²˜ìŒ 4ê°œ ì°¨ì› ì‹œê°í™”\n",
    "for dim in range(4):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=positions,\n",
    "        y=pe[:, dim].numpy(),\n",
    "        mode='lines+markers',\n",
    "        name=f'dim {dim} ({\"sin\" if dim % 2 == 0 else \"cos\"})'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Positional Encoding: ê° ì°¨ì›ë³„ íŒ¨í„´\",\n",
    "    xaxis_title=\"Position\",\n",
    "    yaxis_title=\"Value\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. PE í–‰ë ¬ ì´ˆê¸°í™” (max_len x d_model)\n",
    "2. ê° ìœ„ì¹˜ì— ëŒ€í•´ sin/cos ê°’ ê³„ì‚°\n",
    "3. ì§ìˆ˜/í™€ìˆ˜ ì¸ë±ìŠ¤ì— ê°ê° í• ë‹¹\n",
    "\n",
    "**í•µì‹¬ ìˆ˜ì‹**:\n",
    "$$PE_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)$$\n",
    "$$PE_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)$$\n",
    "\n",
    "**íŒ¨í„´ í•´ì„**:\n",
    "- ë‚®ì€ ì°¨ì›: ë¹ ë¥´ê²Œ ì§„ë™ (ê³ ì£¼íŒŒ)\n",
    "- ë†’ì€ ì°¨ì›: ì²œì²œíˆ ì§„ë™ (ì €ì£¼íŒŒ)\n",
    "- ê° ìœ„ì¹˜ë§ˆë‹¤ ê³ ìœ í•œ íŒ¨í„´ ìƒì„±\n",
    "\n",
    "**ì™œ sin/cos?**:\n",
    "- ì£¼ê¸°ì„±: ìƒëŒ€ì  ìœ„ì¹˜ ê´€ê³„ í•™ìŠµ ê°€ëŠ¥\n",
    "- ì™¸ì‚½ ê°€ëŠ¥: í•™ìŠµ ì‹œ ë³¸ ì  ì—†ëŠ” ê¸´ ì‹œí€€ìŠ¤ì—ë„ ì ìš©\n",
    "- PE(pos+k)ë¥¼ PE(pos)ì˜ ì„ í˜• ê²°í•©ìœ¼ë¡œ í‘œí˜„ ê°€ëŠ¥\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. Transformer Encoder Layer êµ¬í˜„ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Multi-Head Attention, Add & Norm, Feed-Forwardë¥¼ í¬í•¨í•˜ëŠ” Encoder Layerë¥¼ êµ¬í˜„í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        \n",
    "        self.query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim)\n",
    "        self.fc_out = nn.Linear(embed_dim, embed_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, N, _ = x.shape\n",
    "        \n",
    "        Q = self.query(x).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = self.key(x).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = self.value(x).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(weights, V)\n",
    "        \n",
    "        context = context.transpose(1, 2).contiguous().view(B, N, self.embed_dim)\n",
    "        return self.fc_out(context)\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Multi-Head Attention\n",
    "        self.attention = MultiHeadAttention(embed_dim, num_heads)\n",
    "        \n",
    "        # Layer Normalization\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        # Feed-Forward Network\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ff_dim, embed_dim)\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 1. Multi-Head Attention + Add & Norm\n",
    "        attn_output = self.attention(x)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # 2. Feed-Forward + Add & Norm\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "embed_dim = 64\n",
    "num_heads = 4\n",
    "ff_dim = 256\n",
    "\n",
    "encoder_layer = TransformerEncoderLayer(embed_dim, num_heads, ff_dim)\n",
    "x = torch.randn(2, 10, embed_dim)  # (batch, seq_len, embed_dim)\n",
    "output = encoder_layer(x)\n",
    "\n",
    "print(f\"ì…ë ¥ shape: {x.shape}\")\n",
    "print(f\"ì¶œë ¥ shape: {output.shape}\")\n",
    "print(f\"\\níŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in encoder_layer.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. MultiHeadAttention í´ë˜ìŠ¤ ì •ì˜\n",
    "2. TransformerEncoderLayerì—ì„œ ì¡°ë¦½\n",
    "3. Add & Norm (ì”ì°¨ ì—°ê²° + LayerNorm) ì ìš©\n",
    "\n",
    "**í•µì‹¬ êµ¬ì¡°**:\n",
    "```\n",
    "x -> [Multi-Head Attention] -> [Add & Norm] -> [Feed-Forward] -> [Add & Norm] -> output\n",
    "```\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- Add & Norm: x + dropout(sublayer(x)) í›„ LayerNorm\n",
    "- ì”ì°¨ ì—°ê²°: ê¸°ìš¸ê¸° íë¦„ ê°œì„ , ê¹Šì€ ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥\n",
    "- LayerNorm: í•™ìŠµ ì•ˆì •í™”\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- Pre-LN vs Post-LN: ìµœê·¼ì—ëŠ” LayerNormì„ sublayer ì „ì— ì ìš©í•˜ëŠ” Pre-LNì´ ë” ì•ˆì •ì \n",
    "- ff_dimì€ ë³´í†µ embed_dimì˜ 4ë°°\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. nn.TransformerEncoder í™œìš© â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: PyTorchì˜ nn.TransformerEncoderë¥¼ ì‚¬ìš©í•˜ì—¬ 6ê°œ ë ˆì´ì–´ì˜ Encoderë¥¼ ë§Œë“¤ê³  ìˆœì „íŒŒë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# ì„¤ì •\n",
    "d_model = 256\n",
    "nhead = 8\n",
    "dim_feedforward = 1024\n",
    "num_layers = 6\n",
    "dropout = 0.1\n",
    "\n",
    "# Encoder Layer ì •ì˜\n",
    "encoder_layer = nn.TransformerEncoderLayer(\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    dim_feedforward=dim_feedforward,\n",
    "    dropout=dropout,\n",
    "    batch_first=True  # (batch, seq, feature) í˜•ì‹ ì‚¬ìš©\n",
    ")\n",
    "\n",
    "# Encoder (6 layers)\n",
    "encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "# ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸\n",
    "batch_size = 4\n",
    "seq_len = 50\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "output = encoder(x)\n",
    "\n",
    "print(f\"nn.TransformerEncoder ì„¤ì •:\")\n",
    "print(f\"  - d_model: {d_model}\")\n",
    "print(f\"  - nhead: {nhead}\")\n",
    "print(f\"  - dim_feedforward: {dim_feedforward}\")\n",
    "print(f\"  - num_layers: {num_layers}\")\n",
    "print(f\"\\nì…ë ¥ shape: {x.shape}\")\n",
    "print(f\"ì¶œë ¥ shape: {output.shape}\")\n",
    "print(f\"\\nì´ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in encoder.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. nn.TransformerEncoderLayerë¡œ ë‹¨ì¼ ë ˆì´ì–´ ì •ì˜\n",
    "2. nn.TransformerEncoderë¡œ ì—¬ëŸ¬ ë ˆì´ì–´ ìŠ¤íƒ\n",
    "3. batch_first=Trueë¡œ (batch, seq, feature) í˜•ì‹ ì‚¬ìš©\n",
    "\n",
    "**í•µì‹¬ íŒŒë¼ë¯¸í„°**:\n",
    "- d_model: ì„ë² ë”©/ëª¨ë¸ ì°¨ì›\n",
    "- nhead: Multi-Head Attention í—¤ë“œ ìˆ˜\n",
    "- dim_feedforward: Feed-Forward ë‚´ë¶€ ì°¨ì›\n",
    "- num_layers: Encoder ë ˆì´ì–´ ìˆ˜\n",
    "\n",
    "**ì› ë…¼ë¬¸ ì„¤ì •**:\n",
    "- Base: d_model=512, nhead=8, ff=2048, layers=6\n",
    "- Big: d_model=1024, nhead=16, ff=4096, layers=6\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- batch_first=True: PyTorch 1.9+ì—ì„œ ì§€ì›\n",
    "- Mask ì‚¬ìš©: src_mask (íŒ¨ë”©), src_key_padding_mask (ì–´í…ì…˜ ë§ˆìŠ¤í¬)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. Transformer í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Transformer ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ì„ êµ¬í˜„í•˜ê³ , ê°€ìƒì˜ ë°ì´í„°ë¡œ 1 ì—í¬í¬ í•™ìŠµì„ ìˆ˜í–‰í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ - Part 1: Positional Encoding ë° ëª¨ë¸ ì •ì˜\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerTextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, ff_dim, num_layers, num_classes, max_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Embedding + Positional Encoding\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_encoding = PositionalEncoding(embed_dim, max_len, dropout)\n",
    "        \n",
    "        # 2. Transformer Encoder (2 layers)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # 3. ë¶„ë¥˜ í—¤ë“œ (í‰ê·  í’€ë§ + FC)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len) - í† í° ì¸ë±ìŠ¤\n",
    "        x = self.embedding(x)       # (batch, seq_len, embed_dim)\n",
    "        x = self.pos_encoding(x)    # + positional encoding\n",
    "        x = self.encoder(x)         # Transformer Encoder\n",
    "        \n",
    "        # í‰ê·  í’€ë§\n",
    "        x = x.mean(dim=1)           # (batch, embed_dim)\n",
    "        x = self.classifier(x)      # (batch, num_classes)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "print(\"ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ - Part 2: ë°ì´í„° ì¤€ë¹„ ë° ëª¨ë¸ ìƒì„±\n",
    "\n",
    "# ì„¤ì •\n",
    "vocab_size = 10000\n",
    "embed_dim = 128\n",
    "num_heads = 4\n",
    "ff_dim = 256\n",
    "num_layers = 2\n",
    "num_classes = 2\n",
    "max_len = 100\n",
    "batch_size = 32\n",
    "\n",
    "# ê°€ìƒì˜ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” í† í°í™”ëœ í…ìŠ¤íŠ¸ ì‚¬ìš©)\n",
    "num_samples = 500\n",
    "X_train = torch.randint(0, vocab_size, (num_samples, max_len))\n",
    "y_train = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TransformerTextClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    num_heads=num_heads,\n",
    "    ff_dim=ff_dim,\n",
    "    num_layers=num_layers,\n",
    "    num_classes=num_classes,\n",
    "    max_len=max_len\n",
    ").to(device)\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {len(train_dataset)} ìƒ˜í”Œ\")\n",
    "print(f\"ë°°ì¹˜ ìˆ˜: {len(train_loader)}\")\n",
    "print(f\"ëª¨ë¸ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ - Part 3: í•™ìŠµ ë£¨í”„ (1 ì—í¬í¬)\n",
    "\n",
    "model.train()\n",
    "total_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "losses = []\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"í•™ìŠµ ì‹œì‘! (1 ì—í¬í¬)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for batch_idx, (texts, labels) in enumerate(train_loader):\n",
    "    texts, labels = texts.to(device), labels.to(device)\n",
    "    \n",
    "    # Forward\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(texts)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # í†µê³„\n",
    "    total_loss += loss.item()\n",
    "    losses.append(loss.item())\n",
    "    _, predicted = outputs.max(1)\n",
    "    total += labels.size(0)\n",
    "    correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    if batch_idx % 5 == 0:\n",
    "        print(f\"Batch {batch_idx:3d}/{len(train_loader)}: Loss={loss.item():.4f}\")\n",
    "\n",
    "avg_loss = total_loss / len(train_loader)\n",
    "accuracy = 100. * correct / total\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"ì—í¬í¬ ì™„ë£Œ!\")\n",
    "print(f\"  í‰ê·  Loss: {avg_loss:.4f}\")\n",
    "print(f\"  ì •í™•ë„: {accuracy:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ - Part 4: í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(1, len(losses) + 1)),\n",
    "    y=losses,\n",
    "    mode='lines',\n",
    "    name='Loss'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='í•™ìŠµ ì†ì‹¤ (1 ì—í¬í¬)',\n",
    "    xaxis_title='Batch',\n",
    "    yaxis_title='Loss'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì „ì²´ íŒŒì´í”„ë¼ì¸**:\n",
    "1. **PositionalEncoding**: sin/cos íŒ¨í„´ìœ¼ë¡œ ìœ„ì¹˜ ì •ë³´ ìƒì„±\n",
    "2. **TransformerTextClassifier**:\n",
    "   - Embedding -> Positional Encoding -> TransformerEncoder -> Mean Pooling -> Classifier\n",
    "3. **í•™ìŠµ ë£¨í”„**: Forward -> Loss -> Backward -> Update\n",
    "\n",
    "**ëª¨ë¸ êµ¬ì¡°**:\n",
    "```\n",
    "í† í° ì¸ë±ìŠ¤ (batch, seq_len)\n",
    "    â†“ Embedding\n",
    "ì„ë² ë”© (batch, seq_len, embed_dim)\n",
    "    â†“ Positional Encoding\n",
    "ìœ„ì¹˜ ì •ë³´ ì¶”ê°€ëœ ì„ë² ë”©\n",
    "    â†“ TransformerEncoder (2 layers)\n",
    "ë¬¸ë§¥ ë²¡í„° (batch, seq_len, embed_dim)\n",
    "    â†“ Mean Pooling\n",
    "ë¬¸ì¥ ë²¡í„° (batch, embed_dim)\n",
    "    â†“ Classifier (FC)\n",
    "í´ë˜ìŠ¤ ì ìˆ˜ (batch, num_classes)\n",
    "```\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- Mean Pooling: ëª¨ë“  í† í°ì˜ í‰ê· ìœ¼ë¡œ ë¬¸ì¥ í‘œí˜„\n",
    "- ëŒ€ì•ˆ: [CLS] í† í° ì‚¬ìš© (BERT ìŠ¤íƒ€ì¼)\n",
    "\n",
    "**í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°€ì´ë“œ**:\n",
    "| ì„¤ì • | ì‘ì€ ëª¨ë¸ | ì¤‘ê°„ ëª¨ë¸ | í° ëª¨ë¸ |\n",
    "|-----|---------|---------|--------|\n",
    "| embed_dim | 128 | 256 | 512 |\n",
    "| num_heads | 4 | 8 | 8 |\n",
    "| ff_dim | 256 | 1024 | 2048 |\n",
    "| num_layers | 2 | 4 | 6 |\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì‹¤ì œ í•™ìŠµ ì‹œ ìˆ˜ì‹­ ì—í¬í¬ í•„ìš”\n",
    "- í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ (warmup) ê¶Œì¥\n",
    "- ë°°ì¹˜ í¬ê¸°ëŠ” ë©”ëª¨ë¦¬ í—ˆìš© ë²”ìœ„ ë‚´ ìµœëŒ€ë¡œ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "### Transformer í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ê°œë… | í•µì‹¬ ìˆ˜ì‹/ì½”ë“œ | ì—­í•  |\n",
    "|-----|---------------|------|\n",
    "| Self-Attention | softmax(QK^T/sqrt(d_k))V | ì‹œí€€ìŠ¤ ë‚´ ê´€ê³„ íŒŒì•… |\n",
    "| Multi-Head | Concat(head_1, ..., head_h)W_O | ë‹¤ì–‘í•œ ê´€ì  í†µí•© |\n",
    "| Positional Encoding | sin/cos íŒ¨í„´ | ìˆœì„œ ì •ë³´ ì£¼ì… |\n",
    "| Add & Norm | x + sublayer(x), LayerNorm | í•™ìŠµ ì•ˆì •í™” |\n",
    "| Feed-Forward | Linear -> ReLU -> Linear | ë¹„ì„ í˜• ë³€í™˜ |\n",
    "\n",
    "### Attention ê³µì‹\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "\n",
    "### ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "- [ ] embed_dim % num_heads == 0 í™•ì¸\n",
    "- [ ] Positional Encoding ì ìš©\n",
    "- [ ] batch_first=True ì„¤ì • (PyTorch 1.9+)\n",
    "- [ ] Dropout ì ì ˆíˆ ì‚¬ìš© (0.1~0.3)\n",
    "- [ ] í•™ìŠµë¥  warmup ê³ ë ¤\n",
    "- [ ] ê¸´ ì‹œí€€ìŠ¤ ì‹œ ë©”ëª¨ë¦¬ ì£¼ì˜ (O(n^2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
