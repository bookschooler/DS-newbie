{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3-3: ì¢…í•© ì‹¤ìŠµ - ë¡œê·¸ ë¶„ì„ ìë™í™” ë´‡ (ì •ë‹µ)\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- 3ì¼ê°„ ë°°ìš´ ëª¨ë“  ê°œë…ì„ í†µí•©í•˜ì—¬ ì‹¤ì „ í”„ë¡œì íŠ¸ ì™„ì„±\n",
    "- globìœ¼ë¡œ íŒŒì¼ íƒìƒ‰, reë¡œ íŒ¨í„´ ì¶”ì¶œ, ì œë„ˆë ˆì´í„°ë¡œ íš¨ìœ¨ì  ì²˜ë¦¬\n",
    "- í´ë˜ìŠ¤ ê¸°ë°˜ ì„¤ê³„ì™€ ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ì ìš©í•œ ê²¬ê³ í•œ ì½”ë“œ ì‘ì„±\n",
    "- JSONìœ¼ë¡œ ê²°ê³¼ ì €ì¥ ë° ë¡œê¹…ìœ¼ë¡œ í”„ë¡œì„¸ìŠ¤ ì¶”ì \n",
    "\n",
    "## í”„ë¡œì íŠ¸ ê°œìš”\n",
    "ì„œë²„ ë¡œê·¸ íŒŒì¼ë“¤ì„ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì—ëŸ¬ì™€ ê²½ê³ ë¥¼ ì¶”ì¶œí•˜ê³ ,\n",
    "í†µê³„ë¥¼ ìƒì„±í•œ ë’¤ JSON ë¦¬í¬íŠ¸ë¡œ ì €ì¥í•˜ëŠ” ìë™í™” ë´‡ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "\n",
    "### í†µí•© ê°œë…\n",
    "- **Day 1**: Collections (Counter, defaultdict), comprehensions\n",
    "- **Day 2**: Generators, file I/O, JSON, modules\n",
    "- **Day 3**: OOP classes, exception handling, logging, regex, glob, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: â­ Setup - ìƒ˜í”Œ ë¡œê·¸ íŒŒì¼ ìƒì„±\n",
    "\n",
    "ë¨¼ì € ë¶„ì„í•  ìƒ˜í”Œ ë¡œê·¸ íŒŒì¼ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ë¡œê·¸ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "log_dir = \"server_logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# ìƒ˜í”Œ ë¡œê·¸ ë°ì´í„° (ë‹¤ì–‘í•œ ë¡œê·¸ ë ˆë²¨ í¬í•¨)\n",
    "sample_logs = [\n",
    "    \"2025-01-15 10:23:45 INFO Server started successfully\",\n",
    "    \"2025-01-15 10:24:12 ERROR Database connection failed: timeout\",\n",
    "    \"2025-01-15 10:25:33 WARNING Memory usage at 85%\",\n",
    "    \"2025-01-15 10:26:01 INFO User login: user123\",\n",
    "    \"2025-01-15 10:27:18 ERROR File not found: /data/config.json\",\n",
    "    \"2025-01-15 10:28:45 WARNING Disk space low: 10% remaining\",\n",
    "    \"2025-01-15 10:29:22 INFO API request processed in 120ms\",\n",
    "    \"2025-01-15 10:30:55 ERROR Authentication failed for user: admin\",\n",
    "]\n",
    "\n",
    "# 3ê°œì˜ ë¡œê·¸ íŒŒì¼ ìƒì„±\n",
    "dates = [\"2025_01_15\", \"2025_01_16\", \"2025_01_17\"]\n",
    "\n",
    "for date in dates:\n",
    "    file_path = os.path.join(log_dir, f\"app_{date}.log\")\n",
    "    \n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        # ê° ë‚ ì§œì— ë§ê²Œ ë¡œê·¸ íƒ€ì„ìŠ¤íƒ¬í”„ ìˆ˜ì •\n",
    "        for log_line in sample_logs * 3:  # ë¡œê·¸ë¥¼ 3ë²ˆ ë°˜ë³µí•˜ì—¬ ì¶©ë¶„í•œ ë°ì´í„° ìƒì„±\n",
    "            # ë‚ ì§œ ë¶€ë¶„ë§Œ ë³€ê²½\n",
    "            modified_log = log_line.replace(\"2025-01-15\", date.replace(\"_\", \"-\"))\n",
    "            f.write(modified_log + \"\\n\")\n",
    "\n",
    "print(f\"âœ… {len(dates)}ê°œì˜ ë¡œê·¸ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "print(f\"ğŸ“ ë””ë ‰í† ë¦¬: {log_dir}/\")\n",
    "\n",
    "# ìƒì„±ëœ íŒŒì¼ í™•ì¸\n",
    "for date in dates:\n",
    "    file_path = os.path.join(log_dir, f\"app_{date}.log\")\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    print(f\"  - app_{date}.log ({file_size} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2: â­â­ File Discovery - globìœ¼ë¡œ ë¡œê·¸ íŒŒì¼ ì°¾ê¸°\n",
    "\n",
    "glob ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • íŒ¨í„´ì˜ ë¡œê·¸ íŒŒì¼ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# server_logs ë””ë ‰í† ë¦¬ì—ì„œ .log í™•ì¥ìë¥¼ ê°€ì§„ ëª¨ë“  íŒŒì¼ ì°¾ê¸°\n",
    "log_files = glob.glob(\"server_logs/*.log\")\n",
    "\n",
    "# íŒŒì¼ëª… ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "log_files.sort()\n",
    "\n",
    "print(f\"ë°œê²¬ëœ ë¡œê·¸ íŒŒì¼: {len(log_files)}ê°œ\")\n",
    "for file in log_files:\n",
    "    print(f\"  - {file}\")\n",
    "\n",
    "# ì¶”ê°€: íŠ¹ì • ë‚ ì§œ íŒ¨í„´ìœ¼ë¡œ í•„í„°ë§\n",
    "jan_15_logs = glob.glob(\"server_logs/*2025_01_15.log\")\n",
    "print(f\"\\n2025ë…„ 1ì›” 15ì¼ ë¡œê·¸: {len(jan_15_logs)}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: â­â­â­ Pattern Extraction - ì •ê·œì‹ìœ¼ë¡œ ë¡œê·¸ íŒŒì‹±\n",
    "\n",
    "ì •ê·œì‹ì„ ì‚¬ìš©í•˜ì—¬ ë¡œê·¸ ë¼ì¸ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„, ë ˆë²¨, ë©”ì‹œì§€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# ë¡œê·¸ íŒ¨í„´: YYYY-MM-DD HH:MM:SS LEVEL Message\n",
    "# ê·¸ë£¹ 1: ë‚ ì§œì‹œê°„ (\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\n",
    "# ê·¸ë£¹ 2: ë ˆë²¨ (INFO|WARNING|ERROR)\n",
    "# ê·¸ë£¹ 3: ë©”ì‹œì§€ (.+)\n",
    "log_pattern = r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}) (INFO|WARNING|ERROR) (.+)\"\n",
    "\n",
    "# íŒ¨í„´ ì»´íŒŒì¼ (ì„±ëŠ¥ í–¥ìƒ)\n",
    "compiled_pattern = re.compile(log_pattern)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_lines = [\n",
    "    \"2025-01-15 10:24:12 ERROR Database connection failed: timeout\",\n",
    "    \"2025-01-15 10:25:33 WARNING Memory usage at 85%\",\n",
    "    \"2025-01-15 10:26:01 INFO User login: user123\",\n",
    "    \"Invalid log line\",  # ë§¤ì¹­ ì‹¤íŒ¨ ì¼€ì´ìŠ¤\n",
    "]\n",
    "\n",
    "print(\"ë¡œê·¸ íŒŒì‹± í…ŒìŠ¤íŠ¸:\")\n",
    "for line in test_lines:\n",
    "    match = compiled_pattern.match(line)\n",
    "    \n",
    "    if match:\n",
    "        timestamp, level, message = match.groups()\n",
    "        print(f\"\\nì›ë³¸: {line}\")\n",
    "        print(f\"  ğŸ“… íƒ€ì„ìŠ¤íƒ¬í”„: {timestamp}\")\n",
    "        print(f\"  ğŸ·ï¸  ë ˆë²¨: {level}\")\n",
    "        print(f\"  ğŸ’¬ ë©”ì‹œì§€: {message}\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨: {line}\")\n",
    "\n",
    "# ì¶”ê°€: íŠ¹ì • ë ˆë²¨ë§Œ í•„í„°ë§í•˜ëŠ” íŒ¨í„´\n",
    "error_pattern = r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}) ERROR (.+)\"\n",
    "print(\"\\n\\nERRORë§Œ ì¶”ì¶œ:\")\n",
    "for line in test_lines:\n",
    "    if re.match(error_pattern, line):\n",
    "        print(f\"  ğŸ”´ {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 4: â­â­â­ Generator - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë¡œê·¸ ì²˜ë¦¬\n",
    "\n",
    "ì œë„ˆë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ìš©ëŸ‰ ë¡œê·¸ íŒŒì¼ì„ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log_file(file_path, pattern):\n",
    "    \"\"\"\n",
    "    ë¡œê·¸ íŒŒì¼ì„ í•œ ì¤„ì”© ì½ì–´ íŒŒì‹± ê²°ê³¼ë¥¼ yieldí•˜ëŠ” ì œë„ˆë ˆì´í„°\n",
    "    \n",
    "    Args:\n",
    "        file_path: ë¡œê·¸ íŒŒì¼ ê²½ë¡œ\n",
    "        pattern: ì •ê·œì‹ íŒ¨í„´ (ì»´íŒŒì¼ëœ ê°ì²´ ë˜ëŠ” ë¬¸ìì—´)\n",
    "    \n",
    "    Yields:\n",
    "        dict: {'timestamp': str, 'level': str, 'message': str}\n",
    "    \"\"\"\n",
    "    # íŒ¨í„´ì´ ë¬¸ìì—´ì´ë©´ ì»´íŒŒì¼\n",
    "    if isinstance(pattern, str):\n",
    "        pattern = re.compile(pattern)\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            line = line.strip()  # ì•ë’¤ ê³µë°± ì œê±°\n",
    "            \n",
    "            if not line:  # ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°\n",
    "                continue\n",
    "            \n",
    "            match = pattern.match(line)\n",
    "            \n",
    "            if match:\n",
    "                timestamp, level, message = match.groups()\n",
    "                yield {\n",
    "                    'timestamp': timestamp,\n",
    "                    'level': level,\n",
    "                    'message': message,\n",
    "                    'file': file_path,\n",
    "                    'line_number': line_num\n",
    "                }\n",
    "            else:\n",
    "                # ë§¤ì¹­ ì‹¤íŒ¨í•œ ë¼ì¸ì€ ê±´ë„ˆë›°ê±°ë‚˜ ê²½ê³  ë¡œê·¸ ì¶œë ¥ ê°€ëŠ¥\n",
    "                pass\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "if log_files:\n",
    "    print(\"ì œë„ˆë ˆì´í„° í…ŒìŠ¤íŠ¸:\")\n",
    "    log_gen = parse_log_file(log_files[0], compiled_pattern)\n",
    "    \n",
    "    print(\"\\nì²« 5ê°œ ë¡œê·¸ ì—”íŠ¸ë¦¬:\")\n",
    "    for i, entry in enumerate(log_gen):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        print(f\"  {i+1}. [{entry['level']}] {entry['timestamp']} - {entry['message'][:50]}...\")\n",
    "    \n",
    "    # ì œë„ˆë ˆì´í„° ì²´ì´ë‹: ERRORë§Œ í•„í„°ë§\n",
    "    print(\"\\nERROR ë¡œê·¸ë§Œ í•„í„°ë§:\")\n",
    "    error_gen = (entry for entry in parse_log_file(log_files[0], compiled_pattern) \n",
    "                 if entry['level'] == 'ERROR')\n",
    "    \n",
    "    for i, entry in enumerate(error_gen, 1):\n",
    "        if i > 3:\n",
    "            break\n",
    "        print(f\"  {i}. {entry['timestamp']} - {entry['message']}\")\n",
    "\n",
    "# ì œë„ˆë ˆì´í„°ì˜ ì¥ì  í™•ì¸\n",
    "print(\"\\nğŸ’¡ ì œë„ˆë ˆì´í„° ì¥ì :\")\n",
    "print(\"  - ë©”ëª¨ë¦¬ íš¨ìœ¨: ì „ì²´ íŒŒì¼ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ì§€ ì•ŠìŒ\")\n",
    "print(\"  - Lazy evaluation: í•„ìš”í•œ ë§Œí¼ë§Œ ì²˜ë¦¬\")\n",
    "print(\"  - ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ì— ì´ìƒì \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 5: â­â­â­â­ LogAnalyzer Class - OOP ê¸°ë°˜ ë¶„ì„ê¸°\n",
    "\n",
    "í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œê·¸ ë¶„ì„ ë¡œì§ì„ ìº¡ìŠí™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "class LogAnalyzer:\n",
    "    \"\"\"\n",
    "    ë¡œê·¸ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ í†µê³„ë¥¼ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, log_pattern):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            log_pattern: ë¡œê·¸ íŒŒì‹±ì„ ìœ„í•œ ì •ê·œì‹ íŒ¨í„´\n",
    "        \"\"\"\n",
    "        self.pattern = log_pattern if isinstance(log_pattern, re.Pattern) else re.compile(log_pattern)\n",
    "        self.level_counter = Counter()  # ë¡œê·¸ ë ˆë²¨ë³„ ì¹´ìš´íŠ¸\n",
    "        self.errors = []  # ERROR ë¡œê·¸ ëª©ë¡\n",
    "        self.warnings = []  # WARNING ë¡œê·¸ ëª©ë¡\n",
    "        self.daily_stats = defaultdict(lambda: defaultdict(int))  # ë‚ ì§œë³„ ë ˆë²¨ í†µê³„\n",
    "        self.processed_files = []  # ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡\n",
    "        self.total_lines = 0  # ì „ì²´ ì²˜ë¦¬ëœ ë¼ì¸ ìˆ˜\n",
    "    \n",
    "    def analyze_file(self, file_path):\n",
    "        \"\"\"\n",
    "        ë‹¨ì¼ ë¡œê·¸ íŒŒì¼ ë¶„ì„\n",
    "        \n",
    "        Args:\n",
    "            file_path: ë¡œê·¸ íŒŒì¼ ê²½ë¡œ\n",
    "        \n",
    "        Returns:\n",
    "            int: ì²˜ë¦¬ëœ ë¡œê·¸ ì—”íŠ¸ë¦¬ ìˆ˜\n",
    "        \"\"\"\n",
    "        entry_count = 0\n",
    "        \n",
    "        for entry in parse_log_file(file_path, self.pattern):\n",
    "            # ë ˆë²¨ë³„ ì¹´ìš´íŠ¸\n",
    "            self.level_counter[entry['level']] += 1\n",
    "            \n",
    "            # ë‚ ì§œ ì¶”ì¶œ (YYYY-MM-DD)\n",
    "            date = entry['timestamp'].split()[0]\n",
    "            self.daily_stats[date][entry['level']] += 1\n",
    "            \n",
    "            # ERRORì™€ WARNING ë³„ë„ ì €ì¥\n",
    "            if entry['level'] == 'ERROR':\n",
    "                self.errors.append({\n",
    "                    'timestamp': entry['timestamp'],\n",
    "                    'message': entry['message'],\n",
    "                    'file': file_path\n",
    "                })\n",
    "            elif entry['level'] == 'WARNING':\n",
    "                self.warnings.append({\n",
    "                    'timestamp': entry['timestamp'],\n",
    "                    'message': entry['message'],\n",
    "                    'file': file_path\n",
    "                })\n",
    "            \n",
    "            entry_count += 1\n",
    "            self.total_lines += 1\n",
    "        \n",
    "        self.processed_files.append(file_path)\n",
    "        return entry_count\n",
    "    \n",
    "    def analyze_directory(self, directory_pattern):\n",
    "        \"\"\"\n",
    "        ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ë¡œê·¸ íŒŒì¼ ë¶„ì„\n",
    "        \n",
    "        Args:\n",
    "            directory_pattern: glob íŒ¨í„´ (ì˜ˆ: \"logs/*.log\")\n",
    "        \n",
    "        Returns:\n",
    "            dict: íŒŒì¼ë³„ ì²˜ë¦¬ ê²°ê³¼\n",
    "        \"\"\"\n",
    "        files = glob.glob(directory_pattern)\n",
    "        results = {}\n",
    "        \n",
    "        for file_path in files:\n",
    "            count = self.analyze_file(file_path)\n",
    "            results[file_path] = count\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"\n",
    "        ë¶„ì„ ê²°ê³¼ ìš”ì•½ ë°˜í™˜\n",
    "        \n",
    "        Returns:\n",
    "            dict: í†µê³„ ìš”ì•½\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"total_logs\": sum(self.level_counter.values()),\n",
    "            \"total_lines_processed\": self.total_lines,\n",
    "            \"files_processed\": len(self.processed_files),\n",
    "            \"level_counts\": dict(self.level_counter),\n",
    "            \"error_count\": len(self.errors),\n",
    "            \"warning_count\": len(self.warnings),\n",
    "            \"info_count\": self.level_counter.get('INFO', 0),\n",
    "            \"daily_stats\": {date: dict(stats) for date, stats in self.daily_stats.items()},\n",
    "            \"top_errors\": self.errors[:5],  # ìƒìœ„ 5ê°œ ì—ëŸ¬\n",
    "            \"top_warnings\": self.warnings[:5],  # ìƒìœ„ 5ê°œ ê²½ê³ \n",
    "            \"processed_files\": self.processed_files\n",
    "        }\n",
    "    \n",
    "    def get_error_summary(self):\n",
    "        \"\"\"\n",
    "        ì—ëŸ¬ ë©”ì‹œì§€ íŒ¨í„´ ë¶„ì„\n",
    "        \n",
    "        Returns:\n",
    "            Counter: ì—ëŸ¬ ìœ í˜•ë³„ ë¹ˆë„\n",
    "        \"\"\"\n",
    "        # ì—ëŸ¬ ë©”ì‹œì§€ì˜ ì²« ë‹¨ì–´ë¡œ ê·¸ë£¹í™”\n",
    "        error_types = Counter()\n",
    "        for error in self.errors:\n",
    "            # ë©”ì‹œì§€ì˜ ì²« ë¶€ë¶„ ì¶”ì¶œ\n",
    "            first_word = error['message'].split(':')[0] if ':' in error['message'] else error['message'].split()[0]\n",
    "            error_types[first_word] += 1\n",
    "        return error_types\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "print(\"LogAnalyzer í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸:\\n\")\n",
    "analyzer = LogAnalyzer(compiled_pattern)\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ì „ì²´ ë¶„ì„\n",
    "results = analyzer.analyze_directory(\"server_logs/*.log\")\n",
    "\n",
    "print(\"íŒŒì¼ë³„ ì²˜ë¦¬ ê²°ê³¼:\")\n",
    "for file, count in results.items():\n",
    "    print(f\"  {file}: {count}ê°œ ë¡œê·¸ ì—”íŠ¸ë¦¬\")\n",
    "\n",
    "# ìš”ì•½ ì •ë³´\n",
    "summary = analyzer.get_summary()\n",
    "print(f\"\\nì „ì²´ í†µê³„:\")\n",
    "print(f\"  ì „ì²´ ë¡œê·¸: {summary['total_logs']}ê°œ\")\n",
    "print(f\"  ë ˆë²¨ë³„: {summary['level_counts']}\")\n",
    "print(f\"  ERROR: {summary['error_count']}ê°œ\")\n",
    "print(f\"  WARNING: {summary['warning_count']}ê°œ\")\n",
    "\n",
    "# ì—ëŸ¬ íŒ¨í„´ ë¶„ì„\n",
    "error_types = analyzer.get_error_summary()\n",
    "print(f\"\\nì—ëŸ¬ ìœ í˜•ë³„ ë¹ˆë„:\")\n",
    "for error_type, count in error_types.most_common(3):\n",
    "    print(f\"  {error_type}: {count}íšŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 6: â­â­â­â­ Statistics & Reporting - í†µê³„ ì§‘ê³„ ë° ë¦¬í¬íŠ¸\n",
    "\n",
    "ë¶„ì„ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥í•˜ê³  ì‹œê°ì ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_report(summary, output_file=\"log_report.json\"):\n",
    "    \"\"\"\n",
    "    ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "    \n",
    "    Args:\n",
    "        summary: ë¶„ì„ ìš”ì•½ ë”•ì…”ë„ˆë¦¬\n",
    "        output_file: ì¶œë ¥ íŒŒì¼ëª…\n",
    "    \n",
    "    Returns:\n",
    "        str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ\n",
    "    \"\"\"\n",
    "    report = {\n",
    "        \"metadata\": {\n",
    "            \"generated_at\": datetime.now().isoformat(),\n",
    "            \"version\": \"1.0\",\n",
    "            \"analyzer\": \"LogAnalyzerBot\"\n",
    "        },\n",
    "        \"analysis\": summary\n",
    "    }\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "def print_report(summary):\n",
    "    \"\"\"\n",
    "    ë¶„ì„ ê²°ê³¼ë¥¼ ì½˜ì†”ì— ì¶œë ¥\n",
    "    \n",
    "    Args:\n",
    "        summary: ë¶„ì„ ìš”ì•½ ë”•ì…”ë„ˆë¦¬\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š ë¡œê·¸ ë¶„ì„ ë¦¬í¬íŠ¸\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ì „ì²´ ìš”ì•½\n",
    "    print(f\"\\nğŸ“ˆ ì „ì²´ í†µê³„\")\n",
    "    print(f\"  ì´ ë¡œê·¸ ì—”íŠ¸ë¦¬: {summary['total_logs']:,}ê°œ\")\n",
    "    print(f\"  ì²˜ë¦¬ëœ íŒŒì¼: {summary['files_processed']}ê°œ\")\n",
    "    \n",
    "    # ë ˆë²¨ë³„ ì¹´ìš´íŠ¸\n",
    "    print(f\"\\nğŸ·ï¸  ë¡œê·¸ ë ˆë²¨ë³„ ë¶„í¬\")\n",
    "    level_counts = summary['level_counts']\n",
    "    total = sum(level_counts.values())\n",
    "    \n",
    "    for level, count in sorted(level_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / total * 100) if total > 0 else 0\n",
    "        bar = \"â–ˆ\" * int(percentage / 2)  # ê°„ë‹¨í•œ ë§‰ëŒ€ ê·¸ë˜í”„\n",
    "        print(f\"  {level:8s}: {count:4d} ({percentage:5.1f}%) {bar}\")\n",
    "    \n",
    "    # ì—ëŸ¬ì™€ ê²½ê³ \n",
    "    print(f\"\\nâš ï¸  ì¤‘ìš” ì´ìŠˆ\")\n",
    "    print(f\"  ERROR: {summary['error_count']}ê°œ\")\n",
    "    print(f\"  WARNING: {summary['warning_count']}ê°œ\")\n",
    "    \n",
    "    # ìƒìœ„ ì—ëŸ¬\n",
    "    if summary['top_errors']:\n",
    "        print(f\"\\nğŸ”´ ìƒìœ„ ERROR ë¡œê·¸ (ìµœëŒ€ 5ê°œ)\")\n",
    "        for i, error in enumerate(summary['top_errors'], 1):\n",
    "            print(f\"  {i}. [{error['timestamp']}] {error['message'][:60]}...\")\n",
    "    \n",
    "    # ìƒìœ„ ê²½ê³ \n",
    "    if summary['top_warnings']:\n",
    "        print(f\"\\nğŸŸ¡ ìƒìœ„ WARNING ë¡œê·¸ (ìµœëŒ€ 5ê°œ)\")\n",
    "        for i, warning in enumerate(summary['top_warnings'], 1):\n",
    "            print(f\"  {i}. [{warning['timestamp']}] {warning['message'][:60]}...\")\n",
    "    \n",
    "    # ë‚ ì§œë³„ í†µê³„\n",
    "    if summary['daily_stats']:\n",
    "        print(f\"\\nğŸ“… ë‚ ì§œë³„ í†µê³„\")\n",
    "        for date, stats in sorted(summary['daily_stats'].items()):\n",
    "            print(f\"  {date}:\")\n",
    "            for level, count in sorted(stats.items()):\n",
    "                print(f\"    {level}: {count}ê°œ\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "def generate_html_report(summary, output_file=\"log_report.html\"):\n",
    "    \"\"\"\n",
    "    HTML í˜•ì‹ì˜ ë¦¬í¬íŠ¸ ìƒì„± (ë³´ë„ˆìŠ¤)\n",
    "    \n",
    "    Args:\n",
    "        summary: ë¶„ì„ ìš”ì•½ ë”•ì…”ë„ˆë¦¬\n",
    "        output_file: ì¶œë ¥ HTML íŒŒì¼ëª…\n",
    "    \"\"\"\n",
    "    html_template = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>ë¡œê·¸ ë¶„ì„ ë¦¬í¬íŠ¸</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
    "            h1 {{ color: #333; }}\n",
    "            .stat {{ background: #f0f0f0; padding: 10px; margin: 10px 0; border-radius: 5px; }}\n",
    "            .error {{ color: #d32f2f; }}\n",
    "            .warning {{ color: #f57c00; }}\n",
    "            .info {{ color: #1976d2; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>ğŸ“Š ë¡œê·¸ ë¶„ì„ ë¦¬í¬íŠ¸</h1>\n",
    "        <div class=\"stat\">\n",
    "            <h2>ì „ì²´ í†µê³„</h2>\n",
    "            <p>ì´ ë¡œê·¸: {summary['total_logs']:,}ê°œ</p>\n",
    "            <p>ì²˜ë¦¬ëœ íŒŒì¼: {summary['files_processed']}ê°œ</p>\n",
    "        </div>\n",
    "        <div class=\"stat\">\n",
    "            <h2>ë ˆë²¨ë³„ ë¶„í¬</h2>\n",
    "            <p class=\"error\">ERROR: {summary['error_count']}ê°œ</p>\n",
    "            <p class=\"warning\">WARNING: {summary['warning_count']}ê°œ</p>\n",
    "            <p class=\"info\">INFO: {summary['info_count']}ê°œ</p>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_template)\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "summary = analyzer.get_summary()\n",
    "print_report(summary)\n",
    "\n",
    "# JSON ì €ì¥\n",
    "json_file = save_report(summary)\n",
    "print(f\"\\nğŸ’¾ JSON ë¦¬í¬íŠ¸ ì €ì¥: {json_file}\")\n",
    "\n",
    "# HTML ë¦¬í¬íŠ¸ ìƒì„± (ë³´ë„ˆìŠ¤)\n",
    "html_file = generate_html_report(summary)\n",
    "print(f\"ğŸ’¾ HTML ë¦¬í¬íŠ¸ ì €ì¥: {html_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 7: â­â­â­â­â­ Complete Automation - ì™„ì „ ìë™í™” íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "ì˜ˆì™¸ ì²˜ë¦¬, ë¡œê¹…, ê·¸ë¦¬ê³  ëª¨ë“  ê¸°ëŠ¥ì„ í†µí•©í•œ ì™„ì „í•œ ìë™í™” ë´‡ì„ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('log_analyzer.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class LogAnalyzerBot:\n",
    "    \"\"\"\n",
    "    ì™„ì „ ìë™í™”ëœ ë¡œê·¸ ë¶„ì„ ë´‡\n",
    "    ì˜ˆì™¸ ì²˜ë¦¬, ë¡œê¹…, ë¦¬í¬íŒ…ì„ ëª¨ë‘ í¬í•¨\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, log_directory, output_dir=\"reports\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            log_directory: ë¡œê·¸ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬\n",
    "            output_dir: ë¦¬í¬íŠ¸ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬\n",
    "        \"\"\"\n",
    "        self.log_directory = Path(log_directory)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # ë¡œê·¸ íŒ¨í„´\n",
    "        self.log_pattern = r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}) (INFO|WARNING|ERROR) (.+)\"\n",
    "        self.analyzer = None\n",
    "    \n",
    "    def validate_log_directory(self):\n",
    "        \"\"\"\n",
    "        ë¡œê·¸ ë””ë ‰í† ë¦¬ ìœ íš¨ì„± ê²€ì‚¬\n",
    "        \n",
    "        Returns:\n",
    "            bool: ìœ íš¨ì„± ì—¬ë¶€\n",
    "        \n",
    "        Raises:\n",
    "            FileNotFoundError: ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šì„ ë•Œ\n",
    "            PermissionError: ì½ê¸° ê¶Œí•œì´ ì—†ì„ ë•Œ\n",
    "        \"\"\"\n",
    "        if not self.log_directory.exists():\n",
    "            raise FileNotFoundError(f\"ë¡œê·¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.log_directory}\")\n",
    "        \n",
    "        if not self.log_directory.is_dir():\n",
    "            raise NotADirectoryError(f\"ê²½ë¡œê°€ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {self.log_directory}\")\n",
    "        \n",
    "        # ë¡œê·¸ íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "        log_files = list(self.log_directory.glob(\"*.log\"))\n",
    "        if not log_files:\n",
    "            logger.warning(f\"ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.log_directory}\")\n",
    "            return False\n",
    "        \n",
    "        logger.info(f\"{len(log_files)}ê°œì˜ ë¡œê·¸ íŒŒì¼ ë°œê²¬\")\n",
    "        return True\n",
    "    \n",
    "    def analyze_logs(self):\n",
    "        \"\"\"\n",
    "        ë¡œê·¸ ë¶„ì„ ì‹¤í–‰\n",
    "        \n",
    "        Returns:\n",
    "            dict: ë¶„ì„ ê²°ê³¼ ìš”ì•½\n",
    "        \"\"\"\n",
    "        logger.info(\"ë¡œê·¸ ë¶„ì„ ì‹œì‘\")\n",
    "        \n",
    "        self.analyzer = LogAnalyzer(self.log_pattern)\n",
    "        pattern = str(self.log_directory / \"*.log\")\n",
    "        \n",
    "        try:\n",
    "            results = self.analyzer.analyze_directory(pattern)\n",
    "            logger.info(f\"{len(results)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "            \n",
    "            summary = self.analyzer.get_summary()\n",
    "            logger.info(f\"ì´ {summary['total_logs']}ê°œ ë¡œê·¸ ë¶„ì„ ì™„ë£Œ\")\n",
    "            \n",
    "            return summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ë¡œê·¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\", exc_info=True)\n",
    "            raise\n",
    "    \n",
    "    def generate_reports(self, summary):\n",
    "        \"\"\"\n",
    "        ë¦¬í¬íŠ¸ ìƒì„± ë° ì €ì¥\n",
    "        \n",
    "        Args:\n",
    "            summary: ë¶„ì„ ê²°ê³¼ ìš”ì•½\n",
    "        \n",
    "        Returns:\n",
    "            dict: ìƒì„±ëœ ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œë“¤\n",
    "        \"\"\"\n",
    "        logger.info(\"ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘\")\n",
    "        \n",
    "        # íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ íŒŒì¼ëª…\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # JSON ë¦¬í¬íŠ¸\n",
    "        json_path = self.output_dir / f\"log_report_{timestamp}.json\"\n",
    "        save_report(summary, str(json_path))\n",
    "        logger.info(f\"JSON ë¦¬í¬íŠ¸ ì €ì¥: {json_path}\")\n",
    "        \n",
    "        # HTML ë¦¬í¬íŠ¸\n",
    "        html_path = self.output_dir / f\"log_report_{timestamp}.html\"\n",
    "        generate_html_report(summary, str(html_path))\n",
    "        logger.info(f\"HTML ë¦¬í¬íŠ¸ ì €ì¥: {html_path}\")\n",
    "        \n",
    "        return {\n",
    "            'json': str(json_path),\n",
    "            'html': str(html_path)\n",
    "        }\n",
    "    \n",
    "    def send_alerts(self, summary, error_threshold=10):\n",
    "        \"\"\"\n",
    "        ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ì•Œë¦¼ (ì‹œë®¬ë ˆì´ì…˜)\n",
    "        \n",
    "        Args:\n",
    "            summary: ë¶„ì„ ê²°ê³¼ ìš”ì•½\n",
    "            error_threshold: ì—ëŸ¬ ì„ê³„ê°’\n",
    "        \"\"\"\n",
    "        error_count = summary['error_count']\n",
    "        \n",
    "        if error_count > error_threshold:\n",
    "            alert_message = f\"âš ï¸  ê²½ê³ : {error_count}ê°œì˜ ì—ëŸ¬ ê°ì§€ (ì„ê³„ê°’: {error_threshold})\"\n",
    "            logger.warning(alert_message)\n",
    "            print(f\"\\n{alert_message}\")\n",
    "            print(\"ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì´ë©”ì¼/SMS/Slack ì•Œë¦¼ì„ ì „ì†¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            logger.info(f\"ì—ëŸ¬ ìˆ˜ ì •ìƒ ë²”ìœ„: {error_count}/{error_threshold}\")\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        ì „ì²´ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰\n",
    "        \n",
    "        Returns:\n",
    "            bool: ì„±ê³µ ì—¬ë¶€\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"=\"*60)\n",
    "            logger.info(\"ë¡œê·¸ ë¶„ì„ ë´‡ ì‹œì‘\")\n",
    "            logger.info(\"=\"*60)\n",
    "            \n",
    "            # 1. ë¡œê·¸ ë””ë ‰í† ë¦¬ ê²€ì¦\n",
    "            if not self.validate_log_directory():\n",
    "                logger.warning(\"ë¶„ì„í•  ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤\")\n",
    "                return False\n",
    "            \n",
    "            # 2. ë¡œê·¸ ë¶„ì„\n",
    "            summary = self.analyze_logs()\n",
    "            \n",
    "            # 3. ì½˜ì†”ì— ë¦¬í¬íŠ¸ ì¶œë ¥\n",
    "            print_report(summary)\n",
    "            \n",
    "            # 4. ë¦¬í¬íŠ¸ íŒŒì¼ ìƒì„±\n",
    "            report_files = self.generate_reports(summary)\n",
    "            \n",
    "            # 5. ì•Œë¦¼ ì²´í¬\n",
    "            self.send_alerts(summary)\n",
    "            \n",
    "            logger.info(\"=\"*60)\n",
    "            logger.info(\"ë¡œê·¸ ë¶„ì„ ì™„ë£Œ\")\n",
    "            logger.info(f\"ìƒì„±ëœ ë¦¬í¬íŠ¸: {report_files}\")\n",
    "            logger.info(\"=\"*60)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            logger.error(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}\")\n",
    "            return False\n",
    "        except PermissionError as e:\n",
    "            logger.error(f\"íŒŒì¼ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}\", exc_info=True)\n",
    "            return False\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ¤– ë¡œê·¸ ë¶„ì„ ìë™í™” ë´‡ ì‹œì‘\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    bot = LogAnalyzerBot(\"server_logs\")\n",
    "    success = bot.run()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"âœ… ë¡œê·¸ ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        print(\"=\"*60)\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"âŒ ë¡œê·¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ“ log_analyzer.log íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## í™•ì¥ ì•„ì´ë””ì–´ êµ¬í˜„ ì˜ˆì œ\n",
    "\n",
    "### 1. ì´ë©”ì¼ ì•Œë¦¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "def send_alert_email(summary, threshold=10):\n",
    "    \"\"\"\n",
    "    ì—ëŸ¬ê°€ ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ë©´ ì´ë©”ì¼ ë°œì†¡\n",
    "    \n",
    "    Args:\n",
    "        summary: ë¶„ì„ ê²°ê³¼ ìš”ì•½\n",
    "        threshold: ì—ëŸ¬ ì„ê³„ê°’\n",
    "    \"\"\"\n",
    "    if summary['error_count'] <= threshold:\n",
    "        return\n",
    "    \n",
    "    # ì´ë©”ì¼ ì„¤ì • (ì‹¤ì œ ì‚¬ìš© ì‹œ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬)\n",
    "    smtp_server = \"smtp.gmail.com\"\n",
    "    smtp_port = 587\n",
    "    sender_email = \"your_email@gmail.com\"\n",
    "    sender_password = \"your_password\"  # ì•± ë¹„ë°€ë²ˆí˜¸ ì‚¬ìš© ê¶Œì¥\n",
    "    receiver_email = \"admin@example.com\"\n",
    "    \n",
    "    # ì´ë©”ì¼ ë³¸ë¬¸ ì‘ì„±\n",
    "    message = MIMEMultipart(\"alternative\")\n",
    "    message[\"Subject\"] = f\"âš ï¸ ë¡œê·¸ ì•Œë¦¼: {summary['error_count']}ê°œ ì—ëŸ¬ ê°ì§€\"\n",
    "    message[\"From\"] = sender_email\n",
    "    message[\"To\"] = receiver_email\n",
    "    \n",
    "    text = f\"\"\"\n",
    "    ë¡œê·¸ ë¶„ì„ ì•Œë¦¼\n",
    "    \n",
    "    ì—ëŸ¬ ìˆ˜: {summary['error_count']}ê°œ (ì„ê³„ê°’: {threshold})\n",
    "    ê²½ê³  ìˆ˜: {summary['warning_count']}ê°œ\n",
    "    ì „ì²´ ë¡œê·¸: {summary['total_logs']}ê°œ\n",
    "    \n",
    "    ìƒìœ„ ì—ëŸ¬:\n",
    "    {chr(10).join(f\"- {e['message']}\" for e in summary['top_errors'][:3])}\n",
    "    \"\"\"\n",
    "    \n",
    "    part = MIMEText(text, \"plain\")\n",
    "    message.attach(part)\n",
    "    \n",
    "    # ì´ë©”ì¼ ë°œì†¡ (ì‹¤ì œ í™˜ê²½ì—ì„œë§Œ ì‹¤í–‰)\n",
    "    try:\n",
    "        # with smtplib.SMTP(smtp_server, smtp_port) as server:\n",
    "        #     server.starttls()\n",
    "        #     server.login(sender_email, sender_password)\n",
    "        #     server.sendmail(sender_email, receiver_email, message.as_string())\n",
    "        logger.info(\"ì•Œë¦¼ ì´ë©”ì¼ ë°œì†¡ ì™„ë£Œ\")\n",
    "        print(\"ğŸ“§ ì´ë©”ì¼ ì•Œë¦¼ì´ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤ (ì‹œë®¬ë ˆì´ì…˜)\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ì´ë©”ì¼ì€ ë°œì†¡í•˜ì§€ ì•ŠìŒ)\n",
    "print(\"\\nì´ë©”ì¼ ì•Œë¦¼ ê¸°ëŠ¥ (ì‹œë®¬ë ˆì´ì…˜):\")\n",
    "send_alert_email(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ëŒ€ì‹œë³´ë“œ ìƒì„± (Matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì£¼ì˜: Jupyterì—ì„œ ì‹¤í–‰ ì‹œ matplotlib í•„ìš”\n",
    "# pip install matplotlib\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from collections import Counter\n",
    "    \n",
    "    def create_dashboard(summary, output_file=\"dashboard.png\"):\n",
    "        \"\"\"\n",
    "        ë¶„ì„ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ì—¬ ëŒ€ì‹œë³´ë“œ ìƒì„±\n",
    "        \n",
    "        Args:\n",
    "            summary: ë¶„ì„ ê²°ê³¼ ìš”ì•½\n",
    "            output_file: ì¶œë ¥ ì´ë¯¸ì§€ íŒŒì¼ëª…\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        fig.suptitle('ë¡œê·¸ ë¶„ì„ ëŒ€ì‹œë³´ë“œ', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. ë¡œê·¸ ë ˆë²¨ë³„ íŒŒì´ ì°¨íŠ¸\n",
    "        level_counts = summary['level_counts']\n",
    "        colors = {'ERROR': '#d32f2f', 'WARNING': '#f57c00', 'INFO': '#1976d2'}\n",
    "        \n",
    "        axes[0, 0].pie(\n",
    "            level_counts.values(),\n",
    "            labels=level_counts.keys(),\n",
    "            autopct='%1.1f%%',\n",
    "            colors=[colors.get(k, '#777') for k in level_counts.keys()],\n",
    "            startangle=90\n",
    "        )\n",
    "        axes[0, 0].set_title('ë¡œê·¸ ë ˆë²¨ ë¶„í¬')\n",
    "        \n",
    "        # 2. ë‚ ì§œë³„ ì—ëŸ¬ íŠ¸ë Œë“œ\n",
    "        daily_errors = {date: stats.get('ERROR', 0) \n",
    "                       for date, stats in summary['daily_stats'].items()}\n",
    "        \n",
    "        axes[0, 1].plot(list(daily_errors.keys()), list(daily_errors.values()), \n",
    "                       marker='o', color='#d32f2f', linewidth=2)\n",
    "        axes[0, 1].set_title('ë‚ ì§œë³„ ì—ëŸ¬ ì¶”ì´')\n",
    "        axes[0, 1].set_xlabel('ë‚ ì§œ')\n",
    "        axes[0, 1].set_ylabel('ì—ëŸ¬ ìˆ˜')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. ë ˆë²¨ë³„ ë§‰ëŒ€ ê·¸ë˜í”„\n",
    "        axes[1, 0].bar(\n",
    "            level_counts.keys(),\n",
    "            level_counts.values(),\n",
    "            color=[colors.get(k, '#777') for k in level_counts.keys()]\n",
    "        )\n",
    "        axes[1, 0].set_title('ë ˆë²¨ë³„ ë¡œê·¸ ìˆ˜')\n",
    "        axes[1, 0].set_ylabel('ê°œìˆ˜')\n",
    "        axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # 4. í†µê³„ ìš”ì•½ í…Œì´ë¸”\n",
    "        axes[1, 1].axis('off')\n",
    "        stats_text = f\"\"\"\n",
    "        ğŸ“Š ì „ì²´ í†µê³„\n",
    "        \n",
    "        ì´ ë¡œê·¸: {summary['total_logs']:,}ê°œ\n",
    "        ì²˜ë¦¬ëœ íŒŒì¼: {summary['files_processed']}ê°œ\n",
    "        \n",
    "        ğŸ”´ ERROR: {summary['error_count']}ê°œ\n",
    "        ğŸŸ¡ WARNING: {summary['warning_count']}ê°œ\n",
    "        ğŸ”µ INFO: {summary['info_count']}ê°œ\n",
    "        \"\"\"\n",
    "        axes[1, 1].text(0.1, 0.5, stats_text, fontsize=12, \n",
    "                       verticalalignment='center', family='monospace')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"ğŸ“Š ëŒ€ì‹œë³´ë“œ ì €ì¥: {output_file}\")\n",
    "        plt.show()\n",
    "    \n",
    "    # ì‹¤í–‰\n",
    "    create_dashboard(summary)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âš ï¸  matplotlibì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ì„¤ì¹˜: pip install matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ìŠ¤ì¼€ì¤„ë§ (Schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì£¼ì˜: ì‹¤ì œ ì‚¬ìš© ì‹œ schedule íŒ¨í‚¤ì§€ í•„ìš”\n",
    "# pip install schedule\n",
    "\n",
    "def scheduled_analysis_demo():\n",
    "    \"\"\"\n",
    "    ì •ê¸°ì ìœ¼ë¡œ ë¡œê·¸ ë¶„ì„ ì‹¤í–‰ (ë°ëª¨)\n",
    "    \"\"\"\n",
    "    code_example = '''\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "def run_analysis():\n",
    "    \"\"\"ë¶„ì„ ì‘ì—… ì‹¤í–‰\"\"\"\n",
    "    bot = LogAnalyzerBot(\"server_logs\")\n",
    "    bot.run()\n",
    "\n",
    "# ë§¤ ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰\n",
    "schedule.every().hour.do(run_analysis)\n",
    "\n",
    "# ë§¤ì¼ ì˜¤ì „ 9ì‹œì— ì‹¤í–‰\n",
    "schedule.every().day.at(\"09:00\").do(run_analysis)\n",
    "\n",
    "# ì›”ìš”ì¼ë§ˆë‹¤ ì‹¤í–‰\n",
    "schedule.every().monday.do(run_analysis)\n",
    "\n",
    "print(\"ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘...\")\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬\n",
    "    '''\n",
    "    \n",
    "    print(\"\\nâ° ìŠ¤ì¼€ì¤„ë§ ì˜ˆì œ ì½”ë“œ:\")\n",
    "    print(code_example)\n",
    "\n",
    "scheduled_analysis_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (Watchdog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì£¼ì˜: ì‹¤ì œ ì‚¬ìš© ì‹œ watchdog íŒ¨í‚¤ì§€ í•„ìš”\n",
    "# pip install watchdog\n",
    "\n",
    "def realtime_monitoring_demo():\n",
    "    \"\"\"\n",
    "    ì‹¤ì‹œê°„ ë¡œê·¸ íŒŒì¼ ëª¨ë‹ˆí„°ë§ (ë°ëª¨)\n",
    "    \"\"\"\n",
    "    code_example = '''\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "import time\n",
    "\n",
    "class LogFileHandler(FileSystemEventHandler):\n",
    "    \"\"\"ë¡œê·¸ íŒŒì¼ ë³€ê²½ ê°ì§€ ë° ìë™ ë¶„ì„\"\"\"\n",
    "    \n",
    "    def __init__(self, analyzer_bot):\n",
    "        self.bot = analyzer_bot\n",
    "    \n",
    "    def on_modified(self, event):\n",
    "        if event.src_path.endswith('.log'):\n",
    "            print(f\"ë¡œê·¸ íŒŒì¼ ë³€ê²½ ê°ì§€: {event.src_path}\")\n",
    "            # ì¦‰ì‹œ ë¶„ì„ ì‹¤í–‰\n",
    "            self.bot.run()\n",
    "    \n",
    "    def on_created(self, event):\n",
    "        if event.src_path.endswith('.log'):\n",
    "            print(f\"ìƒˆ ë¡œê·¸ íŒŒì¼ ìƒì„±: {event.src_path}\")\n",
    "            self.bot.run()\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆ\n",
    "bot = LogAnalyzerBot(\"server_logs\")\n",
    "event_handler = LogFileHandler(bot)\n",
    "observer = Observer()\n",
    "observer.schedule(event_handler, path=\"server_logs\", recursive=False)\n",
    "\n",
    "print(\"ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘...\")\n",
    "observer.start()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    observer.stop()\n",
    "\n",
    "observer.join()\n",
    "    '''\n",
    "    \n",
    "    print(\"\\nğŸ‘€ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì½”ë“œ:\")\n",
    "    print(code_example)\n",
    "\n",
    "realtime_monitoring_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì „ì²´ í†µí•© ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ í•˜ë‚˜ì˜ ì…€ì—ì„œ ì‹¤í–‰\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸš€ ë¡œê·¸ ë¶„ì„ ìë™í™” ë´‡ - ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. ë´‡ ìƒì„± ë° ì‹¤í–‰\n",
    "bot = LogAnalyzerBot(\"server_logs\", output_dir=\"reports\")\n",
    "success = bot.run()\n",
    "\n",
    "if success:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“ ìƒì„±ëœ íŒŒì¼ ëª©ë¡:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # reports ë””ë ‰í† ë¦¬ ë‚´ìš© í™•ì¸\n",
    "    import os\n",
    "    if os.path.exists(\"reports\"):\n",
    "        for file in os.listdir(\"reports\"):\n",
    "            file_path = os.path.join(\"reports\", file)\n",
    "            size = os.path.getsize(file_path)\n",
    "            print(f\"  ğŸ“„ {file} ({size:,} bytes)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\në‹¤ìŒ ë‹¨ê³„:\")\n",
    "    print(\"  1. reports/ í´ë”ì—ì„œ ìƒì„±ëœ ë¦¬í¬íŠ¸ í™•ì¸\")\n",
    "    print(\"  2. log_analyzer.log íŒŒì¼ì—ì„œ ìƒì„¸ ë¡œê·¸ í™•ì¸\")\n",
    "    print(\"  3. í•„ìš”ì‹œ í™•ì¥ ê¸°ëŠ¥ ì¶”ê°€ (ì´ë©”ì¼, ìŠ¤ì¼€ì¤„ë§ ë“±)\")\n",
    "else:\n",
    "    print(\"\\nâŒ ì‘ì—… ì‹¤íŒ¨. log_analyzer.logë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## í•™ìŠµ ì •ë¦¬ ë° ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "### ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "- âœ… Task 1: ìƒ˜í”Œ ë¡œê·¸ íŒŒì¼ 3ê°œ ìƒì„± ì™„ë£Œ\n",
    "- âœ… Task 2: globìœ¼ë¡œ ë¡œê·¸ íŒŒì¼ ë°œê²¬ ì„±ê³µ\n",
    "- âœ… Task 3: ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ ë¡œê·¸ íŒŒì‹± ì„±ê³µ\n",
    "- âœ… Task 4: ì œë„ˆë ˆì´í„°ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬ êµ¬í˜„\n",
    "- âœ… Task 5: LogAnalyzer í´ë˜ìŠ¤ êµ¬í˜„ ì™„ë£Œ\n",
    "- âœ… Task 6: JSON ë¦¬í¬íŠ¸ ìƒì„± ë° ì½˜ì†” ì¶œë ¥ ì„±ê³µ\n",
    "- âœ… Task 7: ì™„ì „ ìë™í™” ë´‡ êµ¬í˜„ ë° ì‹¤í–‰ ì„±ê³µ\n",
    "- âœ… ì˜ˆì™¸ ì²˜ë¦¬ê°€ ëª¨ë“  ì£¼ìš” ë©”ì„œë“œì— ì ìš©ë¨\n",
    "- âœ… ë¡œê¹…ì´ ì ì ˆí•˜ê²Œ êµ¬í˜„ë¨\n",
    "- âœ… ì½”ë“œê°€ PEP 8 ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¥¼ ë”°ë¦„\n",
    "\n",
    "### í•µì‹¬ í•™ìŠµ ë‚´ìš©\n",
    "\n",
    "#### Day 1 ê°œë… í™œìš©\n",
    "- **Collections**: Counterë¡œ ë ˆë²¨ë³„ ì¹´ìš´íŠ¸, defaultdictë¡œ ë‚ ì§œë³„ í†µê³„\n",
    "- **Comprehensions**: ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬ ì»´í”„ë¦¬í—¨ì…˜ìœ¼ë¡œ ê°„ê²°í•œ ë°ì´í„° ì²˜ë¦¬\n",
    "\n",
    "#### Day 2 ê°œë… í™œìš©\n",
    "- **Generators**: ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬\n",
    "- **File I/O**: ë¡œê·¸ ì½ê¸°, ë¦¬í¬íŠ¸ ì €ì¥\n",
    "- **JSON**: êµ¬ì¡°í™”ëœ ë°ì´í„° ì €ì¥ ë° êµí™˜\n",
    "- **Modules**: glob, re ë“± í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©\n",
    "\n",
    "#### Day 3 ê°œë… í™œìš©\n",
    "- **OOP**: LogAnalyzer, LogAnalyzerBot í´ë˜ìŠ¤ë¡œ ë¡œì§ ìº¡ìŠí™”\n",
    "- **Exception Handling**: try-exceptë¡œ ê²¬ê³ í•œ ì—ëŸ¬ ì²˜ë¦¬\n",
    "- **Logging**: í”„ë¡œì„¸ìŠ¤ ì¶”ì  ë° ë””ë²„ê¹…\n",
    "- **Regex**: ë¡œê·¸ íŒ¨í„´ íŒŒì‹±\n",
    "- **Glob**: íŒŒì¼ íŒ¨í„´ ë§¤ì¹­\n",
    "- **Datetime**: íƒ€ì„ìŠ¤íƒ¬í”„ ì²˜ë¦¬ ë° ë¦¬í¬íŠ¸ ìƒì„±\n",
    "\n",
    "### ì‹¤ì „ ì ìš© í¬ì¸íŠ¸\n",
    "\n",
    "1. **í™•ì¥ì„±**: í´ë˜ìŠ¤ ê¸°ë°˜ ì„¤ê³„ë¡œ ì‰½ê²Œ ê¸°ëŠ¥ ì¶”ê°€ ê°€ëŠ¥\n",
    "2. **ê²¬ê³ ì„±**: ì˜ˆì™¸ ì²˜ë¦¬ì™€ ë¡œê¹…ìœ¼ë¡œ ì•ˆì •ì ì¸ ìš´ì˜\n",
    "3. **íš¨ìœ¨ì„±**: ì œë„ˆë ˆì´í„°ë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬\n",
    "4. **ìœ ì§€ë³´ìˆ˜ì„±**: ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬ì™€ ë¬¸ì„œí™”\n",
    "5. **ìë™í™”**: ë°˜ë³µ ì‘ì—…ì„ ì½”ë“œë¡œ ìë™í™”í•˜ì—¬ ìƒì‚°ì„± í–¥ìƒ\n",
    "\n",
    "---\n",
    "\n",
    "## ì¶•í•˜í•©ë‹ˆë‹¤! ğŸ‰\n",
    "\n",
    "3ì¼ê°„ì˜ Python ë¶€íŠ¸ìº í”„ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí•˜ì…¨ìŠµë‹ˆë‹¤!\n",
    "\n",
    "ì´ì œ ì—¬ëŸ¬ë¶„ì€:\n",
    "- Python í•µì‹¬ ë°ì´í„° êµ¬ì¡°ë¥¼ ëŠ¥ìˆ™í•˜ê²Œ ë‹¤ë£° ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "- ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë°ìœ¼ë¡œ ê²¬ê³ í•œ ì‹œìŠ¤í…œì„ ì„¤ê³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "- ì‹¤ì „ í”„ë¡œì íŠ¸ë¥¼ ìë™í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "\n",
    "ê³„ì†í•´ì„œ Pythonì„ í•™ìŠµí•˜ê³  ì‹¤ì „ì— ì ìš©í•´ë³´ì„¸ìš”! ğŸ’ª"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
