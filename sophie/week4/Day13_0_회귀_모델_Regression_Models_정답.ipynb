{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day13_0: íšŒê·€ ëª¨ë¸ (Regression Models) - ì •ë‹µ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# í™˜ê²½ ì„¤ì •\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.datasets import fetch_california_housing\nfrom scipy.stats import randint, uniform\n\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cb\n\nimport warnings\nwarnings.filterwarnings('ignore')\nnp.random.seed(42)\n\n# ë°ì´í„° ì¤€ë¹„\nhousing = fetch_california_housing()\ndf = pd.DataFrame(housing.data, columns=housing.feature_names)\ndf['MedHouseVal'] = housing.target\n\nX = df.drop('MedHouseVal', axis=1)\ny = df['MedHouseVal']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nprint(\"ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q1. ì„ í˜• íšŒê·€ ê¸°ë³¸ â­\n",
    "\n",
    "**ë¬¸ì œ**: LinearRegression ëª¨ë¸ì„ í•™ìŠµí•˜ê³  R2 ìŠ¤ì½”ì–´ë¥¼ ê³„ì‚°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "# 1. ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 2. ì˜ˆì¸¡\n",
    "y_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# 3. R2 ìŠ¤ì½”ì–´ ê³„ì‚°\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦\n",
    "assert 0.5 < r2 < 0.7, \"R2 ìŠ¤ì½”ì–´ê°€ ì˜ˆìƒ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤\"\n",
    "print(\"ê²€ì¦ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. LinearRegression ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "2. fit()ìœ¼ë¡œ í•™ìŠµ (ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ì‚¬ìš©)\n",
    "3. predict()ë¡œ ì˜ˆì¸¡\n",
    "4. r2_score()ë¡œ í‰ê°€\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ì„ í˜• íšŒê·€ëŠ” ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„°ì—ì„œ ë” ì•ˆì •ì \n",
    "- R2ëŠ” 0~1 ì‚¬ì´ ê°’ìœ¼ë¡œ, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- ìŠ¤ì¼€ì¼ë§ ì—†ì´ë„ ê°€ëŠ¥í•˜ì§€ë§Œ ê³„ìˆ˜ í•´ì„ì´ ì–´ë ¤ì›€\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- í•™ìŠµê³¼ í…ŒìŠ¤íŠ¸ì— ë‹¤ë¥¸ ìŠ¤ì¼€ì¼ëŸ¬ ì ìš©\n",
    "- fit_transformì„ í…ŒìŠ¤íŠ¸ì—ë„ ì‚¬ìš© (ì •ë³´ ëˆ„ì¶œ)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì„ í˜• íšŒê·€ëŠ” í•­ìƒ ê¸°ì¤€ ëª¨ë¸ë¡œ ë¨¼ì € ì‹œë„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q2. Ridge ì •ê·œí™” â­\n",
    "\n",
    "**ë¬¸ì œ**: alpha=10ì¸ Ridge ëª¨ë¸ì„ í•™ìŠµí•˜ê³  RMSEë¥¼ ê³„ì‚°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "# 1. Ridge ëª¨ë¸ ìƒì„± (alpha=10)\n",
    "ridge_model = Ridge(alpha=10)\n",
    "\n",
    "# 2. í•™ìŠµ\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 3. ì˜ˆì¸¡\n",
    "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "# 4. RMSE ê³„ì‚°\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦\n",
    "assert 0.7 < rmse < 0.8, \"RMSEê°€ ì˜ˆìƒ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤\"\n",
    "print(\"ê²€ì¦ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. Ridge(alpha=10)ìœ¼ë¡œ ì •ê·œí™” ê°•ë„ ì„¤ì •\n",
    "2. RMSE = sqrt(MSE)ë¡œ ê³„ì‚°\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- alphaê°€ í´ìˆ˜ë¡ ê³„ìˆ˜ê°€ ì‘ì•„ì§ (ì •ê·œí™” ê°•í•¨)\n",
    "- RMSEëŠ” ì›ë˜ ë‹¨ìœ„ë¡œ í•´ì„ ê°€ëŠ¥ ($100,000)\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- from sklearn.metrics import mean_squared_error + np.sqrt()\n",
    "- ë˜ëŠ” sklearn 1.4+ì—ì„œëŠ” root_mean_squared_error ì‚¬ìš©\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- MSEì™€ RMSE í˜¼ë™\n",
    "- sqrt ì ìš© ëˆ„ë½\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- alpha ê°’ì€ êµì°¨ ê²€ì¦ìœ¼ë¡œ ê²°ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q3. Lasso íŠ¹ì„± ì„ íƒ â­â­\n",
    "\n",
    "**ë¬¸ì œ**: alpha=0.1ì¸ Lasso ëª¨ë¸ì„ í•™ìŠµí•˜ê³ , 0ì´ ì•„ë‹Œ ê³„ìˆ˜ì˜ ê°œìˆ˜ë¥¼ ì¶œë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "# 1. Lasso ëª¨ë¸ ìƒì„± (alpha=0.1)\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "\n",
    "# 2. í•™ìŠµ\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 3. 0ì´ ì•„ë‹Œ ê³„ìˆ˜ ê°œìˆ˜ ê³„ì‚°\n",
    "non_zero_count = np.sum(lasso_model.coef_ != 0)\n",
    "\n",
    "print(f\"ì „ì²´ íŠ¹ì„± ìˆ˜: {len(X.columns)}\")\n",
    "print(f\"ì„ íƒëœ íŠ¹ì„± ìˆ˜ (0ì´ ì•„ë‹Œ ê³„ìˆ˜): {non_zero_count}\")\n",
    "\n",
    "# ì„ íƒëœ íŠ¹ì„± í™•ì¸\n",
    "selected_features = X.columns[lasso_model.coef_ != 0]\n",
    "print(f\"ì„ íƒëœ íŠ¹ì„±: {list(selected_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦\n",
    "assert non_zero_count <= len(X.columns), \"ê³„ìˆ˜ ê°œìˆ˜ê°€ íŠ¹ì„± ìˆ˜ë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"\n",
    "print(\"ê²€ì¦ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. Lassoì˜ L1 ì •ê·œí™”ëŠ” ê³„ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆìŒ\n",
    "2. np.sum(coef_ != 0)ìœ¼ë¡œ 0ì´ ì•„ë‹Œ ê°œìˆ˜ ê³„ì‚°\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- LassoëŠ” ìë™ íŠ¹ì„± ì„ íƒ ê¸°ëŠ¥\n",
    "- alphaê°€ í´ìˆ˜ë¡ ë” ë§ì€ íŠ¹ì„±ì´ 0ì´ ë¨\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- np.count_nonzero(lasso_model.coef_)\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- coef_.sum()ìœ¼ë¡œ ê°œìˆ˜ ê³„ì‚° (ê°’ì˜ í•©ê³„ì™€ í˜¼ë™)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- íŠ¹ì„±ì´ ë§ì„ ë•Œ Lassoë¡œ í•µì‹¬ ë³€ìˆ˜ë§Œ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q4. Random Forest í•™ìŠµ â­â­\n",
    "\n",
    "**ë¬¸ì œ**: n_estimators=50, max_depth=10ì¸ Random Forestë¥¼ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ í‰ê°€í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "# 1. Random Forest ëª¨ë¸ ìƒì„±\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=50,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2. í•™ìŠµ (ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. ì˜ˆì¸¡\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# 4. ì„±ëŠ¥ í‰ê°€\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "\n",
    "print(f\"R2 Score: {r2_rf:.4f}\")\n",
    "print(f\"RMSE: {rmse_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦\n",
    "assert r2_rf > 0.7, \"R2ê°€ 0.7ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤\"\n",
    "print(\"ê²€ì¦ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. RandomForestRegressor ìƒì„±\n",
    "2. ì›ë³¸ ë°ì´í„°ë¡œ í•™ìŠµ (ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”)\n",
    "3. R2ì™€ RMSE ëª¨ë‘ ê³„ì‚°\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- n_estimators: íŠ¸ë¦¬ ê°œìˆ˜ (ë§ì„ìˆ˜ë¡ ì•ˆì •ì )\n",
    "- max_depth: íŠ¸ë¦¬ ê¹Šì´ (ê³¼ì í•© ë°©ì§€)\n",
    "- n_jobs=-1: ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- n_jobs ìƒëµ ê°€ëŠ¥ (ë‹¨ì¼ ì½”ì–´)\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- íŠ¸ë¦¬ ëª¨ë¸ì— ìŠ¤ì¼€ì¼ë§ ì ìš© (ë¶ˆí•„ìš”í•˜ì§€ë§Œ í•´ë„ ë¨)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- random_state ê³ ì •ìœ¼ë¡œ ì¬í˜„ì„± í™•ë³´"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q5. íŠ¹ì„± ì¤‘ìš”ë„ ì¶”ì¶œ â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Random Forestì˜ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ DataFrameìœ¼ë¡œ ë§Œë“¤ê³  ìƒìœ„ 3ê°œë¥¼ ì¶œë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "# 1. íŠ¹ì„± ì¤‘ìš”ë„ DataFrame ìƒì„±\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "})\n",
    "\n",
    "# 2. ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# 3. ìƒìœ„ 3ê°œ ì¶œë ¥\n",
    "print(\"=== íŠ¹ì„± ì¤‘ìš”ë„ Top 3 ===\")\n",
    "print(importance_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦\n",
    "assert importance_df.shape[0] == len(X.columns), \"íŠ¹ì„± ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤\"\n",
    "assert importance_df['Importance'].sum() - 1.0 < 0.01, \"ì¤‘ìš”ë„ í•©ì´ 1ì´ ì•„ë‹™ë‹ˆë‹¤\"\n",
    "print(\"ê²€ì¦ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. feature_importances_ ì†ì„±ìœ¼ë¡œ ì¤‘ìš”ë„ ì¶”ì¶œ\n",
    "2. DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "3. sort_values + head(3)\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- íŠ¹ì„± ì¤‘ìš”ë„ëŠ” í•´ë‹¹ íŠ¹ì„±ì˜ ë¶ˆìˆœë„ ê°ì†Œ ê¸°ì—¬ë„\n",
    "- í•©ê³„ê°€ 1ì´ ë˜ë„ë¡ ì •ê·œí™”ë¨\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- nlargest(3, 'Importance') ì‚¬ìš©\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ascending=Trueë¡œ ì •ë ¬ (ë‚®ì€ ìˆœ)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì¤‘ìš”ë„ ë‚®ì€ íŠ¹ì„± ì œê±°ë¡œ ëª¨ë¸ ê°„ì†Œí™”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q6. XGBoost í•™ìŠµ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: learning_rate=0.05, max_depth=8ì¸ XGBoost ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ í‰ê°€í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "# 1. XGBoost ëª¨ë¸ ìƒì„±\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    n_estimators=100,  # ê¸°ë³¸ê°’\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "# 2. í•™ìŠµ\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. ì˜ˆì¸¡\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# 4. ì„±ëŠ¥ í‰ê°€\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "print(f\"R2 Score: {r2_xgb:.4f}\")\n",
    "print(f\"RMSE: {rmse_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦\n",
    "assert r2_xgb > 0.8, \"XGBoost R2ê°€ 0.8ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤\"\n",
    "print(\"ê²€ì¦ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. XGBRegressor ìƒì„±\n",
    "2. learning_rateì™€ max_depth ì„¤ì •\n",
    "3. verbosity=0ìœ¼ë¡œ ì¶œë ¥ ì–µì œ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- learning_rate: ê° íŠ¸ë¦¬ì˜ ê¸°ì—¬ë„ (ì‘ì„ìˆ˜ë¡ ì•ˆì •ì )\n",
    "- max_depth: ê°œë³„ íŠ¸ë¦¬ ê¹Šì´\n",
    "- n_estimatorsì™€ learning_rateëŠ” trade-off\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- eta ëŒ€ì‹  learning_rate ì‚¬ìš© (ë™ì¼)\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- learning_rateê°€ ë„ˆë¬´ ë†’ìœ¼ë©´ ê³¼ì í•©\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- learning_rate ë‚®ì¶”ê³  n_estimators ë†’ì´ë©´ ì„±ëŠ¥ í–¥ìƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q7. LightGBM í•™ìŠµ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: n_estimators=200, num_leaves=31ì¸ LightGBM ëª¨ë¸ì„ í•™ìŠµí•˜ê³  R2ë¥¼ ê³„ì‚°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "# 1. LightGBM ëª¨ë¸ ìƒì„±\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# 2. í•™ìŠµ\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. ì˜ˆì¸¡\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# 4. R2 ê³„ì‚°\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "\n",
    "print(f\"R2 Score: {r2_lgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦\n",
    "assert r2_lgb > 0.8, \"LightGBM R2ê°€ 0.8ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤\"\n",
    "print(\"ê²€ì¦ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. LGBMRegressor ìƒì„±\n",
    "2. num_leavesëŠ” LightGBM íŠ¹ìœ ì˜ íŒŒë¼ë¯¸í„°\n",
    "3. verbose=-1ë¡œ ê²½ê³  ì–µì œ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- num_leaves: ë¦¬í”„ ë…¸ë“œ ìˆ˜ (2^max_depthë³´ë‹¤ ì‘ê²Œ)\n",
    "- LightGBMì€ Leaf-wise ë¶„í•  (ë” íš¨ìœ¨ì )\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- max_depth ëŒ€ì‹  num_leavesë¡œ ë³µì¡ë„ ì œì–´\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- num_leavesê°€ ë„ˆë¬´ í¬ë©´ ê³¼ì í•©\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ LightGBMì´ XGBoostë³´ë‹¤ ë¹ ë¦„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q8. GridSearchCV ì‹¤ìŠµ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Ridgeì˜ alphaë¥¼ [0.01, 0.1, 1, 10, 100] ì¤‘ì—ì„œ GridSearchCVë¡œ ìµœì í™”í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "# 1. íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# 2. ê¸°ë³¸ ëª¨ë¸\n",
    "ridge_base = Ridge()\n",
    "\n",
    "# 3. GridSearchCV ì„¤ì •\n",
    "grid_search = GridSearchCV(\n",
    "    ridge_base,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# 4. í•™ìŠµ\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 5. ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ìµœì  alpha: {grid_search.best_params_['alpha']}\")\n",
    "print(f\"ìµœì  CV RMSE: {np.sqrt(-grid_search.best_score_):.4f}\")\n",
    "\n",
    "# 6. ì „ì²´ ê²°ê³¼ í™•ì¸\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results['RMSE'] = np.sqrt(-cv_results['mean_test_score'])\n",
    "print(\"\\n=== Alphaë³„ ì„±ëŠ¥ ===\")\n",
    "print(cv_results[['param_alpha', 'RMSE']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦\n",
    "assert grid_search.best_params_['alpha'] in [0.01, 0.1, 1, 10, 100]\n",
    "print(\"ê²€ì¦ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. param_gridì— íƒìƒ‰í•  ê°’ ì •ì˜\n",
    "2. cv=5ë¡œ 5-fold êµì°¨ ê²€ì¦\n",
    "3. scoring='neg_mean_squared_error' (ìŒìˆ˜ MSE)\n",
    "4. best_params_, best_score_ë¡œ ê²°ê³¼ í™•ì¸\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- GridSearchCVëŠ” ëª¨ë“  ì¡°í•© ì‹œë„\n",
    "- sklearn scoringì€ \"ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ\"ì´ ê¸°ë³¸ â†’ MSEì— ìŒìˆ˜\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- scoring='r2' ì‚¬ìš© ê°€ëŠ¥\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- neg_mean_squared_errorì—ì„œ ìŒìˆ˜ ì²˜ë¦¬ ëˆ„ë½\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- return_train_score=Trueë¡œ ê³¼ì í•© í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q9. RandomizedSearchCV ì‹¤ìŠµ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Random Forestì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ RandomizedSearchCVë¡œ ìµœì í™”í•˜ì„¸ìš”.\n",
    "- n_estimators: 50~200\n",
    "- max_depth: 5~20\n",
    "- n_iter=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "# 1. íŒŒë¼ë¯¸í„° ë¶„í¬ ì •ì˜\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 201),  # 50~200\n",
    "    'max_depth': randint(5, 21)        # 5~20\n",
    "}\n",
    "\n",
    "# 2. ê¸°ë³¸ ëª¨ë¸\n",
    "rf_base = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# 3. RandomizedSearchCV ì„¤ì •\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf_base,\n",
    "    param_dist,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 4. í•™ìŠµ\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# 5. ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ìµœì  íŒŒë¼ë¯¸í„°:\")\n",
    "print(f\"  n_estimators: {random_search.best_params_['n_estimators']}\")\n",
    "print(f\"  max_depth: {random_search.best_params_['max_depth']}\")\n",
    "print(f\"\\nìµœì  CV RMSE: {np.sqrt(-random_search.best_score_):.4f}\")\n",
    "\n",
    "# 6. ìµœì  ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred_best = best_rf.predict(X_test)\n",
    "print(f\"í…ŒìŠ¤íŠ¸ R2: {r2_score(y_test, y_pred_best):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦\n",
    "assert 50 <= random_search.best_params_['n_estimators'] <= 200\n",
    "assert 5 <= random_search.best_params_['max_depth'] <= 20\n",
    "print(\"ê²€ì¦ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. scipy.stats.randintë¡œ ì •ìˆ˜ ë¶„í¬ ì •ì˜\n",
    "2. n_iter=10ìœ¼ë¡œ 10ë²ˆë§Œ íƒìƒ‰\n",
    "3. random_state ê³ ì •ìœ¼ë¡œ ì¬í˜„ì„± í™•ë³´\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- RandomizedSearchCVëŠ” ë¬´ì‘ìœ„ ìƒ˜í”Œë§\n",
    "- GridSearchCVë³´ë‹¤ íš¨ìœ¨ì  (ëŒ€ê·œëª¨ íƒìƒ‰)\n",
    "- n_iterë¡œ íƒìƒ‰ íšŸìˆ˜ ì œì–´\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- uniform()ìœ¼ë¡œ ì‹¤ìˆ˜ ë¶„í¬ ì •ì˜\n",
    "- loguniform()ìœ¼ë¡œ ë¡œê·¸ ìŠ¤ì¼€ì¼\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- randint(50, 200) â†’ 50~199 (ìƒí•œ ë¯¸í¬í•¨)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- n_iterëŠ” ì‹œê°„ê³¼ ì •í™•ë„ì˜ trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q10. ëª¨ë¸ ë¹„êµ ì¢…í•© â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: 3ê°œ ì´ìƒì˜ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  RMSEì™€ R2ë¥¼ ë¹„êµí•˜ëŠ” DataFrameì„ ë§Œë“  í›„, Plotlyë¡œ ì‹œê°í™”í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ì •ë‹µ ì½”ë“œ\n# 1. ì—¬ëŸ¬ ëª¨ë¸ ì •ì˜\nmodels = {\n    'Linear Regression': LinearRegression(),\n    'Ridge': Ridge(alpha=1.0),\n    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42),\n    'XGBoost': xgb.XGBRegressor(n_estimators=100, max_depth=6, verbosity=0, random_state=42),\n    'LightGBM': lgb.LGBMRegressor(n_estimators=100, verbose=-1, random_state=42),\n    'CatBoost': cb.CatBoostRegressor(n_estimators=100, max_depth=6, verbose=0, random_state=42)\n}\n\n# 2. ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸\nresults = []\n\n# 3. ê° ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\nfor name, model in models.items():\n    # ì„ í˜• ëª¨ë¸ì€ ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ì‚¬ìš©\n    if name in ['Linear Regression', 'Ridge']:\n        model.fit(X_train_scaled, y_train)\n        y_pred = model.predict(X_test_scaled)\n    else:\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n    \n    # í‰ê°€ ì§€í‘œ ê³„ì‚°\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    r2 = r2_score(y_test, y_pred)\n    \n    results.append({\n        'Model': name,\n        'RMSE': rmse,\n        'R2': r2\n    })\n\n# 4. DataFrame ìƒì„±\nresults_df = pd.DataFrame(results).sort_values('RMSE')\nprint(\"=== ëª¨ë¸ ë¹„êµ ê²°ê³¼ ===\")\nprint(results_df.to_string(index=False))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Plotly ì‹œê°í™”\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['RMSE (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)', 'R2 Score (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)'])\n",
    "\n",
    "# RMSE ë°” ì°¨íŠ¸\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=results_df['Model'], \n",
    "        y=results_df['RMSE'], \n",
    "        name='RMSE',\n",
    "        marker_color='indianred',\n",
    "        text=results_df['RMSE'].round(4),\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# R2 ë°” ì°¨íŠ¸\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=results_df['Model'], \n",
    "        y=results_df['R2'], \n",
    "        name='R2',\n",
    "        marker_color='seagreen',\n",
    "        text=results_df['R2'].round(4),\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='íšŒê·€ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ',\n",
    "    height=500,\n",
    "    showlegend=False\n",
    ")\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦\n",
    "assert len(results_df) >= 3, \"ìµœì†Œ 3ê°œ ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤\"\n",
    "assert 'RMSE' in results_df.columns and 'R2' in results_df.columns\n",
    "print(\"ê²€ì¦ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. ë”•ì…”ë„ˆë¦¬ë¡œ ì—¬ëŸ¬ ëª¨ë¸ ì •ì˜\n",
    "2. for ë£¨í”„ë¡œ í•™ìŠµ/í‰ê°€ ë°˜ë³µ\n",
    "3. ì„ í˜•/íŠ¸ë¦¬ ëª¨ë¸ ìŠ¤ì¼€ì¼ë§ ë¶„ê¸° ì²˜ë¦¬\n",
    "4. make_subplotsë¡œ ë‘ ì§€í‘œ ë™ì‹œ ì‹œê°í™”\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ëª¨ë¸ ë¹„êµëŠ” ë™ì¼ ë°ì´í„°ì…‹ì—ì„œ ìˆ˜í–‰\n",
    "- RMSEì™€ R2 ëª¨ë‘ í™•ì¸ (ìƒí˜¸ë³´ì™„)\n",
    "- ì‹œê°í™”ë¡œ ì§ê´€ì  ë¹„êµ\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- px.bar()ë¡œ ê°„ë‹¨íˆ ì‹œê°í™”\n",
    "- cross_val_scoreë¡œ ë” robustí•œ ë¹„êµ\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ìŠ¤ì¼€ì¼ë§ í•„ìš” ëª¨ë¸ì— ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
    "- ë™ì¼ í‰ê°€ ë°ì´í„° ë¯¸ì‚¬ìš©\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- í•­ìƒ baseline(Linear Regression) í¬í•¨\n",
    "- êµì°¨ ê²€ì¦ìœ¼ë¡œ ë¶„ì‚°ë„ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Q11. CatBoost ê¸°ë³¸ í•™ìŠµ â­â­â­\n\n**ë¬¸ì œ**: CatBoostRegressorë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒê·€ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.\n- n_estimators=100, max_depth=6, learning_rate=0.1\n- R2 ìŠ¤ì½”ì–´ì™€ RMSEë¥¼ ì¶œë ¥í•˜ì„¸ìš”.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ì •ë‹µ ì½”ë“œ\n# 1. CatBoost ëª¨ë¸ ìƒì„±\ncat_model = cb.CatBoostRegressor(\n    n_estimators=100,\n    max_depth=6,\n    learning_rate=0.1,\n    random_state=42,\n    verbose=0  # ì¶œë ¥ ìˆ¨ê¹€\n)\n\n# 2. í•™ìŠµ\ncat_model.fit(X_train, y_train)\n\n# 3. ì˜ˆì¸¡\ny_pred_cat = cat_model.predict(X_test)\n\n# 4. ì„±ëŠ¥ í‰ê°€\nr2_cat = r2_score(y_test, y_pred_cat)\nrmse_cat = np.sqrt(mean_squared_error(y_test, y_pred_cat))\n\nprint(f\"R2 Score: {r2_cat:.4f}\")\nprint(f\"RMSE: {rmse_cat:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ê²€ì¦\nassert r2_cat > 0.8, \"CatBoost R2ê°€ 0.8ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤\"\nprint(\"ê²€ì¦ í†µê³¼!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### ğŸ’¡ í’€ì´ ì„¤ëª…\n\n**ì ‘ê·¼ ë°©ë²•**:\n1. CatBoostRegressor ìƒì„±\n2. verbose=0ìœ¼ë¡œ í•™ìŠµ ë¡œê·¸ ìˆ¨ê¹€\n3. XGBoost/LightGBMê³¼ ë™ì¼í•œ ì‚¬ìš©ë²•\n\n**í•µì‹¬ ê°œë…**:\n- CatBoostëŠ” Yandexì—ì„œ ê°œë°œí•œ Gradient Boosting ë¼ì´ë¸ŒëŸ¬ë¦¬\n- **ë²”ì£¼í˜• íŠ¹ì„± ìë™ ì²˜ë¦¬**ê°€ í•µì‹¬ ì¥ì \n- Ordered Target Statisticsë¡œ íƒ€ê²Ÿ ëˆ„ìˆ˜ ë°©ì§€\n- ëŒ€ì¹­ íŠ¸ë¦¬(Oblivious Trees) ì‚¬ìš©ìœ¼ë¡œ ì˜ˆì¸¡ ì†ë„ ë¹ ë¦„\n\n**ëŒ€ì•ˆ**:\n- iterations ëŒ€ì‹  n_estimators ì‚¬ìš© (ë™ì¼)\n- depth ëŒ€ì‹  max_depth ì‚¬ìš© (ë™ì¼)\n\n**í”í•œ ì‹¤ìˆ˜**:\n- verbose ì„¤ì • ì•ˆ í•˜ë©´ í•™ìŠµ ë¡œê·¸ê°€ ë§ì´ ì¶œë ¥ë¨\n- silent=True (deprecated) ëŒ€ì‹  verbose=0 ì‚¬ìš©\n\n**ì‹¤ë¬´ íŒ**:\n- ë²”ì£¼í˜• íŠ¹ì„±ì´ ë§ì€ ë°ì´í„°ì…‹ì—ì„œ CatBoostê°€ íŠ¹íˆ ê°•ì \n- cat_features íŒŒë¼ë¯¸í„°ë¡œ ë²”ì£¼í˜• ì»¬ëŸ¼ ì¸ë±ìŠ¤ ì§€ì • ê°€ëŠ¥",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Q12. ë¶€ìŠ¤íŒ… 3ëŒ€ì¥ ë¹„êµ â­â­â­â­\n\n**ë¬¸ì œ**: XGBoost, LightGBM, CatBoost ì„¸ ê°€ì§€ ëª¨ë¸ì„ ëª¨ë‘ í•™ìŠµí•˜ê³ , ì„±ëŠ¥(RMSE, R2)ì„ ë¹„êµí•˜ëŠ” DataFrameì„ ë§Œë“œì„¸ìš”.\n- ë™ì¼í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‚¬ìš©: n_estimators=100, max_depth=6, learning_rate=0.1\n- ì–´ë–¤ ëª¨ë¸ì´ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ë‚˜ìš”?",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ì •ë‹µ ì½”ë“œ\n# 1. ë¶€ìŠ¤íŒ… 3ëŒ€ì¥ ëª¨ë¸ ì •ì˜ (ë™ì¼ í•˜ì´í¼íŒŒë¼ë¯¸í„°)\nboosting_models = {\n    'XGBoost': xgb.XGBRegressor(\n        n_estimators=100, max_depth=6, learning_rate=0.1,\n        random_state=42, verbosity=0\n    ),\n    'LightGBM': lgb.LGBMRegressor(\n        n_estimators=100, max_depth=6, learning_rate=0.1,\n        random_state=42, verbose=-1\n    ),\n    'CatBoost': cb.CatBoostRegressor(\n        n_estimators=100, max_depth=6, learning_rate=0.1,\n        random_state=42, verbose=0\n    )\n}\n\n# 2. ê²°ê³¼ ì €ì¥\nboosting_results = []\n\n# 3. ê° ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\nfor name, model in boosting_models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    \n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    r2 = r2_score(y_test, y_pred)\n    \n    boosting_results.append({\n        'Model': name,\n        'RMSE': rmse,\n        'R2': r2\n    })\n\n# 4. DataFrame ìƒì„± ë° ì •ë ¬\nboosting_df = pd.DataFrame(boosting_results).sort_values('RMSE')\nprint(\"=== ë¶€ìŠ¤íŒ… 3ëŒ€ì¥ ì„±ëŠ¥ ë¹„êµ ===\")\nprint(boosting_df.to_string(index=False))\n\n# 5. ìµœê³  ì„±ëŠ¥ ëª¨ë¸\nbest_model = boosting_df.iloc[0]['Model']\nprint(f\"\\nê°€ì¥ ì¢‹ì€ ì„±ëŠ¥: {best_model}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ê²€ì¦\nassert len(boosting_df) == 3, \"3ê°œ ëª¨ë¸ì´ ëª¨ë‘ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤\"\nassert all(boosting_df['R2'] > 0.8), \"ëª¨ë“  ëª¨ë¸ì˜ R2ê°€ 0.8 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤\"\nprint(\"ê²€ì¦ í†µê³¼!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### ğŸ’¡ í’€ì´ ì„¤ëª…\n\n**ì ‘ê·¼ ë°©ë²•**:\n1. ì„¸ ëª¨ë¸ì— ë™ì¼í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©\n2. for ë£¨í”„ë¡œ í•™ìŠµ/í‰ê°€ ë°˜ë³µ\n3. RMSE ê¸°ì¤€ ì •ë ¬ë¡œ ìµœê³  ì„±ëŠ¥ í™•ì¸\n\n**í•µì‹¬ ê°œë…**:\n- **XGBoost**: Level-wise íŠ¸ë¦¬ ì„±ì¥, ê°€ì¥ ë²”ìš©ì \n- **LightGBM**: Leaf-wise íŠ¸ë¦¬ ì„±ì¥, ì†ë„ê°€ ê°€ì¥ ë¹ ë¦„\n- **CatBoost**: ëŒ€ì¹­ íŠ¸ë¦¬, ë²”ì£¼í˜• ìë™ ì²˜ë¦¬\n\n**ë¶€ìŠ¤íŒ… 3ëŒ€ì¥ ë¹„êµí‘œ**:\n\n| íŠ¹ì„± | XGBoost | LightGBM | CatBoost |\n|------|---------|----------|----------|\n| ê°œë°œì‚¬ | DMLC | Microsoft | Yandex |\n| ì†ë„ | ë¹ ë¦„ | ê°€ì¥ ë¹ ë¦„ | ë³´í†µ |\n| ë²”ì£¼í˜• ì²˜ë¦¬ | ìˆ˜ë™ ì¸ì½”ë”© | ìˆ˜ë™ ì¸ì½”ë”© | ìë™ |\n| ì¶”ì²œ ìƒí™© | ì¼ë°˜ì  | ëŒ€ìš©ëŸ‰ | ë²”ì£¼í˜• ë§ì„ ë•Œ |\n\n**í”í•œ ì‹¤ìˆ˜**:\n- ì„¸ ëª¨ë¸ì— ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‚¬ìš© (ê³µì •í•œ ë¹„êµ ë¶ˆê°€)\n- verbose ì„¤ì • ëˆ„ë½ìœ¼ë¡œ ë¡œê·¸ ê³¼ë‹¤ ì¶œë ¥\n\n**ì‹¤ë¬´ íŒ**:\n- ë°ì´í„°ì…‹ íŠ¹ì„±ì— ë”°ë¼ ìµœì  ëª¨ë¸ì´ ë‹¤ë¦„\n- ë²”ì£¼í˜• íŠ¹ì„± ë§ìœ¼ë©´ CatBoost ìš°ì„  ì‹œë„\n- ëŒ€ìš©ëŸ‰ ë°ì´í„°ë©´ LightGBM ì¶”ì²œ\n- ì²˜ìŒ ì‹œì‘í•œë‹¤ë©´ XGBoostê°€ ì•ˆì „í•œ ì„ íƒ",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## ğŸ“Š í•™ìŠµ ì •ë¦¬\n\n### Part 1: ì„ í˜• ëª¨ë¸ í•µì‹¬ ìš”ì•½\n\n| ëª¨ë¸ | íŠ¹ì§• | ì–¸ì œ ì‚¬ìš©? |\n|------|------|------------|\n| Linear Regression | ê°€ì¥ ê¸°ë³¸, í•´ì„ ìš©ì´ | ê¸°ì¤€ ëª¨ë¸, ì„ í˜• ê´€ê³„ |\n| Ridge (L2) | ê³„ìˆ˜ ì¶•ì†Œ | ë‹¤ì¤‘ê³µì„ ì„±, ê³¼ì í•© ë°©ì§€ |\n| Lasso (L1) | íŠ¹ì„± ì„ íƒ | í•µì‹¬ ë³€ìˆ˜ ì¶”ì¶œ |\n| ElasticNet | L1+L2 ì¡°í•© | Ridgeì™€ Lasso ì¥ì  ê²°í•© |\n\n### Part 2: ë¹„ì„ í˜• ëª¨ë¸ & íŠœë‹ ìš”ì•½\n\n| ëª¨ë¸ | íŠ¹ì§• | í•µì‹¬ íŒŒë¼ë¯¸í„° |\n|------|------|---------------|\n| Decision Tree | ë¹„ì„ í˜• í•™ìŠµ | max_depth, min_samples_split |\n| Random Forest | ì•™ìƒë¸”, ì•ˆì •ì  | n_estimators, max_depth |\n| XGBoost | ê³ ì„±ëŠ¥, Kaggle ì¸ê¸° | learning_rate, max_depth |\n| LightGBM | ë¹ ë¥¸ ì†ë„, ëŒ€ìš©ëŸ‰ | num_leaves, learning_rate |\n| CatBoost | ë²”ì£¼í˜• ìë™ ì²˜ë¦¬ | cat_features, learning_rate |\n\n### ğŸ’¡ ë¶€ìŠ¤íŒ… 3ëŒ€ì¥ ì„ íƒ ê°€ì´ë“œ\n\n| ìƒí™© | ì¶”ì²œ ëª¨ë¸ |\n|------|----------|\n| ë²”ì£¼í˜• íŠ¹ì„±ì´ ë§ì„ ë•Œ | **CatBoost** |\n| ëŒ€ìš©ëŸ‰ ë°ì´í„° | **LightGBM** |\n| ì•ˆì •ì ì¸ ì„±ëŠ¥ í•„ìš” | **XGBoost** |\n| ë¹ ë¥¸ ì‹œì‘/ì¼ë°˜ì ì¸ ê²½ìš° | XGBoost ë˜ëŠ” LightGBM |\n\n### ğŸ’¡ ì‹¤ë¬´ íŒ\n\n1. **ê¸°ì¤€ ëª¨ë¸ë¶€í„°**: Linear Regressionìœ¼ë¡œ ì‹œì‘í•˜ì—¬ baseline ì„¤ì •\n2. **ìŠ¤ì¼€ì¼ë§ ì£¼ì˜**: ì„ í˜• ëª¨ë¸ì€ ìŠ¤ì¼€ì¼ë§ í•„ìˆ˜, íŠ¸ë¦¬ ëª¨ë¸ì€ ë¶ˆí•„ìš”\n3. **ê³¼ì í•© ë°©ì§€**: ì •ê·œí™”(Ridge/Lasso) ë˜ëŠ” íŠ¸ë¦¬ ê¹Šì´ ì œí•œ\n4. **êµì°¨ ê²€ì¦**: GridSearchCV/RandomizedSearchCV í•„ìˆ˜\n5. **ì•™ìƒë¸” íš¨ê³¼**: ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ Random Forest, Boostingì´ ëŒ€ì²´ë¡œ ìš°ìˆ˜\n6. **CatBoost í™œìš©**: ë²”ì£¼í˜• íŠ¹ì„± ë§ìœ¼ë©´ ì¸ì½”ë”© ì—†ì´ ë°”ë¡œ ì‚¬ìš©"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}