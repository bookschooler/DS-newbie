{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day11_2 ë³„ì²¨: ê³ ê¸‰ ê°ì„± ë¶„ì„ (LLM & Embedding)\n",
    "\n",
    "## ğŸ“š í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "**Part 1: LLM ê¸°ë°˜ ê°ì„± ë¶„ì„**\n",
    "1. Google Gemini API ì„¤ì • ë° ì‚¬ìš©ë²• ìµíˆê¸°\n",
    "2. Zero-shot ê°ì„± ë¶„ë¥˜ êµ¬í˜„í•˜ê¸°\n",
    "3. Few-shot í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì´í•´í•˜ê¸°\n",
    "4. ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ë¶„ì„í•˜ê¸°\n",
    "5. LLM ê°ì„± ë¶„ì„ ê²°ê³¼ í‰ê°€í•˜ê¸°\n",
    "\n",
    "**Part 2: ì„ë² ë”© ê¸°ë°˜ ê°ì„± ë¶„ì„**\n",
    "1. í…ìŠ¤íŠ¸ ì„ë² ë”© ê°œë… ì´í•´í•˜ê¸°\n",
    "2. Google Gemini Embedding API í™œìš©í•˜ê¸°\n",
    "3. sentence-transformersë¡œ ë¡œì»¬ ì„ë² ë”© ìƒì„±í•˜ê¸°\n",
    "4. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ê°ì„± ë¶„ë¥˜ êµ¬í˜„í•˜ê¸°\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ì™œ ì´ê²ƒì„ ë°°ìš°ë‚˜ìš”?\n",
    "\n",
    "| ë°©ë²• | ì¥ì  | ë‹¨ì  | ì í•©í•œ ìƒí™© |\n",
    "|------|------|------|------------|\n",
    "| ì‚¬ì „ ê¸°ë°˜ | ë¹ ë¦„, ë¬´ë£Œ, í•´ì„ ì‰¬ì›€ | ë„ë©”ì¸ í•œì •ì  | ì´ˆê¸° ë¶„ì„, ì•Œë ¤ì§„ ë„ë©”ì¸ |\n",
    "| LLM Zero-shot | ë¼ë²¨ ë¶ˆí•„ìš”, ìœ ì—°í•¨ | API ë¹„ìš©, ì†ë„ | ë‹¤ì–‘í•œ ë„ë©”ì¸, ìƒˆë¡œìš´ í‘œí˜„ |\n",
    "| LLM Few-shot | ë†’ì€ ì •í™•ë„, ì»¤ìŠ¤í…€ | ì˜ˆì œ ì¤€ë¹„ í•„ìš” | íŠ¹ì • ë„ë©”ì¸, ì„¸ë°€í•œ ë¶„ë¥˜ |\n",
    "| ì„ë² ë”© ê¸°ë°˜ | ì˜ë¯¸ ê¸°ë°˜ ë¶„ë¥˜, ëŒ€ëŸ‰ ì²˜ë¦¬ | ê¸°ì¤€ ì„ë² ë”© í•„ìš” | ëŒ€ëŸ‰ ë¶„ë¥˜, ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ |\n",
    "\n",
    "**ë¶„ì„ê°€ ê´€ì **: LLMê³¼ ì„ë² ë”©ì€ ì‚¬ì „ì— ì—†ëŠ” ìƒˆë¡œìš´ í‘œí˜„ë„ ì´í•´í•  ìˆ˜ ìˆì–´ ì‹¤ë¬´ì—ì„œ ì ì  ë” ì¤‘ìš”í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: LLM ê¸°ë°˜ ê°ì„± ë¶„ì„\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 Google Gemini API ì„¤ì •\n",
    "\n",
    "### API í‚¤ ë°œê¸‰ ë°©ë²•\n",
    "\n",
    "1. [Google AI Studio](https://aistudio.google.com/) ì ‘ì†\n",
    "2. Google ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸\n",
    "3. \"Get API key\" í´ë¦­\n",
    "4. \"Create API key\" ì„ íƒ\n",
    "5. ìƒì„±ëœ í‚¤ë¥¼ ë³µì‚¬í•˜ì—¬ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "\n",
    "### ë¬´ë£Œ í•œë„\n",
    "\n",
    "- **gemini-2.0-flash**: ë¶„ë‹¹ 15 ìš”ì²­, ì¼ì¼ 1,500 ìš”ì²­\n",
    "- **gemini-embedding-001**: ì›” 100ë§Œ í† í° ë¬´ë£Œ\n",
    "\n",
    "> âš ï¸ **ì£¼ì˜**: API í‚¤ëŠ” ì ˆëŒ€ ì½”ë“œì— ì§ì ‘ ë„£ì§€ ë§ˆì„¸ìš”! í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ìµœì´ˆ 1íšŒ)\n",
    "# !pip install google-genai pandas plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import time\n",
    "\n",
    "# Google Gemini API\n",
    "try:\n",
    "    from google import genai\n",
    "    from google.genai import types\n",
    "    gemini_available = True\n",
    "    print(\"Google Gemini API ë¡œë“œ ì™„ë£Œ\")\n",
    "except ImportError:\n",
    "    gemini_available = False\n",
    "    print(\"google-genai ë¯¸ì„¤ì¹˜. pip install google-genai ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.\")\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if GOOGLE_API_KEY and gemini_available:\n",
    "    client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "    print(\"Gemini API í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì™„ë£Œ\")\n",
    "else:\n",
    "    client = None\n",
    "    print(\"API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"í™˜ê²½ë³€ìˆ˜ ì„¤ì •: export GOOGLE_API_KEY='your-api-key'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 Zero-shot ê°ì„± ë¶„ë¥˜\n",
    "\n",
    "### Zero-shotì´ë€?\n",
    "\n",
    "**Zero-shot Learning**ì€ ì‚¬ì „ ì˜ˆì œ ì—†ì´ ëª¨ë¸ì´ ìƒˆë¡œìš´ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "LLMì—ê²Œ \"ì´ í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ ë¶„ì„í•´ì¤˜\"ë¼ê³  ìš”ì²­í•˜ë©´, ëª¨ë¸ì´ í•™ìŠµëœ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì¥ë‹¨ì \n",
    "\n",
    "| ì¥ì  | ë‹¨ì  |\n",
    "|------|------|\n",
    "| ì˜ˆì œ ë°ì´í„° ë¶ˆí•„ìš” | ë³µì¡í•œ ë¶„ë¥˜ì— ë¶€ì •í™•í•  ìˆ˜ ìˆìŒ |\n",
    "| ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ | ë„ë©”ì¸ íŠ¹í™” ìš©ì–´ì— ì•½í•¨ |\n",
    "| ìƒˆë¡œìš´ ë„ë©”ì¸ì— ë°”ë¡œ ì ìš© | ì¼ê´€ì„±ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_zero_shot(text):\n",
    "    \"\"\"\n",
    "    Zero-shot ë°©ì‹ìœ¼ë¡œ ê°ì„± ë¶„ì„\n",
    "    \n",
    "    Parameters:\n",
    "    - text: ë¶„ì„í•  í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "    - dict: ê°ì„±(ê¸ì •/ë¶€ì •/ì¤‘ë¦½), ì‹ ë¢°ë„, ì„¤ëª…\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        return {\"sentiment\": \"unknown\", \"confidence\": 0, \"reason\": \"API ë¯¸ì„¤ì •\"}\n",
    "    \n",
    "    prompt = f\"\"\"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "í…ìŠ¤íŠ¸: {text}\n",
    "\n",
    "ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:\n",
    "ê°ì„±: [ê¸ì •/ë¶€ì •/ì¤‘ë¦½]\n",
    "ì‹ ë¢°ë„: [ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ]\n",
    "ì´ìœ : [í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…]\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash-exp\",\n",
    "            contents=prompt\n",
    "        )\n",
    "        result_text = response.text\n",
    "        \n",
    "        # ê²°ê³¼ íŒŒì‹±\n",
    "        lines = result_text.strip().split('\\n')\n",
    "        result = {\"raw\": result_text}\n",
    "        \n",
    "        for line in lines:\n",
    "            if 'ê°ì„±:' in line:\n",
    "                result['sentiment'] = line.split(':')[1].strip()\n",
    "            elif 'ì‹ ë¢°ë„:' in line:\n",
    "                result['confidence'] = line.split(':')[1].strip()\n",
    "            elif 'ì´ìœ :' in line:\n",
    "                result['reason'] = line.split(':')[1].strip()\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return {\"sentiment\": \"error\", \"error\": str(e)}\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ (API í‚¤ê°€ ìˆì„ ë•Œë§Œ ì‹¤í–‰)\n",
    "if client:\n",
    "    test_texts = [\n",
    "        \"ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”! ë°°ì†¡ë„ ë¹ ë¥´ê³  í’ˆì§ˆë„ ìµœê³ ì˜ˆìš”.\",\n",
    "        \"ëˆ ì•„ê¹Œì›Œìš”. ì™„ì „ ì‹¤ë§ì…ë‹ˆë‹¤. ë‹¤ì‹œëŠ” ì•ˆ ì‚´ ê±°ì˜ˆìš”.\",\n",
    "        \"ê·¸ëƒ¥ ê·¸ë˜ìš”. ê¸°ëŒ€í–ˆë˜ ê²ƒê³¼ ë¹„ìŠ·í•´ìš”.\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Zero-shot ê°ì„± ë¶„ì„ ê²°ê³¼\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for text in test_texts:\n",
    "        result = analyze_sentiment_zero_shot(text)\n",
    "        print(f\"\\ní…ìŠ¤íŠ¸: {text}\")\n",
    "        print(f\"  ê°ì„±: {result.get('sentiment', 'N/A')}\")\n",
    "        print(f\"  ì‹ ë¢°ë„: {result.get('confidence', 'N/A')}\")\n",
    "        print(f\"  ì´ìœ : {result.get('reason', 'N/A')}\")\n",
    "        time.sleep(1)  # API ì†ë„ ì œí•œ ëŒ€ë¹„\n",
    "else:\n",
    "    print(\"APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: ë‹¤ì–‘í•œ Zero-shot í”„ë¡¬í”„íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_simple(text):\n",
    "    \"\"\"ê°„ë‹¨í•œ Zero-shot í”„ë¡¬í”„íŠ¸ (3ë¶„ë¥˜)\"\"\"\n",
    "    if not client:\n",
    "        return \"API ë¯¸ì„¤ì •\"\n",
    "    \n",
    "    prompt = f\"\"\"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µí•˜ì„¸ìš”.\n",
    "í…ìŠ¤íŠ¸: {text}\n",
    "ê°ì„±:\"\"\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-exp\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    return response.text.strip()\n",
    "\n",
    "\n",
    "def analyze_sentiment_scale(text):\n",
    "    \"\"\"5ì  ì²™ë„ Zero-shot í”„ë¡¬í”„íŠ¸\"\"\"\n",
    "    if not client:\n",
    "        return \"API ë¯¸ì„¤ì •\"\n",
    "    \n",
    "    prompt = f\"\"\"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì„± ì ìˆ˜ë¥¼ 1~5 ì‚¬ì´ì˜ ìˆ«ìë¡œë§Œ ë‹µí•˜ì„¸ìš”.\n",
    "1: ë§¤ìš° ë¶€ì •, 2: ë¶€ì •, 3: ì¤‘ë¦½, 4: ê¸ì •, 5: ë§¤ìš° ê¸ì •\n",
    "\n",
    "í…ìŠ¤íŠ¸: {text}\n",
    "ì ìˆ˜:\"\"\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-exp\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    return response.text.strip()\n",
    "\n",
    "\n",
    "def analyze_sentiment_detailed(text):\n",
    "    \"\"\"ìƒì„¸ ë¶„ì„ Zero-shot í”„ë¡¬í”„íŠ¸\"\"\"\n",
    "    if not client:\n",
    "        return \"API ë¯¸ì„¤ì •\"\n",
    "    \n",
    "    prompt = f\"\"\"ë‹¤ìŒ ê³ ê° ë¦¬ë·°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë¦¬ë·°: {text}\n",
    "\n",
    "JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:\n",
    "{{\n",
    "  \"overall_sentiment\": \"ê¸ì •/ë¶€ì •/ì¤‘ë¦½\",\n",
    "  \"aspects\": [\n",
    "    {{\"aspect\": \"ì–¸ê¸‰ëœ ì¸¡ë©´\", \"sentiment\": \"ê¸ì •/ë¶€ì •/ì¤‘ë¦½\"}}\n",
    "  ],\n",
    "  \"keywords\": [\"í•µì‹¬ í‚¤ì›Œë“œë“¤\"],\n",
    "  \"summary\": \"í•œ ì¤„ ìš”ì•½\"\n",
    "}}\"\"\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-exp\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    return response.text.strip()\n",
    "\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "if client:\n",
    "    test_review = \"ë°°ì†¡ì€ ë¹¨ëëŠ”ë° ì œí’ˆ í’ˆì§ˆì´ ë³„ë¡œì˜ˆìš”. ê°€ê²© ëŒ€ë¹„ ì‹¤ë§ì…ë‹ˆë‹¤.\"\n",
    "    \n",
    "    print(\"ë‹¤ì–‘í•œ Zero-shot í”„ë¡¬í”„íŠ¸ ë¹„êµ\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\në¦¬ë·°: {test_review}\")\n",
    "    print(f\"\\n[ê°„ë‹¨í•œ ë¶„ë¥˜] {analyze_sentiment_simple(test_review)}\")\n",
    "    time.sleep(1)\n",
    "    print(f\"\\n[5ì  ì²™ë„] {analyze_sentiment_scale(test_review)}\")\n",
    "    time.sleep(1)\n",
    "    print(f\"\\n[ìƒì„¸ ë¶„ì„]\\n{analyze_sentiment_detailed(test_review)}\")\n",
    "else:\n",
    "    print(\"APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 Few-shot í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§\n",
    "\n",
    "### Few-shotì´ë€?\n",
    "\n",
    "**Few-shot Learning**ì€ ëª‡ ê°œì˜ ì˜ˆì œë¥¼ ì œê³µí•˜ì—¬ ëª¨ë¸ì´ íŒ¨í„´ì„ í•™ìŠµí•˜ê²Œ í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\n",
    "\n",
    "### Zero-shot vs Few-shot\n",
    "\n",
    "| êµ¬ë¶„ | Zero-shot | Few-shot |\n",
    "|------|-----------|----------|\n",
    "| ì˜ˆì œ | ì—†ìŒ | 2~5ê°œ |\n",
    "| ì •í™•ë„ | ë³´í†µ | ë†’ìŒ |\n",
    "| ì¼ê´€ì„± | ë‚®ìŒ | ë†’ìŒ |\n",
    "| í† í° ì‚¬ìš© | ì ìŒ | ë§ìŒ |\n",
    "| ì»¤ìŠ¤í„°ë§ˆì´ì§• | ì œí•œì  | ìœ ì—°í•¨ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_few_shot(text, examples=None):\n",
    "    \"\"\"\n",
    "    Few-shot ë°©ì‹ìœ¼ë¡œ ê°ì„± ë¶„ì„\n",
    "    \n",
    "    Parameters:\n",
    "    - text: ë¶„ì„í•  í…ìŠ¤íŠ¸\n",
    "    - examples: ì˜ˆì œ ë¦¬ìŠ¤íŠ¸ [(í…ìŠ¤íŠ¸, ê°ì„±), ...]\n",
    "    \n",
    "    Returns:\n",
    "    - str: ê°ì„± ë¶„ë¥˜ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        return \"API ë¯¸ì„¤ì •\"\n",
    "    \n",
    "    # ê¸°ë³¸ ì˜ˆì œ\n",
    "    if examples is None:\n",
    "        examples = [\n",
    "            (\"ì •ë§ ë§Œì¡±í•©ë‹ˆë‹¤! ìµœê³ ì˜ ì œí’ˆì´ì—ìš”.\", \"ê¸ì •\"),\n",
    "            (\"ì™„ì „ ì‹¤ë§ì´ì—ìš”. ë‹¤ì‹œëŠ” ì•ˆ ì‚´ ê±°ì˜ˆìš”.\", \"ë¶€ì •\"),\n",
    "            (\"ë³´í†µì´ì—ìš”. íŠ¹ë³„íˆ ì¢‹ì§€ë„ ë‚˜ì˜ì§€ë„ ì•Šì•„ìš”.\", \"ì¤‘ë¦½\"),\n",
    "            (\"ê°€ê²©ì´ ì¢€ ë¹„ì‹¸ê¸´ í•œë° í’ˆì§ˆì€ ì¢‹ì•„ìš”.\", \"ê¸ì •\"),\n",
    "            (\"ë°°ì†¡ì€ ë¹¨ëëŠ”ë° ì œí’ˆì´ ê¸°ëŒ€ì— ëª» ë¯¸ì³ìš”.\", \"ë¶€ì •\")\n",
    "        ]\n",
    "    \n",
    "    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "    prompt = \"\"\"ë‹¤ìŒì€ ê³ ê° ë¦¬ë·°ì˜ ê°ì„± ë¶„ë¥˜ ì˜ˆì‹œì…ë‹ˆë‹¤.\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    for ex_text, ex_sentiment in examples:\n",
    "        prompt += f\"ë¦¬ë·°: {ex_text}\\nê°ì„±: {ex_sentiment}\\n\\n\"\n",
    "    \n",
    "    prompt += f\"\"\"ìœ„ì˜ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ë¦¬ë·°ì˜ ê°ì„±ì„ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë¦¬ë·°: {text}\n",
    "ê°ì„±:\"\"\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-exp\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    return response.text.strip()\n",
    "\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "if client:\n",
    "    test_texts = [\n",
    "        \"ì‚¬ì´ì¦ˆê°€ ë”± ë§ì•„ìš”! ìƒ‰ìƒë„ ì˜ˆì˜ê³  ë§Œì¡±í•©ë‹ˆë‹¤.\",\n",
    "        \"í•œ ë‹¬ ë§Œì— ê³ ì¥ë‚¬ì–´ìš”. í™˜ë¶ˆ ë°›ê³  ì‹¶ì–´ìš”.\",\n",
    "        \"ê°€ì„±ë¹„ëŠ” ê´œì°®ì€ ê²ƒ ê°™ì•„ìš”.\",\n",
    "        \"ë°°ì†¡ì´ ë„ˆë¬´ ëŠë ¤ìš”. 2ì£¼ë‚˜ ê±¸ë ¸ì–´ìš”.\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Few-shot ê°ì„± ë¶„ì„ ê²°ê³¼\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for text in test_texts:\n",
    "        result = analyze_sentiment_few_shot(text)\n",
    "        print(f\"\\në¦¬ë·°: {text}\")\n",
    "        print(f\"  ê°ì„±: {result}\")\n",
    "        time.sleep(1)\n",
    "else:\n",
    "    print(\"APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: ë„ë©”ì¸ íŠ¹í™” Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŒì‹ì  ë¦¬ë·° íŠ¹í™” ì˜ˆì œ\n",
    "food_review_examples = [\n",
    "    (\"ë§›ìˆì–´ìš”! ì–‘ë„ ë§ê³  ê°€ê²©ë„ ì ë‹¹í•´ìš”.\", \"ê¸ì •\"),\n",
    "    (\"ë„ˆë¬´ ì§œê³  ëŠë¼í•´ìš”. ìœ„ìƒë„ ë³„ë¡œì¸ ê²ƒ ê°™ì•„ìš”.\", \"ë¶€ì •\"),\n",
    "    (\"í‰ë²”í•´ìš”. íŠ¹ë³„íˆ ë§›ìˆì§€ë„ ë§›ì—†ì§€ë„ ì•Šì•„ìš”.\", \"ì¤‘ë¦½\"),\n",
    "    (\"ìŒì‹ì€ ë§›ìˆëŠ”ë° ì„œë¹„ìŠ¤ê°€ ë¶ˆì¹œì ˆí•´ìš”.\", \"ì¤‘ë¦½\"),  # ë³µí•© ê°ì„±\n",
    "    (\"ì›¨ì´íŒ…ì´ ê¸¸ì—ˆì§€ë§Œ ê¸°ë‹¤ë¦° ë³´ëŒì´ ìˆì–´ìš”!\", \"ê¸ì •\")\n",
    "]\n",
    "\n",
    "# ì „ìì œí’ˆ ë¦¬ë·° íŠ¹í™” ì˜ˆì œ\n",
    "electronics_examples = [\n",
    "    (\"ì„±ëŠ¥ ì¢‹ê³  ë°œì—´ë„ ì ì–´ìš”. ê°€ì„±ë¹„ ìµœê³ !\", \"ê¸ì •\"),\n",
    "    (\"í•œ ë‹¬ ë§Œì— ê³ ì¥ë‚¬ì–´ìš”. ASë„ ë³„ë¡œì˜ˆìš”.\", \"ë¶€ì •\"),\n",
    "    (\"í‰ë²”í•œ ìŠ¤í™ì´ì—ìš”. ê°€ê²© ëŒ€ë¹„ ë¬´ë‚œí•©ë‹ˆë‹¤.\", \"ì¤‘ë¦½\"),\n",
    "    (\"ë””ìì¸ì€ ì˜ˆìœë° ë°°í„°ë¦¬ê°€ ë„ˆë¬´ ë¹¨ë¦¬ ë‹³ì•„ìš”.\", \"ë¶€ì •\"),\n",
    "    (\"ì²˜ìŒì—” ë¶ˆì•ˆí–ˆëŠ”ë° ì¨ë³´ë‹ˆ ì¢‹ì•„ìš”!\", \"ê¸ì •\")\n",
    "]\n",
    "\n",
    "if client:\n",
    "    # ìŒì‹ì  ë¦¬ë·° í…ŒìŠ¤íŠ¸\n",
    "    food_review = \"êµ­ë¬¼ì´ ì§„í•˜ê³  ë©´ë°œì´ ì«„ê¹ƒí•´ìš”. ì¬ë°©ë¬¸ ì˜ì‚¬ 100%!\"\n",
    "    result = analyze_sentiment_few_shot(food_review, food_review_examples)\n",
    "    print(f\"[ìŒì‹ì  ë¦¬ë·°] {food_review}\")\n",
    "    print(f\"  ê°ì„±: {result}\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # ì „ìì œí’ˆ ë¦¬ë·° í…ŒìŠ¤íŠ¸\n",
    "    electronics_review = \"í™”ë©´ì€ ì„ ëª…í•œë° ìŠ¤í”¼ì»¤ ìŒì§ˆì´ ì•„ì‰¬ì›Œìš”.\"\n",
    "    result = analyze_sentiment_few_shot(electronics_review, electronics_examples)\n",
    "    print(f\"\\n[ì „ìì œí’ˆ ë¦¬ë·°] {electronics_review}\")\n",
    "    print(f\"  ê°ì„±: {result}\")\n",
    "else:\n",
    "    print(\"APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 ë°°ì¹˜ ì²˜ë¦¬ ë° ê²°ê³¼ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_batch(texts, method=\"zero-shot\", delay=1):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ë¡œ ê°ì„± ë¶„ì„\n",
    "    \n",
    "    Parameters:\n",
    "    - texts: í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
    "    - method: \"zero-shot\" ë˜ëŠ” \"few-shot\"\n",
    "    - delay: API í˜¸ì¶œ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: ë¶„ì„ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        print(f\"ì²˜ë¦¬ ì¤‘... {i+1}/{len(texts)}\", end=\"\\r\")\n",
    "        \n",
    "        if method == \"few-shot\":\n",
    "            sentiment = analyze_sentiment_few_shot(text)\n",
    "        else:\n",
    "            sentiment = analyze_sentiment_simple(text)\n",
    "        \n",
    "        results.append({\n",
    "            \"text\": text,\n",
    "            \"sentiment\": sentiment\n",
    "        })\n",
    "        \n",
    "        if i < len(texts) - 1:\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    print(\"\\në¶„ì„ ì™„ë£Œ!\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# ìƒ˜í”Œ ë¦¬ë·° ë°ì´í„°\n",
    "sample_reviews = [\n",
    "    \"ë°°ì†¡ ë¹ ë¥´ê³  í¬ì¥ ê¼¼ê¼¼í•´ìš”. ë§Œì¡±í•©ë‹ˆë‹¤!\",\n",
    "    \"ì‚¬ì§„ê³¼ ë„ˆë¬´ ë‹¤ë¥´ê²Œ ìƒê²¼ì–´ìš”. ì‹¤ë§ì…ë‹ˆë‹¤.\",\n",
    "    \"ê°€ê²© ëŒ€ë¹„ ë¬´ë‚œí•´ìš”.\",\n",
    "    \"í’ˆì§ˆ ì¢‹ì•„ìš”! ì¬êµ¬ë§¤ ì˜ì‚¬ ìˆì–´ìš”.\",\n",
    "    \"êµí™˜ ìš”ì²­í–ˆëŠ”ë° ì‘ëŒ€ê°€ ë¶ˆì¹œì ˆí•´ìš”.\",\n",
    "    \"ìƒ‰ìƒì´ ìƒê°ë³´ë‹¤ ì˜ˆë»ìš”.\",\n",
    "    \"í•œ ë‹¬ ì¨ë´¤ëŠ”ë° ì•„ì§ ì˜ ëª¨ë¥´ê² ì–´ìš”.\",\n",
    "    \"ìµœì•…ì´ì—ìš”. í™˜ë¶ˆ ë°›ì•˜ì–´ìš”.\"\n",
    "]\n",
    "\n",
    "if client:\n",
    "    # ë°°ì¹˜ ë¶„ì„ ì‹¤í–‰\n",
    "    results_df = analyze_batch(sample_reviews, method=\"few-shot\")\n",
    "    print(\"\\në¶„ì„ ê²°ê³¼:\")\n",
    "    print(results_df)\n",
    "else:\n",
    "    print(\"APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°\n",
    "    results_df = pd.DataFrame({\n",
    "        \"text\": sample_reviews,\n",
    "        \"sentiment\": [\"ê¸ì •\", \"ë¶€ì •\", \"ì¤‘ë¦½\", \"ê¸ì •\", \"ë¶€ì •\", \"ê¸ì •\", \"ì¤‘ë¦½\", \"ë¶€ì •\"]\n",
    "    })\n",
    "    print(\"\\n[ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°]\")\n",
    "    print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.5 LLM ê°ì„± ë¶„ì„ ê²°ê³¼ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°ì„± ë¶„í¬ ì‹œê°í™”\n",
    "sentiment_counts = results_df['sentiment'].value_counts()\n",
    "\n",
    "# ìƒ‰ìƒ ì •ì˜\n",
    "colors = {'ê¸ì •': '#2ecc71', 'ë¶€ì •': '#e74c3c', 'ì¤‘ë¦½': '#95a5a6'}\n",
    "\n",
    "fig = px.pie(\n",
    "    values=sentiment_counts.values,\n",
    "    names=sentiment_counts.index,\n",
    "    title='LLM ê°ì„± ë¶„ì„ ê²°ê³¼ ë¶„í¬',\n",
    "    color=sentiment_counts.index,\n",
    "    color_discrete_map=colors,\n",
    "    hole=0.4\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    textposition='inside',\n",
    "    textinfo='percent+label+value',\n",
    "    textfont_size=14\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=600,\n",
    "    height=450\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: ì„ë² ë”© ê¸°ë°˜ ê°ì„± ë¶„ì„\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 í…ìŠ¤íŠ¸ ì„ë² ë”© ê°œë…\n",
    "\n",
    "### ì„ë² ë”©ì´ë€?\n",
    "\n",
    "**ì„ë² ë”©(Embedding)**ì€ í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„°(ìˆ«ì ë°°ì—´)ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "### ì™œ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ë‚˜ìš”?\n",
    "\n",
    "| íŠ¹ì§• | ì„¤ëª… |\n",
    "|------|------|\n",
    "| ì˜ë¯¸ í‘œí˜„ | ë¹„ìŠ·í•œ ì˜ë¯¸ì˜ í…ìŠ¤íŠ¸ëŠ” ê°€ê¹Œìš´ ë²¡í„° |\n",
    "| ìˆ˜ì¹˜ ì—°ì‚° | í…ìŠ¤íŠ¸ ê°„ ìœ ì‚¬ë„ ê³„ì‚° ê°€ëŠ¥ |\n",
    "| ë²”ìš©ì„± | ê²€ìƒ‰, ë¶„ë¥˜, ì¶”ì²œ ë“± ë‹¤ì–‘í•œ í™œìš© |\n",
    "\n",
    "### ì˜ˆì‹œ\n",
    "\n",
    "```\n",
    "\"ì¢‹ì•„ìš”\" â†’ [0.2, 0.8, 0.1, ...] (768ì°¨ì› ë˜ëŠ” 3072ì°¨ì›)\n",
    "\"ìµœê³ ì˜ˆìš”\" â†’ [0.25, 0.75, 0.15, ...] (ë¹„ìŠ·í•œ ë²¡í„°)\n",
    "\"ì‹«ì–´ìš”\" â†’ [-0.3, 0.1, 0.5, ...] (ë‹¤ë¥¸ ë²¡í„°)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 Google Gemini Embedding API\n",
    "\n",
    "### gemini-embedding-001 íŠ¹ì§•\n",
    "\n",
    "- **ì°¨ì›**: 3072 (ê¸°ë³¸), `output_dimensionality`ë¡œ ì¶•ì†Œ ê°€ëŠ¥\n",
    "- **ì§€ì› ì–¸ì–´**: 100+ ì–¸ì–´ (í•œêµ­ì–´ í¬í•¨)\n",
    "- **ìµœëŒ€ ì…ë ¥**: 2,048 í† í°\n",
    "- **ë¬´ë£Œ í•œë„**: ì›” 100ë§Œ í† í°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_gemini(text, dimension=256):\n",
    "    \"\"\"\n",
    "    Google Gemini APIë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±\n",
    "    \n",
    "    Parameters:\n",
    "    - text: í…ìŠ¤íŠ¸ (ë¬¸ìì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸)\n",
    "    - dimension: ì¶œë ¥ ì°¨ì› (ê¸°ë³¸ 256, ìµœëŒ€ 3072)\n",
    "    \n",
    "    Returns:\n",
    "    - numpy array: ì„ë² ë”© ë²¡í„°\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        return None\n",
    "    \n",
    "    result = client.models.embed_content(\n",
    "        model=\"gemini-embedding-001\",\n",
    "        contents=text,\n",
    "        config=types.EmbedContentConfig(output_dimensionality=dimension)\n",
    "    )\n",
    "    \n",
    "    # ë‹¨ì¼ í…ìŠ¤íŠ¸ë©´ ì²« ë²ˆì§¸ ì„ë² ë”©ë§Œ ë°˜í™˜\n",
    "    if isinstance(text, str):\n",
    "        return np.array(result.embeddings[0].values)\n",
    "    else:\n",
    "        return np.array([emb.values for emb in result.embeddings])\n",
    "\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "if client:\n",
    "    test_text = \"ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”!\"\n",
    "    embedding = get_embedding_gemini(test_text, dimension=256)\n",
    "    \n",
    "    print(f\"í…ìŠ¤íŠ¸: {test_text}\")\n",
    "    print(f\"ì„ë² ë”© ì°¨ì›: {len(embedding)}\")\n",
    "    print(f\"ì„ë² ë”© (ì²˜ìŒ 10ê°œ): {embedding[:10].round(4)}\")\n",
    "else:\n",
    "    print(\"APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 sentence-transformers (ë¡œì»¬ ì„ë² ë”©)\n",
    "\n",
    "### ì¥ì \n",
    "\n",
    "- **ë¬´ë£Œ**: API ë¹„ìš© ì—†ìŒ\n",
    "- **ì˜¤í”„ë¼ì¸**: ì¸í„°ë„· ì—°ê²° ë¶ˆí•„ìš”\n",
    "- **ë¹ ë¦„**: ë¡œì»¬ ì²˜ë¦¬ë¡œ ì§€ì—° ì‹œê°„ ì—†ìŒ\n",
    "\n",
    "### ì¶”ì²œ ëª¨ë¸\n",
    "\n",
    "| ëª¨ë¸ëª… | ì–¸ì–´ | ì°¨ì› | íŠ¹ì§• |\n",
    "|--------|------|------|------|\n",
    "| `jhgan/ko-sbert-nli` | í•œêµ­ì–´ | 768 | í•œêµ­ì–´ íŠ¹í™” |\n",
    "| `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` | ë‹¤êµ­ì–´ | 384 | ê²½ëŸ‰, ë¹ ë¦„ |\n",
    "| `sentence-transformers/all-MiniLM-L6-v2` | ì˜ì–´ | 384 | ê³ ì„±ëŠ¥ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence-transformers ì„¤ì¹˜ (ìµœì´ˆ 1íšŒ)\n",
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence-transformers ë¡œë“œ\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    # í•œêµ­ì–´ ëª¨ë¸ ë¡œë“œ (ì²˜ìŒ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œ)\n",
    "    local_model = SentenceTransformer('jhgan/ko-sbert-nli')\n",
    "    local_embedding_available = True\n",
    "    print(\"sentence-transformers ë¡œë“œ ì™„ë£Œ\")\n",
    "except ImportError:\n",
    "    local_embedding_available = False\n",
    "    print(\"sentence-transformers ë¯¸ì„¤ì¹˜. pip install sentence-transformers ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_local(text):\n",
    "    \"\"\"\n",
    "    sentence-transformersë¡œ ë¡œì»¬ ì„ë² ë”© ìƒì„±\n",
    "    \n",
    "    Parameters:\n",
    "    - text: í…ìŠ¤íŠ¸ (ë¬¸ìì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸)\n",
    "    \n",
    "    Returns:\n",
    "    - numpy array: ì„ë² ë”© ë²¡í„°\n",
    "    \"\"\"\n",
    "    if not local_embedding_available:\n",
    "        return None\n",
    "    \n",
    "    return local_model.encode(text)\n",
    "\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "if local_embedding_available:\n",
    "    test_texts = [\n",
    "        \"ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”!\",\n",
    "        \"ìµœê³ ì˜ ì„ íƒì´ì—ˆì–´ìš”.\",\n",
    "        \"ì™„ì „ ì‹¤ë§ì…ë‹ˆë‹¤.\"\n",
    "    ]\n",
    "    \n",
    "    embeddings = get_embedding_local(test_texts)\n",
    "    \n",
    "    print(\"ë¡œì»¬ ì„ë² ë”© ìƒì„± ê²°ê³¼\")\n",
    "    print(f\"ì„ë² ë”© shape: {embeddings.shape}\")\n",
    "    for i, text in enumerate(test_texts):\n",
    "        print(f\"\\n{text}\")\n",
    "        print(f\"  ì„ë² ë”© (ì²˜ìŒ 5ê°œ): {embeddings[i][:5].round(4)}\")\n",
    "else:\n",
    "    print(\"sentence-transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ê°ì„± ë¶„ë¥˜\n",
    "\n",
    "### ì›ë¦¬\n",
    "\n",
    "1. **ì°¸ì¡° ì„ë² ë”© ìƒì„±**: ê¸ì •/ë¶€ì • ëŒ€í‘œ ë¬¸ì¥ì˜ ì„ë² ë”©\n",
    "2. **ëŒ€ìƒ ì„ë² ë”© ìƒì„±**: ë¶„ë¥˜í•  í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©\n",
    "3. **ìœ ì‚¬ë„ ê³„ì‚°**: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ì–´ëŠ ìª½ì— ë” ê°€ê¹Œìš´ì§€ ì¸¡ì •\n",
    "4. **ë¶„ë¥˜**: ìœ ì‚¬ë„ê°€ ë†’ì€ ìª½ìœ¼ë¡œ ë¶„ë¥˜\n",
    "\n",
    "### ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n",
    "\n",
    "```\n",
    "cos(A, B) = (A Â· B) / (||A|| Ã— ||B||)\n",
    "```\n",
    "\n",
    "- **1**: ì™„ì „íˆ ë™ì¼í•œ ë°©í–¥ (ë§¤ìš° ìœ ì‚¬)\n",
    "- **0**: ì§êµ (ê´€ë ¨ ì—†ìŒ)\n",
    "- **-1**: ë°˜ëŒ€ ë°©í–¥ (ì™„ì „íˆ ë‹¤ë¦„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class EmbeddingSentimentClassifier:\n",
    "    \"\"\"\n",
    "    ì„ë² ë”© ê¸°ë°˜ ê°ì„± ë¶„ë¥˜ê¸°\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_func):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - embedding_func: ì„ë² ë”© ìƒì„± í•¨ìˆ˜\n",
    "        \"\"\"\n",
    "        self.get_embedding = embedding_func\n",
    "        self.reference_embeddings = {}\n",
    "    \n",
    "    def fit(self, positive_texts, negative_texts, neutral_texts=None):\n",
    "        \"\"\"\n",
    "        ì°¸ì¡° ì„ë² ë”© ìƒì„±\n",
    "        \n",
    "        Parameters:\n",
    "        - positive_texts: ê¸ì • ì˜ˆì œ ë¦¬ìŠ¤íŠ¸\n",
    "        - negative_texts: ë¶€ì • ì˜ˆì œ ë¦¬ìŠ¤íŠ¸\n",
    "        - neutral_texts: ì¤‘ë¦½ ì˜ˆì œ ë¦¬ìŠ¤íŠ¸ (ì„ íƒ)\n",
    "        \"\"\"\n",
    "        # ê¸ì • ì„ë² ë”© (í‰ê· )\n",
    "        pos_embs = self.get_embedding(positive_texts)\n",
    "        self.reference_embeddings['ê¸ì •'] = np.mean(pos_embs, axis=0)\n",
    "        \n",
    "        # ë¶€ì • ì„ë² ë”© (í‰ê· )\n",
    "        neg_embs = self.get_embedding(negative_texts)\n",
    "        self.reference_embeddings['ë¶€ì •'] = np.mean(neg_embs, axis=0)\n",
    "        \n",
    "        # ì¤‘ë¦½ ì„ë² ë”© (ì„ íƒ)\n",
    "        if neutral_texts:\n",
    "            neu_embs = self.get_embedding(neutral_texts)\n",
    "            self.reference_embeddings['ì¤‘ë¦½'] = np.mean(neu_embs, axis=0)\n",
    "        \n",
    "        print(f\"ì°¸ì¡° ì„ë² ë”© ìƒì„± ì™„ë£Œ: {list(self.reference_embeddings.keys())}\")\n",
    "    \n",
    "    def predict(self, text):\n",
    "        \"\"\"\n",
    "        í…ìŠ¤íŠ¸ ê°ì„± ë¶„ë¥˜\n",
    "        \n",
    "        Returns:\n",
    "        - dict: ë¶„ë¥˜ ê²°ê³¼, ê° ì¹´í…Œê³ ë¦¬ë³„ ìœ ì‚¬ë„\n",
    "        \"\"\"\n",
    "        # ëŒ€ìƒ ì„ë² ë”©\n",
    "        if isinstance(text, str):\n",
    "            text_emb = self.get_embedding(text).reshape(1, -1)\n",
    "        else:\n",
    "            text_emb = self.get_embedding(text)\n",
    "        \n",
    "        # ê° ì°¸ì¡°ì™€ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "        similarities = {}\n",
    "        for label, ref_emb in self.reference_embeddings.items():\n",
    "            sim = cosine_similarity(text_emb, ref_emb.reshape(1, -1))[0][0]\n",
    "            similarities[label] = sim\n",
    "        \n",
    "        # ê°€ì¥ ìœ ì‚¬í•œ ì¹´í…Œê³ ë¦¬\n",
    "        predicted = max(similarities, key=similarities.get)\n",
    "        \n",
    "        return {\n",
    "            'text': text if isinstance(text, str) else text[0],\n",
    "            'prediction': predicted,\n",
    "            'similarities': similarities\n",
    "        }\n",
    "    \n",
    "    def predict_batch(self, texts):\n",
    "        \"\"\"ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ì¼ê´„ ë¶„ë¥˜\"\"\"\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            results.append(self.predict(text))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ë² ë”© í•¨ìˆ˜ ì„ íƒ (API ë˜ëŠ” ë¡œì»¬)\n",
    "if local_embedding_available:\n",
    "    embedding_func = get_embedding_local\n",
    "    print(\"ë¡œì»¬ ì„ë² ë”© (sentence-transformers) ì‚¬ìš©\")\n",
    "elif client:\n",
    "    embedding_func = get_embedding_gemini\n",
    "    print(\"Google Gemini Embedding API ì‚¬ìš©\")\n",
    "else:\n",
    "    embedding_func = None\n",
    "    print(\"ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© ë°©ë²•ì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding_func:\n",
    "    # ë¶„ë¥˜ê¸° ì´ˆê¸°í™”\n",
    "    classifier = EmbeddingSentimentClassifier(embedding_func)\n",
    "    \n",
    "    # ì°¸ì¡° í…ìŠ¤íŠ¸ ì •ì˜\n",
    "    positive_examples = [\n",
    "        \"ì •ë§ ì¢‹ì•„ìš”! ë§Œì¡±í•©ë‹ˆë‹¤.\",\n",
    "        \"ìµœê³ ì˜ ì œí’ˆì´ì—ìš”!\",\n",
    "        \"ì™„ì „ ì¶”ì²œí•´ìš”. í›Œë¥­í•©ë‹ˆë‹¤.\",\n",
    "        \"ê¸°ëŒ€ ì´ìƒì´ì—ìš”. ê°ì‚¬í•©ë‹ˆë‹¤.\",\n",
    "        \"í’ˆì§ˆì´ ì¢‹ê³  ë°°ì†¡ë„ ë¹¨ë¼ìš”.\"\n",
    "    ]\n",
    "    \n",
    "    negative_examples = [\n",
    "        \"ë³„ë¡œì˜ˆìš”. ì‹¤ë§ì…ë‹ˆë‹¤.\",\n",
    "        \"ìµœì•…ì´ì—ìš”. ëˆ ì•„ê¹Œì›Œìš”.\",\n",
    "        \"í™˜ë¶ˆ ë°›ê³  ì‹¶ì–´ìš”.\",\n",
    "        \"í’ˆì§ˆì´ ë„ˆë¬´ ì•ˆ ì¢‹ì•„ìš”.\",\n",
    "        \"ë‹¤ì‹œëŠ” ì•ˆ ì‚´ ê±°ì˜ˆìš”.\"\n",
    "    ]\n",
    "    \n",
    "    neutral_examples = [\n",
    "        \"ê·¸ëƒ¥ ê·¸ë˜ìš”.\",\n",
    "        \"ë³´í†µì´ì—ìš”.\",\n",
    "        \"ë¬´ë‚œí•©ë‹ˆë‹¤.\",\n",
    "        \"íŠ¹ë³„íˆ ì¢‹ì§€ë„ ë‚˜ì˜ì§€ë„ ì•Šì•„ìš”.\",\n",
    "        \"ê°€ê²© ëŒ€ë¹„ ì ë‹¹í•´ìš”.\"\n",
    "    ]\n",
    "    \n",
    "    # ì°¸ì¡° ì„ë² ë”© ìƒì„±\n",
    "    classifier.fit(positive_examples, negative_examples, neutral_examples)\n",
    "else:\n",
    "    print(\"ì„ë² ë”© í•¨ìˆ˜ê°€ ì—†ì–´ ë¶„ë¥˜ê¸°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "if embedding_func:\n",
    "    test_reviews = [\n",
    "        \"ì´ ì œí’ˆ ì§„ì§œ ëŒ€ë°•ì´ì—ìš”! ë„ˆë¬´ ë§Œì¡±í•´ìš”.\",\n",
    "        \"ê¸°ëŒ€í–ˆëŠ”ë° ì™„ì „ ì‹¤ë§ì´ì—ìš”.\",\n",
    "        \"ê´œì°®ì•„ìš”. ë‚˜ì˜ì§€ ì•Šì•„ìš”.\",\n",
    "        \"ë°°ì†¡ì€ ë¹¨ëëŠ”ë° í’ˆì§ˆì´ ì•„ì‰¬ì›Œìš”.\",\n",
    "        \"ê°€ì„±ë¹„ ìµœê³ ! ì¬êµ¬ë§¤ ì˜ì‚¬ ìˆì–´ìš”.\"\n",
    "    ]\n",
    "    \n",
    "    print(\"ì„ë² ë”© ê¸°ë°˜ ê°ì„± ë¶„ë¥˜ ê²°ê³¼\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for review in test_reviews:\n",
    "        result = classifier.predict(review)\n",
    "        print(f\"\\në¦¬ë·°: {review}\")\n",
    "        print(f\"  ë¶„ë¥˜: {result['prediction']}\")\n",
    "        print(f\"  ìœ ì‚¬ë„: ê¸ì •={result['similarities']['ê¸ì •']:.3f}, \"\n",
    "              f\"ë¶€ì •={result['similarities']['ë¶€ì •']:.3f}, \"\n",
    "              f\"ì¤‘ë¦½={result['similarities']['ì¤‘ë¦½']:.3f}\")\n",
    "else:\n",
    "    print(\"ì„ë² ë”© í•¨ìˆ˜ê°€ ì—†ì–´ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: ì„ë² ë”© ì‹œê°í™” (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "if embedding_func:\n",
    "    # ëª¨ë“  í…ìŠ¤íŠ¸ ì„ë² ë”©\n",
    "    all_texts = positive_examples + negative_examples + neutral_examples + test_reviews\n",
    "    all_labels = (['ê¸ì •'] * len(positive_examples) + \n",
    "                  ['ë¶€ì •'] * len(negative_examples) + \n",
    "                  ['ì¤‘ë¦½'] * len(neutral_examples) +\n",
    "                  ['í…ŒìŠ¤íŠ¸'] * len(test_reviews))\n",
    "    \n",
    "    all_embeddings = embedding_func(all_texts)\n",
    "    \n",
    "    # PCAë¡œ 2ì°¨ì› ì¶•ì†Œ\n",
    "    pca = PCA(n_components=2)\n",
    "    embeddings_2d = pca.fit_transform(all_embeddings)\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    vis_df = pd.DataFrame({\n",
    "        'x': embeddings_2d[:, 0],\n",
    "        'y': embeddings_2d[:, 1],\n",
    "        'text': all_texts,\n",
    "        'label': all_labels\n",
    "    })\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        vis_df,\n",
    "        x='x', y='y',\n",
    "        color='label',\n",
    "        hover_data=['text'],\n",
    "        title='í…ìŠ¤íŠ¸ ì„ë² ë”© ì‹œê°í™” (PCA)',\n",
    "        color_discrete_map={'ê¸ì •': '#2ecc71', 'ë¶€ì •': '#e74c3c', 'ì¤‘ë¦½': '#95a5a6', 'í…ŒìŠ¤íŠ¸': '#3498db'}\n",
    "    )\n",
    "    \n",
    "    fig.update_traces(marker=dict(size=12))\n",
    "    fig.update_layout(width=800, height=600)\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"ì„ë² ë”© í•¨ìˆ˜ê°€ ì—†ì–´ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ ì‹¤ìŠµ í€´ì¦ˆ\n",
    "\n",
    "**ë‚œì´ë„**: â­ (ì‰¬ì›€) ~ â­â­â­â­â­ (ì–´ë ¤ì›€)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Zero-shot í”„ë¡¬í”„íŠ¸ ì‘ì„±í•˜ê¸° â­\n",
    "\n",
    "**ë¬¸ì œ**: í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ëŠ” Zero-shot í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "text = \"ì´ ì˜í™” ì •ë§ ì¬ë¯¸ì—†ì–´ìš”. ì‹œê°„ ë‚­ë¹„ì˜€ì–´ìš”.\"\n",
    "```\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**: ê°ì„±ë§Œ í•œ ë‹¨ì–´ë¡œ ë‹µí•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ì‘ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ì´ ì˜í™” ì •ë§ ì¬ë¯¸ì—†ì–´ìš”. ì‹œê°„ ë‚­ë¹„ì˜€ì–´ìš”.\"\n",
    "\n",
    "# ì—¬ê¸°ì— í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”\n",
    "prompt = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Few-shot ì˜ˆì œ êµ¬ì„±í•˜ê¸° â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ìŒì‹ì  ë¦¬ë·° ê°ì„± ë¶„ë¥˜ë¥¼ ìœ„í•œ Few-shot ì˜ˆì œë¥¼ 5ê°œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "- ê¸ì • 2ê°œ, ë¶€ì • 2ê°œ, ì¤‘ë¦½ 1ê°œ\n",
    "- ì‹¤ì œ ìŒì‹ì  ë¦¬ë·° ìŠ¤íƒ€ì¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì˜ˆì œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n",
    "food_examples = [\n",
    "    # (\"ë¦¬ë·° í…ìŠ¤íŠ¸\", \"ê°ì„±\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°í•˜ê¸° â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‘ ë²¡í„° Aì™€ Bì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì§ì ‘ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "A = np.array([1, 2, 3])\n",
    "B = np.array([4, 5, 6])\n",
    "```\n",
    "\n",
    "**íŒíŠ¸**: `cos(A, B) = (A Â· B) / (||A|| Ã— ||B||)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_manual(A, B):\n",
    "    \"\"\"\n",
    "    ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ìˆ˜ë™ ê³„ì‚°\n",
    "    \"\"\"\n",
    "    # ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n",
    "    pass\n",
    "\n",
    "A = np.array([1, 2, 3])\n",
    "B = np.array([4, 5, 6])\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. 5ì  ì²™ë„ ê°ì„± ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: LLMì´ 1~5ì ìœ¼ë¡œ ê°ì„±ì„ í‰ê°€í•˜ê³  ì´ìœ ë„ ì„¤ëª…í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "text = \"ë°°ì†¡ì€ ë¹¨ëëŠ”ë° ì œí’ˆ í’ˆì§ˆì´ ê¸°ëŒ€ì— ëª» ë¯¸ì³ìš”.\"\n",
    "```\n",
    "\n",
    "**ì¶œë ¥ í˜•ì‹**:\n",
    "```\n",
    "ì ìˆ˜: 3\n",
    "ì´ìœ : ë°°ì†¡ì€ ì¢‹ì•˜ìœ¼ë‚˜ í’ˆì§ˆì— ë¶ˆë§Œì¡±\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ë°°ì†¡ì€ ë¹¨ëëŠ”ë° ì œí’ˆ í’ˆì§ˆì´ ê¸°ëŒ€ì— ëª» ë¯¸ì³ìš”.\"\n",
    "\n",
    "# ì—¬ê¸°ì— í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. ì¸¡ë©´(Aspect) ê¸°ë°˜ ê°ì„± ë¶„ì„ í”„ë¡¬í”„íŠ¸ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë¦¬ë·°ì—ì„œ ì—¬ëŸ¬ ì¸¡ë©´(ë°°ì†¡, í’ˆì§ˆ, ê°€ê²© ë“±)ë³„ë¡œ ê°ì„±ì„ ì¶”ì¶œí•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "text = \"ë°°ì†¡ì€ ë¹ ë¥´ê³  ì¢‹ì•˜ì–´ìš”. ê·¼ë° í’ˆì§ˆì´ ë³„ë¡œê³  ê°€ê²©ë„ ë¹„ì‹¸ë„¤ìš”.\"\n",
    "```\n",
    "\n",
    "**ê¸°ëŒ€ ì¶œë ¥**:\n",
    "```\n",
    "- ë°°ì†¡: ê¸ì •\n",
    "- í’ˆì§ˆ: ë¶€ì •\n",
    "- ê°€ê²©: ë¶€ì •\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ë°°ì†¡ì€ ë¹ ë¥´ê³  ì¢‹ì•˜ì–´ìš”. ê·¼ë° í’ˆì§ˆì´ ë³„ë¡œê³  ê°€ê²©ë„ ë¹„ì‹¸ë„¤ìš”.\"\n",
    "\n",
    "# ì—¬ê¸°ì— í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. ë°°ì¹˜ ê°ì„± ë¶„ì„ í•¨ìˆ˜ ê°œì„  â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë°°ì¹˜ ê°ì„± ë¶„ì„ í•¨ìˆ˜ì— ì§„í–‰ë¥  í‘œì‹œì™€ ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "- ì§„í–‰ë¥  í‘œì‹œ (ì˜ˆ: \"3/10 ì™„ë£Œ\")\n",
    "- API ì—ëŸ¬ ì‹œ ì¬ì‹œë„ (ìµœëŒ€ 3íšŒ)\n",
    "- ì‹¤íŒ¨í•œ í•­ëª©ì€ 'error'ë¡œ í‘œì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_batch_improved(texts, max_retries=3):\n",
    "    \"\"\"\n",
    "    ê°œì„ ëœ ë°°ì¹˜ ê°ì„± ë¶„ì„ í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    # ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. ì„ë² ë”© ê¸°ë°˜ ê°ì„± ê°•ë„ ì¸¡ì • â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ í™œìš©í•˜ì—¬ -1(ë§¤ìš° ë¶€ì •) ~ +1(ë§¤ìš° ê¸ì •) ì‚¬ì´ì˜ ì—°ì†ì ì¸ ê°ì„± ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "**íŒíŠ¸**: `ì ìˆ˜ = ê¸ì • ìœ ì‚¬ë„ - ë¶€ì • ìœ ì‚¬ë„`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentiment_score(text, classifier):\n",
    "    \"\"\"\n",
    "    ì„ë² ë”© ê¸°ë°˜ ê°ì„± ì ìˆ˜ ê³„ì‚° (-1 ~ +1)\n",
    "    \"\"\"\n",
    "    # ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. LLM vs ì„ë² ë”© ë¹„êµ ë¶„ì„ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë™ì¼í•œ 10ê°œ ë¦¬ë·°ì— ëŒ€í•´ LLM(Few-shot)ê³¼ ì„ë² ë”© ë°©ì‹ìœ¼ë¡œ ê°ì„±ì„ ë¶„ë¥˜í•˜ê³ , ê²°ê³¼ë¥¼ ë¹„êµí•˜ëŠ” ì‹œê°í™”ë¥¼ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "- 10ê°œ ë¦¬ë·° ë¶„ì„\n",
    "- ë‘ ë°©ì‹ì˜ ì¼ì¹˜ìœ¨ ê³„ì‚°\n",
    "- ë¶ˆì¼ì¹˜í•˜ëŠ” ë¦¬ë·° í‘œì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_reviews = [\n",
    "    \"ì™„ì „ ë§Œì¡±í•´ìš”! ìµœê³ ì˜ êµ¬ë§¤ì˜€ì–´ìš”.\",\n",
    "    \"ëˆ ì•„ê¹Œì›Œìš”. ì‹¤ë§ì…ë‹ˆë‹¤.\",\n",
    "    \"ê·¸ëƒ¥ ê·¸ë˜ìš”. ë³´í†µì´ì—ìš”.\",\n",
    "    \"ë°°ì†¡ì€ ë¹¨ëëŠ”ë° í’ˆì§ˆì´...\",\n",
    "    \"ê°€ì„±ë¹„ ì¢‹ì•„ìš”! ì¶”ì²œí•©ë‹ˆë‹¤.\",\n",
    "    \"ê¸°ëŒ€í–ˆëŠ”ë° ë³„ë¡œë„¤ìš”.\",\n",
    "    \"ë‚˜ì˜ì§€ ì•Šì•„ìš”.\",\n",
    "    \"ìµœì•…ì´ì—ìš”. í™˜ë¶ˆí–ˆì–´ìš”.\",\n",
    "    \"ë””ìì¸ ì˜ˆì˜ê³  ê¸°ëŠ¥ë„ ì¢‹ì•„ìš”.\",\n",
    "    \"ê°€ê²©ë§Œ ì¢€ ì €ë ´í•˜ë©´ ì¢‹ê² ì–´ìš”.\"\n",
    "]\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. ì¢…í•© ê°ì„± ë¶„ì„ íŒŒì´í”„ë¼ì¸ â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ê¸°ëŠ¥ì„ ëª¨ë‘ ê°–ì¶˜ ì¢…í•© ê°ì„± ë¶„ì„ í´ë˜ìŠ¤ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "1. LLM(Zero-shot/Few-shot) + ì„ë² ë”© ë°©ì‹ ëª¨ë‘ ì§€ì›\n",
    "2. ì•™ìƒë¸” ë¶„ë¥˜ (ë‘ ë°©ì‹ ê²°ê³¼ ì¢…í•©)\n",
    "3. ì‹ ë¢°ë„ ì ìˆ˜ ì‚°ì¶œ\n",
    "4. ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedSentimentAnalyzer:\n",
    "    \"\"\"\n",
    "    ì¢…í•© ê°ì„± ë¶„ì„ê¸°\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n",
    "        pass\n",
    "    \n",
    "    def analyze(self, text, method='ensemble'):\n",
    "        \"\"\"\n",
    "        í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„\n",
    "        \n",
    "        Parameters:\n",
    "        - text: ë¶„ì„í•  í…ìŠ¤íŠ¸\n",
    "        - method: 'llm', 'embedding', 'ensemble'\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def analyze_batch(self, texts, method='ensemble'):\n",
    "        \"\"\"ë°°ì¹˜ ë¶„ì„\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. ê°ì„± ë¶„ì„ ëŒ€ì‹œë³´ë“œ â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¢…í•© ëŒ€ì‹œë³´ë“œë¥¼ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "**ë¶„ì„ í•­ëª©**:\n",
    "1. ì „ì²´ ê°ì„± ë¶„í¬ (íŒŒì´ ì°¨íŠ¸)\n",
    "2. ë°©ë²•ë³„ ë¶„ë¥˜ ê²°ê³¼ ë¹„êµ (ë§‰ëŒ€ ì°¨íŠ¸)\n",
    "3. ì„ë² ë”© ì‹œê°í™” (ì‚°ì ë„)\n",
    "4. ê°ì„± ì ìˆ˜ ë¶„í¬ (íˆìŠ¤í† ê·¸ë¨)\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "- `make_subplots`ë¡œ 2x2 ë ˆì´ì•„ì›ƒ\n",
    "- ì¸ì‚¬ì´íŠ¸ 3ê°œ ì´ìƒ ë„ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_reviews = [\n",
    "    \"ì •ë§ ì¢‹ì•„ìš”! ë§Œì¡±í•©ë‹ˆë‹¤.\",\n",
    "    \"ë³„ë¡œì˜ˆìš”. ì‹¤ë§ì…ë‹ˆë‹¤.\",\n",
    "    \"ê·¸ëƒ¥ ê·¸ë˜ìš”.\",\n",
    "    \"ìµœê³ ì˜ ì„ íƒì´ì—ˆì–´ìš”!\",\n",
    "    \"ëˆ ì•„ê¹Œì›Œìš”.\",\n",
    "    \"ê°€ê²© ëŒ€ë¹„ ê´œì°®ì•„ìš”.\",\n",
    "    \"ë‹¤ì‹œëŠ” ì•ˆ ì‚´ ê±°ì˜ˆìš”.\",\n",
    "    \"ì¶”ì²œí•©ë‹ˆë‹¤!\",\n",
    "    \"ë³´í†µì´ì—ìš”.\",\n",
    "    \"ì™„ì „ ì‹¤ë§ì´ì—ìš”.\",\n",
    "    \"ê¸°ëŒ€ ì´ìƒì´ì—ìš”!\",\n",
    "    \"ê·¸ëƒ¥ ë¬´ë‚œí•´ìš”.\"\n",
    "]\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "### Part 1: LLM ê¸°ë°˜ ê°ì„± ë¶„ì„ í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ê°œë… | ì„¤ëª… | í™œìš© |\n",
    "|------|------|------|\n",
    "| Zero-shot | ì˜ˆì œ ì—†ì´ ë°”ë¡œ ë¶„ë¥˜ | ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ |\n",
    "| Few-shot | ëª‡ ê°œ ì˜ˆì œë¡œ í•™ìŠµ | ë„ë©”ì¸ íŠ¹í™” ë¶„ë¥˜ |\n",
    "| í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ | íš¨ê³¼ì ì¸ ì§€ì‹œë¬¸ ì‘ì„± | ì •í™•ë„ í–¥ìƒ |\n",
    "| ë°°ì¹˜ ì²˜ë¦¬ | ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ì¼ê´„ ë¶„ì„ | ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ |\n",
    "\n",
    "### Part 2: ì„ë² ë”© ê¸°ë°˜ ê°ì„± ë¶„ì„ í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ê°œë… | ì„¤ëª… | í™œìš© |\n",
    "|------|------|------|\n",
    "| í…ìŠ¤íŠ¸ ì„ë² ë”© | í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ | ì˜ë¯¸ ê¸°ë°˜ ë¶„ì„ |\n",
    "| Gemini Embedding | Google API ì„ë² ë”© | ê³ í’ˆì§ˆ, ë‹¤êµ­ì–´ |\n",
    "| sentence-transformers | ë¡œì»¬ ì„ë² ë”© | ë¬´ë£Œ, ì˜¤í”„ë¼ì¸ |\n",
    "| ì½”ì‚¬ì¸ ìœ ì‚¬ë„ | ë²¡í„° ê°„ ìœ ì‚¬ë„ ì¸¡ì • | ê°ì„± ë¶„ë¥˜ |\n",
    "\n",
    "### ğŸ’¡ ì‹¤ë¬´ íŒ\n",
    "\n",
    "1. **Zero-shot ë¨¼ì €**: ë¹ ë¥´ê²Œ í”„ë¡œí† íƒ€ì…, ì„±ëŠ¥ ë¶€ì¡± ì‹œ Few-shot\n",
    "2. **ë„ë©”ì¸ ì˜ˆì œ**: Few-shotì— ë„ë©”ì¸ íŠ¹í™” ì˜ˆì œ ì‚¬ìš©\n",
    "3. **ì„ë² ë”© ìºì‹±**: ë™ì¼ í…ìŠ¤íŠ¸ ì¬ë¶„ì„ ì‹œ ì„ë² ë”© ì €ì¥í•´ë‘ê¸°\n",
    "4. **ì•™ìƒë¸” í™œìš©**: LLM + ì„ë² ë”© ê²°ê³¼ ì¢…í•©ìœ¼ë¡œ ì‹ ë¢°ë„ í–¥ìƒ\n",
    "5. **ë¹„ìš© ê´€ë¦¬**: API í˜¸ì¶œ íšŸìˆ˜ ìµœì†Œí™”, ë¡œì»¬ ëª¨ë¸ í™œìš©\n",
    "6. **ë°°ì¹˜ ì²˜ë¦¬**: ëŒ€ëŸ‰ ë°ì´í„°ëŠ” ë°°ì¹˜ë¡œ íš¨ìœ¨ì  ì²˜ë¦¬\n",
    "7. **ì‹œê°í™” í•„ìˆ˜**: ë¶„ì„ ê²°ê³¼ëŠ” í•­ìƒ ì‹œê°í™”ë¡œ ê²€ì¦"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
