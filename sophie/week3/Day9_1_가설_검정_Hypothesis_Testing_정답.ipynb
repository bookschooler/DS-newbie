{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day9_1: ê°€ì„¤ ê²€ì • (Hypothesis Testing) - ì •ë‹µ\n",
    "\n",
    "## ğŸ“š í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "**Part 1: ê¸°ì´ˆ ê°œë…**\n",
    "1. ê·€ë¬´ê°€ì„¤ê³¼ ëŒ€ë¦½ê°€ì„¤ì˜ ì°¨ì´ ì´í•´í•˜ê¸°\n",
    "2. p-valueì˜ ì˜ë¯¸ì™€ í•´ì„ ë°©ë²• ë°°ìš°ê¸°\n",
    "3. ìœ ì˜ìˆ˜ì¤€(Î±)ê³¼ ì‹ ë¢°ìˆ˜ì¤€ì˜ ê´€ê³„ íŒŒì•…í•˜ê¸°\n",
    "4. Type I ì˜¤ë¥˜ì™€ Type II ì˜¤ë¥˜ êµ¬ë¶„í•˜ê¸°\n",
    "5. ê°€ì„¤ ê²€ì • í”„ë¡œì„¸ìŠ¤ ì „ì²´ íë¦„ ì´í•´í•˜ê¸°\n",
    "\n",
    "**Part 2: ê²€ì • ë°©ë²•**\n",
    "1. t-test (ë‹¨ì¼, ë…ë¦½, ëŒ€ì‘) êµ¬ë¶„í•˜ì—¬ ì‚¬ìš©í•˜ê¸°\n",
    "2. chi-square ê²€ì •ìœ¼ë¡œ ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„í•˜ê¸°\n",
    "3. ANOVAë¡œ 3ê°œ ì´ìƒ ê·¸ë£¹ ë¹„êµí•˜ê¸°\n",
    "4. ìƒê´€ê³„ìˆ˜(Pearson, Spearman) ê³„ì‚°í•˜ê³  í•´ì„í•˜ê¸°\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ ì‹¤ìŠµ í€´ì¦ˆ ì •ë‹µ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. p-value í•´ì„ â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ p-value ì¤‘ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•  ìˆ˜ ìˆëŠ” ê²ƒì„ ëª¨ë‘ ì°¾ìœ¼ì„¸ìš”. (ìœ ì˜ìˆ˜ì¤€ Î± = 0.05)\n",
    "\n",
    "```python\n",
    "p_values = [0.001, 0.03, 0.08, 0.15, 0.50]\n",
    "```\n",
    "\n",
    "**ê¸°ëŒ€ ê²°ê³¼**: ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•  ìˆ˜ ìˆëŠ” p-value ë¦¬ìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "p_values = [0.001, 0.03, 0.08, 0.15, 0.50]\n",
    "alpha = 0.05  # ìœ ì˜ìˆ˜ì¤€ ì„¤ì •\n",
    "\n",
    "# ë°©ë²• 1: ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ìœ¼ë¡œ í•„í„°ë§\n",
    "rejected = [p for p in p_values if p < alpha]\n",
    "\n",
    "print(\"ìœ ì˜ìˆ˜ì¤€ alpha = 0.05 ê¸°ì¤€\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ê·€ë¬´ê°€ì„¤ ê¸°ê° ê°€ëŠ¥í•œ p-value: {rejected}\")\n",
    "print(f\"ê·€ë¬´ê°€ì„¤ ì±„íƒë˜ëŠ” p-value: {[p for p in p_values if p >= alpha]}\")\n",
    "\n",
    "# ìƒì„¸ í•´ì„\n",
    "print(\"\\nìƒì„¸ í•´ì„:\")\n",
    "for p in p_values:\n",
    "    if p < alpha:\n",
    "        print(f\"  p = {p:.3f} < 0.05 -> ê·€ë¬´ê°€ì„¤ ê¸°ê°\")\n",
    "    else:\n",
    "        print(f\"  p = {p:.3f} >= 0.05 -> ê·€ë¬´ê°€ì„¤ ì±„íƒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert rejected == [0.001, 0.03], \"ê·€ë¬´ê°€ì„¤ ê¸°ê° p-valueê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.\"\n",
    "assert len(rejected) == 2, \"ê¸°ê° ê°€ëŠ¥í•œ p-valueëŠ” 2ê°œì…ë‹ˆë‹¤.\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q1 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- p-valueì™€ ìœ ì˜ìˆ˜ì¤€(alpha)ì„ ë¹„êµí•˜ì—¬ ê·€ë¬´ê°€ì„¤ ê¸°ê° ì—¬ë¶€ íŒë‹¨\n",
    "- p < alphaì´ë©´ ê·€ë¬´ê°€ì„¤ ê¸°ê° (í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨)\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- p-value: ê·€ë¬´ê°€ì„¤ì´ ì°¸ì¼ ë•Œ, ê´€ì¸¡ëœ ë°ì´í„°(ë˜ëŠ” ë” ê·¹ë‹¨ì ì¸ ë°ì´í„°)ê°€ ë‚˜ì˜¬ í™•ë¥ \n",
    "- ìœ ì˜ìˆ˜ì¤€(alpha): ê·€ë¬´ê°€ì„¤ì´ ì°¸ì¸ë°ë„ ê¸°ê°í•  ìµœëŒ€ í—ˆìš© í™•ë¥  (ë³´í†µ 0.05)\n",
    "- p < alpha: ê·€ë¬´ê°€ì„¤ ê¸°ê° -> \"í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨\"\n",
    "\n",
    "**ëŒ€ì•ˆ ë°©ë²•**:\n",
    "```python\n",
    "# filter í•¨ìˆ˜ ì‚¬ìš©\n",
    "rejected = list(filter(lambda p: p < 0.05, p_values))\n",
    "\n",
    "# numpy ì‚¬ìš©\n",
    "arr = np.array(p_values)\n",
    "rejected = arr[arr < 0.05].tolist()\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- p < alphaë¥¼ p <= alphaë¡œ ì˜ëª» ì‚¬ìš© (ì—„ë°€íˆëŠ” < ì‚¬ìš©)\n",
    "- ìœ ì˜ìˆ˜ì¤€ì„ ëª…ì‹œí•˜ì§€ ì•Šê³  í•´ì„\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- p-value í•´ì„ ì‹œ í•­ìƒ ìœ ì˜ìˆ˜ì¤€ì„ ë¨¼ì € ëª…ì‹œí•˜ì„¸ìš”\n",
    "- 0.05ê°€ ê´€í–‰ì´ì§€ë§Œ ë¶„ì•¼ë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ (ì˜ë£Œ: 0.01, íƒìƒ‰ì : 0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q2. ë‹¨ì¼ í‘œë³¸ t-test â­â­\n",
    "\n",
    "**ë¬¸ì œ**: í•œ ë§¤ì¥ì˜ ì¼ì¼ í‰ê·  ë§¤ì¶œì´ 150ë§Œì›ì¸ì§€ ê²€ì¦í•˜ì„¸ìš”. (ìœ ì˜ìˆ˜ì¤€ 0.05)\n",
    "\n",
    "```python\n",
    "daily_sales = [145, 152, 148, 155, 150, 147, 153, 149, 151, 146]\n",
    "target_avg = 150\n",
    "```\n",
    "\n",
    "**ì¶œë ¥**: t-statistic, p-value, ê²°ë¡  (ê·€ë¬´ê°€ì„¤ ê¸°ê° ì—¬ë¶€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "daily_sales = [145, 152, 148, 155, 150, 147, 153, 149, 151, 146]\n",
    "target_avg = 150\n",
    "alpha = 0.05\n",
    "\n",
    "# ê°€ì„¤ ì„¤ì •\n",
    "# H0: í‰ê·  ë§¤ì¶œ = 150ë§Œì›\n",
    "# H1: í‰ê·  ë§¤ì¶œ != 150ë§Œì›\n",
    "\n",
    "# ë‹¨ì¼ í‘œë³¸ t-test ìˆ˜í–‰\n",
    "t_stat, p_value = stats.ttest_1samp(daily_sales, target_avg)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=\" * 50)\n",
    "print(\"ë‹¨ì¼ í‘œë³¸ t-test ê²°ê³¼\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nê°€ì„¤ ì„¤ì •:\")\n",
    "print(f\"  H0: í‰ê·  ë§¤ì¶œ = {target_avg}ë§Œì›\")\n",
    "print(f\"  H1: í‰ê·  ë§¤ì¶œ != {target_avg}ë§Œì›\")\n",
    "\n",
    "print(f\"\\ní‘œë³¸ í†µê³„ëŸ‰:\")\n",
    "print(f\"  í‘œë³¸ í‰ê· : {np.mean(daily_sales):.2f}ë§Œì›\")\n",
    "print(f\"  í‘œë³¸ í‘œì¤€í¸ì°¨: {np.std(daily_sales, ddof=1):.2f}ë§Œì›\")\n",
    "print(f\"  í‘œë³¸ í¬ê¸°: {len(daily_sales)}\")\n",
    "\n",
    "print(f\"\\nê²€ì • ê²°ê³¼:\")\n",
    "print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "print(f\"  p-value: {p_value:.4f}\")\n",
    "\n",
    "print(f\"\\nê²°ë¡  (alpha = {alpha}):\")\n",
    "if p_value < alpha:\n",
    "    print(f\"  p-value ({p_value:.4f}) < alpha ({alpha})\")\n",
    "    print(f\"  -> ê·€ë¬´ê°€ì„¤ ê¸°ê°\")\n",
    "    print(f\"  -> ë§¤ì¥ í‰ê·  ë§¤ì¶œì€ {target_avg}ë§Œì›ê³¼ ìœ ì˜í•œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"  p-value ({p_value:.4f}) >= alpha ({alpha})\")\n",
    "    print(f\"  -> ê·€ë¬´ê°€ì„¤ ì±„íƒ\")\n",
    "    print(f\"  -> ë§¤ì¥ í‰ê·  ë§¤ì¶œì€ {target_avg}ë§Œì›ê³¼ ìœ ì˜í•œ ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert isinstance(t_stat, float), \"t_statëŠ” float íƒ€ì…ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert isinstance(p_value, float), \"p_valueëŠ” float íƒ€ì…ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert 0 <= p_value <= 1, \"p-valueëŠ” 0ê³¼ 1 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "# ì´ ê²½ìš° p-valueê°€ 0.05ë³´ë‹¤ í¬ë¯€ë¡œ ê·€ë¬´ê°€ì„¤ ì±„íƒ\n",
    "assert p_value > 0.05, \"ì´ ë°ì´í„°ì—ì„œëŠ” p-valueê°€ 0.05ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q2 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. ê°€ì„¤ ì„¤ì •: H0 (í‰ê·  = 150) vs H1 (í‰ê·  != 150)\n",
    "2. `stats.ttest_1samp()` í•¨ìˆ˜ë¡œ ë‹¨ì¼ í‘œë³¸ t-test ìˆ˜í–‰\n",
    "3. p-valueì™€ ìœ ì˜ìˆ˜ì¤€ ë¹„êµí•˜ì—¬ ê²°ë¡  ë„ì¶œ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ë‹¨ì¼ í‘œë³¸ t-test: í•œ ê·¸ë£¹ì˜ í‰ê· ì´ íŠ¹ì • ê°’ê³¼ ê°™ì€ì§€ ê²€ì •\n",
    "- t-statistic: (í‘œë³¸í‰ê·  - ëª¨ì§‘ë‹¨í‰ê· ) / (í‘œë³¸í‘œì¤€í¸ì°¨ / sqrt(n))\n",
    "- ì–‘ì¸¡ ê²€ì •(two-tailed): ê¸°ë³¸ê°’, \"ê°™ì§€ ì•Šë‹¤\"ë¥¼ ê²€ì •\n",
    "\n",
    "**ëŒ€ì•ˆ ë°©ë²•**:\n",
    "```python\n",
    "# ìˆ˜ë™ ê³„ì‚°\n",
    "sample_mean = np.mean(daily_sales)\n",
    "sample_std = np.std(daily_sales, ddof=1)  # ë¶ˆí¸ í‘œì¤€í¸ì°¨\n",
    "n = len(daily_sales)\n",
    "t_manual = (sample_mean - target_avg) / (sample_std / np.sqrt(n))\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ë‹¨ì¸¡ ê²€ì •ê³¼ ì–‘ì¸¡ ê²€ì • í˜¼ë™ (stats.ttest_1sampì€ ì–‘ì¸¡ ê²€ì •)\n",
    "- ddof=1 (ë¶ˆí¸ í‘œì¤€í¸ì°¨) ì‚¬ìš© ì•ˆí•¨\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë‹¨ì¼ í‘œë³¸ t-testëŠ” \"ìš°ë¦¬ íšŒì‚¬ vs ì—…ê³„ í‰ê· \" ë¹„êµì— ìœ ìš©\n",
    "- í‘œë³¸ í¬ê¸°ê°€ ì‘ìœ¼ë©´ ê²€ì •ë ¥ì´ ë‚®ì•„ ìœ ì˜í•œ ì°¨ì´ë¥¼ ëª» ì°¾ì„ ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q3. ë…ë¦½ í‘œë³¸ t-test â­â­\n",
    "\n",
    "**ë¬¸ì œ**: í‰ì¼ê³¼ ì£¼ë§ì˜ í‰ê·  ë°©ë¬¸ì ìˆ˜ì— ì°¨ì´ê°€ ìˆëŠ”ì§€ ê²€ì¦í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "weekday_visitors = [320, 345, 330, 355, 340, 325, 350]\n",
    "weekend_visitors = [450, 480, 465, 495, 470, 485, 475]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "weekday_visitors = [320, 345, 330, 355, 340, 325, 350]\n",
    "weekend_visitors = [450, 480, 465, 495, 470, 485, 475]\n",
    "alpha = 0.05\n",
    "\n",
    "# ê°€ì„¤ ì„¤ì •\n",
    "# H0: í‰ì¼ ë°©ë¬¸ì í‰ê·  = ì£¼ë§ ë°©ë¬¸ì í‰ê· \n",
    "# H1: í‰ì¼ ë°©ë¬¸ì í‰ê·  != ì£¼ë§ ë°©ë¬¸ì í‰ê· \n",
    "\n",
    "# ë…ë¦½ í‘œë³¸ t-test ìˆ˜í–‰\n",
    "t_stat, p_value = stats.ttest_ind(weekday_visitors, weekend_visitors)\n",
    "\n",
    "# ê¸°ì´ˆ í†µê³„ëŸ‰ ê³„ì‚°\n",
    "weekday_mean = np.mean(weekday_visitors)\n",
    "weekend_mean = np.mean(weekend_visitors)\n",
    "difference = weekend_mean - weekday_mean\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=\" * 50)\n",
    "print(\"ë…ë¦½ í‘œë³¸ t-test ê²°ê³¼\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\ní‰ì¼ ë°©ë¬¸ì:\")\n",
    "print(f\"  í‰ê· : {weekday_mean:.1f}ëª…\")\n",
    "print(f\"  í‘œì¤€í¸ì°¨: {np.std(weekday_visitors, ddof=1):.2f}\")\n",
    "\n",
    "print(f\"\\nì£¼ë§ ë°©ë¬¸ì:\")\n",
    "print(f\"  í‰ê· : {weekend_mean:.1f}ëª…\")\n",
    "print(f\"  í‘œì¤€í¸ì°¨: {np.std(weekend_visitors, ddof=1):.2f}\")\n",
    "\n",
    "print(f\"\\nì°¨ì´: {difference:.1f}ëª… ({(difference/weekday_mean)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nê²€ì • ê²°ê³¼:\")\n",
    "print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "print(f\"  p-value: {p_value:.6f}\")\n",
    "\n",
    "print(f\"\\nê²°ë¡ :\")\n",
    "if p_value < alpha:\n",
    "    print(f\"  p-value ({p_value:.6f}) < alpha ({alpha})\")\n",
    "    print(f\"  -> ê·€ë¬´ê°€ì„¤ ê¸°ê°\")\n",
    "    print(f\"  -> í‰ì¼ê³¼ ì£¼ë§ì˜ ë°©ë¬¸ì ìˆ˜ì— ìœ ì˜í•œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(f\"  p-value ({p_value:.6f}) >= alpha ({alpha})\")\n",
    "    print(f\"  -> ê·€ë¬´ê°€ì„¤ ì±„íƒ\")\n",
    "    print(f\"  -> í‰ì¼ê³¼ ì£¼ë§ì˜ ë°©ë¬¸ì ìˆ˜ì— ìœ ì˜í•œ ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert p_value < 0.05, \"ì´ ë°ì´í„°ì—ì„œëŠ” p-valueê°€ 0.05ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert t_stat < 0, \"ì£¼ë§ì´ ë” ë§ìœ¼ë¯€ë¡œ t-statisticì€ ìŒìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert weekend_mean > weekday_mean, \"ì£¼ë§ ë°©ë¬¸ìê°€ ë” ë§ì•„ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q3 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. ë‘ ë…ë¦½ëœ ê·¸ë£¹(í‰ì¼ vs ì£¼ë§)ì˜ í‰ê·  ì°¨ì´ ê²€ì •\n",
    "2. `stats.ttest_ind()` í•¨ìˆ˜ë¡œ ë…ë¦½ í‘œë³¸ t-test ìˆ˜í–‰\n",
    "3. í‰ê·  ì°¨ì´ì˜ í†µê³„ì  ìœ ì˜ì„± íŒë‹¨\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ë…ë¦½ í‘œë³¸ t-test: ì„œë¡œ ë‹¤ë¥¸ ë‘ ê·¸ë£¹ì˜ í‰ê·  ë¹„êµ\n",
    "- \"ë…ë¦½\": ë‘ ê·¸ë£¹ì´ ì„œë¡œ ê´€ë ¨ ì—†ìŒ (ê°™ì€ ì‚¬ëŒì´ ì•„ë‹˜)\n",
    "- ë“±ë¶„ì‚° ê°€ì •: ê¸°ë³¸ì ìœ¼ë¡œ ë‘ ê·¸ë£¹ì˜ ë¶„ì‚°ì´ ê°™ë‹¤ê³  ê°€ì •\n",
    "\n",
    "**ëŒ€ì•ˆ ë°©ë²•**:\n",
    "```python\n",
    "# ë“±ë¶„ì‚° ê°€ì • ì—†ëŠ” Welch's t-test\n",
    "t_stat, p_value = stats.ttest_ind(weekday_visitors, weekend_visitors, equal_var=False)\n",
    "\n",
    "# Levene ê²€ì •ìœ¼ë¡œ ë“±ë¶„ì‚° ê°€ì • í™•ì¸\n",
    "levene_stat, levene_p = stats.levene(weekday_visitors, weekend_visitors)\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ë…ë¦½ í‘œë³¸ t-testì™€ ëŒ€ì‘ í‘œë³¸ t-test í˜¼ë™\n",
    "- ê°™ì€ ì‚¬ëŒì˜ ì „í›„ ë¹„êµì— ë…ë¦½ t-test ì‚¬ìš© (ì˜ëª»ë¨)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- A/B í…ŒìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ê²€ì • ë°©ë²•\n",
    "- í‘œë³¸ í¬ê¸°ê°€ ë‹¤ë¥´ê±°ë‚˜ ë¶„ì‚°ì´ ë‹¤ë¥´ë©´ `equal_var=False` ì˜µì…˜ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q4. ëŒ€ì‘ í‘œë³¸ t-test â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë¦¬ë‰´ì–¼ ì „í›„ ì‚¬ì´íŠ¸ ì´ìš©ì‹œê°„ì— ìœ ì˜í•œ ì°¨ì´ê°€ ìˆëŠ”ì§€ ê²€ì¦í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "before_renewal = [3.2, 3.5, 3.1, 3.8, 3.4, 3.6, 3.3, 3.7]\n",
    "after_renewal = [4.1, 4.3, 4.0, 4.5, 4.2, 4.4, 4.1, 4.6]\n",
    "```\n",
    "\n",
    "**ì¶œë ¥**: í‰ê·  ì¦ê°€ëŸ‰, t-statistic, p-value, ê²°ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "before_renewal = [3.2, 3.5, 3.1, 3.8, 3.4, 3.6, 3.3, 3.7]\n",
    "after_renewal = [4.1, 4.3, 4.0, 4.5, 4.2, 4.4, 4.1, 4.6]\n",
    "alpha = 0.05\n",
    "\n",
    "# ê°€ì„¤ ì„¤ì •\n",
    "# H0: ë¦¬ë‰´ì–¼ ì „í›„ ì´ìš©ì‹œê°„ì— ì°¨ì´ê°€ ì—†ë‹¤\n",
    "# H1: ë¦¬ë‰´ì–¼ í›„ ì´ìš©ì‹œê°„ì´ ì¦ê°€í–ˆë‹¤\n",
    "\n",
    "# ê°œì¸ë³„ ë³€í™”ëŸ‰ ê³„ì‚°\n",
    "differences = [after - before for before, after in zip(before_renewal, after_renewal)]\n",
    "\n",
    "# ëŒ€ì‘ í‘œë³¸ t-test ìˆ˜í–‰\n",
    "t_stat, p_value = stats.ttest_rel(before_renewal, after_renewal)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=\" * 50)\n",
    "print(\"ëŒ€ì‘ í‘œë³¸ t-test ê²°ê³¼\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\në¦¬ë‰´ì–¼ ì „:\")\n",
    "print(f\"  í‰ê·  ì´ìš©ì‹œê°„: {np.mean(before_renewal):.2f}ë¶„\")\n",
    "\n",
    "print(f\"\\në¦¬ë‰´ì–¼ í›„:\")\n",
    "print(f\"  í‰ê·  ì´ìš©ì‹œê°„: {np.mean(after_renewal):.2f}ë¶„\")\n",
    "\n",
    "print(f\"\\në³€í™”ëŸ‰:\")\n",
    "print(f\"  í‰ê·  ì¦ê°€ëŸ‰: {np.mean(differences):.2f}ë¶„\")\n",
    "print(f\"  ì¦ê°€ìœ¨: {(np.mean(after_renewal)/np.mean(before_renewal)-1)*100:.1f}%\")\n",
    "print(f\"  ê°œì¸ë³„ ë³€í™”: {[f'{d:.1f}' for d in differences]}\")\n",
    "\n",
    "print(f\"\\nê²€ì • ê²°ê³¼:\")\n",
    "print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "print(f\"  p-value: {p_value:.6f}\")\n",
    "\n",
    "print(f\"\\nê²°ë¡ :\")\n",
    "if p_value < alpha:\n",
    "    print(f\"  p-value ({p_value:.6f}) < alpha ({alpha})\")\n",
    "    print(f\"  -> ê·€ë¬´ê°€ì„¤ ê¸°ê°\")\n",
    "    print(f\"  -> ë¦¬ë‰´ì–¼ì´ ì´ìš©ì‹œê°„ ì¦ê°€ì— í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(f\"  p-value ({p_value:.6f}) >= alpha ({alpha})\")\n",
    "    print(f\"  -> ê·€ë¬´ê°€ì„¤ ì±„íƒ\")\n",
    "    print(f\"  -> ë¦¬ë‰´ì–¼ íš¨ê³¼ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert p_value < 0.05, \"ì´ ë°ì´í„°ì—ì„œëŠ” p-valueê°€ 0.05ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert np.mean(differences) > 0, \"ë¦¬ë‰´ì–¼ í›„ ì´ìš©ì‹œê°„ì´ ì¦ê°€í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert len(before_renewal) == len(after_renewal), \"ì „í›„ ë°ì´í„° ê°œìˆ˜ê°€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q4 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. ê°™ì€ ì‚¬ìš©ìì˜ ì „í›„ ë°ì´í„°ì´ë¯€ë¡œ ëŒ€ì‘ í‘œë³¸ t-test ì‚¬ìš©\n",
    "2. `stats.ttest_rel()` í•¨ìˆ˜ë¡œ ê²€ì • ìˆ˜í–‰\n",
    "3. ê°œì¸ë³„ ë³€í™”ëŸ‰ë„ í•¨ê»˜ ë¶„ì„\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ëŒ€ì‘ í‘œë³¸ t-test: ë™ì¼ ëŒ€ìƒì˜ ì „í›„ ë¹„êµ (paired)\n",
    "- ì°¨ì´ê°’ì˜ í‰ê· ì´ 0ì¸ì§€ ê²€ì •í•˜ëŠ” ê²ƒê³¼ ë™ì¼\n",
    "- ê°œì¸ì°¨ë¥¼ í†µì œí•˜ì—¬ ë” ë¯¼ê°í•œ ê²€ì • ê°€ëŠ¥\n",
    "\n",
    "**ëŒ€ì•ˆ ë°©ë²•**:\n",
    "```python\n",
    "# ì°¨ì´ê°’ì— ëŒ€í•œ ë‹¨ì¼ í‘œë³¸ t-test (ë™ì¼í•œ ê²°ê³¼)\n",
    "t_stat2, p_value2 = stats.ttest_1samp(differences, 0)\n",
    "# ì´ê²ƒì€ \"í‰ê·  ë³€í™”ëŸ‰ì´ 0ì¸ê°€?\"ë¥¼ ê²€ì •\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ì „í›„ ë¹„êµì— ë…ë¦½ í‘œë³¸ t-test ì‚¬ìš© (ê°œì¸ì°¨ í†µì œ ëª»í•¨)\n",
    "- ì „í›„ ë°ì´í„° ìˆœì„œê°€ ë§ì§€ ì•ŠìŒ\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë¦¬ë‰´ì–¼ íš¨ê³¼, êµìœ¡ íš¨ê³¼, ì¹˜ë£Œ íš¨ê³¼ ë“± ì „í›„ ë¹„êµì— í•„ìˆ˜\n",
    "- ê°œì¸ë³„ ë³€í™”ëŸ‰ì„ í•¨ê»˜ ë³´ë©´ ì´ìƒì¹˜ ë°œê²¬ì— ìœ ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q5. Chi-square ê²€ì • â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì—°ë ¹ëŒ€ì™€ ì œí’ˆ êµ¬ë§¤ ì—¬ë¶€ê°€ ë…ë¦½ì ì¸ì§€ ê²€ì¦í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "# êµì°¨í‘œ: í–‰(ì—°ë ¹ëŒ€), ì—´(êµ¬ë§¤ ì—¬ë¶€)\n",
    "age_purchase = np.array([\n",
    "    [30, 70],  # 20ëŒ€: êµ¬ë§¤O, êµ¬ë§¤X\n",
    "    [50, 50],  # 30ëŒ€\n",
    "    [40, 60]   # 40ëŒ€\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "age_purchase = np.array([\n",
    "    [30, 70],  # 20ëŒ€: êµ¬ë§¤O, êµ¬ë§¤X\n",
    "    [50, 50],  # 30ëŒ€\n",
    "    [40, 60]   # 40ëŒ€\n",
    "])\n",
    "alpha = 0.05\n",
    "\n",
    "# ê°€ì„¤ ì„¤ì •\n",
    "# H0: ì—°ë ¹ëŒ€ì™€ ì œí’ˆ êµ¬ë§¤ ì—¬ë¶€ëŠ” ë…ë¦½ì ì´ë‹¤\n",
    "# H1: ì—°ë ¹ëŒ€ì™€ ì œí’ˆ êµ¬ë§¤ ì—¬ë¶€ëŠ” ê´€ë ¨ì´ ìˆë‹¤\n",
    "\n",
    "# Chi-square ê²€ì • ìˆ˜í–‰\n",
    "chi2, p_value, dof, expected = stats.chi2_contingency(age_purchase)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=\" * 60)\n",
    "print(\"Chi-square ê²€ì • ê²°ê³¼\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ê´€ì¸¡ ë¹ˆë„ ì¶œë ¥\n",
    "print(\"\\nê´€ì¸¡ ë¹ˆë„:\")\n",
    "observed_df = pd.DataFrame(\n",
    "    age_purchase,\n",
    "    index=['20ëŒ€', '30ëŒ€', '40ëŒ€'],\n",
    "    columns=['êµ¬ë§¤O', 'êµ¬ë§¤X']\n",
    ")\n",
    "observed_df['í•©ê³„'] = observed_df.sum(axis=1)\n",
    "observed_df['êµ¬ë§¤ìœ¨'] = (observed_df['êµ¬ë§¤O'] / observed_df['í•©ê³„'] * 100).round(1).astype(str) + '%'\n",
    "print(observed_df)\n",
    "\n",
    "# ê¸°ëŒ€ ë¹ˆë„ ì¶œë ¥\n",
    "print(\"\\nê¸°ëŒ€ ë¹ˆë„ (ë…ë¦½ ê°€ì • ì‹œ):\")\n",
    "expected_df = pd.DataFrame(\n",
    "    expected,\n",
    "    index=['20ëŒ€', '30ëŒ€', '40ëŒ€'],\n",
    "    columns=['êµ¬ë§¤O', 'êµ¬ë§¤X']\n",
    ").round(2)\n",
    "print(expected_df)\n",
    "\n",
    "print(f\"\\nê²€ì • ê²°ê³¼:\")\n",
    "print(f\"  Chi-square í†µê³„ëŸ‰: {chi2:.4f}\")\n",
    "print(f\"  p-value: {p_value:.4f}\")\n",
    "print(f\"  ììœ ë„: {dof}\")\n",
    "\n",
    "print(f\"\\nê²°ë¡ :\")\n",
    "if p_value < alpha:\n",
    "    print(f\"  p-value ({p_value:.4f}) < alpha ({alpha})\")\n",
    "    print(f\"  -> ê·€ë¬´ê°€ì„¤ ê¸°ê°\")\n",
    "    print(f\"  -> ì—°ë ¹ëŒ€ì™€ ì œí’ˆ êµ¬ë§¤ ì—¬ë¶€ëŠ” ìœ ì˜í•œ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(f\"  p-value ({p_value:.4f}) >= alpha ({alpha})\")\n",
    "    print(f\"  -> ê·€ë¬´ê°€ì„¤ ì±„íƒ\")\n",
    "    print(f\"  -> ì—°ë ¹ëŒ€ì™€ ì œí’ˆ êµ¬ë§¤ ì—¬ë¶€ëŠ” ë…ë¦½ì ì…ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert chi2 > 0, \"Chi-square í†µê³„ëŸ‰ì€ ì–‘ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert dof == 2, \"ììœ ë„ëŠ” (3-1) * (2-1) = 2ì—¬ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert expected.shape == age_purchase.shape, \"ê¸°ëŒ€ ë¹ˆë„ì™€ ê´€ì¸¡ ë¹ˆë„ì˜ í˜•íƒœê°€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q5 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. êµì°¨í‘œ(contingency table) í˜•íƒœë¡œ ë°ì´í„° ì¤€ë¹„\n",
    "2. `stats.chi2_contingency()` í•¨ìˆ˜ë¡œ Chi-square ê²€ì • ìˆ˜í–‰\n",
    "3. ê´€ì¸¡ ë¹ˆë„ì™€ ê¸°ëŒ€ ë¹ˆë„ ë¹„êµ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- Chi-square ê²€ì •: ë‘ ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ë…ë¦½ì„± ê²€ì •\n",
    "- ê¸°ëŒ€ ë¹ˆë„: ë‘ ë³€ìˆ˜ê°€ ë…ë¦½ì´ë©´ ê¸°ëŒ€ë˜ëŠ” ë¹ˆë„\n",
    "- ììœ ë„: (í–‰-1) * (ì—´-1) = (3-1) * (2-1) = 2\n",
    "\n",
    "**ëŒ€ì•ˆ ë°©ë²•**:\n",
    "```python\n",
    "# Fisher's exact test (ì†Œí‘œë³¸ì— ì í•©)\n",
    "# 2x2 í‘œë§Œ ì§€ì›\n",
    "oddsratio, fisher_p = stats.fisher_exact([[30, 70], [50, 50]])\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- êµì°¨í‘œ í–‰/ì—´ ìˆœì„œ í˜¼ë™\n",
    "- ê¸°ëŒ€ ë¹ˆë„ê°€ 5 ë¯¸ë§Œì¸ ì…€ì´ ìˆì„ ë•Œ Chi-square ë¶€ì ì ˆ\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì„¤ë¬¸ì¡°ì‚¬ ë¶„ì„ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©\n",
    "- ê¸°ëŒ€ ë¹ˆë„ê°€ 5 ë¯¸ë§Œì¸ ì…€ì´ 20% ì´ìƒì´ë©´ Fisher's exact test ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2 ì‹¬í™” í€´ì¦ˆ ì •ë‹µ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. ANOVA ë¶„ì„ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: 3ê°œ ë§ˆì¼€íŒ… ì±„ë„ì˜ í‰ê·  ì „í™˜ìœ¨ì— ì°¨ì´ê°€ ìˆëŠ”ì§€ ANOVAë¡œ ê²€ì¦í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "email = [3.2, 3.5, 3.8, 3.1, 3.6]\n",
    "sns = [4.1, 4.3, 4.5, 3.9, 4.2]\n",
    "search = [3.0, 2.8, 3.2, 2.9, 3.1]\n",
    "```\n",
    "\n",
    "**ì¶œë ¥**: ê° ì±„ë„ í‰ê· , F-statistic, p-value, ìµœê³  ì„±ê³¼ ì±„ë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "email = [3.2, 3.5, 3.8, 3.1, 3.6]\n",
    "sns = [4.1, 4.3, 4.5, 3.9, 4.2]\n",
    "search = [3.0, 2.8, 3.2, 2.9, 3.1]\n",
    "alpha = 0.05\n",
    "\n",
    "# ê°€ì„¤ ì„¤ì •\n",
    "# H0: ëª¨ë“  ì±„ë„ì˜ í‰ê·  ì „í™˜ìœ¨ì´ ê°™ë‹¤\n",
    "# H1: ì ì–´ë„ í•œ ì±„ë„ì˜ í‰ê·  ì „í™˜ìœ¨ì´ ë‹¤ë¥´ë‹¤\n",
    "\n",
    "# One-Way ANOVA ìˆ˜í–‰\n",
    "f_stat, p_value = stats.f_oneway(email, sns, search)\n",
    "\n",
    "# ì±„ë„ë³„ í†µê³„ëŸ‰\n",
    "channels = {\n",
    "    'ì´ë©”ì¼': email,\n",
    "    'SNS': sns,\n",
    "    'ê²€ìƒ‰ê´‘ê³ ': search\n",
    "}\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=\" * 60)\n",
    "print(\"ANOVA ë¶„ì„ ê²°ê³¼\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nì±„ë„ë³„ ì „í™˜ìœ¨ í†µê³„:\")\n",
    "channel_means = {}\n",
    "for name, data in channels.items():\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data, ddof=1)\n",
    "    channel_means[name] = mean\n",
    "    print(f\"  {name}: í‰ê·  {mean:.2f}%, í‘œì¤€í¸ì°¨ {std:.2f}\")\n",
    "\n",
    "print(f\"\\nê²€ì • ê²°ê³¼:\")\n",
    "print(f\"  F-statistic: {f_stat:.4f}\")\n",
    "print(f\"  p-value: {p_value:.6f}\")\n",
    "\n",
    "print(f\"\\nê²°ë¡ :\")\n",
    "if p_value < alpha:\n",
    "    print(f\"  p-value ({p_value:.6f}) < alpha ({alpha})\")\n",
    "    print(f\"  -> ê·€ë¬´ê°€ì„¤ ê¸°ê°\")\n",
    "    print(f\"  -> ì±„ë„ ê°„ ì „í™˜ìœ¨ì— ìœ ì˜í•œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "    # ìµœê³ /ìµœì € ì„±ê³¼ ì±„ë„\n",
    "    best_channel = max(channel_means, key=channel_means.get)\n",
    "    worst_channel = min(channel_means, key=channel_means.get)\n",
    "    print(f\"\\n  ìµœê³  ì„±ê³¼ ì±„ë„: {best_channel} ({channel_means[best_channel]:.2f}%)\")\n",
    "    print(f\"  ìµœì € ì„±ê³¼ ì±„ë„: {worst_channel} ({channel_means[worst_channel]:.2f}%)\")\n",
    "else:\n",
    "    print(f\"  p-value ({p_value:.6f}) >= alpha ({alpha})\")\n",
    "    print(f\"  -> ê·€ë¬´ê°€ì„¤ ì±„íƒ\")\n",
    "    print(f\"  -> ì±„ë„ ê°„ ì „í™˜ìœ¨ì— ìœ ì˜í•œ ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert f_stat > 0, \"F-statisticì€ ì–‘ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert p_value < 0.05, \"ì´ ë°ì´í„°ì—ì„œëŠ” p-valueê°€ 0.05ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert max(channel_means, key=channel_means.get) == 'SNS', \"SNSê°€ ìµœê³  ì„±ê³¼ ì±„ë„ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q6 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. 3ê°œ ê·¸ë£¹ì˜ í‰ê·  ë¹„êµì´ë¯€ë¡œ ANOVA ì‚¬ìš©\n",
    "2. `stats.f_oneway()` í•¨ìˆ˜ë¡œ One-Way ANOVA ìˆ˜í–‰\n",
    "3. ìœ ì˜í•˜ë©´ ì–´ë–¤ ê·¸ë£¹ì´ ë‹¤ë¥¸ì§€ ì¶”ê°€ ë¶„ì„\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ANOVA: 3ê°œ ì´ìƒ ê·¸ë£¹ì˜ í‰ê·  ì°¨ì´ ë™ì‹œ ê²€ì •\n",
    "- F-statistic: ì§‘ë‹¨ ê°„ ë¶„ì‚° / ì§‘ë‹¨ ë‚´ ë¶„ì‚°\n",
    "- ê·€ë¬´ê°€ì„¤: ëª¨ë“  ê·¸ë£¹ í‰ê· ì´ ê°™ë‹¤\n",
    "\n",
    "**ëŒ€ì•ˆ ë°©ë²•**:\n",
    "```python\n",
    "# ì‚¬í›„ ê²€ì • (Tukey HSD)\n",
    "from scipy.stats import tukey_hsd\n",
    "result = tukey_hsd(email, sns, search)\n",
    "# ì–´ë–¤ ê·¸ë£¹ë“¤ ê°„ì— ì°¨ì´ê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- 2ê°œ ê·¸ë£¹ ë¹„êµì— ANOVA ì‚¬ìš© (t-testê°€ ì ì ˆ)\n",
    "- ANOVA í›„ ì‚¬í›„ ê²€ì • ìƒëµ\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ANOVAëŠ” \"ì°¨ì´ê°€ ìˆë‹¤\"ë§Œ ì•Œë ¤ì¤Œ, ì–´ë–¤ ê·¸ë£¹ì¸ì§€ëŠ” ì‚¬í›„ ê²€ì • í•„ìš”\n",
    "- ë‹¤ì¤‘ ë¹„êµ ì‹œ Bonferroni ë³´ì • ê³ ë ¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q7. Pearson ìƒê´€ê³„ìˆ˜ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ê³µë¶€ì‹œê°„ê³¼ ì‹œí—˜ì ìˆ˜ì˜ ìƒê´€ê³„ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³  í•´ì„í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "study_hours = [2, 3, 5, 4, 6, 7, 8, 5, 6, 7]\n",
    "test_scores = [60, 65, 75, 70, 80, 85, 90, 72, 78, 88]\n",
    "```\n",
    "\n",
    "**ì¶œë ¥**: ìƒê´€ê³„ìˆ˜, p-value, ìƒê´€ ê°•ë„ í•´ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "study_hours = [2, 3, 5, 4, 6, 7, 8, 5, 6, 7]\n",
    "test_scores = [60, 65, 75, 70, 80, 85, 90, 72, 78, 88]\n",
    "alpha = 0.05\n",
    "\n",
    "# Pearson ìƒê´€ê³„ìˆ˜ ê³„ì‚°\n",
    "pearson_corr, p_value = stats.pearsonr(study_hours, test_scores)\n",
    "\n",
    "# ìƒê´€ ê°•ë„ í•´ì„ í•¨ìˆ˜\n",
    "def interpret_correlation(r):\n",
    "    abs_r = abs(r)\n",
    "    if abs_r >= 0.8:\n",
    "        strength = \"ë§¤ìš° ê°•í•œ\"\n",
    "    elif abs_r >= 0.6:\n",
    "        strength = \"ê°•í•œ\"\n",
    "    elif abs_r >= 0.4:\n",
    "        strength = \"ì¤‘ê°„\"\n",
    "    elif abs_r >= 0.2:\n",
    "        strength = \"ì•½í•œ\"\n",
    "    else:\n",
    "        strength = \"ë§¤ìš° ì•½í•œ\"\n",
    "    \n",
    "    direction = \"ì–‘ì˜\" if r > 0 else \"ìŒì˜\"\n",
    "    return f\"{strength} {direction} ìƒê´€ê´€ê³„\"\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=\" * 50)\n",
    "print(\"Pearson ìƒê´€ë¶„ì„ ê²°ê³¼\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\në°ì´í„° ìš”ì•½:\")\n",
    "print(f\"  ê³µë¶€ì‹œê°„ í‰ê· : {np.mean(study_hours):.1f}ì‹œê°„\")\n",
    "print(f\"  ì‹œí—˜ì ìˆ˜ í‰ê· : {np.mean(test_scores):.1f}ì \")\n",
    "\n",
    "print(f\"\\nìƒê´€ë¶„ì„ ê²°ê³¼:\")\n",
    "print(f\"  Pearson ìƒê´€ê³„ìˆ˜ (r): {pearson_corr:.4f}\")\n",
    "print(f\"  p-value: {p_value:.6f}\")\n",
    "print(f\"  ê²°ì •ê³„ìˆ˜ (r^2): {pearson_corr**2:.4f}\")\n",
    "\n",
    "print(f\"\\ní•´ì„:\")\n",
    "print(f\"  ìƒê´€ ê°•ë„: {interpret_correlation(pearson_corr)}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"  í†µê³„ì  ìœ ì˜ì„±: ìœ ì˜í•¨ (p = {p_value:.6f} < {alpha})\")\n",
    "    print(f\"\\nê²°ë¡ : ê³µë¶€ì‹œê°„ì´ ì¦ê°€í• ìˆ˜ë¡ ì‹œí—˜ì ìˆ˜ê°€ ìœ ì˜í•˜ê²Œ ì¦ê°€í•©ë‹ˆë‹¤.\")\n",
    "    print(f\"       ê³µë¶€ì‹œê°„ì´ ì‹œí—˜ì ìˆ˜ ë³€ë™ì˜ {pearson_corr**2*100:.1f}%ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"  í†µê³„ì  ìœ ì˜ì„±: ìœ ì˜í•˜ì§€ ì•ŠìŒ (p = {p_value:.6f} >= {alpha})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert -1 <= pearson_corr <= 1, \"ìƒê´€ê³„ìˆ˜ëŠ” -1ê³¼ 1 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert pearson_corr > 0.8, \"ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert p_value < 0.05, \"ìƒê´€ê´€ê³„ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q7 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. `stats.pearsonr()` í•¨ìˆ˜ë¡œ Pearson ìƒê´€ê³„ìˆ˜ ê³„ì‚°\n",
    "2. ìƒê´€ê³„ìˆ˜ ì ˆëŒ€ê°’ìœ¼ë¡œ ê°•ë„ í•´ì„\n",
    "3. p-valueë¡œ í†µê³„ì  ìœ ì˜ì„± íŒë‹¨\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- Pearson ìƒê´€ê³„ìˆ˜: ë‘ ì—°ì†í˜• ë³€ìˆ˜ì˜ ì„ í˜• ê´€ê³„ ê°•ë„\n",
    "- ë²”ìœ„: -1 (ì™„ì „ ìŒì˜ ìƒê´€) ~ +1 (ì™„ì „ ì–‘ì˜ ìƒê´€)\n",
    "- ê²°ì •ê³„ìˆ˜(r^2): í•œ ë³€ìˆ˜ê°€ ë‹¤ë¥¸ ë³€ìˆ˜ ë³€ë™ì„ ì„¤ëª…í•˜ëŠ” ë¹„ìœ¨\n",
    "\n",
    "**ëŒ€ì•ˆ ë°©ë²•**:\n",
    "```python\n",
    "# Spearman ìƒê´€ê³„ìˆ˜ (ìˆœìœ„ ê¸°ë°˜)\n",
    "spearman_corr, spearman_p = stats.spearmanr(study_hours, test_scores)\n",
    "\n",
    "# numpyë¡œ ìƒê´€ê³„ìˆ˜ë§Œ ê³„ì‚°\n",
    "corr_matrix = np.corrcoef(study_hours, test_scores)\n",
    "r = corr_matrix[0, 1]\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ìƒê´€ê´€ê³„ë¥¼ ì¸ê³¼ê´€ê³„ë¡œ í•´ì„\n",
    "- ê²°ì •ê³„ìˆ˜(r^2)ì™€ ìƒê´€ê³„ìˆ˜(r) í˜¼ë™\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ìƒê´€ê³„ìˆ˜ëŠ” ì„ í˜• ê´€ê³„ë§Œ ì¸¡ì •, ë¹„ì„ í˜•ì€ ëª» ì¡ìŒ\n",
    "- ì´ìƒì¹˜ì— ë¯¼ê°í•˜ë¯€ë¡œ ì‚°ì ë„ë¡œ ë¨¼ì € í™•ì¸ í•„ìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q8. ì‚°ì ë„ ì‹œê°í™” â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì˜¨ë„ì™€ ì•„ì´ìŠ¤í¬ë¦¼ íŒë§¤ëŸ‰ì˜ ê´€ê³„ë¥¼ `px.scatter`ë¡œ ì‹œê°í™”í•˜ê³  ìƒê´€ê³„ìˆ˜ë¥¼ ì œëª©ì— í‘œì‹œí•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "temperature = [18, 22, 25, 28, 30, 32, 35, 27, 29, 31]\n",
    "icecream_sales = [150, 180, 220, 250, 280, 310, 350, 240, 270, 300]\n",
    "```\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**: trendline ì¶”ê°€, ìƒê´€ê³„ìˆ˜ë¥¼ ì œëª©ì— í¬í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "temperature = [18, 22, 25, 28, 30, 32, 35, 27, 29, 31]\n",
    "icecream_sales = [150, 180, 220, 250, 280, 310, 350, 240, 270, 300]\n",
    "\n",
    "# ìƒê´€ê³„ìˆ˜ ê³„ì‚°\n",
    "pearson_corr, p_value = stats.pearsonr(temperature, icecream_sales)\n",
    "\n",
    "# DataFrame ìƒì„±\n",
    "df = pd.DataFrame({\n",
    "    'ì˜¨ë„': temperature,\n",
    "    'ì•„ì´ìŠ¤í¬ë¦¼íŒë§¤ëŸ‰': icecream_sales\n",
    "})\n",
    "\n",
    "# ì‚°ì ë„ ì‹œê°í™”\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='ì˜¨ë„',\n",
    "    y='ì•„ì´ìŠ¤í¬ë¦¼íŒë§¤ëŸ‰',\n",
    "    title=f'ì˜¨ë„ vs ì•„ì´ìŠ¤í¬ë¦¼ íŒë§¤ëŸ‰ (r = {pearson_corr:.3f}, p = {p_value:.4f})',\n",
    "    trendline='ols',  # ì„ í˜• íšŒê·€ì„  ì¶”ê°€\n",
    "    labels={'ì˜¨ë„': 'ì˜¨ë„ (C)', 'ì•„ì´ìŠ¤í¬ë¦¼íŒë§¤ëŸ‰': 'íŒë§¤ëŸ‰ (ê°œ)'},\n",
    "    width=700,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "# ë§ˆì»¤ ìŠ¤íƒ€ì¼ë§\n",
    "fig.update_traces(\n",
    "    marker=dict(size=12, color='royalblue', line=dict(width=1, color='white')),\n",
    "    selector=dict(mode='markers')\n",
    ")\n",
    "\n",
    "# ì¶”ì„¸ì„  ìŠ¤íƒ€ì¼ë§\n",
    "fig.update_traces(\n",
    "    line=dict(color='red', width=2, dash='dash'),\n",
    "    selector=dict(mode='lines')\n",
    ")\n",
    "\n",
    "# ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
    "fig.update_layout(\n",
    "    font=dict(size=12),\n",
    "    title_font_size=14,\n",
    "    xaxis=dict(gridcolor='lightgray'),\n",
    "    yaxis=dict(gridcolor='lightgray'),\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# í•´ì„ ì¶œë ¥\n",
    "print(f\"\\nìƒê´€ë¶„ì„ ê²°ê³¼:\")\n",
    "print(f\"  ìƒê´€ê³„ìˆ˜: {pearson_corr:.4f}\")\n",
    "print(f\"  p-value: {p_value:.6f}\")\n",
    "print(f\"\\ní•´ì„: ì˜¨ë„ê°€ ë†’ì•„ì§ˆìˆ˜ë¡ ì•„ì´ìŠ¤í¬ë¦¼ íŒë§¤ëŸ‰ì´ ì¦ê°€í•˜ëŠ” ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert pearson_corr > 0.9, \"ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert len(temperature) == len(icecream_sales), \"ë°ì´í„° ê¸¸ì´ê°€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert 'fig' in dir(), \"fig ë³€ìˆ˜ê°€ ì •ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q8 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. `stats.pearsonr()`ë¡œ ìƒê´€ê³„ìˆ˜ ê³„ì‚°\n",
    "2. `px.scatter()`ë¡œ ì‚°ì ë„ ìƒì„± (trendline='ols' ì¶”ê°€)\n",
    "3. ì œëª©ì— ìƒê´€ê³„ìˆ˜ì™€ p-value í‘œì‹œ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ì‚°ì ë„: ë‘ ì—°ì†í˜• ë³€ìˆ˜ì˜ ê´€ê³„ ì‹œê°í™”\n",
    "- trendline='ols': ìµœì†Œì œê³±ë²• íšŒê·€ì„ \n",
    "- ì‹œê°í™”ì™€ í†µê³„ëŸ‰ í•¨ê»˜ ì œì‹œ\n",
    "\n",
    "**ëŒ€ì•ˆ ë°©ë²•**:\n",
    "```python\n",
    "# plotly graph_objects ì‚¬ìš©\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=temperature, y=icecream_sales, mode='markers'))\n",
    "\n",
    "# numpyë¡œ ì¶”ì„¸ì„  ê³„ì‚°\n",
    "z = np.polyfit(temperature, icecream_sales, 1)\n",
    "p = np.poly1d(z)\n",
    "fig.add_trace(go.Scatter(x=temperature, y=p(temperature), mode='lines'))\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- trendline ì˜µì…˜ ë¯¸ì‚¬ìš©\n",
    "- ìƒê´€ê³„ìˆ˜ë¥¼ ê·¸ë˜í”„ì— í‘œì‹œ ì•ˆí•¨\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- í•­ìƒ ì‚°ì ë„ë¡œ ë°ì´í„° ë¶„í¬ í™•ì¸ í›„ ìƒê´€ê³„ìˆ˜ í•´ì„\n",
    "- ì´ìƒì¹˜ê°€ ìƒê´€ê³„ìˆ˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ì‹œê°ì ìœ¼ë¡œ í™•ì¸ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q9. ìƒê´€ê³„ìˆ˜ í–‰ë ¬ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ë°ì´í„°ë¡œ ìƒê´€ê³„ìˆ˜ í–‰ë ¬ì„ ë§Œë“¤ê³  'ë§¤ì¶œ'ê³¼ ê°€ì¥ ê°•í•œ ìƒê´€ì´ ìˆëŠ” ë³€ìˆ˜ë¥¼ ì°¾ìœ¼ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "data = pd.DataFrame({\n",
    "    'ê´‘ê³ ë¹„': [100, 150, 200, 250, 300],\n",
    "    'ë°©ë¬¸ì': [1200, 1800, 2400, 3000, 3600],\n",
    "    'ì²´ë¥˜ì‹œê°„': [3.2, 3.8, 4.5, 5.1, 5.8],\n",
    "    'ë§¤ì¶œ': [120, 180, 240, 300, 360]\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9. ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'ê´‘ê³ ë¹„': [100, 150, 200, 250, 300],\n",
    "    'ë°©ë¬¸ì': [1200, 1800, 2400, 3000, 3600],\n",
    "    'ì²´ë¥˜ì‹œê°„': [3.2, 3.8, 4.5, 5.1, 5.8],\n",
    "    'ë§¤ì¶œ': [120, 180, 240, 300, 360]\n",
    "})\n",
    "\n",
    "# ìƒê´€ê³„ìˆ˜ í–‰ë ¬ ê³„ì‚°\n",
    "corr_matrix = data.corr()\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=\" * 60)\n",
    "print(\"ìƒê´€ê³„ìˆ˜ í–‰ë ¬ ë¶„ì„\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nìƒê´€ê³„ìˆ˜ í–‰ë ¬:\")\n",
    "print(corr_matrix.round(4))\n",
    "\n",
    "# ë§¤ì¶œê³¼ì˜ ìƒê´€ê³„ìˆ˜ ì¶”ì¶œ (ë§¤ì¶œ ìì²´ ì œì™¸)\n",
    "revenue_corr = corr_matrix['ë§¤ì¶œ'].drop('ë§¤ì¶œ')\n",
    "\n",
    "print(\"\\në§¤ì¶œê³¼ì˜ ìƒê´€ê³„ìˆ˜:\")\n",
    "for var, corr in revenue_corr.sort_values(ascending=False).items():\n",
    "    print(f\"  {var}: {corr:.4f}\")\n",
    "\n",
    "# ê°€ì¥ ê°•í•œ ìƒê´€ ë³€ìˆ˜ ì°¾ê¸°\n",
    "strongest_var = revenue_corr.abs().idxmax()\n",
    "strongest_corr = revenue_corr[strongest_var]\n",
    "\n",
    "print(f\"\\nê°€ì¥ ê°•í•œ ìƒê´€ ë³€ìˆ˜: {strongest_var} (r = {strongest_corr:.4f})\")\n",
    "\n",
    "# íˆíŠ¸ë§µ ì‹œê°í™”\n",
    "fig = px.imshow(\n",
    "    corr_matrix,\n",
    "    text_auto='.3f',\n",
    "    aspect='auto',\n",
    "    color_continuous_scale='RdBu_r',\n",
    "    title='ë³€ìˆ˜ ê°„ ìƒê´€ê³„ìˆ˜ íˆíŠ¸ë§µ',\n",
    "    width=500,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(size=12),\n",
    "    title_font_size=14\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9. í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert corr_matrix.shape == (4, 4), \"ìƒê´€ê³„ìˆ˜ í–‰ë ¬ì€ 4x4 í¬ê¸°ì—¬ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert all(corr_matrix.diagonal() == 1), \"ëŒ€ê°ì„ ì€ ëª¨ë‘ 1ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "# ëª¨ë“  ë³€ìˆ˜ê°€ ë§¤ì¶œê³¼ ì™„ë²½í•œ ìƒê´€ê´€ê³„ (r=1.0)\n",
    "assert all(revenue_corr.abs() >= 0.99), \"ëª¨ë“  ë³€ìˆ˜ê°€ ë§¤ì¶œê³¼ ë§¤ìš° ê°•í•œ ìƒê´€ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q9 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. `df.corr()`ë¡œ ìƒê´€ê³„ìˆ˜ í–‰ë ¬ ê³„ì‚°\n",
    "2. ë§¤ì¶œ ì—´ì—ì„œ ê°€ì¥ í° ì ˆëŒ€ê°’ ì°¾ê¸°\n",
    "3. íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ìƒê´€ê³„ìˆ˜ í–‰ë ¬: ëª¨ë“  ë³€ìˆ˜ ìŒì˜ ìƒê´€ê³„ìˆ˜\n",
    "- ëŒ€ê°ì„ ì€ í•­ìƒ 1 (ìê¸° ìì‹ ê³¼ì˜ ìƒê´€)\n",
    "- ëŒ€ì¹­ í–‰ë ¬ (corr(A,B) = corr(B,A))\n",
    "\n",
    "**ëŒ€ì•ˆ ë°©ë²•**:\n",
    "```python\n",
    "# seaborn ì‚¬ìš© (matplotlib ê¸°ë°˜)\n",
    "import seaborn as sns\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r')\n",
    "\n",
    "# íŠ¹ì • ë³€ìˆ˜ì™€ì˜ ìƒê´€ë§Œ ê³„ì‚°\n",
    "for col in data.columns:\n",
    "    if col != 'ë§¤ì¶œ':\n",
    "        r, p = stats.pearsonr(data[col], data['ë§¤ì¶œ'])\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ìê¸° ìì‹ ê³¼ì˜ ìƒê´€(1.0) í¬í•¨í•˜ì—¬ ìµœëŒ“ê°’ ì°¾ê¸°\n",
    "- ìŒì˜ ìƒê´€ ë¬´ì‹œ (ì ˆëŒ€ê°’ìœ¼ë¡œ ë¹„êµí•´ì•¼)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë‹¤ì¤‘ê³µì„ ì„± í™•ì¸ì— ìœ ìš© (ë…ë¦½ë³€ìˆ˜ ê°„ ìƒê´€ì´ ë†’ìœ¼ë©´ ë¬¸ì œ)\n",
    "- íˆíŠ¸ë§µìœ¼ë¡œ ë¹ ë¥´ê²Œ íŒ¨í„´ íŒŒì•… ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q10. ì¢…í•© ë¶„ì„ í”„ë¡œì íŠ¸ â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì™„ì „íˆ ë¶„ì„í•˜ì„¸ìš”.\n",
    "\n",
    "**ì‹œë‚˜ë¦¬ì˜¤**: 3ê°œ ì§€ì (ê°•ë‚¨, í™ëŒ€, ì‹ ì´Œ)ì˜ ì£¼ë§ ë§¤ì¶œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬:\n",
    "1. ANOVAë¡œ ì§€ì  ê°„ ì°¨ì´ ê²€ì¦\n",
    "2. ê° ì§€ì ë³„ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°\n",
    "3. ìœ ì˜í•œ ì°¨ì´ê°€ ìˆë‹¤ë©´ ìµœê³ /ìµœì € ì„±ê³¼ ì§€ì  íŒŒì•…\n",
    "4. ìƒê´€ë¶„ì„: ë°©ë¬¸ì ìˆ˜ì™€ ë§¤ì¶œì˜ ìƒê´€ê´€ê³„ ë¶„ì„\n",
    "\n",
    "```python\n",
    "gangnam_sales = [450, 480, 465, 495, 470, 485, 475]\n",
    "hongdae_sales = [420, 435, 425, 445, 430, 440, 428]\n",
    "sinchon_sales = [380, 395, 385, 405, 390, 400, 388]\n",
    "\n",
    "# ë°©ë¬¸ì ìˆ˜ (ì „ì²´ í•©ì‚°)\n",
    "total_visitors = [3200, 3400, 3300, 3600, 3350, 3500, 3380]\n",
    "total_sales = [1250, 1310, 1275, 1345, 1290, 1325, 1291]\n",
    "```\n",
    "\n",
    "**ì¶œë ¥**: ì™„ì „í•œ ë¶„ì„ ë¦¬í¬íŠ¸ (í†µê³„ëŸ‰, ê²€ì • ê²°ê³¼, ì‹œê°í™”, ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10. ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "gangnam_sales = [450, 480, 465, 495, 470, 485, 475]\n",
    "hongdae_sales = [420, 435, 425, 445, 430, 440, 428]\n",
    "sinchon_sales = [380, 395, 385, 405, 390, 400, 388]\n",
    "\n",
    "total_visitors = [3200, 3400, 3300, 3600, 3350, 3500, 3380]\n",
    "total_sales = [1250, 1310, 1275, 1345, 1290, 1325, 1291]\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# ====================================================================\n",
    "# 1. ANOVA ë¶„ì„: ì§€ì  ê°„ ë§¤ì¶œ ì°¨ì´ ê²€ì¦\n",
    "# ====================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸: ì£¼ë§ ë§¤ì¶œ ë¶„ì„\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Part 1: ANOVA ë¶„ì„ - ì§€ì  ê°„ ë§¤ì¶œ ì°¨ì´\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ANOVA ê²€ì •\n",
    "f_stat, anova_p = stats.f_oneway(gangnam_sales, hongdae_sales, sinchon_sales)\n",
    "\n",
    "print(f\"\\nê°€ì„¤ ì„¤ì •:\")\n",
    "print(f\"  H0: ëª¨ë“  ì§€ì ì˜ í‰ê·  ë§¤ì¶œì´ ê°™ë‹¤\")\n",
    "print(f\"  H1: ì ì–´ë„ í•œ ì§€ì ì˜ í‰ê·  ë§¤ì¶œì´ ë‹¤ë¥´ë‹¤\")\n",
    "\n",
    "# ====================================================================\n",
    "# 2. ì§€ì ë³„ í†µê³„ëŸ‰\n",
    "# ====================================================================\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Part 2: ì§€ì ë³„ ê¸°ìˆ  í†µê³„ëŸ‰\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "branches = {\n",
    "    'ê°•ë‚¨ì ': gangnam_sales,\n",
    "    'í™ëŒ€ì ': hongdae_sales,\n",
    "    'ì‹ ì´Œì ': sinchon_sales\n",
    "}\n",
    "\n",
    "branch_stats = {}\n",
    "for name, data in branches.items():\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data, ddof=1)\n",
    "    branch_stats[name] = {'í‰ê· ': mean, 'í‘œì¤€í¸ì°¨': std}\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  í‰ê·  ë§¤ì¶œ: {mean:.1f}ë§Œì›\")\n",
    "    print(f\"  í‘œì¤€í¸ì°¨: {std:.2f}ë§Œì›\")\n",
    "    print(f\"  ë²”ìœ„: {min(data)} ~ {max(data)}ë§Œì›\")\n",
    "\n",
    "# ANOVA ê²°ê³¼\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"ANOVA ê²€ì • ê²°ê³¼\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  F-statistic: {f_stat:.4f}\")\n",
    "print(f\"  p-value: {anova_p:.8f}\")\n",
    "\n",
    "# ====================================================================\n",
    "# 3. ê²°ë¡  ë° ìµœê³ /ìµœì € ì„±ê³¼ ì§€ì \n",
    "# ====================================================================\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Part 3: ê²°ë¡  ë° ì„±ê³¼ ìˆœìœ„\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "if anova_p < alpha:\n",
    "    print(f\"\\nê²€ì • ê²°ê³¼: p-value ({anova_p:.8f}) < alpha ({alpha})\")\n",
    "    print(\"-> ê·€ë¬´ê°€ì„¤ ê¸°ê°: ì§€ì  ê°„ ë§¤ì¶œì— ìœ ì˜í•œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "    # ìµœê³ /ìµœì € ì„±ê³¼ ì§€ì \n",
    "    means = {name: stats['í‰ê· '] for name, stats in branch_stats.items()}\n",
    "    best_branch = max(means, key=means.get)\n",
    "    worst_branch = min(means, key=means.get)\n",
    "    \n",
    "    print(f\"\\nì„±ê³¼ ìˆœìœ„:\")\n",
    "    for rank, (name, mean) in enumerate(sorted(means.items(), key=lambda x: -x[1]), 1):\n",
    "        print(f\"  {rank}ìœ„: {name} ({mean:.1f}ë§Œì›)\")\n",
    "    \n",
    "    print(f\"\\nìµœê³  ì„±ê³¼ ì§€ì : {best_branch} ({means[best_branch]:.1f}ë§Œì›)\")\n",
    "    print(f\"ìµœì € ì„±ê³¼ ì§€ì : {worst_branch} ({means[worst_branch]:.1f}ë§Œì›)\")\n",
    "    print(f\"ê²©ì°¨: {means[best_branch] - means[worst_branch]:.1f}ë§Œì› ({(means[best_branch]/means[worst_branch]-1)*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"\\nê²€ì • ê²°ê³¼: p-value ({anova_p:.8f}) >= alpha ({alpha})\")\n",
    "    print(\"-> ê·€ë¬´ê°€ì„¤ ì±„íƒ: ì§€ì  ê°„ ë§¤ì¶œì— ìœ ì˜í•œ ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10. ì •ë‹µ ì½”ë“œ (ê³„ì†) - ìƒê´€ë¶„ì„\n",
    "\n",
    "# ====================================================================\n",
    "# 4. ìƒê´€ë¶„ì„: ë°©ë¬¸ì ìˆ˜ vs ë§¤ì¶œ\n",
    "# ====================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Part 4: ìƒê´€ë¶„ì„ - ë°©ë¬¸ì ìˆ˜ì™€ ë§¤ì¶œ\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ìƒê´€ê³„ìˆ˜ ê³„ì‚°\n",
    "pearson_corr, corr_p = stats.pearsonr(total_visitors, total_sales)\n",
    "\n",
    "print(f\"\\në°ì´í„° ìš”ì•½:\")\n",
    "print(f\"  í‰ê·  ë°©ë¬¸ì: {np.mean(total_visitors):.0f}ëª…\")\n",
    "print(f\"  í‰ê·  ë§¤ì¶œ: {np.mean(total_sales):.1f}ë§Œì›\")\n",
    "\n",
    "print(f\"\\nìƒê´€ë¶„ì„ ê²°ê³¼:\")\n",
    "print(f\"  Pearson ìƒê´€ê³„ìˆ˜: {pearson_corr:.4f}\")\n",
    "print(f\"  p-value: {corr_p:.6f}\")\n",
    "print(f\"  ê²°ì •ê³„ìˆ˜ (r^2): {pearson_corr**2:.4f}\")\n",
    "\n",
    "# í•´ì„\n",
    "if pearson_corr > 0.8:\n",
    "    strength = \"ë§¤ìš° ê°•í•œ ì–‘ì˜\"\n",
    "elif pearson_corr > 0.6:\n",
    "    strength = \"ê°•í•œ ì–‘ì˜\"\n",
    "elif pearson_corr > 0.4:\n",
    "    strength = \"ì¤‘ê°„ ê°•ë„ì˜ ì–‘ì˜\"\n",
    "else:\n",
    "    strength = \"ì•½í•œ\"\n",
    "\n",
    "print(f\"\\ní•´ì„: {strength} ìƒê´€ê´€ê³„\")\n",
    "if corr_p < alpha:\n",
    "    print(f\"  -> í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨ (p < 0.05)\")\n",
    "    print(f\"  -> ë°©ë¬¸ì ìˆ˜ ì¦ê°€ê°€ ë§¤ì¶œ ë³€ë™ì˜ {pearson_corr**2*100:.1f}%ë¥¼ ì„¤ëª…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10. ì •ë‹µ ì½”ë“œ (ê³„ì†) - ì‹œê°í™”\n",
    "\n",
    "# ====================================================================\n",
    "# 5. ì‹œê°í™”\n",
    "# ====================================================================\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ì§€ì ë³„ ë°•ìŠ¤í”Œë¡¯\n",
    "fig1 = go.Figure()\n",
    "\n",
    "for name, data in branches.items():\n",
    "    fig1.add_trace(go.Box(y=data, name=name, boxmean=True))\n",
    "\n",
    "fig1.update_layout(\n",
    "    title=f'ì§€ì ë³„ ì£¼ë§ ë§¤ì¶œ ë¶„í¬ (ANOVA p = {anova_p:.6f})',\n",
    "    yaxis_title='ë§¤ì¶œ (ë§Œì›)',\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig1.show()\n",
    "\n",
    "# ë°©ë¬¸ì-ë§¤ì¶œ ì‚°ì ë„\n",
    "df_corr = pd.DataFrame({\n",
    "    'ë°©ë¬¸ììˆ˜': total_visitors,\n",
    "    'ì´ë§¤ì¶œ': total_sales\n",
    "})\n",
    "\n",
    "fig2 = px.scatter(\n",
    "    df_corr,\n",
    "    x='ë°©ë¬¸ììˆ˜',\n",
    "    y='ì´ë§¤ì¶œ',\n",
    "    title=f'ë°©ë¬¸ì ìˆ˜ vs ì´ ë§¤ì¶œ (r = {pearson_corr:.3f})',\n",
    "    trendline='ols',\n",
    "    labels={'ë°©ë¬¸ììˆ˜': 'ë°©ë¬¸ì ìˆ˜ (ëª…)', 'ì´ë§¤ì¶œ': 'ì´ ë§¤ì¶œ (ë§Œì›)'},\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig2.update_traces(\n",
    "    marker=dict(size=12, color='royalblue'),\n",
    "    selector=dict(mode='markers')\n",
    ")\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10. ì •ë‹µ ì½”ë“œ (ê³„ì†) - ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸\n",
    "\n",
    "# ====================================================================\n",
    "# 6. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸\n",
    "# ====================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Part 5: ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë° ê¶Œì¥ì‚¬í•­\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n[ì£¼ìš” ë°œê²¬ì‚¬í•­]\")\n",
    "print(f\"  1. ì§€ì  ê°„ ìœ ì˜í•œ ë§¤ì¶œ ì°¨ì´ í™•ì¸ (p < 0.001)\")\n",
    "print(f\"  2. ê°•ë‚¨ì ì´ ì‹ ì´Œì  ëŒ€ë¹„ {(means['ê°•ë‚¨ì ']/means['ì‹ ì´Œì ']-1)*100:.1f}% ë†’ì€ ë§¤ì¶œ\")\n",
    "print(f\"  3. ë°©ë¬¸ìì™€ ë§¤ì¶œ ê°„ {strength} ìƒê´€ê´€ê³„ (r = {pearson_corr:.3f})\")\n",
    "\n",
    "print(\"\\n[ê¶Œì¥ì‚¬í•­]\")\n",
    "print(f\"  1. ê°•ë‚¨ì  ì„±ê³µ ìš”ì¸ ë¶„ì„ í›„ íƒ€ ì§€ì ì— ì ìš©\")\n",
    "print(f\"  2. ì‹ ì´Œì  ë§¤ì¶œ ê°œì„  ì „ëµ ìˆ˜ë¦½ í•„ìš”\")\n",
    "print(f\"  3. ë°©ë¬¸ì ìˆ˜ ì¦ëŒ€ ë§ˆì¼€íŒ… ê°•í™” (ë§¤ì¶œ ì§ê²°)\")\n",
    "print(f\"  4. ê°ë‹¨ê°€ ë¶„ì„ ì¶”ê°€ ê¶Œì¥ (ë§¤ì¶œ/ë°©ë¬¸ì)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ë¶„ì„ ì™„ë£Œ\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10. í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert anova_p < 0.001, \"ANOVA p-valueê°€ ë§¤ìš° ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert max(means, key=means.get) == 'ê°•ë‚¨ì ', \"ê°•ë‚¨ì ì´ ìµœê³  ë§¤ì¶œì´ì–´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert min(means, key=means.get) == 'ì‹ ì´Œì ', \"ì‹ ì´Œì ì´ ìµœì € ë§¤ì¶œì´ì–´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "assert pearson_corr > 0.9, \"ë°©ë¬¸ì-ë§¤ì¶œ ê°„ ë§¤ìš° ê°•í•œ ìƒê´€ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "print(\"\\nëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q10 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. ANOVAë¡œ ì§€ì  ê°„ ì°¨ì´ ê²€ì¦ -> ìœ ì˜í•œ ì°¨ì´ í™•ì¸\n",
    "2. ì§€ì ë³„ ê¸°ìˆ í†µê³„ëŸ‰ ê³„ì‚° -> í‰ê· , í‘œì¤€í¸ì°¨\n",
    "3. ì„±ê³¼ ìˆœìœ„ ë° ê²©ì°¨ ë¶„ì„ -> ìµœê³ /ìµœì € ì§€ì  íŒŒì•…\n",
    "4. ìƒê´€ë¶„ì„ -> ë°©ë¬¸ìì™€ ë§¤ì¶œ ê´€ê³„ í™•ì¸\n",
    "5. ì‹œê°í™” -> ë°•ìŠ¤í”Œë¡¯, ì‚°ì ë„\n",
    "6. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ì¢…í•© ë¶„ì„: ì—¬ëŸ¬ í†µê³„ ê¸°ë²•ì„ ì¡°í•©í•˜ì—¬ ì „ì²´ì ì¸ ê·¸ë¦¼ íŒŒì•…\n",
    "- ANOVA + ê¸°ìˆ í†µê³„ + ìƒê´€ë¶„ì„ = ì™„ì „í•œ ë¶„ì„\n",
    "- ì‹œê°í™”ë¡œ ê²°ê³¼ ì „ë‹¬ë ¥ ê°•í™”\n",
    "\n",
    "**ëŒ€ì•ˆ ë°©ë²•**:\n",
    "```python\n",
    "# ì‚¬í›„ ê²€ì • ì¶”ê°€ (Tukey HSD)\n",
    "from scipy.stats import tukey_hsd\n",
    "result = tukey_hsd(gangnam_sales, hongdae_sales, sinchon_sales)\n",
    "\n",
    "# íš¨ê³¼ í¬ê¸° ê³„ì‚° (Cohen's d)\n",
    "def cohens_d(group1, group2):\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "    pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "    return (np.mean(group1) - np.mean(group2)) / pooled_std\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ANOVAë§Œ í•˜ê³  ì‚¬í›„ ê²€ì • ìƒëµ\n",
    "- í†µê³„ì  ìœ ì˜ì„±ê³¼ ì‹¤ë¬´ì  ì¤‘ìš”ì„± í˜¼ë™\n",
    "- ì‹œê°í™” ì—†ì´ ìˆ«ìë§Œ ì œì‹œ\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë¶„ì„ ê²°ê³¼ëŠ” í•­ìƒ ë¹„ì¦ˆë‹ˆìŠ¤ ì–¸ì–´ë¡œ ë²ˆì—­\n",
    "- \"p < 0.05\"ë³´ë‹¤ \"ê°•ë‚¨ì ì´ 21% ë†’ì€ ë§¤ì¶œ\"ì´ ë” ì˜ë¯¸ ìˆìŒ\n",
    "- ê¶Œì¥ì‚¬í•­ê¹Œì§€ ì œì‹œí•´ì•¼ ì™„ì „í•œ ë¶„ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "### Part 1: ê¸°ì´ˆ ê°œë… í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ê°œë… | ì •ì˜ | í•µì‹¬ í¬ì¸íŠ¸ |\n",
    "|------|------|-------------|\n",
    "| ê·€ë¬´ê°€ì„¤(H0) | ì°¨ì´/íš¨ê³¼ê°€ ì—†ë‹¤ëŠ” ê°€ì • | ê¸°ê°í•˜ë ¤ëŠ” ëŒ€ìƒ |\n",
    "| ëŒ€ë¦½ê°€ì„¤(H1) | ì°¨ì´/íš¨ê³¼ê°€ ìˆë‹¤ëŠ” ì£¼ì¥ | ì¦ëª…í•˜ë ¤ëŠ” ëŒ€ìƒ |\n",
    "| p-value | H0ê°€ ì°¸ì¼ ë•Œ í˜„ì¬ ë°ì´í„°ê°€ ë‚˜ì˜¬ í™•ë¥  | p < alpha -> H0 ê¸°ê° |\n",
    "| ìœ ì˜ìˆ˜ì¤€(alpha) | H0 ê¸°ê° ê¸°ì¤€ (ë³´í†µ 0.05) | ì—„ê²©í• ìˆ˜ë¡ ë‚®ê²Œ ì„¤ì • |\n",
    "| Type I ì˜¤ë¥˜ | ì‹¤ì œ ì°¨ì´ ì—†ëŠ”ë° \"ìˆë‹¤\" íŒë‹¨ | False Positive |\n",
    "| Type II ì˜¤ë¥˜ | ì‹¤ì œ ì°¨ì´ ìˆëŠ”ë° \"ì—†ë‹¤\" íŒë‹¨ | False Negative |\n",
    "\n",
    "### Part 2: ê²€ì • ë°©ë²• í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ê²€ì • ë°©ë²• | ìš©ë„ | Python í•¨ìˆ˜ | ì–¸ì œ ì“°ë‚˜? |\n",
    "|----------|------|-------------|----------|\n",
    "| ë‹¨ì¼ í‘œë³¸ t-test | 1ê°œ ê·¸ë£¹ í‰ê·  vs ê¸°ì¤€ê°’ | `stats.ttest_1samp()` | ìš°ë¦¬ íšŒì‚¬ vs ì—…ê³„ í‰ê·  |\n",
    "| ë…ë¦½ í‘œë³¸ t-test | 2ê°œ ë…ë¦½ ê·¸ë£¹ í‰ê·  ë¹„êµ | `stats.ttest_ind()` | A/B í…ŒìŠ¤íŠ¸ |\n",
    "| ëŒ€ì‘ í‘œë³¸ t-test | ê°™ì€ ëŒ€ìƒ ì „í›„ ë¹„êµ | `stats.ttest_rel()` | ë¦¬ë‰´ì–¼ ì „í›„, ì¹˜ë£Œ ì „í›„ |\n",
    "| Chi-square | ë²”ì£¼í˜• ë³€ìˆ˜ ë…ë¦½ì„± ê²€ì • | `stats.chi2_contingency()` | ì„±ë³„ vs ì„ í˜¸ë„ |\n",
    "| ANOVA | 3ê°œ ì´ìƒ ê·¸ë£¹ í‰ê·  ë¹„êµ | `stats.f_oneway()` | ì§€ì—­ë³„ ë§¤ì¶œ ë¹„êµ |\n",
    "| Pearson ìƒê´€ | ì„ í˜• ìƒê´€ê´€ê³„ ì¸¡ì • | `stats.pearsonr()` | ê´‘ê³ ë¹„ vs ë§¤ì¶œ |\n",
    "| Spearman ìƒê´€ | ë¹„ì„ í˜• ìƒê´€ê´€ê³„ ì¸¡ì • | `stats.spearmanr()` | ìˆœìœ„ ê¸°ë°˜ ìƒê´€ |\n",
    "\n",
    "### ğŸ’¡ ì‹¤ë¬´ íŒ\n",
    "\n",
    "1. **p-value í•´ì„ ì£¼ì˜**: p < 0.05ë§Œ ë§¹ì‹ í•˜ì§€ ë§ê³  ì‹¤ë¬´ì  ì˜ë¯¸(effect size)ë„ ê³ ë ¤\n",
    "2. **t-test ì„ íƒ**: ë…ë¦½ vs ëŒ€ì‘ êµ¬ë¶„ ì¤‘ìš”! ê°™ì€ ì‚¬ëŒ ì „í›„ = ëŒ€ì‘, ë‹¤ë¥¸ ì‚¬ëŒ = ë…ë¦½\n",
    "3. **ANOVA í›„ ì‚¬í›„ë¶„ì„**: ANOVAì—ì„œ ìœ ì˜í•˜ë©´ ì–´ë–¤ ê·¸ë£¹ì´ ë‹¤ë¥¸ì§€ ì¶”ê°€ ë¶„ì„ í•„ìš”\n",
    "4. **ìƒê´€ != ì¸ê³¼**: ìƒê´€ê´€ê³„ë§Œìœ¼ë¡œ ì¸ê³¼ê´€ê³„ ì£¼ì¥ ê¸ˆì§€! (ì•„ì´ìŠ¤í¬ë¦¼-ìµì‚¬ ì˜ˆì‹œ)\n",
    "5. **í‘œë³¸ í¬ê¸°**: ë„ˆë¬´ ì‘ìœ¼ë©´ ìœ ì˜í•œ ì°¨ì´ ëª» ì°¾ê³ , ë„ˆë¬´ í¬ë©´ ì‚¬ì†Œí•œ ì°¨ì´ë„ ìœ ì˜í•˜ê²Œ ë‚˜ì˜´\n",
    "6. **ì‹œê°í™” í•„ìˆ˜**: í†µê³„ëŸ‰ë§Œ ë³´ì§€ ë§ê³  `px.scatter`ë¡œ ë°ì´í„° ë¶„í¬ í™•ì¸\n",
    "7. **ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸**: í†µê³„ì  ìœ ì˜ì„±ê³¼ ì‹¤ë¬´ì  ì¤‘ìš”ì„±ì€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
