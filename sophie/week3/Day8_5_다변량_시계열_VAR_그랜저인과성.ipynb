{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day8_5: ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë¶„ì„ (VAR + ê·¸ëœì € ì¸ê³¼ì„±)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "**Part 1: ê¸°ì´ˆ - ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •**\n",
    "1. ìƒê´€ê´€ê³„ vs ì¸ê³¼ê´€ê³„ ì°¨ì´ ì´í•´í•˜ê¸°\n",
    "2. ê·¸ëœì € ì¸ê³¼ì„±(Granger Causality) ê°œë… íŒŒì•…í•˜ê¸°\n",
    "3. statsmodelsë¡œ ê·¸ëœì € ì¸ê³¼ì„± ê²€ì • ìˆ˜í–‰í•˜ê¸°\n",
    "4. ì–‘ë°©í–¥ ì¸ê³¼ì„± ê²€ì • ë° í•´ì„í•˜ê¸°\n",
    "5. ê²½ì œ ë°ì´í„°ë¡œ ì¸ê³¼ê´€ê³„ ë¶„ì„ ì‹¤ìŠµí•˜ê¸°\n",
    "\n",
    "**Part 2: ì‹¬í™” - VAR ëª¨ë¸**\n",
    "1. VAR(Vector AutoRegression) ëª¨ë¸ ì´í•´í•˜ê¸°\n",
    "2. ìµœì  ì‹œì°¨(lag) ê²°ì •í•˜ê¸° (AIC, BIC)\n",
    "3. VAR ëª¨ë¸ í•™ìŠµ ë° ë‹¤ë³€ëŸ‰ ì˜ˆì¸¡í•˜ê¸°\n",
    "4. ì°¨ë¶„ ë³µì›(ì—­ë³€í™˜)ìœ¼ë¡œ ì›ë³¸ ìŠ¤ì¼€ì¼ ì˜ˆì¸¡í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ ì™œ ì´ê²ƒì„ ë°°ìš°ë‚˜ìš”?\n",
    "\n",
    "| ê°œë… | ì‹¤ë¬´ í™œìš© | ì˜ˆì‹œ |\n",
    "|------|----------|------|\n",
    "| **ê·¸ëœì € ì¸ê³¼ì„±** | ë³€ìˆ˜ ê°„ ì¸ê³¼ê´€ê³„ ê·œëª… | ê´‘ê³ ë¹„ â†’ ë§¤ì¶œ? ê¸ˆë¦¬ â†’ ì£¼ê°€? |\n",
    "| **VAR ëª¨ë¸** | ì—¬ëŸ¬ ë³€ìˆ˜ ë™ì‹œ ì˜ˆì¸¡ | ê²½ì œì§€í‘œ, ë‹¤ì¤‘ ì¢…ëª© ì£¼ê°€ |\n",
    "| **ìƒí˜¸ì‘ìš© ë¶„ì„** | ë³€ìˆ˜ ê°„ ì˜í–¥ë ¥ íŒŒì•… | A ë¶€ì„œ ì„±ê³¼ â†’ B ë¶€ì„œ ì„±ê³¼? |\n",
    "| **ì •ì±… íš¨ê³¼ ë¶„ì„** | ì •ì±…ì˜ íŒŒê¸‰ íš¨ê³¼ | ê¸ˆë¦¬ ì¸ìƒ â†’ í™˜ìœ¨/ë¬¼ê°€ ì˜í–¥ |\n",
    "\n",
    "**ë¶„ì„ê°€ ê´€ì **: ë‹¨ë³€ëŸ‰ ARIMAëŠ” í•œ ë³€ìˆ˜ë§Œ ì˜ˆì¸¡í•˜ì§€ë§Œ, í˜„ì‹¤ì—ì„œëŠ” ì—¬ëŸ¬ ë³€ìˆ˜ê°€ ì„œë¡œ ì˜í–¥ì„ ì£¼ê³ ë°›ìŠµë‹ˆë‹¤. VARê³¼ ê·¸ëœì € ê²€ì •ì€ ì´ëŸ¬í•œ ë³µì¡í•œ ê´€ê³„ë¥¼ ë¶„ì„í•˜ëŠ” í•µì‹¬ ë„êµ¬ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)\n",
    "# !pip install statsmodels yfinance plotly pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ì‹œê³„ì—´ ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller, grangercausalitytests\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: ê¸°ì´ˆ - ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 ìƒê´€ê´€ê³„ vs ì¸ê³¼ê´€ê³„\n",
    "\n",
    "### ì¤‘ìš”í•œ êµ¬ë¶„\n",
    "\n",
    "| ê°œë… | ì˜ë¯¸ | ì˜ˆì‹œ |\n",
    "|------|------|------|\n",
    "| **ìƒê´€ê´€ê³„** | ë‘ ë³€ìˆ˜ê°€ í•¨ê»˜ ì›€ì§ì„ | ì•„ì´ìŠ¤í¬ë¦¼ íŒë§¤ â†” ìµì‚¬ ì‚¬ê³  |\n",
    "| **ì¸ê³¼ê´€ê³„** | í•œ ë³€ìˆ˜ê°€ ë‹¤ë¥¸ ë³€ìˆ˜ì— ì˜í–¥ | ê´‘ê³ ë¹„ â†’ ë§¤ì¶œ |\n",
    "\n",
    "### ìƒê´€ê´€ê³„ â‰  ì¸ê³¼ê´€ê³„\n",
    "\n",
    "\"ì•„ì´ìŠ¤í¬ë¦¼ íŒë§¤ëŸ‰ê³¼ ìµì‚¬ ì‚¬ê³ ëŠ” ìƒê´€ê´€ê³„ê°€ ìˆë‹¤\"\n",
    "- ë‘˜ ë‹¤ **ì—¬ë¦„(ìˆ¨ì€ ë³€ìˆ˜)**ì— ì¦ê°€\n",
    "- ì•„ì´ìŠ¤í¬ë¦¼ì´ ìµì‚¬ë¥¼ ìœ ë°œí•˜ëŠ” ê²ƒì´ ì•„ë‹˜!\n",
    "\n",
    "### ê·¸ëœì € ì¸ê³¼ì„±ì´ë€?\n",
    "\n",
    "**\"Xê°€ Yë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ”ê°€?\"**\n",
    "\n",
    "- ì—„ë°€í•œ ì¸ê³¼ê´€ê³„ëŠ” ì•„ë‹˜ (\"ì˜ˆì¸¡ ì¸ê³¼ì„±\")\n",
    "- ì‹œê°„ì  ì„ í–‰ê´€ê³„ ê¸°ë°˜\n",
    "- \"Xì˜ ê³¼ê±° ê°’ì´ Y ì˜ˆì¸¡ì— ìœ ì˜ë¯¸í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ”ê°€?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ë¹„ìœ \n",
    "\n",
    "**ë§ˆì¼€íŒ… ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤**\n",
    "\n",
    "| ì§ˆë¬¸ | ë¶„ì„ ë°©ë²• | ê²°ê³¼ í•´ì„ |\n",
    "|------|----------|----------|\n",
    "| \"ê´‘ê³ ë¹„ì™€ ë§¤ì¶œì´ ì—°ê´€ë˜ì–´ ìˆë‚˜?\" | ìƒê´€ë¶„ì„ | r=0.8 (ê°•í•œ ì–‘ì˜ ìƒê´€) |\n",
    "| \"ê´‘ê³ ë¹„ê°€ ë§¤ì¶œì„ ì¼ìœ¼í‚¤ëŠ”ê°€?\" | ê·¸ëœì € ê²€ì • | ê´‘ê³ ë¹„ â†’ ë§¤ì¶œ (ì˜ˆì¸¡ë ¥ ìˆìŒ) |\n",
    "| \"ë§¤ì¶œì´ ê´‘ê³ ë¹„ì— ì˜í–¥ì„ ì£¼ë‚˜?\" | ì—­ë°©í–¥ ê²€ì • | ë§¤ì¶œ â†’ ê´‘ê³ ë¹„? (ì˜ˆì‚° ë°°ì •) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 ì‹¤ìŠµ ë°ì´í„° ì¤€ë¹„\n",
    "\n",
    "M2 í†µí™”ëŸ‰(Money)ê³¼ ê°œì¸ì†Œë¹„ì§€ì¶œ(Spending) ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ìƒì„± (Money Stock & Spending ì‹œë®¬ë ˆì´ì…˜)\n",
    "# ì‹¤ì œë¡œëŠ” FRED API ë“±ì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "np.random.seed(42)\n",
    "\n",
    "# ë‚ ì§œ ì¸ë±ìŠ¤ ìƒì„±\n",
    "dates = pd.date_range(start='2010-01-01', periods=150, freq='MS')\n",
    "\n",
    "# Money: ì¶”ì„¸ + ëœë¤\n",
    "money_trend = np.linspace(1000, 2500, 150)\n",
    "money = money_trend + np.cumsum(np.random.randn(150) * 30)\n",
    "\n",
    "# Spending: Moneyì— ì§€ì—° ë°˜ì‘ + ìì²´ íŠ¸ë Œë“œ\n",
    "spending_trend = np.linspace(800, 1800, 150)\n",
    "spending = spending_trend + 0.3 * np.roll(money, 3) + np.cumsum(np.random.randn(150) * 20)\n",
    "\n",
    "# DataFrame ìƒì„±\n",
    "df_econ = pd.DataFrame({\n",
    "    'Money': money,\n",
    "    'Spending': spending\n",
    "}, index=dates)\n",
    "\n",
    "print(f\"ë°ì´í„° ê¸°ê°„: {df_econ.index[0].date()} ~ {df_econ.index[-1].date()}\")\n",
    "print(f\"ë°ì´í„° ê°œìˆ˜: {len(df_econ)}\")\n",
    "df_econ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê³„ì—´ ì‹œê°í™”\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True,\n",
    "                    subplot_titles=['M2 í†µí™”ëŸ‰ (Money)', 'ê°œì¸ì†Œë¹„ì§€ì¶œ (Spending)'])\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_econ.index, y=df_econ['Money'],\n",
    "                         mode='lines', name='Money', line=dict(color='blue')),\n",
    "              row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_econ.index, y=df_econ['Spending'],\n",
    "                         mode='lines', name='Spending', line=dict(color='green')),\n",
    "              row=2, col=1)\n",
    "\n",
    "fig.update_layout(title='ê²½ì œ ì§€í‘œ ì‹œê³„ì—´', height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒê´€ê´€ê³„ í™•ì¸\n",
    "correlation = df_econ['Money'].corr(df_econ['Spending'])\n",
    "print(f\"Moneyì™€ Spendingì˜ ìƒê´€ê³„ìˆ˜: {correlation:.4f}\")\n",
    "print(\"\\n=> ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„! í•˜ì§€ë§Œ ì¸ê³¼ê´€ê³„ëŠ” ë³„ë„ë¡œ ê²€ì • í•„ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •\n",
    "\n",
    "### ê°€ì„¤ ì„¤ì •\n",
    "\n",
    "- **ê·€ë¬´ê°€ì„¤ (H0)**: Xê°€ Yë¥¼ ê·¸ëœì €-ì›ì¸í•˜ì§€ ì•ŠëŠ”ë‹¤ (Xì˜ ê³¼ê±°ê°’ì´ Y ì˜ˆì¸¡ì— ë„ì›€ì´ ì•ˆ ë¨)\n",
    "- **ëŒ€ë¦½ê°€ì„¤ (H1)**: Xê°€ Yë¥¼ ê·¸ëœì €-ì›ì¸í•œë‹¤ (Xì˜ ê³¼ê±°ê°’ì´ Y ì˜ˆì¸¡ì— ë„ì›€ì´ ë¨)\n",
    "\n",
    "### p-value í•´ì„\n",
    "\n",
    "- **p < 0.05**: ê·€ë¬´ê°€ì„¤ ê¸°ê° â†’ Xê°€ Yë¥¼ ê·¸ëœì €-ì›ì¸í•¨\n",
    "- **p >= 0.05**: ê·€ë¬´ê°€ì„¤ ì±„íƒ â†’ ì¸ê³¼ê´€ê³„ ì—†ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ìƒì„± í™•ë³´ë¥¼ ìœ„í•œ ì°¨ë¶„\n",
    "def adf_test(series, name=''):\n",
    "    \"\"\"ADF ê²€ì •\"\"\"\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f'{name}: ADF={result[0]:.4f}, p-value={result[1]:.4f}', end='')\n",
    "    print(\" -> ì •ìƒ\" if result[1] < 0.05 else \" -> ë¹„ì •ìƒ\")\n",
    "    return result[1]\n",
    "\n",
    "print(\"=== ì›ë³¸ ë°ì´í„° ì •ìƒì„± ===\")\n",
    "adf_test(df_econ['Money'], 'Money')\n",
    "adf_test(df_econ['Spending'], 'Spending')\n",
    "\n",
    "# 1ì°¨ ì°¨ë¶„\n",
    "df_diff = df_econ.diff().dropna()\n",
    "\n",
    "print(\"\\n=== 1ì°¨ ì°¨ë¶„ í›„ ì •ìƒì„± ===\")\n",
    "adf_test(df_diff['Money'], 'Money_diff')\n",
    "adf_test(df_diff['Spending'], 'Spending_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def granger_causality_test(data, x_col, y_col, maxlag=12):\n",
    "    \"\"\"\n",
    "    ê·¸ëœì € ì¸ê³¼ì„± ê²€ì • ìˆ˜í–‰\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        ì‹œê³„ì—´ ë°ì´í„° (ì •ìƒì„± í™•ë³´ í•„ìš”)\n",
    "    x_col : str\n",
    "        ì›ì¸ ë³€ìˆ˜ (X â†’ Y ê²€ì •ì—ì„œ X)\n",
    "    y_col : str\n",
    "        ê²°ê³¼ ë³€ìˆ˜\n",
    "    maxlag : int\n",
    "        ê²€ì •í•  ìµœëŒ€ ì‹œì°¨\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : lagë³„ p-value\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •: {x_col} â†’ {y_col} ===\")\n",
    "    \n",
    "    # grangercausalitytestsëŠ” [Y, X] ìˆœì„œë¡œ ì…ë ¥\n",
    "    # Yë¥¼ ì˜ˆì¸¡í•  ë•Œ Xê°€ ë„ì›€ì´ ë˜ëŠ”ì§€ ê²€ì •\n",
    "    test_data = data[[y_col, x_col]].dropna()\n",
    "    \n",
    "    # ê²€ì • ìˆ˜í–‰ (verbose=Falseë¡œ ìƒì„¸ ì¶œë ¥ ìˆ¨ê¹€)\n",
    "    results = grangercausalitytests(test_data, maxlag=maxlag, verbose=False)\n",
    "    \n",
    "    # ê²°ê³¼ ì •ë¦¬\n",
    "    p_values = {}\n",
    "    print(f\"\\n{'Lag':<5} {'F-statistic':<15} {'p-value':<12} {'ìœ ì˜ì„±':<10}\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    for lag in range(1, maxlag + 1):\n",
    "        # ssr_ftest ê²°ê³¼ ì‚¬ìš© (F-ê²€ì •)\n",
    "        f_stat = results[lag][0]['ssr_ftest'][0]\n",
    "        p_val = results[lag][0]['ssr_ftest'][1]\n",
    "        p_values[lag] = p_val\n",
    "        \n",
    "        significance = \"***\" if p_val < 0.01 else \"**\" if p_val < 0.05 else \"*\" if p_val < 0.1 else \"\"\n",
    "        print(f\"{lag:<5} {f_stat:<15.4f} {p_val:<12.4f} {significance}\")\n",
    "    \n",
    "    # ê°€ì¥ ìœ ì˜í•œ ì‹œì°¨ ì°¾ê¸°\n",
    "    best_lag = min(p_values, key=p_values.get)\n",
    "    best_p = p_values[best_lag]\n",
    "    \n",
    "    print(\"\\nê²°ë¡ :\")\n",
    "    if best_p < 0.05:\n",
    "        print(f\"  => '{x_col}'ê°€ '{y_col}'ë¥¼ ê·¸ëœì €-ì›ì¸í•©ë‹ˆë‹¤ (lag={best_lag}, p={best_p:.4f})\")\n",
    "    else:\n",
    "        print(f\"  => '{x_col}'ê°€ '{y_col}'ë¥¼ ê·¸ëœì €-ì›ì¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (p >= 0.05)\")\n",
    "    \n",
    "    return p_values\n",
    "\n",
    "# Money â†’ Spending ê²€ì •\n",
    "p_vals_1 = granger_causality_test(df_diff, 'Money', 'Spending', maxlag=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—­ë°©í–¥ ê²€ì •: Spending â†’ Money\n",
    "p_vals_2 = granger_causality_test(df_diff, 'Spending', 'Money', maxlag=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê²°ê³¼ í•´ì„\n",
    "\n",
    "| ê²€ì • ë°©í–¥ | ê²°ê³¼ | í•´ì„ |\n",
    "|----------|------|------|\n",
    "| Money â†’ Spending | p < 0.05 | í†µí™”ëŸ‰ì´ ì†Œë¹„ì§€ì¶œì— ì„ í–‰ |\n",
    "| Spending â†’ Money | p >= 0.05 | ì†Œë¹„ì§€ì¶œì€ í†µí™”ëŸ‰ ì˜ˆì¸¡ì— ë„ì›€ ì•ˆ ë¨ |\n",
    "\n",
    "**ê²½ì œí•™ì  í•´ì„**: \n",
    "- í†µí™”ëŸ‰ ì¦ê°€ â†’ (ì‹œì°¨ë¥¼ ë‘ê³ ) â†’ ì†Œë¹„ì§€ì¶œ ì¦ê°€\n",
    "- í†µí™”ì •ì±…ì´ ì‹¤ë¬¼ê²½ì œì— ì˜í–¥ì„ ë¯¸ì¹¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 ì£¼ì‹ ë°ì´í„°ë¡œ ì¸ê³¼ì„± ë¶„ì„\n",
    "\n",
    "ì‹¤ì œ ì£¼ì‹ ë°ì´í„°ì—ì„œ ì¸ê³¼ê´€ê³„ë¥¼ ë¶„ì„í•´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# ê´€ë ¨ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘: ì‚¼ì„±ì „ì vs SKí•˜ì´ë‹‰ìŠ¤\n",
    "samsung = yf.download('005930.KS', start='2022-01-01', end='2024-12-31')['Close']\n",
    "skhynix = yf.download('000660.KS', start='2022-01-01', end='2024-12-31')['Close']\n",
    "\n",
    "# DataFrame ê²°í•©\n",
    "df_stock = pd.DataFrame({\n",
    "    'Samsung': samsung,\n",
    "    'SKHynix': skhynix\n",
    "}).dropna()\n",
    "\n",
    "print(f\"ë°ì´í„° ê¸°ê°„: {df_stock.index[0].date()} ~ {df_stock.index[-1].date()}\")\n",
    "print(f\"ë°ì´í„° ê°œìˆ˜: {len(df_stock)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "# ì •ê·œí™” (ì‹œì‘ì  = 100)\n",
    "samsung_norm = df_stock['Samsung'] / df_stock['Samsung'].iloc[0] * 100\n",
    "skhynix_norm = df_stock['SKHynix'] / df_stock['SKHynix'].iloc[0] * 100\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_stock.index, y=samsung_norm,\n",
    "                         name='ì‚¼ì„±ì „ì', line=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=df_stock.index, y=skhynix_norm,\n",
    "                         name='SKí•˜ì´ë‹‰ìŠ¤', line=dict(color='red')))\n",
    "\n",
    "fig.update_layout(title='ì‚¼ì„±ì „ì vs SKí•˜ì´ë‹‰ìŠ¤ ì£¼ê°€ ì¶”ì´ (ì •ê·œí™”)',\n",
    "                  yaxis_title='ìƒëŒ€ ê°€ê²© (ì‹œì‘=100)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìˆ˜ìµë¥ ë¡œ ë³€í™˜ (ì •ìƒì„± í™•ë³´ + ìŠ¤ì¼€ì¼ í†µì¼)\n",
    "df_returns = df_stock.pct_change().dropna() * 100  # ë°±ë¶„ìœ¨ ìˆ˜ìµë¥ \n",
    "\n",
    "# ì •ìƒì„± í™•ì¸\n",
    "print(\"=== ìˆ˜ìµë¥  ë°ì´í„° ì •ìƒì„± ===\")\n",
    "adf_test(df_returns['Samsung'], 'Samsung ìˆ˜ìµë¥ ')\n",
    "adf_test(df_returns['SKHynix'], 'SKHynix ìˆ˜ìµë¥ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì–‘ë°©í–¥ ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ë°˜ë„ì²´ ì£¼ì‹ ê°„ ê·¸ëœì € ì¸ê³¼ì„± ë¶„ì„\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ì‚¼ì„±ì „ì â†’ SKí•˜ì´ë‹‰ìŠ¤\n",
    "granger_causality_test(df_returns, 'Samsung', 'SKHynix', maxlag=5)\n",
    "\n",
    "# SKí•˜ì´ë‹‰ìŠ¤ â†’ ì‚¼ì„±ì „ì\n",
    "granger_causality_test(df_returns, 'SKHynix', 'Samsung', maxlag=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì£¼ì‹ ì¸ê³¼ì„± í•´ì„ ì£¼ì˜ì‚¬í•­\n",
    "\n",
    "1. **ë¦¬ë“œ-ë˜ê·¸ ê´€ê³„**: í° ì¢…ëª©ì´ ì‘ì€ ì¢…ëª©ì— ì„ í–‰í•˜ëŠ” ê²½í–¥\n",
    "2. **íš¨ìœ¨ì  ì‹œì¥**: ì´ë¡ ì ìœ¼ë¡œ ì£¼ê°€ëŠ” ì¦‰ì‹œ ì •ë³´ ë°˜ì˜ (ì¸ê³¼ì„± ì•½í•¨)\n",
    "3. **ê³µí†µ ìš”ì¸**: ë°˜ë„ì²´ ì—…í™©, í™˜ìœ¨ ë“± ì œ3ì˜ ë³€ìˆ˜ ì¡´ì¬\n",
    "4. **íˆ¬ì ì£¼ì˜**: ê·¸ëœì € ì¸ê³¼ì„± â‰  ìˆ˜ìµ ë³´ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: ì‹¬í™” - VAR ëª¨ë¸\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 VAR ëª¨ë¸ ì´í•´\n",
    "\n",
    "### VAR(Vector AutoRegression)ì´ë€?\n",
    "\n",
    "**ì—¬ëŸ¬ ì‹œê³„ì—´ ë³€ìˆ˜**ê°€ ì„œë¡œ ì˜í–¥ì„ ì£¼ê³ ë°›ëŠ” ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ëŠ” **ë‹¤ë³€ëŸ‰** ì‹œê³„ì—´ ë¶„ì„ ê¸°ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "### ë‹¨ë³€ëŸ‰ vs ë‹¤ë³€ëŸ‰\n",
    "\n",
    "| íŠ¹ì„± | ARIMA (ë‹¨ë³€ëŸ‰) | VAR (ë‹¤ë³€ëŸ‰) |\n",
    "|------|---------------|-------------|\n",
    "| ë³€ìˆ˜ ìˆ˜ | 1ê°œ | 2ê°œ ì´ìƒ |\n",
    "| ì˜ˆì¸¡ ëŒ€ìƒ | Yì˜ ë¯¸ë˜ê°’ | Y1, Y2, ... ëª¨ë‘ |\n",
    "| ìƒí˜¸ì‘ìš© | ì—†ìŒ | ë³€ìˆ˜ ê°„ ì˜í–¥ ë°˜ì˜ |\n",
    "| í™œìš© | ë‹¨ì¼ KPI ì˜ˆì¸¡ | ì—°ê´€ ì§€í‘œ ë™ì‹œ ì˜ˆì¸¡ |\n",
    "\n",
    "### VAR(p) ëª¨ë¸ ìˆ˜ì‹\n",
    "\n",
    "2ê°œ ë³€ìˆ˜ (Y1, Y2)ì¸ ê²½ìš°:\n",
    "\n",
    "$$Y_{1,t} = c_1 + \\phi_{11,1}Y_{1,t-1} + \\phi_{12,1}Y_{2,t-1} + \\cdots + \\epsilon_{1,t}$$\n",
    "$$Y_{2,t} = c_2 + \\phi_{21,1}Y_{1,t-1} + \\phi_{22,1}Y_{2,t-1} + \\cdots + \\epsilon_{2,t}$$\n",
    "\n",
    "â†’ ê° ë³€ìˆ˜ê°€ **ìì‹ ì˜ ê³¼ê±°**ë¿ë§Œ ì•„ë‹ˆë¼ **ë‹¤ë¥¸ ë³€ìˆ˜ì˜ ê³¼ê±°**ì—ë„ ì˜í–¥ë°›ìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ë¹„ìœ \n",
    "\n",
    "**ë¶€ì„œ ê°„ ì„±ê³¼ ë¶„ì„**\n",
    "\n",
    "| ë³€ìˆ˜ | ì˜ë¯¸ |\n",
    "|------|------|\n",
    "| Y1 = ë§ˆì¼€íŒ… ì„±ê³¼ | ì´ë²ˆ ë‹¬ ë§ˆì¼€íŒ… ì„±ê³¼ |\n",
    "| Y2 = ì˜ì—… ì„±ê³¼ | ì´ë²ˆ ë‹¬ ì˜ì—… ì„±ê³¼ |\n",
    "\n",
    "**VAR ëª¨ë¸ í•´ì„:**\n",
    "- ë§ˆì¼€íŒ… ì„±ê³¼ = ì§€ë‚œë‹¬ ë§ˆì¼€íŒ… + ì§€ë‚œë‹¬ ì˜ì—… + ì˜¤ì°¨\n",
    "- ì˜ì—… ì„±ê³¼ = ì§€ë‚œë‹¬ ì˜ì—… + ì§€ë‚œë‹¬ ë§ˆì¼€íŒ… + ì˜¤ì°¨\n",
    "\n",
    "â†’ ë‘ ë¶€ì„œê°€ ì„œë¡œ ì˜í–¥ì„ ì£¼ê³ ë°›ëŠ” ê´€ê³„ ëª¨ë¸ë§!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 VAR ëª¨ë¸ êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²½ì œ ë°ì´í„° ì‚¬ìš© (ì•ì„œ ìƒì„±í•œ df_econ)\n",
    "# ì •ìƒì„±ì„ ìœ„í•´ 1ì°¨ ì°¨ë¶„ ì ìš©\n",
    "df_diff = df_econ.diff().dropna()\n",
    "\n",
    "# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
    "n_test = 12  # í…ŒìŠ¤íŠ¸ ê¸°ê°„\n",
    "train_var = df_diff[:-n_test]\n",
    "test_var = df_diff[-n_test:]\n",
    "\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_var)}ê°œ\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_var)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAR ëª¨ë¸ ìƒì„± ë° ìµœì  ì‹œì°¨ ì„ íƒ\n",
    "model_var = VAR(train_var)\n",
    "\n",
    "# ìµœì  ì‹œì°¨(lag) ê²°ì • - AIC, BIC ë“± ê¸°ì¤€\n",
    "lag_selection = model_var.select_order(maxlags=15)\n",
    "print(\"=== ìµœì  ì‹œì°¨ ì„ íƒ ===\")\n",
    "print(lag_selection.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì‹œì°¨ ì„ íƒ ê¸°ì¤€ í•´ì„\n",
    "\n",
    "| ê¸°ì¤€ | íŠ¹ì§• |\n",
    "|------|------|\n",
    "| **AIC** | ë³µì¡ë„ í˜ë„í‹° ì•½í•¨, ê³¼ì í•© ê°€ëŠ¥ |\n",
    "| **BIC** | ë³µì¡ë„ í˜ë„í‹° ê°•í•¨, ë‹¨ìˆœ ëª¨ë¸ ì„ í˜¸ |\n",
    "| **HQIC** | AICì™€ BIC ì¤‘ê°„ |\n",
    "| **FPE** | ì˜ˆì¸¡ ì˜¤ì°¨ ìµœì†Œí™” |\n",
    "\n",
    "ì¼ë°˜ì ìœ¼ë¡œ **AIC ë˜ëŠ” BIC** ê¸°ì¤€ì˜ ìµœì  ì‹œì°¨ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIC ê¸°ì¤€ ìµœì  ì‹œì°¨ë¡œ ëª¨ë¸ í•™ìŠµ\n",
    "optimal_lag = lag_selection.aic\n",
    "print(f\"AIC ê¸°ì¤€ ìµœì  ì‹œì°¨: {optimal_lag}\")\n",
    "\n",
    "# VAR ëª¨ë¸ í•™ìŠµ\n",
    "fitted_var = model_var.fit(optimal_lag)\n",
    "print(\"\\nëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(fitted_var.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 VAR ì˜ˆì¸¡ ë° ì—­ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "# VAR ì˜ˆì¸¡ì—ëŠ” ë§ˆì§€ë§‰ lag ê°œì˜ ë°ì´í„° í•„ìš”\n",
    "lag_order = fitted_var.k_ar\n",
    "forecast_input = train_var.values[-lag_order:]\n",
    "\n",
    "# n_test ê¸°ê°„ ì˜ˆì¸¡\n",
    "forecast_var = fitted_var.forecast(y=forecast_input, steps=n_test)\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ\n",
    "df_forecast = pd.DataFrame(\n",
    "    forecast_var,\n",
    "    index=test_var.index,\n",
    "    columns=[col + '_diff_pred' for col in train_var.columns]\n",
    ")\n",
    "\n",
    "print(\"=== ì°¨ë¶„ ë°ì´í„° ì˜ˆì¸¡ ê²°ê³¼ ===\")\n",
    "df_forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_diff_forecast(original_df, forecast_diff, n_diff=1):\n",
    "    \"\"\"\n",
    "    ì°¨ë¶„ëœ ì˜ˆì¸¡ê°’ì„ ì›ë³¸ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    original_df : pd.DataFrame\n",
    "        ì›ë³¸ ë°ì´í„° (ì°¨ë¶„ ì „)\n",
    "    forecast_diff : np.array or pd.DataFrame\n",
    "        ì°¨ë¶„ëœ ì˜ˆì¸¡ê°’\n",
    "    n_diff : int\n",
    "        ì°¨ë¶„ íšŸìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : ì›ë³¸ ìŠ¤ì¼€ì¼ ì˜ˆì¸¡ê°’\n",
    "    \"\"\"\n",
    "    if isinstance(forecast_diff, np.ndarray):\n",
    "        forecast_diff = pd.DataFrame(\n",
    "            forecast_diff,\n",
    "            columns=original_df.columns\n",
    "        )\n",
    "    \n",
    "    # ë§ˆì§€ë§‰ ì›ë³¸ê°’\n",
    "    last_values = original_df.iloc[-1]\n",
    "    \n",
    "    # ëˆ„ì í•©ìœ¼ë¡œ ì—­ë³€í™˜\n",
    "    # 1ì°¨ ì°¨ë¶„: Y(t) = Y(t-1) + diff(t)\n",
    "    forecast_original = forecast_diff.cumsum() + last_values.values\n",
    "    forecast_original.columns = [col + '_forecast' for col in original_df.columns]\n",
    "    \n",
    "    return forecast_original\n",
    "\n",
    "# ì›ë³¸ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜\n",
    "# í›ˆë ¨ ê¸°ê°„ì˜ ë§ˆì§€ë§‰ ê°’ ê¸°ì¤€ (í…ŒìŠ¤íŠ¸ ì‹œì‘ ì§ì „)\n",
    "train_original = df_econ.iloc[:-n_test]\n",
    "\n",
    "df_forecast_original = invert_diff_forecast(\n",
    "    train_original,\n",
    "    forecast_var\n",
    ")\n",
    "df_forecast_original.index = test_var.index\n",
    "\n",
    "print(\"=== ì›ë³¸ ìŠ¤ì¼€ì¼ ì˜ˆì¸¡ ê²°ê³¼ ===\")\n",
    "df_forecast_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
    "test_original = df_econ.iloc[-n_test:]\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True,\n",
    "                    subplot_titles=['Money (í†µí™”ëŸ‰)', 'Spending (ì†Œë¹„ì§€ì¶œ)'])\n",
    "\n",
    "# Money\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_econ.index, y=df_econ['Money'],\n",
    "    mode='lines', name='Money ì‹¤ì œ',\n",
    "    line=dict(color='blue')\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_forecast_original.index, y=df_forecast_original['Money_forecast'],\n",
    "    mode='lines', name='Money ì˜ˆì¸¡',\n",
    "    line=dict(color='blue', dash='dash')\n",
    "), row=1, col=1)\n",
    "\n",
    "# Spending\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_econ.index, y=df_econ['Spending'],\n",
    "    mode='lines', name='Spending ì‹¤ì œ',\n",
    "    line=dict(color='green')\n",
    "), row=2, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_forecast_original.index, y=df_forecast_original['Spending_forecast'],\n",
    "    mode='lines', name='Spending ì˜ˆì¸¡',\n",
    "    line=dict(color='green', dash='dash')\n",
    "), row=2, col=1)\n",
    "\n",
    "fig.update_layout(title='VAR ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼', height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def evaluate_var_forecast(actual, predicted):\n",
    "    \"\"\"VAR ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€\"\"\"\n",
    "    results = {}\n",
    "    for col in actual.columns:\n",
    "        pred_col = col + '_forecast'\n",
    "        if pred_col in predicted.columns:\n",
    "            mae = mean_absolute_error(actual[col], predicted[pred_col])\n",
    "            rmse = np.sqrt(mean_squared_error(actual[col], predicted[pred_col]))\n",
    "            mape = np.mean(np.abs((actual[col].values - predicted[pred_col].values) / actual[col].values)) * 100\n",
    "            results[col] = {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
    "    return results\n",
    "\n",
    "metrics = evaluate_var_forecast(test_original, df_forecast_original)\n",
    "\n",
    "print(\"=== VAR ì˜ˆì¸¡ ì„±ëŠ¥ ===\")\n",
    "for var, m in metrics.items():\n",
    "    print(f\"\\n{var}:\")\n",
    "    print(f\"  MAE: {m['MAE']:.2f}\")\n",
    "    print(f\"  RMSE: {m['RMSE']:.2f}\")\n",
    "    print(f\"  MAPE: {m['MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 VAR ëª¨ë¸ ì§„ë‹¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì”ì°¨ ìê¸°ìƒê´€ ê²€ì • (Durbin-Watson)\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "residuals = fitted_var.resid\n",
    "print(\"=== Durbin-Watson ê²€ì • ===\")\n",
    "print(\"(2ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìê¸°ìƒê´€ ì—†ìŒ)\\n\")\n",
    "\n",
    "for i, col in enumerate(train_var.columns):\n",
    "    dw = durbin_watson(residuals[:, i])\n",
    "    print(f\"{col}: DW = {dw:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³„ìˆ˜ í•´ì„\n",
    "print(\"=== VAR ëª¨ë¸ ê³„ìˆ˜ ===\")\n",
    "print(\"\\nê° ë³€ìˆ˜ì— ëŒ€í•œ íšŒê·€ ê³„ìˆ˜:\")\n",
    "\n",
    "for i, target in enumerate(train_var.columns):\n",
    "    print(f\"\\n[{target} ë°©ì •ì‹]\")\n",
    "    coef_df = pd.DataFrame(\n",
    "        fitted_var.coefs.reshape(-1, len(train_var.columns)).T,\n",
    "        index=train_var.columns\n",
    "    )\n",
    "    print(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ¯ ì‹¤ìŠµ í€´ì¦ˆ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í€´ì¦ˆ 1 â­\n",
    "\n",
    "ìƒê´€ê´€ê³„ì™€ ì¸ê³¼ê´€ê³„ì˜ ì°¨ì´ì ì„ ì„¤ëª…í•˜ê³ , ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •ì˜ ê·€ë¬´ê°€ì„¤ì„ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "# ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš”\n",
    "# ìƒê´€ê´€ê³„: ë‘ ë³€ìˆ˜ê°€ í•¨ê»˜ ______ëŠ” ê²ƒ\n",
    "# ì¸ê³¼ê´€ê³„: í•œ ë³€ìˆ˜ê°€ ë‹¤ë¥¸ ë³€ìˆ˜ì— ______ì„ ì£¼ëŠ” ê²ƒ\n",
    "\n",
    "# ê·¸ëœì € ì¸ê³¼ì„± ê·€ë¬´ê°€ì„¤ (H0):\n",
    "# \"Xê°€ Yë¥¼ ê·¸ëœì €-______í•˜ì§€ ì•ŠëŠ”ë‹¤\"\n",
    "# = \"Xì˜ ê³¼ê±°ê°’ì´ Y ì˜ˆì¸¡ì— ______ì´ ì•ˆ ëœë‹¤\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 1 í’€ì´\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í€´ì¦ˆ 2 â­\n",
    "\n",
    "ê·¸ëœì € ì¸ê³¼ì„± ê²€ì • ê²°ê³¼ p-valueê°€ 0.03ì´ ë‚˜ì™”ìŠµë‹ˆë‹¤. ì´ ê²°ê³¼ë¥¼ ì–´ë–»ê²Œ í•´ì„í•´ì•¼ í•˜ë‚˜ìš”?\n",
    "\n",
    "```python\n",
    "# p-value = 0.03 í•´ì„\n",
    "p_value = 0.03\n",
    "alpha = 0.05  # ìœ ì˜ìˆ˜ì¤€\n",
    "\n",
    "if p_value ______ alpha:\n",
    "    result = \"ê·€ë¬´ê°€ì„¤ ______\"\n",
    "    interpretation = \"Xê°€ Yë¥¼ ê·¸ëœì €-______í•œë‹¤\"\n",
    "else:\n",
    "    result = \"ê·€ë¬´ê°€ì„¤ ______\"\n",
    "    interpretation = \"ì¸ê³¼ê´€ê³„ ______\"\n",
    "\n",
    "print(f\"ê²°ê³¼: {result}\")\n",
    "print(f\"í•´ì„: {interpretation}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 2 í’€ì´\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í€´ì¦ˆ 3 â­â­\n",
    "\n",
    "statsmodelsì˜ grangercausalitytests í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •ì„ ìˆ˜í–‰í•˜ì„¸ìš”.\n",
    "\n",
    "ì£¼ì˜: í•¨ìˆ˜ ì…ë ¥ ìˆœì„œëŠ” [Y, X]ì…ë‹ˆë‹¤ (Yë¥¼ ì˜ˆì¸¡í•  ë•Œ Xê°€ ë„ì›€ì´ ë˜ëŠ”ì§€ ê²€ì •)\n",
    "\n",
    "```python\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# ë°ì´í„° ì¤€ë¹„ (df_diffì— 'Money', 'Spending' ì—´ì´ ìˆë‹¤ê³  ê°€ì •)\n",
    "# \"Moneyê°€ Spendingì„ ê·¸ëœì €-ì›ì¸í•˜ëŠ”ê°€?\" ê²€ì •\n",
    "\n",
    "# grangercausalitytests ì…ë ¥: [ê²°ê³¼ë³€ìˆ˜, ì›ì¸ë³€ìˆ˜]\n",
    "test_data = df_diff[[______, ______]]  # ìˆœì„œ ì£¼ì˜!\n",
    "\n",
    "# ê²€ì • ìˆ˜í–‰ (maxlag=5)\n",
    "results = grangercausalitytests(test_data, maxlag=______, verbose=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 3 í’€ì´\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í€´ì¦ˆ 4 â­â­\n",
    "\n",
    "VAR ëª¨ë¸ê³¼ ARIMA ëª¨ë¸ì˜ ì°¨ì´ì ì„ ì½”ë“œë¡œ ë¹„êµí•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "# ARIMA: ë‹¨ë³€ëŸ‰ (1ê°œ ë³€ìˆ˜)\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "arima_model = ARIMA(df['______'], order=(1,1,1))  # ë‹¨ì¼ ì—´\n",
    "\n",
    "# VAR: ë‹¤ë³€ëŸ‰ (2ê°œ ì´ìƒ ë³€ìˆ˜)\n",
    "from statsmodels.tsa.api import VAR\n",
    "var_model = VAR(df[['______', '______']])  # ì—¬ëŸ¬ ì—´\n",
    "\n",
    "# VARì˜ ì¥ì ì€?\n",
    "# ë³€ìˆ˜ ê°„ ______ì„ ë°˜ì˜í•˜ì—¬ ì˜ˆì¸¡\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 4 í’€ì´\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í€´ì¦ˆ 5 â­â­\n",
    "\n",
    "VAR ëª¨ë¸ì˜ ìµœì  ì‹œì°¨(lag)ë¥¼ ì„ íƒí•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "# VAR ëª¨ë¸ ìƒì„±\n",
    "model = VAR(df_diff)\n",
    "\n",
    "# ìµœì  ì‹œì°¨ ì„ íƒ\n",
    "lag_selection = model._______(maxlags=15)\n",
    "\n",
    "# AIC ê¸°ì¤€ ìµœì  ì‹œì°¨\n",
    "optimal_lag = lag_selection._____\n",
    "print(f\"AIC ê¸°ì¤€ ìµœì  ì‹œì°¨: {optimal_lag}\")\n",
    "\n",
    "# BIC ê¸°ì¤€ ìµœì  ì‹œì°¨\n",
    "optimal_lag_bic = lag_selection._____\n",
    "print(f\"BIC ê¸°ì¤€ ìµœì  ì‹œì°¨: {optimal_lag_bic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 5 í’€ì´\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í€´ì¦ˆ 6 â­â­â­\n",
    "\n",
    "VAR ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ì „ì²´ ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "# 1. ë°ì´í„° ë¶„í• \n",
    "n_test = 12\n",
    "train = df_diff[:-n_test]\n",
    "test = df_diff[-n_test:]\n",
    "\n",
    "# 2. VAR ëª¨ë¸ í•™ìŠµ\n",
    "model = VAR(______)\n",
    "fitted = model.fit(______)\n",
    "\n",
    "# 3. ì˜ˆì¸¡ (forecast ë©”ì„œë“œ ì‚¬ìš©)\n",
    "lag_order = fitted.k_ar\n",
    "forecast_input = train.values[-______:]\n",
    "forecast = fitted.forecast(y=forecast_input, steps=______)\n",
    "\n",
    "print(f\"ì˜ˆì¸¡ shape: {forecast.shape}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 6 í’€ì´\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í€´ì¦ˆ 7 â­â­â­\n",
    "\n",
    "yfinanceë¥¼ ì‚¬ìš©í•˜ì—¬ 2ê°œ ì¢…ëª©ì˜ ì£¼ê°€ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì–‘ë°©í–¥ ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •ì„ ìˆ˜í–‰í•˜ì„¸ìš”.\n",
    "\n",
    "ìš”êµ¬ì‚¬í•­:\n",
    "1. ë„¤ì´ë²„(NAVER)ì™€ ì¹´ì¹´ì˜¤(KAKAO) ì£¼ì‹ ìˆ˜ì§‘\n",
    "2. ìˆ˜ìµë¥ ë¡œ ë³€í™˜ (ì •ìƒì„± í™•ë³´)\n",
    "3. ì–‘ë°©í–¥ ê²€ì •: NAVER â†’ KAKAO, KAKAO â†’ NAVER\n",
    "\n",
    "```python\n",
    "import yfinance as yf\n",
    "\n",
    "# 1. ë°ì´í„° ìˆ˜ì§‘ (í•œêµ­ ì£¼ì‹)\n",
    "naver = yf.download('035420.KS', period='2y')['Close']\n",
    "kakao = yf.download('035720.KS', period='2y')['Close']\n",
    "\n",
    "# 2. DataFrame ê²°í•© ë° ìˆ˜ìµë¥  ë³€í™˜\n",
    "# ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±\n",
    "\n",
    "# 3. ì–‘ë°©í–¥ ê·¸ëœì € ê²€ì •\n",
    "# ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 7 í’€ì´\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í€´ì¦ˆ 8 â­â­â­â­\n",
    "\n",
    "ì°¨ë¶„ëœ VAR ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì›ë³¸ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•˜ì„¸ìš”.\n",
    "\n",
    "íŒíŠ¸: 1ì°¨ ì°¨ë¶„ì˜ ì—­ë³€í™˜ì€ ëˆ„ì í•© + ë§ˆì§€ë§‰ ì›ë³¸ê°’\n",
    "\n",
    "```python\n",
    "def invert_difference(original_series, forecast_diff):\n",
    "    \"\"\"\n",
    "    ì°¨ë¶„ëœ ì˜ˆì¸¡ê°’ì„ ì›ë³¸ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    original_series : pd.Series\n",
    "        ì›ë³¸ ì‹œê³„ì—´ (ì°¨ë¶„ ì „)\n",
    "    forecast_diff : np.array\n",
    "        ì°¨ë¶„ëœ ì˜ˆì¸¡ê°’\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.array : ì›ë³¸ ìŠ¤ì¼€ì¼ ì˜ˆì¸¡ê°’\n",
    "    \"\"\"\n",
    "    # ë§ˆì§€ë§‰ ì›ë³¸ê°’\n",
    "    last_value = original_series.iloc[______]\n",
    "    \n",
    "    # ëˆ„ì í•©ìœ¼ë¡œ ì—­ë³€í™˜\n",
    "    # diff(t) = Y(t) - Y(t-1) ì´ë¯€ë¡œ\n",
    "    # Y(t) = Y(t-1) + diff(t)\n",
    "    forecast_original = np._______(forecast_diff) + last_value\n",
    "    \n",
    "    return forecast_original\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "# original = pd.Series([100, 110, 125, 140])\n",
    "# diff_forecast = np.array([15, 12, 18])  # ì˜ˆì¸¡ëœ ì°¨ë¶„\n",
    "# result = invert_difference(original, diff_forecast)\n",
    "# ì˜ˆìƒ ê²°ê³¼: [155, 167, 185] (140+15=155, 155+12=167, ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 8 í’€ì´\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í€´ì¦ˆ 9 â­â­â­â­\n",
    "\n",
    "ì—¬ëŸ¬ ë³€ìˆ˜ì— ëŒ€í•œ ê·¸ëœì € ì¸ê³¼ì„± ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "def granger_matrix(data, variables, maxlag=5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë³€ìˆ˜ ê°„ ê·¸ëœì € ì¸ê³¼ì„± ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        ì‹œê³„ì—´ ë°ì´í„°\n",
    "    variables : list\n",
    "        ë¶„ì„í•  ë³€ìˆ˜ ëª©ë¡\n",
    "    maxlag : int\n",
    "        ê²€ì •í•  ìµœëŒ€ ì‹œì°¨\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : ì¸ê³¼ì„± ë§¤íŠ¸ë¦­ìŠ¤ (í–‰: ì›ì¸, ì—´: ê²°ê³¼)\n",
    "    \"\"\"\n",
    "    n = len(variables)\n",
    "    matrix = np.zeros((n, n))\n",
    "    \n",
    "    for i, cause in enumerate(variables):\n",
    "        for j, effect in enumerate(variables):\n",
    "            if i != j:  # ìê¸° ìì‹  ì œì™¸\n",
    "                # ê·¸ëœì € ê²€ì • ìˆ˜í–‰\n",
    "                # ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±\n",
    "                pass\n",
    "    \n",
    "    return pd.DataFrame(matrix, index=variables, columns=variables)\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "# matrix = granger_matrix(df_returns, ['Samsung', 'SKHynix', 'Naver'])\n",
    "# ì‹œê°í™”: heatmapìœ¼ë¡œ í‘œì‹œ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 9 í’€ì´\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í€´ì¦ˆ 10 â­â­â­â­â­\n",
    "\n",
    "**ì¢…í•© í”„ë¡œì íŠ¸**: ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•˜ì„¸ìš”.\n",
    "\n",
    "ìš”êµ¬ì‚¬í•­:\n",
    "1. í´ë˜ìŠ¤ëª…: `MultivariateAnalyzer`\n",
    "2. ë©”ì„œë“œ:\n",
    "   - `fit(data, test_size)`: ë°ì´í„° ë¶„í•  ë° ëª¨ë¸ í•™ìŠµ\n",
    "   - `granger_test(x, y)`: ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •\n",
    "   - `predict(steps)`: VAR ì˜ˆì¸¡\n",
    "   - `evaluate()`: ì„±ëŠ¥ í‰ê°€\n",
    "   - `plot()`: ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
    "3. ìë™ ì •ìƒì„± ë³€í™˜ (ì°¨ë¶„) ì§€ì›\n",
    "4. ì—­ë³€í™˜ìœ¼ë¡œ ì›ë³¸ ìŠ¤ì¼€ì¼ ì˜ˆì¸¡\n",
    "\n",
    "```python\n",
    "class MultivariateAnalyzer:\n",
    "    def __init__(self, maxlag=15):\n",
    "        self.maxlag = maxlag\n",
    "        # ì¶”ê°€ ì†ì„±ë“¤...\n",
    "    \n",
    "    def fit(self, data, test_size=12):\n",
    "        \"\"\"ë°ì´í„° ë¶„í• , ì •ìƒì„± ë³€í™˜, VAR í•™ìŠµ\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def granger_test(self, cause, effect, maxlag=None):\n",
    "        \"\"\"ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self, steps=None):\n",
    "        \"\"\"VAR ì˜ˆì¸¡ (ì›ë³¸ ìŠ¤ì¼€ì¼ ë°˜í™˜)\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def plot(self):\n",
    "        \"\"\"ì‹œê°í™”\"\"\"\n",
    "        pass\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "analyzer = MultivariateAnalyzer()\n",
    "analyzer.fit(df_econ, test_size=12)\n",
    "analyzer.granger_test('Money', 'Spending')\n",
    "analyzer.predict()\n",
    "metrics = analyzer.evaluate()\n",
    "analyzer.plot()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 10 í’€ì´\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: ê¸°ì´ˆ í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ê°œë… | ì„¤ëª… | ì½”ë“œ ì˜ˆì‹œ |\n",
    "|------|------|----------|\n",
    "| **ìƒê´€ vs ì¸ê³¼** | í•¨ê»˜ ì›€ì§ì„ vs ì˜í–¥ ê´€ê³„ | correlation â‰  causation |\n",
    "| **ê·¸ëœì € ì¸ê³¼ì„±** | Xì˜ ê³¼ê±°ê°€ Y ì˜ˆì¸¡ì— ë„ì›€? | `grangercausalitytests()` |\n",
    "| **ê·€ë¬´ê°€ì„¤** | Xê°€ Yë¥¼ ì›ì¸í•˜ì§€ ì•ŠìŒ | p < 0.05ë©´ ê¸°ê° |\n",
    "| **ì–‘ë°©í–¥ ê²€ì •** | Xâ†’Y, Yâ†’X ëª¨ë‘ í™•ì¸ | í”¼ë“œë°± ê´€ê³„ íŒŒì•… |\n",
    "| **ì •ìƒì„± í•„ìˆ˜** | ì°¨ë¶„ í›„ ê²€ì • | `adfuller()` + `diff()` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: ì‹¬í™” í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ê°œë… | ì„¤ëª… | ì½”ë“œ ì˜ˆì‹œ |\n",
    "|------|------|----------|\n",
    "| **VAR** | ë‹¤ë³€ëŸ‰ ìê¸°íšŒê·€ | `VAR(df).fit(lag)` |\n",
    "| **ìµœì  ì‹œì°¨** | AIC/BIC ìµœì†Œí™” | `select_order(maxlags=15)` |\n",
    "| **ì˜ˆì¸¡** | ì—¬ëŸ¬ ë³€ìˆ˜ ë™ì‹œ ì˜ˆì¸¡ | `fitted.forecast(steps=n)` |\n",
    "| **ì—­ë³€í™˜** | ì°¨ë¶„ â†’ ì›ë³¸ ìŠ¤ì¼€ì¼ | `cumsum() + last_value` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ íŒ\n",
    "\n",
    "1. **ì •ìƒì„± ë¨¼ì €**: VARë„ ì •ìƒ ì‹œê³„ì—´ í•„ìš” (ì°¨ë¶„ ì ìš©)\n",
    "2. **ê·¸ëœì € â‰  ì§„ì§œ ì¸ê³¼**: \"ì˜ˆì¸¡ ì¸ê³¼ì„±\"ì´ë©° ìˆ¨ì€ ë³€ìˆ˜ ê°€ëŠ¥\n",
    "3. **ì–‘ë°©í–¥ ê²€ì •**: í•œìª½ë§Œ ë³´ì§€ ë§ê³  ì—­ë°©í–¥ë„ í™•ì¸\n",
    "4. **ì‹œì°¨ ì„ íƒ**: AICì™€ BIC ëª¨ë‘ ì°¸ê³ , í•´ì„ ê°€ëŠ¥í•œ ì‹œì°¨ ì„ í˜¸\n",
    "5. **ì—­ë³€í™˜ ì£¼ì˜**: ë‹¤ì¤‘ ì°¨ë¶„ ì‹œ ìˆœì„œëŒ€ë¡œ ì—­ë³€í™˜\n",
    "6. **ë³€ìˆ˜ ê°œìˆ˜**: ë„ˆë¬´ ë§ìœ¼ë©´ ê³¼ì í•©, 2-5ê°œ ê¶Œì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Day8 ì‹œê³„ì—´ ë¶„ì„ ì‹œë¦¬ì¦ˆ ì™„ë£Œ\n",
    "\n",
    "| Day | ì£¼ì œ | í•µì‹¬ ë‚´ìš© |\n",
    "|-----|------|----------|\n",
    "| **Day8_0** | ì‹œê³„ì—´ ê¸°ì´ˆ | datetime, DatetimeIndex, shift, diff |\n",
    "| **Day8_1** | ë¶„ì„ ê¸°ë²• | resample, rolling, ê³„ì ˆë¶„í•´ |\n",
    "| **Day8_2** | ì‹œê°í™”+í”„ë¡œì íŠ¸ | Plotly, yfinance, ëŒ€ì‹œë³´ë“œ |\n",
    "| **Day8_3** | ì •ìƒì„± ì§„ë‹¨ | ADF, KPSS, ACF/PACF |\n",
    "| **Day8_4** | ARIMA/SARIMA | ì˜ˆì¸¡ ëª¨ë¸ë§, auto_arima |\n",
    "| **Day8_5** | VAR+ê·¸ëœì € | ë‹¤ë³€ëŸ‰ ë¶„ì„, ì¸ê³¼ì„± ê²€ì • |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
