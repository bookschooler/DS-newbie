{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day19_0: 생성형 AI와 대규모 언어 모델(LLM) 이해\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "**Part 1: 기초**\n",
    "1. 생성형 AI(Generative AI)의 개념을 정의하고, 전통적인 AI와의 근본적인 차이점을 설명할 수 있습니다.\n",
    "2. 대규모 언어 모델(LLM)이 무엇인지 이해하고, GPT, BERT, T5와 같은 주요 모델들의 구조적 차이와 용도를 비교할 수 있습니다.\n",
    "3. LLM의 발전을 이끈 핵심 기술인 Transformer와 Self-Attention의 원리를 이해합니다.\n",
    "4. OpenAI API를 사용하여 GPT 모델을 호출하고 응답을 받아올 수 있습니다.\n",
    "5. API 파라미터(temperature, max_tokens 등)의 의미를 이해하고 적절히 조절할 수 있습니다.\n",
    "\n",
    "**Part 2: 심화**\n",
    "1. \"크면 클수록 좋다\"는 스케일링 법칙(Scaling Laws)이 LLM 발전에 어떤 의미를 갖는지 설명할 수 있습니다.\n",
    "2. LLM이 현실 세계의 다양한 산업(콘텐츠 제작, 챗봇, 코딩 등)에 어떻게 응용되고 있는지 사례를 통해 이해합니다.\n",
    "3. 프롬프트 엔지니어링 기법을 활용하여 원하는 출력을 유도할 수 있습니다.\n",
    "4. Few-shot 프롬프팅과 시스템 프롬프트를 설계하여 실무 문제를 해결할 수 있습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 왜 이것을 배우나요?\n",
    "\n",
    "| 개념 | 실무 활용 | 예시 |\n",
    "|------|----------|------|\n",
    "| 생성형 AI 개념 | AI 서비스 기획 및 활용 | ChatGPT, Claude, Gemini 이해 |\n",
    "| LLM 아키텍처 | 용도에 맞는 모델 선택 | GPT(생성), BERT(이해), T5(변환) |\n",
    "| OpenAI API | AI 기반 애플리케이션 개발 | 챗봇, 자동 요약, 콘텐츠 생성 |\n",
    "| 프롬프트 엔지니어링 | 원하는 출력 정확도 향상 | 정확한 분류, 일관된 포맷 출력 |\n",
    "\n",
    "**분석가 관점**: LLM API를 활용하면 텍스트 데이터 분석(감성 분류, 요약, 번역)을 자동화할 수 있습니다. 데이터 분석 파이프라인에 LLM을 통합하여 비정형 데이터도 효율적으로 처리할 수 있습니다!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: 기초\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 생성형 AI(Generative AI)란?\n",
    "\n",
    "### \"패턴 인식\"을 넘어 \"패턴 창조\"로\n",
    "\n",
    "생성형 AI는 학습한 데이터의 패턴과 구조를 바탕으로, 세상에 없던 **새로운 콘텐츠(텍스트, 이미지, 코드, 음악 등)를 만들어내는** 인공지능 기술입니다.\n",
    "\n",
    "| 단계 | 설명 |\n",
    "|------|------|\n",
    "| **학습 단계** | 방대한 양의 데이터(예: 웹 텍스트, 이미지 모음)를 학습하며 그 안에 내재된 통계적 패턴과 규칙을 익힙니다. |\n",
    "| **생성 단계** | 사용자로부터 받은 입력(프롬프트, Prompt)을 조건으로, 학습한 패턴에 따라 가장 그럴듯한(probable) 결과물을 새롭게 생성합니다. |\n",
    "\n",
    "**핵심 차별점**: 기존 AI가 주어진 데이터를 **분류(Classification)**하거나 **예측(Prediction)**하는 '판별' 모델에 가까웠다면, 생성형 AI는 새로운 데이터를 '생성'하는 **'생성' 모델**이라는 점에서 근본적인 차이가 있습니다.\n",
    "\n",
    "> **작동 방식 요약**:  \n",
    "> \"수많은 고양이 사진을 본 AI에게 '귀여운 고양이를 그려줘'라고 했을 때, 사진들의 공통적인 특징(뾰족한 귀, 동그란 눈, 수염 등)을 조합하여 세상에 단 하나뿐인 새로운 고양이 이미지를 창조해내는 것\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전통적 AI vs. 생성형 AI 비교\n",
    "\n",
    "전통적 AI와 생성형 AI는 목표와 작동 방식에서 명확히 구분됩니다.\n",
    "\n",
    "| 구분 | 전통적 AI (판별형 AI) | 생성형 AI |\n",
    "|------|---------------------|----------|\n",
    "| **목표** | 데이터 분류, 예측, 추천 | 새로운 콘텐츠 생성 |\n",
    "| **작동 원리** | 정해진 규칙 또는 데이터 패턴 분석 | 학습된 데이터의 확률 분포 기반 생성 |\n",
    "| **산출물** | 예측 값, 분류 레이블 (e.g., 스팸/정상) | 텍스트, 이미지, 코드 등 새로운 데이터 |\n",
    "| **창의성** | 없음 (정해진 범위 내에서 동작) | 높음 (새로운 아이디어/결과물 생성) |\n",
    "| **데이터** | 주로 정형화된 데이터에 강점 | 대규모 비정형 데이터 기반 학습 |\n",
    "| **예시** | 스팸 메일 필터, 상품 추천 시스템 | ChatGPT, DALL-E, GitHub Copilot |\n",
    "\n",
    "**핵심 비유**:\n",
    "> 전통적 AI가 \"이 사진에 고양이가 **있는지 없는지 판단**하는 심판\"이라면,  \n",
    "> 생성형 AI는 \"'상상 속의 고양이'를 **새롭게 그려내는** 화가\"입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 대규모 언어 모델(LLM)이란?\n",
    "\n",
    "### 언어를 이해하고 생성하는 거대한 뇌\n",
    "\n",
    "**대규모 언어 모델(Large Language Model, LLM)**은 수천억 개 이상의 매개변수(Parameter)를 가진 거대한 인공 신경망으로, 방대한 양의 텍스트 데이터를 학습하여 인간의 언어를 이해하고 생성하는 능력을 갖춘 모델입니다.\n",
    "\n",
    "| 특성 | 설명 |\n",
    "|------|------|\n",
    "| **핵심 기술** | 대부분의 현대 LLM은 **Transformer** 아키텍처를 기반으로 합니다. |\n",
    "| **학습 데이터** | 인터넷의 웹 페이지, 책, 뉴스 기사 등 상상할 수 있는 거의 모든 텍스트를 학습합니다. |\n",
    "| **능력** | 문맥 이해, 문장 생성, 번역, 요약, 질의응답 등 다재다능한 언어 과제를 수행할 수 있습니다. |\n",
    "| **대표 주자** | OpenAI의 **GPT** 시리즈, Google의 **BERT, T5, Gemini**, Meta의 **LLaMA** 등이 있습니다. |\n",
    "\n",
    "**\"대규모\"의 의미**:\n",
    "> LLM의 '대규모'는 단순히 큰 것이 아니라, 모델의 크기(파라미터 수)가 일정 수준을 넘어서면서 기존 모델에서는 볼 수 없었던 **창발적 능력(Emergent Abilities)** - 예를 들어 추론, 복잡한 지시 이해 등 - 이 나타나기 시작했다는 점에서 중요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 LLM 아키텍처 비교: GPT vs BERT vs T5\n",
    "\n",
    "LLM은 Transformer 구조를 어떻게 활용하는지에 따라 크게 세 가지 계열로 나뉩니다.\n",
    "\n",
    "| 계열 | 대표 모델 | Transformer 구조 | 핵심 특징 | 주요 용도 |\n",
    "|------|----------|-----------------|----------|----------|\n",
    "| **디코더-Only** | GPT, LLaMA, PaLM | Decoder | **단방향(왼쪽→오른쪽) 문맥**을 보고 다음 단어를 예측 (Auto-regressive). 문장 생성에 특화. | **텍스트 생성**, 챗봇, 창작, 요약 |\n",
    "| **인코더-Only** | BERT, RoBERTa | Encoder | **양방향 문맥**을 모두 보고 빈칸(MASK)을 예측. 문장 전체의 의미 이해에 특화. | **자연어 이해(NLU)**, 문장 분류, 감성 분석, 개체명 인식 |\n",
    "| **인코더-디코더** | T5, BART | Encoder + Decoder | 입력 시퀀스를 다른 출력 시퀀스로 변환하는 **Seq2Seq** 구조. 모든 NLP 문제를 \"Text-to-Text\"로 접근. | **번역**, 요약, 문서 변환 |\n",
    "\n",
    "**모델 선택 가이드**:\n",
    "- 텍스트를 **생성**해야 한다면 → **GPT 계열**\n",
    "- 텍스트를 **이해/분류**해야 한다면 → **BERT 계열**\n",
    "- 텍스트를 **변환**해야 한다면 → **T5 계열**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 핵심 혁신 1: Transformer & Self-Attention\n",
    "\n",
    "### LLM 시대를 연 결정적 기술\n",
    "\n",
    "2017년 논문 **\"Attention Is All You Need\"**에서 등장한 Transformer는 순차적으로 정보를 처리하던 기존 RNN/LSTM의 한계를 극복했습니다.\n",
    "\n",
    "| 구분 | RNN의 한계 | Transformer의 혁신 |\n",
    "|------|-----------|-------------------|\n",
    "| **처리 방식** | **순차 처리**: 문장이 길어지면 처리 속도가 느림 (병렬화 불가) | **병렬 처리**: 문장 전체를 한 번에 입력받아 모든 단어 간 관계를 동시에 계산 |\n",
    "| **장기 의존성** | **장기 의존성 문제**: 문장 앞부분의 정보가 뒤로 갈수록 희미해짐 | **Self-Attention**: 멀리 떨어진 단어 간의 관계도 직접적으로 파악 |\n",
    "\n",
    "### Self-Attention: 단어 간의 관계 네트워크\n",
    "\n",
    "Self-Attention은 문장 내 한 단어가 다른 모든 단어와 얼마나 관련이 있는지(Attention Score)를 계산하여, 중요한 단어의 정보에 더 '집중'하는 메커니즘입니다.\n",
    "\n",
    "```\n",
    "문장: \"그 동물은 길을 건너지 못했다 왜냐하면 피곤해서\"\n",
    "\n",
    "\"못했다\"라는 단어를 처리할 때:\n",
    "- '동물', '건너지', '피곤해서' 등의 단어에 높은 Attention을 줌\n",
    "- 문맥을 파악하여 \"피곤해서 건너지 못했다\"는 의미를 이해\n",
    "```\n",
    "\n",
    "이 메커니즘 덕분에 Transformer는 긴 문장에서도 문맥을 정확하게 파악할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 OpenAI API 기본 사용법\n",
    "\n",
    "### 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 라이브러리 설치 (필요시)\n",
    "# !pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from openai import OpenAI\n",
    "\n",
    "# # .env 파일에서 환경 변수 로드\n",
    "# load_dotenv()\n",
    "\n",
    "# # API 키 설정 (환경변수에서 자동으로 가져옴: OPENAI_API_KEY)\n",
    "# client = OpenAI()\n",
    "\n",
    "# print(\"OpenAI 클라이언트가 설정되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API 키 보안 주의사항\n",
    "\n",
    "| 방법 | 권장 여부 | 설명 |\n",
    "|------|----------|------|\n",
    "| 환경변수 | **권장** | `export OPENAI_API_KEY='sk-...'` |\n",
    "| .env 파일 | 권장 | `.gitignore`에 추가 필수 |\n",
    "| 코드에 직접 입력 | **위험** | 깃허브 유출 위험 |\n",
    "\n",
    "```bash\n",
    "# .env 파일 예시\n",
    "OPENAI_API_KEY=sk-proj-xxxxx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 첫 번째 API 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user said \"안녕하세요! 간단히 자기소개 해주세요.\" which means \"Hello! Please do a brief self-introduction.\" I need to provide a short and friendly introduction of myself. Let me start by greeting them back in Korean. Then mention that I'm an AI assistant developed by Alibaba Cloud. Highlight my capabilities like answering questions, providing information, and helping with tasks. Keep it concise but welcoming. Make sure to use proper Korean etiquette and a helpful tone. Avoid any technical jargon. Maybe end with an invitation for them to ask questions. Let me check the structure: greeting, name, purpose, capabilities, offer help. That should cover it. Now, put it all together in natural Korean.\n",
      "</think>\n",
      "\n",
      "안녕하세요! 저는 알리바바 클라우드에서 개발한 대형 언어 모델인 쿤이차(Qwen)입니다. 궁금한 점이 있거나 정보가 필요하시면 언제든지 도와드릴 수 있어요. 질문해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 가장 기본적인 API 호출\n",
    "response = client.chat.completions.create(\n",
    "    model=\"qwen/qwen3-32b\",  # 사용할 모델\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요! 간단히 자기소개 해주세요.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 응답 출력\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 메시지 역할 (Role) 이해하기\n",
    "\n",
    "| 역할 | 설명 | 예시 |\n",
    "|------|------|------|\n",
    "| `system` | AI의 행동 방식, 역할, 제약 조건 정의 | \"당신은 친절한 요리사입니다\" |\n",
    "| `user` | 사용자의 질문이나 요청 | \"파스타 레시피 알려주세요\" |\n",
    "| `assistant` | AI의 이전 응답 (대화 히스토리) | \"네, 파스타 레시피를 알려드릴게요...\" |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## pandas와 numpy의 차이점\n",
      "\n",
      "| 구분 | **NumPy** | **pandas** |\n",
      "|------|-----------|------------|\n",
      "| **주된 목적** | 고성능 수치 연산 및 다차원 배열 처리 | **표(table) 형태**의 데이터 조작·분석(시계열, 카테고리 등) |\n",
      "| **핵심 자료구조** | `ndarray` (동일한 자료형을 갖는 다차원 배열) | `Series` (1차원 레이블 배열) <br> `DataFrame` (2차원 레이블 테이블) |\n",
      "| **데이터 타입** | 기본적으로 **동일한 dtype**(예: `float64`, `int32`)만 허용 | 각 컬럼마다 **다른 dtype** 가능 (숫자, 문자열, datetime, 범주형 등) |\n",
      "| **인덱싱/라벨링** | 정수 인덱스 기반 슬라이싱·정수 배열 | **라벨 기반 인덱싱** (`.loc`, `.iloc`), 복합 인덱스(MultiIndex) 지원 |\n",
      "| **브로드캐스팅** | 배열 연산 시 자동 브로드캐스팅 지원 | `Series`와 `DataFrame` 간 연산에서도 브로드캐스팅 적용되지만, 라벨 정렬이 먼저 수행 |\n",
      "| **결측치 처리** | `np.nan`은 부동소수점 전용, 정수 배열은 `np.nan`을 직접 저장 불가 (masked array 필요) | `NaN`, `None`, `pd.NA`(새로운 nullable dtype) 등 다양한 결측치 표현·전용 메서드(`.isna()`, `.fillna()`) 제공 |\n",
      "| **파일 입출력** | `np.save`, `np.load`, `np.genfromtxt` 등 (주로 binary/텍스트) | CSV, Excel, JSON, SQL, Parquet, Feather 등 **다양한 포맷**을 손쉽게 읽고 쓸 수 있는 메서드 제공 (`read_csv`, `to_excel` 등) |\n",
      "| **시계열/시간 인덱스** | 기본 제공되지 않음 (datetime 배열은 가능하지만 기능 제한) | 강력한 **시계열 기능** (`DatetimeIndex`, `PeriodIndex`, `Timedelta`, `resample`, `shift`, `rolling` 등) |\n",
      "| **그룹화·집계** | `np.sum`, `np.mean` 등 기본 연산은 가능하지만 그룹별 연산은 직접 구현 필요 | `groupby`, `pivot`, `pivot_table`, `crosstab` 등 **고수준 집계·변형** 기능 제공 |\n",
      "| **성능** | 순수 수치 연산에서 C/Fortran 수준의 속도 (벡터화) | 내부적으로 NumPy 배열을 사용하지만, **인덱스 관리·라벨 정렬** 등 부가 작업으로 약간 느릴 수 있음. 그러나 `DataFrame` 전체를 벡터화하면 여전히 빠름 |\n",
      "| **생태계·연동** | SciPy, scikit‑learn, TensorFlow 등 수치·과학 연산 패키지와 직접 연동 | statsmodels, seaborn, plotly, pandas‑api‑on‑spark 등 데이터 분석·시각화·머신러닝 파이프라인에 최적화된 라이브러리와 연동 |\n",
      "\n",
      "---\n",
      "\n",
      "## 언제 NumPy를 쓰고, 언제 pandas를 써야 할까?\n",
      "\n",
      "| 상황 | 권장 라이브러리 |\n",
      "|------|----------------|\n",
      "| **수치·행렬 연산** (선형대수, FFT, 이미지 처리 등) | `NumPy` |\n",
      "| **다차원 배열을 직접 조작**하고, 메모리 사용을 최소화하고 싶을 때 | `NumPy` |\n",
      "| **표 형식 데이터**(엑셀, CSV, 데이터베이스 등) 를 다루고, 컬럼별 타입이 서로 다를 때 | `pandas` |\n",
      "| **결측치·데이터 정제**(필터링, 변환, 채우기) | `pandas` |\n",
      "| **시계열 분석**(리샘플링, 이동 평균, 시계열 인덱스) | `pandas` |\n",
      "| **그룹별 집계·피벗 테이블** | `pandas` |\n",
      "| **다양한 파일 포맷**(CSV, Excel, JSON, Parquet 등) 입·출력 | `pandas` |\n",
      "| **머신러닝 전처리**(특징 선택, 원‑핫 인코딩, 스케일링) | 보통 `pandas` → `scikit‑learn` (scikit‑learn은 내부적으로 NumPy 배열을 사용) |\n",
      "\n",
      "---\n",
      "\n",
      "## 간단한 예시\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# 1) NumPy: 2차원 배열 연산\n",
      "a = np.arange(12).reshape(3, 4)   # shape (3,4)\n",
      "b = np.arange(4)                  # shape (4,)\n",
      "c = a + b                         # 자동 브로드캐스팅\n",
      "print(c)\n",
      "# [[ 0  2  4  6]\n",
      "#  [ 4  6  8 10]\n",
      "#  [ 8 10 12 14]]\n",
      "\n",
      "# 2) pandas: 라벨 기반 연산 + 결측치 처리\n",
      "df = pd.DataFrame({\n",
      "    'A': [1, 2, np.nan],\n",
      "    'B': [4, np.nan, 6],\n",
      "    'C': ['x', 'y', 'z']\n",
      "})\n",
      "print(df)\n",
      "#      A    B  C\n",
      "# 0  1.0  4.0  x\n",
      "# 1  2.0  NaN  y\n",
      "# 2  NaN  6.0  z\n",
      "\n",
      "# 라벨을 이용한 선택 및 결측치 채우기\n",
      "df_filled = df.fillna({'A': df['A'].mean(), 'B': 0})\n",
      "print(df_filled)\n",
      "#      A    B  C\n",
      "# 0  1.0  4.0  x\n",
      "# 1  2.0  0.0  y\n",
      "# 2  1.5  6.0  z\n",
      "\n",
      "# 시계열 예시\n",
      "date_rng = pd.date_range('2023-01-01', periods=5, freq='D')\n",
      "ts = pd.Series(np.random.randn(5), index=date_rng)\n",
      "print(ts.resample('2D').mean())\n",
      "```\n",
      "\n",
      "- 첫 번째 블록은 **NumPy**만 사용해 행과 열을 직접 연산합니다.  \n",
      "- 두 번째 블록은 **pandas**의 라벨, 결측치, 다양한 dtype을 활용합니다.  \n",
      "- 마지막 블록은 `Series`에 시계열 인덱스를 붙이고 `resample`(리샘플링) 같은 pandas 고수준 기능을 보여줍니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 요약\n",
      "\n",
      "- **NumPy**는 **동일 타입**의 **다차원 배열**에 대한 빠른 수치 연산을 담당하고, 과학·공학 분야에서 핵심적인 역할을 합니다.  \n",
      "- **pandas**는 **라벨이 있는 1·2차원 데이터**(표 형태)를 쉽고 직관적으로 다루기 위해 설계됐으며, **결측치 처리, 시계열, 그룹 연산, 다양한 파일 입출력** 등을 내장하고 있습니다.  \n",
      "- 실제 분석 작업에서는 **두 라이브러리를 함께 사용**하는 경우가 많습니다. 예를 들어, pandas `DataFrame`을 만든 뒤 필요에 따라 `df.values`(NumPy 배열)로 변환해 고성능 수치 연산을 수행하고, 결과를 다시 pandas 형태로 돌아와 정제·시각화하는 흐름이 일반적입니다.\n"
     ]
    }
   ],
   "source": [
    "# 시스템 메시지를 포함한 호출\n",
    "response = client.chat.completions.create(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"당신은 데이터 분석 전문가입니다. 한국어로 답변하세요.\"},\n",
    "        {\"role\": \"user\", \"content\": \"pandas와 numpy의 차이점을 설명해주세요.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.5 API 파라미터 이해하기\n",
    "\n",
    "### 주요 파라미터\n",
    "\n",
    "| 파라미터 | 범위 | 설명 |\n",
    "|---------|------|------|\n",
    "| `model` | - | 사용할 모델 (gpt-4o, gpt-4o-mini 등) |\n",
    "| `temperature` | 0~2 | 창의성/무작위성 조절 (0: 결정적, 높을수록 창의적) |\n",
    "| `max_tokens` | - | 응답의 최대 토큰 수 |\n",
    "| `top_p` | 0~1 | 확률 기반 샘플링 (nucleus sampling) |\n",
    "| `presence_penalty` | -2~2 | 새로운 주제 유도 |\n",
    "| `frequency_penalty` | -2~2 | 반복 감소 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 0.0:\n",
      "사과는 달콤하면서도 상큼한 과육과 바삭한 식감을 가진, 비타민 C와 섬유질이 풍부한 둥근 과일입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# temperature 비교: 낮은 값 (결정적)\n",
    "response_low_temp = client.chat.completions.create(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"사과에 대해 한 문장으로 설명해주세요.\"}],\n",
    "    temperature=0.0,  # 가장 확률 높은 답변\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "print(\"Temperature 0.0:\")\n",
    "print(response_low_temp.choices[0].message.content)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 1.5:\n",
      "사과는 달콤하고 아삭한 식감을 가진, 비타민·식이섬유가 풍부한 다목적 과일입니다.\n"
     ]
    }
   ],
   "source": [
    "# temperature 비교: 높은 값 (창의적)\n",
    "response_high_temp = client.chat.completions.create(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"사과에 대해 한 문장으로 설명해주세요.\"}],\n",
    "    temperature=1.5,  # 더 다양하고 창의적인 답변\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "print(\"Temperature 1.5:\")\n",
    "print(response_high_temp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature 가이드라인\n",
    "\n",
    "| 용도 | 권장 temperature | 이유 |\n",
    "|------|-----------------|------|\n",
    "| 코드 생성 | 0.0 ~ 0.3 | 정확성 중요 |\n",
    "| 데이터 분석 | 0.0 ~ 0.3 | 일관된 결과 필요 |\n",
    "| 일반 대화 | 0.5 ~ 0.7 | 자연스러움 |\n",
    "| 창작/브레인스토밍 | 0.8 ~ 1.5 | 다양성 필요 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: 심화\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 핵심 혁신 2: 스케일링 법칙 (Scaling Laws)\n",
    "\n",
    "### \"크기가 성능을 만든다\"\n",
    "\n",
    "2020년 OpenAI의 연구는 LLM의 성능이 세 가지 요소에 따라 **예측 가능하게 향상**된다는 것을 실험적으로 증명했습니다. 이를 **스케일링 법칙**이라고 합니다.\n",
    "\n",
    "**성능 ∝ (모델 크기, 데이터셋 크기, 컴퓨팅 파워)**\n",
    "\n",
    "| 요소 | 설명 |\n",
    "|------|------|\n",
    "| **모델 크기 (Parameters)** | 신경망의 파라미터(가중치) 수. 클수록 더 복잡한 패턴 학습 가능 |\n",
    "| **데이터셋 크기 (Tokens)** | 모델이 학습하는 텍스트의 양. 많을수록 더 넓은 지식 습득 |\n",
    "| **컴퓨팅 파워 (FLOPs)** | 학습에 사용되는 총 연산량 |\n",
    "\n",
    "이 세 가지 요소를 **균형 있게 함께 늘리면**, 모델의 성능(손실 값 감소)은 멱함수(Power-law) 형태로 꾸준히 향상됩니다.\n",
    "\n",
    "**스케일링 법칙의 시사점**:\n",
    "> \"더 똑똑한 모델을 만들고 싶다면, **더 큰 모델을, 더 많은 데이터로, 더 오래 학습시켜라!**\"  \n",
    "> 이 법칙은 GPT-3와 같은 초거대 AI 모델 개발의 이론적 토대가 되었고, 이후 LLM 경쟁을 촉발시켰습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 LLM의 현실 세계 응용 사례\n",
    "\n",
    "### 산업을 바꾸는 게임 체인저\n",
    "\n",
    "LLM은 다양한 산업 분야에서 혁신적인 서비스를 가능하게 하며 빠르게 확산되고 있습니다.\n",
    "\n",
    "| 분야 | 활용 사례 | 예시 서비스 |\n",
    "|------|----------|------------|\n",
    "| **콘텐츠 생성 & 마케팅** | 블로그 글, 광고 카피, 이메일, 제품 설명 등을 자동으로 생성하여 생산성을 극대화 | Jasper, Copy.ai |\n",
    "| **대화형 AI & 챗봇** | 단순 응대를 넘어, 고객의 의도를 파악하고 사람처럼 자연스러운 대화가 가능한 지능형 챗봇 구현 | ChatGPT, 기업용 AI 상담원 |\n",
    "| **문서 요약 & 지식 관리** | 긴 보고서, 뉴스 기사, 논문을 핵심 내용만 간추려 요약하고, 문서 기반 질의응답 시스템 구축 | 회의록 요약, 법률 문서 분석 |\n",
    "| **코드 생성 & 개발 지원** | 개발자의 주석이나 함수명만 보고 필요한 코드를 자동으로 완성해주어 개발 속도 향상 | GitHub Copilot, Amazon CodeWhisperer |\n",
    "\n",
    "**주의할 점: 환각과 편향**\n",
    "> LLM은 매우 유용하지만, 때때로 사실이 아닌 내용을 그럴듯하게 지어내는 **환각(Hallucination)** 현상이나, 학습 데이터에 내재된 **편향(Bias)**을 드러낼 수 있습니다. 따라서 중요한 작업에는 반드시 사람의 검토가 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 프롬프트 엔지니어링 기초\n",
    "\n",
    "### 좋은 프롬프트의 원칙\n",
    "\n",
    "| 원칙 | 설명 | 예시 |\n",
    "|------|------|------|\n",
    "| **명확성** | 구체적이고 명확한 지시 | \"요약해주세요\" → \"3문장으로 요약해주세요\" |\n",
    "| **역할 부여** | AI에게 특정 역할 지정 | \"당신은 10년 경력의 데이터 분석가입니다\" |\n",
    "| **구조화** | 출력 형식 지정 | \"JSON 형식으로 답변하세요\" |\n",
    "| **단계별 추론** | 복잡한 문제 분해 | \"단계별로 설명해주세요\" |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 나쁜 프롬프트 ===\n",
      "## 파이썬 입문 가이드 (한국어)\n",
      "\n",
      "### 1. 파이썬이란?\n",
      "- **인터프리터 언어**: 코드를 한 줄씩 바로 실행합니다. (컴파일이 필요 없음)\n",
      "- **읽기 쉬운 문법**: 들여쓰기와 간결한 구문 덕분에 초보자에게 친숙합니다.\n",
      "- **다양한 분야**: 웹 개발, 데이터 분석, 인공지능, 자동화, 게임 등 거의 모든 분야에서 사용됩니다.\n",
      "- **플랫폼 독립**: Windows, macOS, Linux 어디서든 동일하게 실행됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. 파이썬 설치 & 실행\n",
      "\n",
      "| OS | 설치 방법 |\n",
      "|----|----------...\n"
     ]
    }
   ],
   "source": [
    "# 나쁜 프롬프트 예시\n",
    "bad_response = client.chat.completions.create(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"파이썬 알려줘\"}],\n",
    "    temperature=0.5\n",
    ")\n",
    "print(\"=== 나쁜 프롬프트 ===\")\n",
    "print(bad_response.choices[0].message.content[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 좋은 프롬프트 ===\n",
      "**1. 정의:**  \n",
      "파이썬은 읽기 쉬운 문법과 풍부한 표준 라이브러리를 갖춘, 범용 목적의 고급 프로그래밍 언어입니다.  \n",
      "\n",
      "**2. 주요 특징:**  \n",
      "- **간결하고 직관적인 문법** – 초보자도 쉽게 배울 수 있도록 설계되었습니다.  \n",
      "- **다양한 라이브러리와 프레임워크** – 데이터 과학, 웹 개발, 자동화 등 여러 분야에서 바로 활용 가능하도록 풍부한 생태계를 제공합니다.  \n",
      "- **플랫폼 독립성** – Windows, macOS, Linux 등 대부분의 운영체제에서 동일하게 실행됩니다.  \n",
      "\n",
      "**3. 대표 활용 분야:**  \n",
      "- **데이터 과학·인공지능** (예: NumPy, pandas, TensorFlow, PyTorch)  \n",
      "- **웹·애플리케이션 개발** (예: Django, Flask)  \n"
     ]
    }
   ],
   "source": [
    "# 좋은 프롬프트 예시\n",
    "good_response = client.chat.completions.create(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"당신은 프로그래밍 교육 전문가입니다. 초보자도 이해할 수 있게 설명하세요.\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"파이썬 프로그래밍 언어에 대해 다음 형식으로 설명해주세요:\n",
    "\n",
    "1. 정의: (한 문장)\n",
    "2. 주요 특징: (3가지 불릿 포인트)\n",
    "3. 대표 활용 분야: (2가지)\"\"\"}\n",
    "    ],\n",
    "    temperature=0.3\n",
    ")\n",
    "print(\"=== 좋은 프롬프트 ===\")\n",
    "print(good_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 Few-shot 프롬프팅\n",
    "\n",
    "### Zero-shot vs One-shot vs Few-shot\n",
    "\n",
    "| 방식 | 예시 수 | 특징 |\n",
    "|------|--------|------|\n",
    "| Zero-shot | 0개 | 예시 없이 직접 지시 |\n",
    "| One-shot | 1개 | 하나의 예시 제공 |\n",
    "| Few-shot | 2~5개 | 여러 예시 제공 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Zero-shot ===\n",
      "부정\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot: 예시 없이 분류\n",
    "zero_shot = client.chat.completions.create(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"\"\"다음 리뷰의 감성을 '긍정', '부정', '중립' 중 하나로 분류하세요.\n",
    "\n",
    "리뷰: \"배송은 빨랐는데 제품 품질이 별로네요.\"\n",
    "감성:\"\"\"}],\n",
    "    temperature=0.0\n",
    ")\n",
    "print(\"=== Zero-shot ===\")\n",
    "print(zero_shot.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Few-shot ===\n",
      "감성: 부정\n"
     ]
    }
   ],
   "source": [
    "# Few-shot: 여러 예시 제공\n",
    "few_shot = client.chat.completions.create(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"\"\"다음 리뷰의 감성을 분류하세요.\n",
    "\n",
    "예시 1:\n",
    "리뷰: \"정말 만족합니다! 다음에도 또 구매할게요.\"\n",
    "감성: 긍정\n",
    "\n",
    "예시 2:\n",
    "리뷰: \"제품이 파손되어 왔어요. 실망입니다.\"\n",
    "감성: 부정\n",
    "\n",
    "예시 3:\n",
    "리뷰: \"그냥 평범해요. 특별한 건 없네요.\"\n",
    "감성: 중립\n",
    "\n",
    "이제 다음 리뷰를 분류하세요:\n",
    "리뷰: \"배송은 빨랐는데 제품 품질이 별로네요.\"\n",
    "감성:\"\"\"}],\n",
    "    temperature=0.0\n",
    ")\n",
    "print(\"=== Few-shot ===\")\n",
    "print(few_shot.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.5 실무 활용 예제\n",
    "\n",
    "### 유틸리티 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_gpt(prompt, system_message=None, temperature=0.7, max_tokens=500):\n",
    "    \"\"\"\n",
    "    GPT API를 호출하고 응답을 파싱하는 함수\n",
    "    \n",
    "    Parameters:\n",
    "    - prompt: 사용자 질문\n",
    "    - system_message: 시스템 메시지 (선택)\n",
    "    - temperature: 창의성 조절 (0~2)\n",
    "    - max_tokens: 최대 응답 길이\n",
    "    \n",
    "    Returns:\n",
    "    - dict: 응답 내용과 메타데이터\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    \n",
    "    if system_message:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"openai/gpt-oss-120b\",\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"content\": response.choices[0].message.content,\n",
    "        \"tokens\": {\n",
    "            \"prompt\": response.usage.prompt_tokens,\n",
    "            \"completion\": response.usage.completion_tokens,\n",
    "            \"total\": response.usage.total_tokens\n",
    "        },\n",
    "        \"finish_reason\": response.choices[0].finish_reason\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답: **머신러닝 (ML)**  \n",
      "- 데이터와 레이블을 이용해 **특징(feature)**을 직접 설계하고, 그 특징을 바탕으로 모델을 학습시킴.  \n",
      "- 대표 알고리즘: 선형 회귀, SVM, 결정 트리, 랜덤 포레스트 등.  \n",
      "- 비교적 적은 데이터와 연산 자원으로도 사용 가능.  \n",
      "\n",
      "**딥러닝 (DL)**  \n",
      "- 다층 **인공신경망**이 자동으로 특징을 추출·학습함(특히 이미지·음성·텍스트에 강함).  \n",
      "- 대표 구조: CNN, RNN, Transformer 등.  \n",
      "- 대규모 데이터와 높은 연산량(GPU/TPU)이 필요하지만, 복잡한 패턴을 높은 정확도로 모델링 가능.  \n",
      "\n",
      "**핵심 차이**  \n",
      "1. **특징 설계**: ML은 수동, DL은 자동.  \n",
      "2. **모델 복잡도**: ML은 비교적 얕고 단순, DL은 깊고 복잡.  \n",
      "3. **데이터·연산 요구**: ML은 적은 데이터·자원, DL은 대규모 데이터·고성능 하드웨어 필요.\n",
      "\n",
      "토큰 사용: 393\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 테스트\n",
    "result = chat_with_gpt(\n",
    "    prompt=\"머신러닝과 딥러닝의 차이점은?\",\n",
    "    system_message=\"간결하게 답변하세요.\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "print(\"응답:\", result[\"content\"])\n",
    "print(f\"\\n토큰 사용: {result['tokens']['total']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 요약 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text, max_sentences=3):\n",
    "    \"\"\"텍스트를 지정된 문장 수로 요약\"\"\"\n",
    "    result = chat_with_gpt(\n",
    "        prompt=f\"\"\"다음 텍스트를 {max_sentences}문장 이내로 요약하세요.\n",
    "\n",
    "텍스트:\n",
    "{text}\n",
    "\n",
    "요약:\"\"\",\n",
    "        system_message=\"당신은 전문 요약가입니다. 핵심 내용만 간결하게 요약하세요.\",\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return result[\"content\"]\n",
    "\n",
    "# 테스트\n",
    "sample_text = \"\"\"인공지능(AI)은 인간의 학습, 추론, 지각, 자연어 처리 등의 지적 능력을 \n",
    "컴퓨터 프로그램으로 구현한 기술입니다. 최근 딥러닝의 발전으로 AI는 이미지 인식, \n",
    "음성 인식, 자연어 처리 등 다양한 분야에서 인간 수준의 성능을 보여주고 있습니다. \n",
    "특히 2022년 ChatGPT의 등장은 대중에게 AI의 가능성을 직접 체험하게 해주었으며, \n",
    "이후 다양한 산업 분야에서 AI 도입이 가속화되고 있습니다.\"\"\"\n",
    "\n",
    "summary = summarize_text(sample_text, max_sentences=2)\n",
    "print(\"=== 원문 ===\")\n",
    "print(sample_text)\n",
    "print(\"\\n=== 요약 ===\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 감성 분류 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def classify_sentiment(text):\n",
    "    \"\"\"텍스트의 감성을 분류하고 JSON으로 반환\"\"\"\n",
    "    result = chat_with_gpt(\n",
    "        prompt=f\"\"\"다음 텍스트의 감성을 분석하세요.\n",
    "\n",
    "텍스트: \"{text}\"\n",
    "\n",
    "다음 JSON 형식으로만 응답하세요:\n",
    "{{\"sentiment\": \"positive/negative/neutral\", \"score\": 0.0~1.0, \"reason\": \"이유\"}}\"\"\",\n",
    "        system_message=\"감성 분석 API입니다. JSON만 출력하세요.\",\n",
    "        temperature=0.0\n",
    "    )\n",
    "    try:\n",
    "        return json.loads(result[\"content\"])\n",
    "    except:\n",
    "        return {\"error\": \"파싱 실패\", \"raw\": result[\"content\"]}\n",
    "\n",
    "# 테스트\n",
    "reviews = [\n",
    "    \"이 제품 정말 최고예요! 강력 추천합니다.\",\n",
    "    \"배송이 늦어서 짜증나요. 다시는 안 삽니다.\",\n",
    "    \"그냥 그래요. 가격 대비 보통입니다.\"\n",
    "]\n",
    "\n",
    "for review in reviews:\n",
    "    result = classify_sentiment(review)\n",
    "    print(f\"리뷰: {review}\")\n",
    "    print(f\"결과: {result}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 퀴즈\n",
    "\n",
    "**난이도 분포**: 기본 3개 / 응용 3개 / 복합 2개 / 종합 2개\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. LLM 개념 이해 (기본)\n",
    "\n",
    "**문제**: 다음 빈칸을 채우세요.\n",
    "\n",
    "1. LLM은 (______) 아키텍처를 기반으로 합니다.\n",
    "2. GPT는 (______)-Only 구조이고, BERT는 (______)-Only 구조입니다.\n",
    "3. GPT는 다음 (______)을 예측하는 방식으로 텍스트를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답을 작성하세요\n",
    "answer1 = \"\"\n",
    "answer2_gpt = \"\"\n",
    "answer2_bert = \"\"\n",
    "answer3 = \"\"\n",
    "\n",
    "print(f\"1. {answer1}\")\n",
    "print(f\"2. GPT: {answer2_gpt}, BERT: {answer2_bert}\")\n",
    "print(f\"3. {answer3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. 기본 API 호출 (기본)\n",
    "\n",
    "**문제**: OpenAI API를 사용하여 \"대한민국의 수도는 어디인가요?\"라는 질문에 답변을 받으세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. 파라미터 이해 (기본)\n",
    "\n",
    "**문제**: temperature를 0.0과 1.5로 각각 설정하여 같은 질문(\"창의적인 회사 이름 하나 제안해주세요\")에 대한 응답을 비교하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. 응답 파싱 (응용)\n",
    "\n",
    "**문제**: API 응답에서 다음 정보를 추출하는 코드를 작성하세요.\n",
    "- 응답 텍스트\n",
    "- 사용된 총 토큰 수\n",
    "- 종료 사유(finish_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Python의 장점 3가지를 알려주세요.\"}]\n",
    ")\n",
    "\n",
    "# 여기에 코드를 작성하세요 (위 response에서 정보 추출)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. 시스템 프롬프트 (응용)\n",
    "\n",
    "**문제**: AI가 \"친절한 한국어 선생님\" 역할을 하도록 시스템 프롬프트를 작성하고, \"안녕하세요\"의 존댓말 사용법을 질문하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. 프롬프트 엔지니어링 (응용)\n",
    "\n",
    "**문제**: 다음 텍스트를 \"불릿 포인트 3개\"로 요약하도록 프롬프트를 작성하세요.\n",
    "\n",
    "텍스트: \"파이썬은 1991년 귀도 반 로섬이 개발한 프로그래밍 언어입니다. 읽기 쉬운 문법과 다양한 라이브러리로 인해 데이터 분석, 웹 개발, 인공지능 등 다양한 분야에서 널리 사용됩니다. 특히 초보자가 배우기 쉬워 프로그래밍 입문 언어로 많이 추천됩니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"파이썬은 1991년 귀도 반 로섬이 개발한 프로그래밍 언어입니다. \n",
    "읽기 쉬운 문법과 다양한 라이브러리로 인해 데이터 분석, 웹 개발, 인공지능 등 \n",
    "다양한 분야에서 널리 사용됩니다. 특히 초보자가 배우기 쉬워 프로그래밍 입문 \n",
    "언어로 많이 추천됩니다.\"\"\"\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Few-shot 프롬프팅 (복합)\n",
    "\n",
    "**문제**: Few-shot 방식으로 이메일 분류기를 만드세요. 카테고리: 업무, 광고, 개인\n",
    "\n",
    "예시를 3개 제공하고, 새로운 이메일 \"내일 회의 시간 변경 건으로 연락드립니다.\"를 분류하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. JSON 출력 (복합)\n",
    "\n",
    "**문제**: 다음 제품 리뷰를 분석하여 JSON 형식으로 출력하는 함수를 작성하세요.\n",
    "\n",
    "출력 형식:\n",
    "```json\n",
    "{\n",
    "    \"product\": \"제품명 추출\",\n",
    "    \"rating\": 1-5,\n",
    "    \"pros\": [\"장점1\", \"장점2\"],\n",
    "    \"cons\": [\"단점1\", \"단점2\"]\n",
    "}\n",
    "```\n",
    "\n",
    "테스트 리뷰: \"갤럭시 S24 사용 중인데, 카메라가 정말 좋고 배터리도 오래가요. 다만 가격이 비싸고 무게가 좀 있네요.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. 텍스트 분석 봇 (종합)\n",
    "\n",
    "**문제**: 긴 텍스트를 입력받아 다음을 수행하는 함수를 작성하세요.\n",
    "1. 핵심 키워드 3개 추출\n",
    "2. 한 문장 요약\n",
    "3. 긍/부정 톤 판단\n",
    "\n",
    "결과는 딕셔너리로 반환하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text):\n",
    "    \"\"\"텍스트를 분석하여 키워드, 요약, 톤을 반환\"\"\"\n",
    "    # 여기에 코드를 작성하세요\n",
    "    pass\n",
    "\n",
    "# 테스트\n",
    "test_text = \"\"\"최근 출시된 AI 스피커 신제품이 큰 인기를 끌고 있습니다. \n",
    "이 제품은 기존 모델보다 음성 인식 정확도가 30% 향상되었으며, \n",
    "스마트홈 연동 기능도 강화되었습니다. 다만 가격이 전작 대비 20% 인상되어 \n",
    "소비자들의 부담이 커질 것으로 예상됩니다.\"\"\"\n",
    "\n",
    "result = analyze_text(test_text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. 다중 리뷰 분류 파이프라인 (종합)\n",
    "\n",
    "**문제**: 여러 개의 고객 리뷰를 받아 감성 분석 후 pandas DataFrame으로 결과를 반환하는 파이프라인을 구축하세요.\n",
    "\n",
    "요구사항:\n",
    "1. 각 리뷰의 감성(긍정/부정/중립)과 신뢰도(0~1) 분석\n",
    "2. 결과를 DataFrame으로 정리\n",
    "3. 감성별 통계 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def analyze_reviews(reviews):\n",
    "    \"\"\"리뷰 리스트를 분석하여 DataFrame 반환\"\"\"\n",
    "    # 여기에 코드를 작성하세요\n",
    "    pass\n",
    "\n",
    "# 테스트 데이터\n",
    "test_reviews = [\n",
    "    \"정말 좋은 제품이에요! 강력 추천합니다.\",\n",
    "    \"배송이 너무 느려요. 일주일이나 걸렸습니다.\",\n",
    "    \"가격 대비 괜찮은 품질입니다.\",\n",
    "    \"AS 서비스가 최악이에요. 다시는 안 삽니다.\",\n",
    "    \"디자인이 예쁘고 사용하기 편해요!\"\n",
    "]\n",
    "\n",
    "result_df = analyze_reviews(test_reviews)\n",
    "print(result_df)\n",
    "print(\"\\n=== 감성별 통계 ===\")\n",
    "# 통계 출력 코드 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 학습 정리\n",
    "\n",
    "### Part 1: 기초 핵심 요약\n",
    "\n",
    "| 개념 | 핵심 내용 | 실무 활용 |\n",
    "|------|----------|----------|\n",
    "| 생성형 AI | 패턴 인식을 넘어 패턴 창조 | ChatGPT, DALL-E, Copilot |\n",
    "| LLM | Transformer 기반 대규모 언어 모델 | GPT(생성), BERT(이해), T5(변환) |\n",
    "| Self-Attention | 단어 간 관계를 병렬로 계산 | 장거리 의존성 해결 |\n",
    "| OpenAI API | `client.chat.completions.create()` | 애플리케이션 개발 |\n",
    "| temperature | 0~2, 창의성 조절 | 0: 결정적, 높을수록 창의적 |\n",
    "\n",
    "### Part 2: 심화 핵심 요약\n",
    "\n",
    "| 개념 | 핵심 기법 | 언제 사용? |\n",
    "|------|----------|----------|\n",
    "| 스케일링 법칙 | 모델/데이터/컴퓨팅 균형 증가 | LLM 성능 예측 |\n",
    "| 프롬프트 엔지니어링 | 명확성, 역할 부여, 구조화 | 원하는 출력 유도 |\n",
    "| Few-shot | 예시 제공 | 일관된 형식, 분류 |\n",
    "| JSON 출력 | 형식 지정 프롬프트 | 데이터 파이프라인 |\n",
    "\n",
    "### 실무 팁\n",
    "\n",
    "1. **API 키 보안**: 환경변수 또는 .env 파일 사용, 절대 코드에 직접 입력 금지\n",
    "2. **temperature 선택**: 분석/코드는 낮게(0~0.3), 창작은 높게(0.8+)\n",
    "3. **토큰 비용 관리**: max_tokens 적절히 설정, 불필요한 출력 제한\n",
    "4. **환각 주의**: 중요한 정보는 반드시 사람이 검증\n",
    "5. **프롬프트 테스트**: 여러 번 실행하여 일관성 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
