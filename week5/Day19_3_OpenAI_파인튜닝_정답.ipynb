{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day19_3: OpenAI 파인튜닝 - LLM을 내 목적에 맞게 맞춤 제작하기 (정답)\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "**Part 1: 기초**\n",
    "1. 파인튜닝(Fine-Tuning)의 개념을 이해하고, 프롬프트 엔지니어링, RAG와의 차이점을 설명할 수 있습니다.\n",
    "2. 파인튜닝이 적합한 시나리오와 부적합한 시나리오를 구별할 수 있습니다.\n",
    "3. OpenAI 파인튜닝을 위한 JSONL 데이터 형식을 이해하고 올바르게 작성할 수 있습니다.\n",
    "4. 고품질 학습 데이터의 특성을 이해하고, 데이터 준비 과정을 수행할 수 있습니다.\n",
    "5. OpenAI Files API를 사용하여 학습 데이터를 업로드할 수 있습니다.\n",
    "\n",
    "**Part 2: 심화**\n",
    "1. OpenAI Fine-tuning API를 사용하여 파인튜닝 작업을 생성하고 모니터링할 수 있습니다.\n",
    "2. 파인튜닝된 모델을 호출하고, 기본 모델과의 성능 차이를 비교 분석할 수 있습니다.\n",
    "3. 하이퍼파라미터(epochs, learning_rate_multiplier)를 조정하여 학습을 최적화할 수 있습니다.\n",
    "4. 실무에서 파인튜닝을 활용하는 전략과 비용 최적화 방법을 이해합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI 클라이언트 초기화\n",
    "client = OpenAI()\n",
    "\n",
    "print(\"환경 설정 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 퀴즈 정답\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. 파인튜닝 개념 이해 (기본)\n",
    "\n",
    "**문제**: 다음 빈칸을 채우세요.\n",
    "\n",
    "1. 파인튜닝은 모델의 내부 (______)을 업데이트하는 과정입니다.\n",
    "2. 새로운 '지식'을 추가하려면 (______)가 적합하고, '행동 방식'을 바꾸려면 (______)가 적합합니다.\n",
    "3. OpenAI 파인튜닝 데이터는 (______) 형식으로 준비해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답\n",
    "answer1 = \"가중치(weights)\"\n",
    "answer2_knowledge = \"RAG\"\n",
    "answer2_behavior = \"파인튜닝\"\n",
    "answer3 = \"JSONL\"\n",
    "\n",
    "print(f\"1. {answer1}\")\n",
    "print(f\"2. 지식: {answer2_knowledge}, 행동: {answer2_behavior}\")\n",
    "print(f\"3. {answer3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**풀이 설명**\n",
    "\n",
    "- **접근 방법**: 파인튜닝의 핵심 개념을 이해하고, 다른 LLM 최적화 기법과의 차이점 파악\n",
    "- **핵심 개념**:\n",
    "  - 파인튜닝은 모델의 **내부 가중치(weights)**를 추가 학습을 통해 업데이트\n",
    "  - RAG는 **외부 지식**을 검색하여 제공하는 방식 (모델 변경 없음)\n",
    "  - 파인튜닝은 모델의 **행동 방식, 스타일, 출력 패턴**을 변경\n",
    "  - OpenAI는 JSONL 형식의 데이터를 요구 (각 줄이 독립적인 JSON 객체)\n",
    "- **실무 팁**: RAG와 파인튜닝은 상호 배타적이지 않으며, 함께 사용할 수 있음\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. JSONL 형식 작성 (기본)\n",
    "\n",
    "**문제**: 다음 정보를 JSONL 형식으로 변환하세요.\n",
    "\n",
    "- 시스템 메시지: \"당신은 친절한 고객 상담원입니다.\"\n",
    "- 사용자 질문: \"환불은 어떻게 하나요?\"\n",
    "- 이상적 답변: \"환불은 구매일로부터 7일 이내에 가능합니다. 마이페이지에서 신청하실 수 있습니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답\n",
    "import json\n",
    "\n",
    "# JSONL 형식의 학습 데이터\n",
    "training_example = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"당신은 친절한 고객 상담원입니다.\"},\n",
    "        {\"role\": \"user\", \"content\": \"환불은 어떻게 하나요?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"환불은 구매일로부터 7일 이내에 가능합니다. 마이페이지에서 신청하실 수 있습니다.\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# JSONL 형식으로 출력 (한 줄)\n",
    "jsonl_line = json.dumps(training_example, ensure_ascii=False)\n",
    "\n",
    "print(\"JSONL 형식:\")\n",
    "print(jsonl_line)\n",
    "\n",
    "# 가독성을 위한 포맷팅 출력\n",
    "print(\"\\n가독성 있는 형식:\")\n",
    "print(json.dumps(training_example, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**풀이 설명**\n",
    "\n",
    "- **접근 방법**: JSONL 형식의 구조 이해 (messages 배열 안에 system, user, assistant 역할)\n",
    "- **핵심 개념**:\n",
    "  - `messages`: 대화 내역을 담는 배열\n",
    "  - `role`: system(행동 지침), user(사용자 입력), assistant(이상적 답변)\n",
    "  - `content`: 각 역할의 실제 내용\n",
    "- **주의사항**: \n",
    "  - ensure_ascii=False로 한글 유니코드 유지\n",
    "  - JSONL은 각 줄이 독립적인 JSON이므로 indent 없이 한 줄로 작성\n",
    "- **실무 팁**: system 메시지는 선택사항이지만, 일관된 행동을 위해 권장\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. 적합한 기술 선택 (기본)\n",
    "\n",
    "**문제**: 다음 각 상황에 가장 적합한 기술(프롬프트 엔지니어링, RAG, 파인튜닝)을 선택하세요.\n",
    "\n",
    "1. 회사의 최신 제품 정보를 기반으로 고객 질문에 답변하는 챗봇\n",
    "2. 모든 마케팅 문구를 특정 브랜드 톤앤매너로 작성하는 봇\n",
    "3. 간단한 텍스트 번역 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답\n",
    "scenario_1 = \"RAG\"  # 최신 정보가 계속 변경되므로 RAG가 적합\n",
    "scenario_2 = \"Fine-tuning\"  # 일관된 스타일/톤앤매너 유지는 파인튜닝\n",
    "scenario_3 = \"Prompting\"  # 간단한 작업은 프롬프트로 충분\n",
    "\n",
    "print(\"각 상황에 적합한 기술:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n1. 최신 제품 정보 챗봇: {scenario_1}\")\n",
    "print(\"   이유: 제품 정보가 자주 업데이트되므로, 벡터 DB에 최신 정보를 저장하고\")\n",
    "print(\"         검색하여 답변하는 RAG가 적합합니다.\")\n",
    "\n",
    "print(f\"\\n2. 브랜드 톤앤매너 유지: {scenario_2}\")\n",
    "print(\"   이유: 모델의 '행동 방식'을 변경해야 하므로 파인튜닝이 적합합니다.\")\n",
    "print(\"         일관된 스타일과 형식을 유지하는 것이 목표입니다.\")\n",
    "\n",
    "print(f\"\\n3. 간단한 번역: {scenario_3}\")\n",
    "print(\"   이유: LLM은 이미 번역 능력이 있으므로, 적절한 프롬프트만으로 충분합니다.\")\n",
    "print(\"         추가 학습이나 외부 지식이 필요하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**풀이 설명**\n",
    "\n",
    "- **접근 방법**: 각 기술의 강점과 적합한 상황을 매칭\n",
    "- **핵심 개념**:\n",
    "  - **RAG**: 최신 정보, 변경되는 지식, 사실 기반 답변이 필요할 때\n",
    "  - **파인튜닝**: 일관된 스타일/톤/형식, 도메인 언어, 행동 변화가 필요할 때\n",
    "  - **프롬프팅**: 간단한 작업, 빠른 프로토타입, LLM이 이미 할 수 있는 작업\n",
    "- **실무 팁**: 복잡한 프로젝트에서는 세 기법을 조합하여 사용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. 학습 데이터 생성 (응용)\n",
    "\n",
    "**문제**: \"친근한 말투의 AI 비서\"를 파인튜닝하기 위한 학습 데이터 3개를 JSONL 형식으로 작성하세요. 각 예시는 다른 주제(날씨, 일정, 추천)여야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답\n",
    "import json\n",
    "\n",
    "# 시스템 메시지 정의\n",
    "system_message = \"당신은 친근하고 따뜻한 말투를 사용하는 AI 비서입니다. 반말 존댓말을 섞어 친구처럼 대화합니다.\"\n",
    "\n",
    "# 학습 데이터 생성\n",
    "training_data = [\n",
    "    # 1. 날씨 관련\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": \"오늘 날씨 어때?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"오늘 서울은 맑고 따뜻해요! 낮 최고 기온이 22도 정도 될 것 같은데, 가벼운 겉옷 하나 챙기면 딱 좋을 것 같아요. 혹시 외출 계획 있어요? 산책하기 좋은 날씨예요!\"}\n",
    "        ]\n",
    "    },\n",
    "    # 2. 일정 관련\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": \"내일 일정 뭐 있어?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"내일 일정 확인해봤어요! 오전 10시에 팀 미팅이 있고, 오후 3시에 클라이언트 콜이 잡혀있네요. 저녁에는 특별한 약속 없어요. 혹시 추가하고 싶은 일정 있어요?\"}\n",
    "        ]\n",
    "    },\n",
    "    # 3. 추천 관련\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": \"점심 뭐 먹을까?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"음, 오늘 점심 고민되죠? 날씨가 좋으니까 테라스 있는 파스타집 어때요? 아니면 든든하게 국밥도 좋고! 최근에 인기 있는 근처 맛집으로는 '봉주르 비스트로'가 있는데, 후기가 진짜 좋더라고요. 어떤 게 끌려요?\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# JSONL 형식으로 출력\n",
    "print(\"친근한 AI 비서 학습 데이터 (JSONL 형식):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, data in enumerate(training_data, 1):\n",
    "    jsonl_line = json.dumps(data, ensure_ascii=False)\n",
    "    print(f\"\\n[{i}] {data['messages'][1]['content']}\")\n",
    "    print(f\"    -> {data['messages'][2]['content'][:50]}...\")\n",
    "\n",
    "# 파일로 저장\n",
    "import os\n",
    "os.makedirs(\"datasets\", exist_ok=True)\n",
    "\n",
    "with open(\"datasets/friendly_assistant_data.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for data in training_data:\n",
    "        f.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"\\n\\nJSONL 파일 저장 완료: datasets/friendly_assistant_data.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**풀이 설명**\n",
    "\n",
    "- **접근 방법**: 일관된 말투 스타일을 유지하면서 다양한 주제의 예시 생성\n",
    "- **핵심 개념**:\n",
    "  - 시스템 메시지로 전체적인 톤앤매너 정의\n",
    "  - 각 예시가 동일한 스타일(친근함)을 유지\n",
    "  - 다양한 주제로 일반화 능력 향상\n",
    "- **대안**: 더 많은 예시 (50개 이상) 추가하면 더 일관된 결과\n",
    "- **실무 팁**: 실제 서비스에서 수집한 대화 데이터를 활용하면 더 자연스러운 학습 가능\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. 파인튜닝 작업 관리 (응용)\n",
    "\n",
    "**문제**: 다음 작업을 수행하는 코드를 작성하세요.\n",
    "\n",
    "1. 현재 진행 중인 파인튜닝 작업 목록 확인\n",
    "2. 가장 최근 작업의 상태와 이벤트 로그 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답\n",
    "\n",
    "# 1. 파인튜닝 작업 목록 확인\n",
    "print(\"파인튜닝 작업 목록:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "jobs = client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "if jobs.data:\n",
    "    for job in jobs.data:\n",
    "        print(f\"\\n작업 ID: {job.id}\")\n",
    "        print(f\"  상태: {job.status}\")\n",
    "        print(f\"  모델: {job.model}\")\n",
    "        if job.fine_tuned_model:\n",
    "            print(f\"  결과 모델: {job.fine_tuned_model}\")\n",
    "else:\n",
    "    print(\"  진행 중인 작업이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 가장 최근 작업의 상태와 이벤트 로그\n",
    "print(\"\\n가장 최근 작업 상세 정보:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if jobs.data:\n",
    "    latest_job = jobs.data[0]\n",
    "    \n",
    "    print(f\"\\n작업 ID: {latest_job.id}\")\n",
    "    print(f\"상태: {latest_job.status}\")\n",
    "    print(f\"기반 모델: {latest_job.model}\")\n",
    "    print(f\"생성 시간: {latest_job.created_at}\")\n",
    "    \n",
    "    if latest_job.finished_at:\n",
    "        print(f\"완료 시간: {latest_job.finished_at}\")\n",
    "    \n",
    "    if latest_job.fine_tuned_model:\n",
    "        print(f\"파인튜닝 모델: {latest_job.fine_tuned_model}\")\n",
    "    \n",
    "    if latest_job.error:\n",
    "        print(f\"에러: {latest_job.error}\")\n",
    "    \n",
    "    # 이벤트 로그\n",
    "    print(\"\\n이벤트 로그 (최근 5개):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    events = client.fine_tuning.jobs.list_events(latest_job.id, limit=5)\n",
    "    for event in events.data:\n",
    "        print(f\"  [{event.created_at}] {event.message}\")\n",
    "else:\n",
    "    print(\"  파인튜닝 작업이 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**풀이 설명**\n",
    "\n",
    "- **접근 방법**: OpenAI Fine-tuning API의 jobs.list()와 list_events() 활용\n",
    "- **핵심 개념**:\n",
    "  - `jobs.list()`: 파인튜닝 작업 목록 조회\n",
    "  - `jobs.retrieve(job_id)`: 특정 작업 상세 조회\n",
    "  - `jobs.list_events(job_id)`: 작업 이벤트 로그 조회\n",
    "- **주의사항**: API 호출에 실패할 수 있으므로 예외 처리 권장\n",
    "- **실무 팁**: 파인튜닝 작업은 수 분~수 시간 소요되므로 정기적 모니터링 필요\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. 비용 계산 (응용)\n",
    "\n",
    "**문제**: 다음 조건의 파인튜닝 비용을 계산하세요.\n",
    "\n",
    "- 학습 데이터: 200개 예시\n",
    "- 예시당 평균 토큰: 800\n",
    "- 에포크: 5\n",
    "- 모델: gpt-4o-mini ($3/1M 학습 토큰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답\n",
    "\n",
    "# 조건 설정\n",
    "num_examples = 200\n",
    "avg_tokens_per_example = 800\n",
    "epochs = 5\n",
    "cost_per_1m_tokens = 3.0  # gpt-4o-mini 학습 비용\n",
    "\n",
    "# 계산\n",
    "total_tokens = num_examples * avg_tokens_per_example * epochs\n",
    "total_cost = (total_tokens / 1_000_000) * cost_per_1m_tokens\n",
    "\n",
    "print(\"파인튜닝 비용 계산:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n입력 조건:\")\n",
    "print(f\"  - 학습 예시 수: {num_examples:,}개\")\n",
    "print(f\"  - 예시당 평균 토큰: {avg_tokens_per_example:,}\")\n",
    "print(f\"  - 에포크: {epochs}\")\n",
    "print(f\"  - 모델: gpt-4o-mini\")\n",
    "print(f\"  - 학습 비용: ${cost_per_1m_tokens}/1M 토큰\")\n",
    "\n",
    "print(f\"\\n계산 과정:\")\n",
    "print(f\"  총 학습 토큰 = {num_examples} × {avg_tokens_per_example} × {epochs}\")\n",
    "print(f\"              = {total_tokens:,} 토큰\")\n",
    "print(f\"\")\n",
    "print(f\"  비용 = ({total_tokens:,} / 1,000,000) × ${cost_per_1m_tokens}\")\n",
    "print(f\"       = {total_tokens / 1_000_000:.3f} × ${cost_per_1m_tokens}\")\n",
    "\n",
    "print(f\"\\n예상 비용: ${total_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**풀이 설명**\n",
    "\n",
    "- **접근 방법**: 총 토큰 수 계산 후 비용 산출\n",
    "- **핵심 공식**: `총 비용 = (예시 수 × 토큰 수 × 에포크 / 1M) × 비용`\n",
    "- **결과**: 200 × 800 × 5 = 800,000 토큰 → $2.40\n",
    "- **실무 팁**: 실제 비용은 추론 비용도 포함해야 함. 파인튜닝된 모델의 추론 비용은 기본 모델보다 약간 높음\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. 데이터 품질 검증 (복합)\n",
    "\n",
    "**문제**: JSONL 파일을 읽어 다음을 검증하는 함수를 작성하세요.\n",
    "\n",
    "1. 각 줄이 유효한 JSON인지 확인\n",
    "2. 필수 키(messages)가 있는지 확인\n",
    "3. 각 메시지에 role과 content가 있는지 확인\n",
    "4. 총 예시 수와 평균 토큰 수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답\n",
    "import json\n",
    "import tiktoken\n",
    "\n",
    "def validate_jsonl(file_path):\n",
    "    \"\"\"JSONL 파일 품질 검증\"\"\"\n",
    "    \n",
    "    print(f\"JSONL 파일 검증: {file_path}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    errors = []\n",
    "    valid_examples = []\n",
    "    total_tokens = 0\n",
    "    \n",
    "    # tiktoken 인코더 (gpt-4o용)\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "    except:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                line = line.strip()\n",
    "                if not line:  # 빈 줄 스킵\n",
    "                    continue\n",
    "                \n",
    "                # 1. JSON 유효성 검사\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    errors.append(f\"Line {line_num}: 유효하지 않은 JSON - {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # 2. messages 키 확인\n",
    "                if 'messages' not in data:\n",
    "                    errors.append(f\"Line {line_num}: 'messages' 키가 없습니다.\")\n",
    "                    continue\n",
    "                \n",
    "                # 3. 각 메시지의 role, content 확인\n",
    "                messages = data['messages']\n",
    "                line_valid = True\n",
    "                line_tokens = 0\n",
    "                \n",
    "                for msg_idx, msg in enumerate(messages):\n",
    "                    if 'role' not in msg:\n",
    "                        errors.append(f\"Line {line_num}, Message {msg_idx}: 'role' 키가 없습니다.\")\n",
    "                        line_valid = False\n",
    "                    if 'content' not in msg:\n",
    "                        errors.append(f\"Line {line_num}, Message {msg_idx}: 'content' 키가 없습니다.\")\n",
    "                        line_valid = False\n",
    "                    else:\n",
    "                        # 토큰 수 계산\n",
    "                        line_tokens += len(encoding.encode(msg['content']))\n",
    "                \n",
    "                if line_valid:\n",
    "                    valid_examples.append(data)\n",
    "                    total_tokens += line_tokens\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"에러: 파일을 찾을 수 없습니다 - {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f\"\\n검증 결과:\")\n",
    "    print(f\"  - 총 예시 수: {len(valid_examples)}개\")\n",
    "    \n",
    "    if valid_examples:\n",
    "        avg_tokens = total_tokens / len(valid_examples)\n",
    "        print(f\"  - 총 토큰 수: {total_tokens:,}\")\n",
    "        print(f\"  - 평균 토큰 수: {avg_tokens:.1f}\")\n",
    "    \n",
    "    if errors:\n",
    "        print(f\"\\n발견된 오류 ({len(errors)}개):\")\n",
    "        for error in errors[:5]:  # 처음 5개만 출력\n",
    "            print(f\"  - {error}\")\n",
    "        if len(errors) > 5:\n",
    "            print(f\"  ... 외 {len(errors) - 5}개\")\n",
    "    else:\n",
    "        print(f\"\\n모든 검증 통과!\")\n",
    "    \n",
    "    return {\n",
    "        'valid_examples': len(valid_examples),\n",
    "        'total_tokens': total_tokens,\n",
    "        'avg_tokens': total_tokens / len(valid_examples) if valid_examples else 0,\n",
    "        'errors': errors\n",
    "    }\n",
    "\n",
    "# 테스트\n",
    "# result = validate_jsonl(\"datasets/news_finetuning_data.jsonl\")\n",
    "print(\"validate_jsonl() 함수 정의 완료\")\n",
    "print(\"\\n사용법: validate_jsonl('파일경로.jsonl')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**풀이 설명**\n",
    "\n",
    "- **접근 방법**: 파일을 한 줄씩 읽으면서 각 조건을 순차적으로 검증\n",
    "- **핵심 개념**:\n",
    "  - JSON 파싱 오류 감지 (try-except)\n",
    "  - 필수 키 존재 여부 확인\n",
    "  - tiktoken으로 정확한 토큰 수 계산\n",
    "- **주의사항**: 빈 줄 처리, 인코딩(UTF-8) 명시\n",
    "- **실무 팁**: 실제 업로드 전 항상 데이터 검증 수행. OpenAI도 자체 검증을 하지만 사전 확인 권장\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. 모델 비교 함수 (복합)\n",
    "\n",
    "**문제**: 기본 모델과 파인튜닝된 모델의 응답을 비교하는 함수를 작성하세요.\n",
    "\n",
    "요구사항:\n",
    "1. 동일한 프롬프트로 두 모델 호출\n",
    "2. 응답 내용, 응답 시간, 토큰 사용량 비교\n",
    "3. 결과를 딕셔너리로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답\n",
    "import time\n",
    "\n",
    "def compare_models(prompt, base_model, finetuned_model, system_message=None):\n",
    "    \"\"\"\n",
    "    기본 모델과 파인튜닝된 모델의 응답을 비교\n",
    "    \n",
    "    Parameters:\n",
    "    - prompt: 테스트할 프롬프트\n",
    "    - base_model: 기본 모델 ID (예: \"gpt-4o-mini\")\n",
    "    - finetuned_model: 파인튜닝된 모델 ID (예: \"ft:gpt-4o-mini:...\")\n",
    "    - system_message: 시스템 메시지 (선택)\n",
    "    \n",
    "    Returns:\n",
    "    - dict: 비교 결과\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {\n",
    "        'prompt': prompt,\n",
    "        'base_model': {},\n",
    "        'finetuned_model': {}\n",
    "    }\n",
    "    \n",
    "    # 메시지 준비\n",
    "    messages = []\n",
    "    if system_message:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    # 1. 기본 모델 호출\n",
    "    print(f\"기본 모델 ({base_model}) 호출 중...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    base_response = client.chat.completions.create(\n",
    "        model=base_model,\n",
    "        messages=messages,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    base_time = time.time() - start_time\n",
    "    \n",
    "    results['base_model'] = {\n",
    "        'response': base_response.choices[0].message.content,\n",
    "        'response_time': round(base_time, 2),\n",
    "        'prompt_tokens': base_response.usage.prompt_tokens,\n",
    "        'completion_tokens': base_response.usage.completion_tokens,\n",
    "        'total_tokens': base_response.usage.total_tokens\n",
    "    }\n",
    "    \n",
    "    # 2. 파인튜닝 모델 호출\n",
    "    print(f\"파인튜닝 모델 ({finetuned_model[:30]}...) 호출 중...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 파인튜닝 모델은 시스템 메시지 없이도 학습된 스타일로 응답\n",
    "    ft_messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    ft_response = client.chat.completions.create(\n",
    "        model=finetuned_model,\n",
    "        messages=ft_messages,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    ft_time = time.time() - start_time\n",
    "    \n",
    "    results['finetuned_model'] = {\n",
    "        'response': ft_response.choices[0].message.content,\n",
    "        'response_time': round(ft_time, 2),\n",
    "        'prompt_tokens': ft_response.usage.prompt_tokens,\n",
    "        'completion_tokens': ft_response.usage.completion_tokens,\n",
    "        'total_tokens': ft_response.usage.total_tokens\n",
    "    }\n",
    "    \n",
    "    # 3. 비교 결과 출력\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"모델 비교 결과\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\n프롬프트: {prompt}\")\n",
    "    \n",
    "    print(f\"\\n[기본 모델]\")\n",
    "    print(f\"  응답: {results['base_model']['response'][:200]}...\")\n",
    "    print(f\"  응답 시간: {results['base_model']['response_time']}초\")\n",
    "    print(f\"  토큰: {results['base_model']['total_tokens']} (입력: {results['base_model']['prompt_tokens']}, 출력: {results['base_model']['completion_tokens']})\")\n",
    "    \n",
    "    print(f\"\\n[파인튜닝 모델]\")\n",
    "    print(f\"  응답: {results['finetuned_model']['response'][:200]}...\")\n",
    "    print(f\"  응답 시간: {results['finetuned_model']['response_time']}초\")\n",
    "    print(f\"  토큰: {results['finetuned_model']['total_tokens']} (입력: {results['finetuned_model']['prompt_tokens']}, 출력: {results['finetuned_model']['completion_tokens']})\")\n",
    "    \n",
    "    # 토큰 절감율 계산\n",
    "    if results['base_model']['prompt_tokens'] > 0:\n",
    "        prompt_token_saving = (1 - results['finetuned_model']['prompt_tokens'] / results['base_model']['prompt_tokens']) * 100\n",
    "        print(f\"\\n프롬프트 토큰 절감율: {prompt_token_saving:.1f}%\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"compare_models() 함수 정의 완료\")\n",
    "print(\"\\n사용법:\")\n",
    "print('result = compare_models(\"질문\", \"gpt-4o-mini\", \"ft:gpt-4o-mini:...\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**풀이 설명**\n",
    "\n",
    "- **접근 방법**: 두 모델을 동일한 조건에서 호출하고 결과 비교\n",
    "- **핵심 개념**:\n",
    "  - 응답 시간 측정 (time 모듈)\n",
    "  - usage 객체에서 토큰 정보 추출\n",
    "  - 파인튜닝 모델은 시스템 메시지 생략 가능 (토큰 절감)\n",
    "- **주의사항**: 네트워크 상태에 따라 응답 시간이 달라질 수 있음\n",
    "- **실무 팁**: 여러 번 테스트하여 평균값 비교 권장\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. 도메인 특화 데이터셋 생성 (종합)\n",
    "\n",
    "**문제**: 특정 도메인(예: 법률, 의료, 금융 중 선택)에 특화된 Q&A 데이터셋을 5개 이상 생성하고, JSONL 파일로 저장하세요.\n",
    "\n",
    "요구사항:\n",
    "1. 일관된 답변 형식 유지\n",
    "2. 도메인 전문 용어 포함\n",
    "3. 다양한 질문 유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답: 금융 도메인 Q&A 데이터셋\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 시스템 메시지 정의\n",
    "system_message = \"\"\"당신은 금융 전문 상담사입니다. \n",
    "고객의 질문에 다음 형식으로 답변합니다:\n",
    "1. [핵심 답변]: 질문에 대한 명확한 답변\n",
    "2. [상세 설명]: 관련 금융 용어와 함께 자세한 설명\n",
    "3. [주의사항]: 고객이 알아야 할 위험이나 고려사항\"\"\"\n",
    "\n",
    "# 금융 Q&A 데이터셋\n",
    "finance_qa_data = [\n",
    "    {\n",
    "        \"question\": \"ETF와 펀드의 차이점이 뭔가요?\",\n",
    "        \"answer\": \"\"\"1. [핵심 답변]: ETF(상장지수펀드)는 주식처럼 실시간 거래가 가능한 펀드이고, 일반 펀드는 하루 한 번 정해진 가격으로 거래됩니다.\n",
    "\n",
    "2. [상세 설명]: ETF는 특정 지수(예: 코스피200)를 추종하며, 증권거래소에 상장되어 주식처럼 매수/매도가 가능합니다. 반면 일반 펀드는 펀드매니저가 종목을 선정하여 운용하며, 기준가격(NAV)으로 환매됩니다. ETF는 운용보수가 0.1~0.5%로 낮고, 펀드는 1~2% 수준입니다.\n",
    "\n",
    "3. [주의사항]: ETF도 시장 위험에 노출되어 원금 손실 가능성이 있습니다. 레버리지 ETF는 변동성이 2~3배 크므로 단기 투자에만 적합합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"신용등급과 대출 금리는 어떤 관계가 있나요?\",\n",
    "        \"answer\": \"\"\"1. [핵심 답변]: 신용등급이 높을수록 대출 금리가 낮아지고, 낮을수록 금리가 높아집니다. 1등급과 10등급 사이에는 연 5~10%p 이상의 금리 차이가 발생할 수 있습니다.\n",
    "\n",
    "2. [상세 설명]: 신용등급은 1~10등급으로 나뉘며, NICE와 KCB 두 기관에서 평가합니다. 1~3등급은 '우량', 4~6등급은 '일반', 7~10등급은 '저신용'으로 분류됩니다. 은행 신용대출은 주로 1~6등급에게 제공되며, 7등급 이하는 저축은행이나 캐피탈 이용이 필요합니다.\n",
    "\n",
    "3. [주의사항]: 단기간에 여러 곳에서 대출 조회를 하면 신용점수가 하락할 수 있습니다. 신용카드 연체, 휴대폰 요금 미납도 등급 하락 요인입니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"적금과 예금 중 어떤 것이 유리한가요?\",\n",
    "        \"answer\": \"\"\"1. [핵심 답변]: 목돈이 있다면 예금이, 매월 일정 금액을 저축할 계획이라면 적금이 적합합니다. 동일 금리 조건에서는 예금의 이자가 더 많습니다.\n",
    "\n",
    "2. [상세 설명]: 정기예금은 목돈을 한 번에 예치하므로 전체 기간 동안 원금에 이자가 붙습니다. 적금은 매월 납입하므로 첫 달 납입금만 전체 기간 이자를 받습니다. 예를 들어 연 5% 금리로 1년간 1,200만원을 운용할 경우, 예금 이자는 약 60만원, 적금 이자는 약 32.5만원입니다.\n",
    "\n",
    "3. [주의사항]: 중도 해지 시 약정 금리보다 낮은 금리가 적용됩니다. 예금자보호는 금융기관당 5,000만원까지만 보장됩니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"DSR이 뭐고, 왜 중요한가요?\",\n",
    "        \"answer\": \"\"\"1. [핵심 답변]: DSR(총부채원리금상환비율)은 연간 소득 대비 모든 대출의 원리금 상환액 비율입니다. 대출 한도를 결정하는 핵심 지표로, 현재 40~50% 규제가 적용됩니다.\n",
    "\n",
    "2. [상세 설명]: DSR = (모든 대출의 연간 원리금 상환액 / 연간 소득) × 100으로 계산합니다. 예를 들어 연소득 6,000만원인 사람이 DSR 40% 규제를 받으면, 연간 원리금 상환액이 2,400만원을 초과할 수 없습니다. 주택담보대출, 신용대출, 학자금대출 등 모든 대출이 포함됩니다.\n",
    "\n",
    "3. [주의사항]: 기존 대출이 있으면 신규 대출 한도가 줄어듭니다. 주택 구매 전 DSR 여유를 미리 확인하세요. 소득 증빙이 어려운 자영업자는 인정소득 기준이 까다롭습니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"ISA 계좌의 장점은 무엇인가요?\",\n",
    "        \"answer\": \"\"\"1. [핵심 답변]: ISA(개인종합자산관리계좌)는 다양한 금융상품을 한 계좌에서 운용하며, 수익에 대해 200~400만원까지 비과세, 초과분은 9.9% 분리과세 혜택을 받습니다.\n",
    "\n",
    "2. [상세 설명]: ISA는 예금, 펀드, ETF, 리츠 등을 하나의 계좌에서 운용합니다. 3년 이상 유지 시 일반형은 200만원, 서민형/농어민형은 400만원까지 비과세입니다. 손익통산이 적용되어, 상품 A에서 100만원 손실, 상품 B에서 300만원 수익이면 순이익 200만원에만 과세합니다.\n",
    "\n",
    "3. [주의사항]: 의무가입 기간(3년) 이전 해지 시 세제 혜택이 사라지고 일반 과세가 적용됩니다. 1인 1계좌만 가능하며, 금융소득종합과세 대상자는 가입이 제한됩니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"주식 양도소득세는 어떻게 계산하나요?\",\n",
    "        \"answer\": \"\"\"1. [핵심 답변]: 국내 주식은 대주주(10억원 이상 또는 지분 1% 이상)만 과세 대상이며, 해외 주식은 연간 수익 250만원 초과분에 22% 세율이 적용됩니다.\n",
    "\n",
    "2. [상세 설명]: 대주주의 국내 주식 양도세는 과세표준 3억원 이하 22%, 3억원 초과 27.5%입니다. 해외 주식은 모든 투자자가 대상이며, 연간 양도차익에서 250만원 공제 후 22%(지방세 포함)가 과세됩니다. 예: 미국 주식에서 1,000만원 수익 시 (1,000만 - 250만) × 22% = 165만원 세금.\n",
    "\n",
    "3. [주의사항]: 해외 주식 양도소득은 다음 해 5월에 확정신고해야 합니다. 손실과 이익은 같은 해 내에서만 상계되며, 이월공제는 불가합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# JSONL 형식으로 변환\n",
    "jsonl_data = []\n",
    "for qa in finance_qa_data:\n",
    "    jsonl_data.append({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": qa[\"question\"]},\n",
    "            {\"role\": \"assistant\", \"content\": qa[\"answer\"]}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# 파일 저장\n",
    "os.makedirs(\"datasets\", exist_ok=True)\n",
    "output_path = \"datasets/finance_qa_finetuning.jsonl\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for data in jsonl_data:\n",
    "        f.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"금융 Q&A 데이터셋 생성 완료!\")\n",
    "print(f\"파일 경로: {output_path}\")\n",
    "print(f\"예시 수: {len(jsonl_data)}개\")\n",
    "\n",
    "print(\"\\n데이터 미리보기:\")\n",
    "for i, qa in enumerate(finance_qa_data[:2], 1):\n",
    "    print(f\"\\n[{i}] Q: {qa['question']}\")\n",
    "    print(f\"    A: {qa['answer'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**풀이 설명**\n",
    "\n",
    "- **접근 방법**: 금융 도메인 선택, 일관된 답변 형식(핵심/상세/주의사항) 설계\n",
    "- **핵심 개념**:\n",
    "  - 시스템 메시지로 답변 형식 정의\n",
    "  - 금융 전문 용어(DSR, ETF, NAV 등) 포함\n",
    "  - 다양한 질문 유형 (비교, 정의, 계산 등)\n",
    "- **대안**: 법률(계약서, 판례), 의료(증상, 처방) 등 다른 도메인도 가능\n",
    "- **실무 팁**: 실제 고객 질문 데이터를 수집하여 더 자연스러운 데이터셋 구축\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. 파인튜닝 파이프라인 구축 (종합)\n",
    "\n",
    "**문제**: 파인튜닝 전체 파이프라인을 클래스로 구현하세요.\n",
    "\n",
    "요구 기능:\n",
    "1. `prepare_data()`: 데이터 준비 및 JSONL 생성\n",
    "2. `upload_and_train()`: 파일 업로드 및 파인튜닝 시작\n",
    "3. `monitor()`: 작업 상태 모니터링\n",
    "4. `evaluate()`: 파인튜닝된 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "class FineTuningPipeline:\n",
    "    \"\"\"OpenAI 파인튜닝 전체 파이프라인을 관리하는 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"gpt-4o-mini-2024-07-18\"):\n",
    "        \"\"\"파이프라인 초기화\"\"\"\n",
    "        self.client = OpenAI()\n",
    "        self.model_name = model_name\n",
    "        self.training_file_id = None\n",
    "        self.job_id = None\n",
    "        self.finetuned_model_id = None\n",
    "        self.data_path = None\n",
    "        \n",
    "        print(f\"FineTuningPipeline 초기화 완료\")\n",
    "        print(f\"기본 모델: {self.model_name}\")\n",
    "    \n",
    "    def prepare_data(self, data, output_path, system_message=None):\n",
    "        \"\"\"\n",
    "        학습 데이터를 JSONL 형식으로 준비\n",
    "        \n",
    "        Parameters:\n",
    "        - data: 학습 데이터 리스트 [{'input': '...', 'output': '...'}, ...]\n",
    "        - output_path: JSONL 파일 저장 경로\n",
    "        - system_message: 시스템 메시지 (선택)\n",
    "        \n",
    "        Returns:\n",
    "        - str: 저장된 파일 경로\n",
    "        \"\"\"\n",
    "        print(\"\\n[Step 1] 데이터 준비 중...\")\n",
    "        \n",
    "        # 디렉토리 생성\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        # JSONL 형식으로 변환\n",
    "        jsonl_data = []\n",
    "        for item in data:\n",
    "            messages = []\n",
    "            \n",
    "            # 시스템 메시지 추가 (선택)\n",
    "            if system_message:\n",
    "                messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "            \n",
    "            # 사용자 입력과 이상적 출력\n",
    "            messages.append({\"role\": \"user\", \"content\": item.get('input', item.get('question', ''))})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": item.get('output', item.get('answer', ''))})\n",
    "            \n",
    "            jsonl_data.append({\"messages\": messages})\n",
    "        \n",
    "        # 파일 저장\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for entry in jsonl_data:\n",
    "                f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "        \n",
    "        self.data_path = output_path\n",
    "        \n",
    "        print(f\"  - JSONL 파일 생성: {output_path}\")\n",
    "        print(f\"  - 학습 예시 수: {len(jsonl_data)}개\")\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    def upload_and_train(self, file_path=None, hyperparameters=None):\n",
    "        \"\"\"\n",
    "        파일 업로드 및 파인튜닝 작업 시작\n",
    "        \n",
    "        Parameters:\n",
    "        - file_path: JSONL 파일 경로 (없으면 self.data_path 사용)\n",
    "        - hyperparameters: 하이퍼파라미터 딕셔너리 (선택)\n",
    "        \n",
    "        Returns:\n",
    "        - str: 파인튜닝 작업 ID\n",
    "        \"\"\"\n",
    "        file_path = file_path or self.data_path\n",
    "        if not file_path:\n",
    "            raise ValueError(\"파일 경로가 지정되지 않았습니다.\")\n",
    "        \n",
    "        print(\"\\n[Step 2] 파일 업로드 및 파인튜닝 시작...\")\n",
    "        \n",
    "        # 파일 업로드\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            training_file = self.client.files.create(\n",
    "                file=f,\n",
    "                purpose=\"fine-tune\"\n",
    "            )\n",
    "        \n",
    "        self.training_file_id = training_file.id\n",
    "        print(f\"  - 파일 업로드 완료: {self.training_file_id}\")\n",
    "        \n",
    "        # 파인튜닝 작업 생성\n",
    "        job_params = {\n",
    "            \"training_file\": self.training_file_id,\n",
    "            \"model\": self.model_name\n",
    "        }\n",
    "        \n",
    "        if hyperparameters:\n",
    "            job_params[\"hyperparameters\"] = hyperparameters\n",
    "        \n",
    "        fine_tuning_job = self.client.fine_tuning.jobs.create(**job_params)\n",
    "        \n",
    "        self.job_id = fine_tuning_job.id\n",
    "        print(f\"  - 파인튜닝 작업 생성: {self.job_id}\")\n",
    "        print(f\"  - 상태: {fine_tuning_job.status}\")\n",
    "        \n",
    "        return self.job_id\n",
    "    \n",
    "    def monitor(self, check_interval=60, max_wait_time=7200):\n",
    "        \"\"\"\n",
    "        파인튜닝 작업 모니터링\n",
    "        \n",
    "        Parameters:\n",
    "        - check_interval: 상태 확인 간격 (초)\n",
    "        - max_wait_time: 최대 대기 시간 (초)\n",
    "        \n",
    "        Returns:\n",
    "        - str: 파인튜닝된 모델 ID (성공 시) 또는 None (실패 시)\n",
    "        \"\"\"\n",
    "        if not self.job_id:\n",
    "            raise ValueError(\"파인튜닝 작업 ID가 없습니다. upload_and_train()을 먼저 실행하세요.\")\n",
    "        \n",
    "        print(f\"\\n[Step 3] 파인튜닝 모니터링 (매 {check_interval}초 확인)...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        while True:\n",
    "            elapsed = time.time() - start_time\n",
    "            if elapsed > max_wait_time:\n",
    "                print(f\"\\n최대 대기 시간 초과 ({max_wait_time}초)\")\n",
    "                return None\n",
    "            \n",
    "            job_info = self.client.fine_tuning.jobs.retrieve(self.job_id)\n",
    "            status = job_info.status\n",
    "            \n",
    "            print(f\"  [{time.strftime('%H:%M:%S')}] 상태: {status}\")\n",
    "            \n",
    "            if status == \"succeeded\":\n",
    "                self.finetuned_model_id = job_info.fine_tuned_model\n",
    "                print(f\"\\n  파인튜닝 완료!\")\n",
    "                print(f\"  모델 ID: {self.finetuned_model_id}\")\n",
    "                return self.finetuned_model_id\n",
    "            \n",
    "            elif status == \"failed\":\n",
    "                print(f\"\\n  파인튜닝 실패: {job_info.error}\")\n",
    "                return None\n",
    "            \n",
    "            elif status == \"cancelled\":\n",
    "                print(f\"\\n  파인튜닝 취소됨\")\n",
    "                return None\n",
    "            \n",
    "            time.sleep(check_interval)\n",
    "    \n",
    "    def evaluate(self, test_prompts, system_message=None):\n",
    "        \"\"\"\n",
    "        파인튜닝된 모델 평가\n",
    "        \n",
    "        Parameters:\n",
    "        - test_prompts: 테스트할 프롬프트 리스트\n",
    "        - system_message: 기본 모델용 시스템 메시지\n",
    "        \n",
    "        Returns:\n",
    "        - list: 평가 결과 리스트\n",
    "        \"\"\"\n",
    "        if not self.finetuned_model_id:\n",
    "            raise ValueError(\"파인튜닝된 모델 ID가 없습니다.\")\n",
    "        \n",
    "        print(f\"\\n[Step 4] 모델 평가...\")\n",
    "        print(f\"  테스트 프롬프트: {len(test_prompts)}개\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i, prompt in enumerate(test_prompts, 1):\n",
    "            print(f\"\\n  [{i}/{len(test_prompts)}] 테스트 중...\")\n",
    "            \n",
    "            # 기본 모델 응답\n",
    "            base_messages = []\n",
    "            if system_message:\n",
    "                base_messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "            base_messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "            \n",
    "            base_response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=base_messages,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            # 파인튜닝 모델 응답\n",
    "            ft_response = self.client.chat.completions.create(\n",
    "                model=self.finetuned_model_id,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'prompt': prompt,\n",
    "                'base_response': base_response.choices[0].message.content,\n",
    "                'ft_response': ft_response.choices[0].message.content,\n",
    "                'base_tokens': base_response.usage.total_tokens,\n",
    "                'ft_tokens': ft_response.usage.total_tokens\n",
    "            })\n",
    "        \n",
    "        # 결과 요약\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"평가 결과 요약\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for r in results:\n",
    "            print(f\"\\nQ: {r['prompt'][:50]}...\")\n",
    "            print(f\"  기본 모델 ({r['base_tokens']} tokens): {r['base_response'][:100]}...\")\n",
    "            print(f\"  파인튜닝 ({r['ft_tokens']} tokens): {r['ft_response'][:100]}...\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_status(self):\n",
    "        \"\"\"현재 파이프라인 상태 확인\"\"\"\n",
    "        print(\"\\n파이프라인 상태:\")\n",
    "        print(f\"  - 기본 모델: {self.model_name}\")\n",
    "        print(f\"  - 데이터 경로: {self.data_path or '미설정'}\")\n",
    "        print(f\"  - 학습 파일 ID: {self.training_file_id or '미설정'}\")\n",
    "        print(f\"  - 작업 ID: {self.job_id or '미설정'}\")\n",
    "        print(f\"  - 파인튜닝 모델: {self.finetuned_model_id or '미설정'}\")\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "print(\"FineTuningPipeline 클래스 정의 완료\")\n",
    "print(\"\\n사용 예시:\")\n",
    "print(\"\"\"pipeline = FineTuningPipeline()\n",
    "pipeline.prepare_data(training_data, \"datasets/my_data.jsonl\")\n",
    "pipeline.upload_and_train()\n",
    "pipeline.monitor(check_interval=60)\n",
    "pipeline.evaluate([\"테스트 질문1\", \"테스트 질문2\"])\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**풀이 설명**\n",
    "\n",
    "- **접근 방법**: 파인튜닝 전체 과정을 단계별 메서드로 분리하여 클래스로 캡슐화\n",
    "- **핵심 개념**:\n",
    "  - `prepare_data()`: 데이터 형식 변환 및 파일 생성\n",
    "  - `upload_and_train()`: OpenAI API를 통한 파일 업로드 및 작업 생성\n",
    "  - `monitor()`: 폴링 방식의 상태 모니터링\n",
    "  - `evaluate()`: 기본 모델과 파인튜닝 모델 비교\n",
    "- **확장 방향**: 검증 데이터 분리, 로깅, 에러 핸들링, 비용 추정 등 추가 가능\n",
    "- **실무 팁**: 프로덕션에서는 클라우드 스토리지와 연동하여 대용량 데이터 처리\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 정리\n",
    "\n",
    "### Part 1: 기초 핵심 요약\n",
    "\n",
    "| 개념 | 핵심 내용 | 실무 활용 |\n",
    "|------|----------|----------|\n",
    "| 파인튜닝 | 모델의 내부 가중치를 업데이트 | 스타일/톤/형식 일관성 |\n",
    "| Prompting vs RAG vs FT | 각각 다른 문제 해결 | 상황에 맞는 기술 선택 |\n",
    "| JSONL 형식 | messages 배열 (system, user, assistant) | 학습 데이터 준비 |\n",
    "| 데이터 품질 | 일관성, 다양성, 정확성 | 최소 50개 이상 권장 |\n",
    "| 파일 업로드 | client.files.create() | purpose=\"fine-tune\" |\n",
    "\n",
    "### Part 2: 심화 핵심 요약\n",
    "\n",
    "| 개념 | 핵심 기법 | 권장 설정 |\n",
    "|------|----------|----------|\n",
    "| 파인튜닝 API | client.fine_tuning.jobs.create() | gpt-4o-mini 권장 |\n",
    "| 모니터링 | jobs.retrieve(), list_events() | 60초 간격 체크 |\n",
    "| 하이퍼파라미터 | n_epochs, learning_rate_multiplier | 자동 설정 우선 |\n",
    "| 비용 최적화 | 작은 모델, 품질 데이터, 짧은 프롬프트 | $3/1M 토큰 (학습) |\n",
    "\n",
    "### 파인튜닝 체크리스트\n",
    "\n",
    "```\n",
    "1. 사전 준비:\n",
    "   [x] 파인튜닝이 적합한 상황인지 확인 (스타일/톤/형식 변경)\n",
    "   [x] 고품질 예시 데이터 50개 이상 준비\n",
    "   [x] 일관된 형식/스타일 유지\n",
    "   \n",
    "2. 데이터 준비:\n",
    "   [x] JSONL 형식으로 변환 (ensure_ascii=False)\n",
    "   [x] messages 구조 검증 (system, user, assistant)\n",
    "   [x] 토큰 수 확인 (너무 길지 않게)\n",
    "   \n",
    "3. 파인튜닝 실행:\n",
    "   [x] 파일 업로드 (purpose=\"fine-tune\")\n",
    "   [x] 작업 생성 (모델, 하이퍼파라미터)\n",
    "   [x] 상태 모니터링 (jobs.retrieve)\n",
    "   \n",
    "4. 평가 및 배포:\n",
    "   [x] 기본 모델과 성능 비교\n",
    "   [x] 다양한 테스트 케이스 검증\n",
    "   [x] 프로덕션 적용\n",
    "```\n",
    "\n",
    "### 실무 팁\n",
    "\n",
    "1. **RAG vs 파인튜닝**: 지식 추가는 RAG, 행동 변화는 파인튜닝\n",
    "2. **데이터 품질이 핵심**: 50개 고품질 > 500개 저품질\n",
    "3. **작은 모델부터**: gpt-4o-mini로 시작, 필요시 gpt-4o로 업그레이드\n",
    "4. **시스템 메시지 생략**: 파인튜닝 후에는 짧은 프롬프트로 충분\n",
    "5. **비용 모니터링**: 학습 비용 + 추론 비용 함께 고려"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
