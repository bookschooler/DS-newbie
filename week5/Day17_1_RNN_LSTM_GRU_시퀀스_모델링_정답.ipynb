{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day17_1: RNN, LSTM, GRU (시퀀스 모델링) - 정답\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q1. RNN 출력 shape 계산하기\n",
    "\n",
    "**문제**: 다음 RNN의 출력 shape을 계산하세요.\n",
    "\n",
    "```python\n",
    "rnn = nn.RNN(input_size=50, hidden_size=100, num_layers=2, batch_first=True)\n",
    "x = torch.randn(16, 20, 50)  # batch=16, seq=20, input=50\n",
    "outputs, h_n = rnn(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "rnn = nn.RNN(input_size=50, hidden_size=100, num_layers=2, batch_first=True)\n",
    "x = torch.randn(16, 20, 50)  # batch=16, seq=20, input=50\n",
    "\n",
    "outputs, h_n = rnn(x)\n",
    "\n",
    "print(f\"outputs shape: {outputs.shape}\")\n",
    "print(f\"h_n shape: {h_n.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트/검증\n",
    "assert outputs.shape == torch.Size([16, 20, 100]), \"outputs shape이 잘못되었습니다\"\n",
    "assert h_n.shape == torch.Size([2, 16, 100]), \"h_n shape이 잘못되었습니다\"\n",
    "print(\"검증 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "- RNN의 출력 shape을 이해하려면 각 차원의 의미를 알아야 합니다.\n",
    "\n",
    "**핵심 개념**:\n",
    "- `outputs`: 모든 시점의 마지막 레이어 hidden state\n",
    "  - shape: (batch, seq_len, hidden_size) = (16, 20, 100)\n",
    "- `h_n`: 모든 레이어의 마지막 시점 hidden state\n",
    "  - shape: (num_layers, batch, hidden_size) = (2, 16, 100)\n",
    "\n",
    "**실무 팁**:\n",
    "- `batch_first=True` 설정 시 입력/출력의 첫 번째 차원이 batch가 됩니다.\n",
    "- 분류 문제에서는 보통 `h_n[-1]` (마지막 레이어의 마지막 hidden)을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q2. Hidden State 이해하기\n",
    "\n",
    "**문제**: RNN의 마지막 시점 출력(outputs[:, -1, :])과 h_n이 같은지 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "# 단일 레이어 RNN\n",
    "rnn_single = nn.RNN(input_size=10, hidden_size=20, num_layers=1, batch_first=True)\n",
    "x = torch.randn(4, 5, 10)  # batch=4, seq=5, input=10\n",
    "\n",
    "outputs, h_n = rnn_single(x)\n",
    "\n",
    "print(f\"outputs[:, -1, :] shape: {outputs[:, -1, :].shape}\")\n",
    "print(f\"h_n.squeeze(0) shape: {h_n.squeeze(0).shape}\")\n",
    "\n",
    "# 같은지 확인\n",
    "is_same = torch.allclose(outputs[:, -1, :], h_n.squeeze(0))\n",
    "print(f\"\\noutputs[:, -1, :] == h_n.squeeze(0): {is_same}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트/검증\n",
    "# 다층 RNN에서는 어떨까?\n",
    "rnn_multi = nn.RNN(input_size=10, hidden_size=20, num_layers=2, batch_first=True)\n",
    "outputs_m, h_n_m = rnn_multi(x)\n",
    "\n",
    "# outputs[:, -1, :]는 마지막 레이어의 마지막 시점\n",
    "# h_n[-1]도 마지막 레이어의 마지막 시점\n",
    "is_same_multi = torch.allclose(outputs_m[:, -1, :], h_n_m[-1])\n",
    "print(f\"다층 RNN에서도 같은가?: {is_same_multi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "- `outputs`와 `h_n`의 관계를 이해합니다.\n",
    "\n",
    "**핵심 개념**:\n",
    "- `outputs[:, -1, :]`: 마지막 레이어의 마지막 시점 hidden state\n",
    "- `h_n[-1]`: 마지막 레이어의 마지막 시점 hidden state\n",
    "- 둘은 동일합니다!\n",
    "\n",
    "**주의사항**:\n",
    "- 다층 RNN에서 `h_n`은 모든 레이어의 마지막 시점을 포함합니다.\n",
    "- 분류에서는 `h_n[-1]`을 사용하는 것이 일반적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q3. 시퀀스 데이터 특성\n",
    "\n",
    "**문제**: 다음 중 시퀀스 데이터가 아닌 것을 고르고 이유를 설명하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답\n",
    "answer = \"\"\"\n",
    "정답: 3. 학생들의 키와 몸무게\n",
    "\n",
    "이유:\n",
    "- 시퀀스 데이터는 순서가 중요한 데이터입니다.\n",
    "- 학생들의 키와 몸무게는 개별 학생의 특성으로, 순서에 의미가 없습니다.\n",
    "- 학생 A, B, C의 순서를 바꿔도 데이터의 의미는 변하지 않습니다.\n",
    "\n",
    "다른 항목들이 시퀀스인 이유:\n",
    "1. 일별 주가: 시간 순서가 중요 (오늘 주가는 어제에 영향받음)\n",
    "2. 영화 리뷰 텍스트: 단어 순서가 의미를 결정 (\"not good\" vs \"good not\")\n",
    "4. 음성 파형: 시간에 따른 소리의 변화, 순서가 필수\n",
    "\"\"\"\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**핵심 개념**:\n",
    "- 시퀀스 데이터: 순서(order)가 의미를 갖는 데이터\n",
    "- 정형 데이터(tabular): 각 샘플이 독립적, 순서 무관\n",
    "\n",
    "**실무 팁**:\n",
    "- 시퀀스 데이터 -> RNN, LSTM, GRU, Transformer\n",
    "- 정형 데이터 -> MLP, Decision Tree, XGBoost 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q4. LSTM 게이트 이해하기\n",
    "\n",
    "**문제**: LSTM의 3가지 게이트(Forget, Input, Output)의 역할을 각각 한 문장으로 설명하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답\n",
    "answer = \"\"\"\n",
    "LSTM의 3가지 게이트:\n",
    "\n",
    "1. Forget Gate (망각 게이트):\n",
    "   - 역할: 이전 Cell State에서 어떤 정보를 버릴지 결정합니다.\n",
    "   - 수식: f_t = sigmoid(W_f * [h_{t-1}, x_t] + b_f)\n",
    "   - 출력 범위: 0~1 (0이면 완전히 잊음, 1이면 완전히 기억)\n",
    "\n",
    "2. Input Gate (입력 게이트):\n",
    "   - 역할: 새로운 정보 중 어떤 것을 Cell State에 저장할지 결정합니다.\n",
    "   - 수식: i_t = sigmoid(W_i * [h_{t-1}, x_t] + b_i)\n",
    "   - 새 후보 값: C_tilde = tanh(W_C * [h_{t-1}, x_t] + b_C)\n",
    "\n",
    "3. Output Gate (출력 게이트):\n",
    "   - 역할: Cell State 중 어떤 부분을 Hidden State로 출력할지 결정합니다.\n",
    "   - 수식: o_t = sigmoid(W_o * [h_{t-1}, x_t] + b_o)\n",
    "   - Hidden State: h_t = o_t * tanh(C_t)\n",
    "\n",
    "Cell State 업데이트:\n",
    "   C_t = f_t * C_{t-1} + i_t * C_tilde\n",
    "   (잊을 것 버리고 + 새로 저장할 것 추가)\n",
    "\"\"\"\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**직관적 이해**:\n",
    "- **Forget Gate**: \"이전에 배운 것 중 뭘 잊을까?\"\n",
    "- **Input Gate**: \"새로 배운 것 중 뭘 기억할까?\"\n",
    "- **Output Gate**: \"기억한 것 중 뭘 말할까?\"\n",
    "\n",
    "**실무 팁**:\n",
    "- LSTM은 Cell State라는 '장기 기억 통로'를 통해 정보가 손실 없이 흐를 수 있습니다.\n",
    "- 게이트는 모두 sigmoid(0~1)로 '얼마나'를 결정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q5. GRU와 LSTM 차이\n",
    "\n",
    "**문제**: GRU가 LSTM보다 파라미터 수가 적은 이유를 설명하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답\n",
    "answer = \"\"\"\n",
    "GRU가 LSTM보다 파라미터가 적은 이유:\n",
    "\n",
    "1. 게이트 수 차이:\n",
    "   - LSTM: 3개 (Forget, Input, Output) + Cell State 계산\n",
    "   - GRU: 2개 (Reset, Update)\n",
    "\n",
    "2. 상태 수 차이:\n",
    "   - LSTM: Hidden State + Cell State (2개)\n",
    "   - GRU: Hidden State만 (1개)\n",
    "\n",
    "3. 파라미터 계산:\n",
    "   - LSTM: 4개의 가중치 행렬 (forget, input, cell, output)\n",
    "     -> 4 * (input_size + hidden_size) * hidden_size\n",
    "   - GRU: 3개의 가중치 행렬 (reset, update, hidden)\n",
    "     -> 3 * (input_size + hidden_size) * hidden_size\n",
    "\n",
    "결론: GRU는 LSTM의 약 75% 파라미터로 비슷한 성능을 낼 수 있어,\n",
    "     학습 속도가 빠르고 메모리 효율적입니다.\n",
    "\"\"\"\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 파라미터 수 비교\n",
    "input_size, hidden_size = 100, 128\n",
    "\n",
    "lstm = nn.LSTM(input_size, hidden_size)\n",
    "gru = nn.GRU(input_size, hidden_size)\n",
    "\n",
    "lstm_params = sum(p.numel() for p in lstm.parameters())\n",
    "gru_params = sum(p.numel() for p in gru.parameters())\n",
    "\n",
    "print(f\"LSTM 파라미터: {lstm_params:,}\")\n",
    "print(f\"GRU 파라미터: {gru_params:,}\")\n",
    "print(f\"비율: GRU/LSTM = {gru_params/lstm_params:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q6. 양방향 RNN\n",
    "\n",
    "**문제**: 양방향 LSTM을 정의하고, 출력 shape을 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "bi_lstm = nn.LSTM(\n",
    "    input_size=30,\n",
    "    hidden_size=64,\n",
    "    num_layers=1,\n",
    "    batch_first=True,\n",
    "    bidirectional=True\n",
    ")\n",
    "\n",
    "# 입력\n",
    "x = torch.randn(8, 15, 30)  # batch=8, seq=15, input=30\n",
    "\n",
    "# 순전파\n",
    "outputs, (h_n, c_n) = bi_lstm(x)\n",
    "\n",
    "print(f\"outputs shape: {outputs.shape}\")\n",
    "print(f\"h_n shape: {h_n.shape}\")\n",
    "print(f\"c_n shape: {c_n.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트/검증\n",
    "assert outputs.shape == torch.Size([8, 15, 128]), \"outputs shape 오류 (hidden*2=128)\"\n",
    "assert h_n.shape == torch.Size([2, 8, 64]), \"h_n shape 오류 (num_layers*2=2)\"\n",
    "print(\"검증 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**핵심 개념**:\n",
    "- `bidirectional=True` 설정 시:\n",
    "  - `outputs` 차원: hidden_size * 2 (순방향 + 역방향 concat)\n",
    "  - `h_n` 첫 번째 차원: num_layers * 2\n",
    "\n",
    "**출력 shape 해석**:\n",
    "- outputs: (8, 15, 128) = (batch, seq, hidden*2)\n",
    "- h_n: (2, 8, 64) = (방향 수, batch, hidden)\n",
    "  - h_n[0]: 순방향 마지막 hidden\n",
    "  - h_n[1]: 역방향 마지막 hidden\n",
    "\n",
    "**실무 팁**:\n",
    "- 분류 시 순방향+역방향 concat: `torch.cat([h_n[0], h_n[1]], dim=1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q7. 시계열 데이터 전처리\n",
    "\n",
    "**문제**: 주가 데이터로 시퀀스 길이 5인 학습 데이터를 생성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "prices = [100, 102, 105, 103, 108, 110, 107, 112, 115, 113]\n",
    "seq_length = 5\n",
    "\n",
    "# 시퀀스 데이터 생성\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(prices) - seq_length):\n",
    "    X.append(prices[i:i+seq_length])  # 과거 5일\n",
    "    y.append(prices[i+seq_length])    # 다음 날\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\n시퀀스 예시:\")\n",
    "for i in range(len(X)):\n",
    "    print(f\"  입력: {X[i]} -> 예측: {y[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트/검증\n",
    "assert X.shape == (5, 5), \"X shape이 (5, 5)여야 합니다\"\n",
    "assert y.shape == (5,), \"y shape이 (5,)여야 합니다\"\n",
    "assert list(X[0]) == [100, 102, 105, 103, 108], \"첫 번째 시퀀스 확인\"\n",
    "assert y[0] == 110, \"첫 번째 타겟 확인\"\n",
    "print(\"검증 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "- 슬라이딩 윈도우 방식으로 시퀀스 생성\n",
    "- 과거 N일 -> 다음 1일 예측\n",
    "\n",
    "**핵심 개념**:\n",
    "```\n",
    "원본: [100, 102, 105, 103, 108, 110, 107, 112, 115, 113]\n",
    "         |----시퀀스 1----|  타겟1\n",
    "              |----시퀀스 2----|  타겟2\n",
    "                   |----시퀀스 3----|  타겟3\n",
    "                        ....\n",
    "```\n",
    "\n",
    "**실무 팁**:\n",
    "- 시계열 예측에서는 미래 데이터 누출(data leakage)에 주의!\n",
    "- 훈련/테스트 분할 시 시간 순서 유지 필수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q8. 임베딩 레이어 이해\n",
    "\n",
    "**문제**: Embedding 레이어의 출력 shape을 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "vocab_size = 1000\n",
    "embed_dim = 64\n",
    "\n",
    "# 임베딩 레이어 생성\n",
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
    "\n",
    "# 입력: 토큰 인덱스 (batch=4, seq=10)\n",
    "# 각 값은 0 ~ vocab_size-1 사이의 정수\n",
    "x = torch.randint(0, vocab_size, (4, 10))\n",
    "\n",
    "# 임베딩 적용\n",
    "embedded = embedding(x)\n",
    "\n",
    "print(f\"입력 shape: {x.shape}\")\n",
    "print(f\"입력 dtype: {x.dtype}\")\n",
    "print(f\"\\n출력 shape: {embedded.shape}\")\n",
    "print(f\"출력 dtype: {embedded.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트/검증\n",
    "assert embedded.shape == torch.Size([4, 10, 64]), \"출력 shape 오류\"\n",
    "print(\"검증 통과!\")\n",
    "\n",
    "# 임베딩 가중치 확인\n",
    "print(f\"\\n임베딩 가중치 shape: {embedding.weight.shape}\")\n",
    "print(f\"파라미터 수: {embedding.weight.numel():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**핵심 개념**:\n",
    "- Embedding: 정수 인덱스 -> 실수 벡터 변환 (룩업 테이블)\n",
    "- 입력: (batch, seq_len) - LongTensor\n",
    "- 출력: (batch, seq_len, embed_dim) - FloatTensor\n",
    "\n",
    "**작동 원리**:\n",
    "```\n",
    "vocab_size=1000, embed_dim=64\n",
    "-> 1000x64 행렬 (각 단어별 64차원 벡터)\n",
    "\n",
    "입력 [3, 7, 2] -> 3번 행, 7번 행, 2번 행 추출\n",
    "```\n",
    "\n",
    "**실무 팁**:\n",
    "- 사전 학습된 임베딩(Word2Vec, GloVe, FastText) 로드 가능\n",
    "- `padding_idx` 설정으로 패딩 토큰 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q9. 주가 예측 LSTM 구현\n",
    "\n",
    "**문제**: 사인파 데이터로 다음 값을 예측하는 LSTM 모델을 구현하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 사인파 데이터\n",
    "np.random.seed(42)\n",
    "x_data = np.linspace(0, 20*np.pi, 500)\n",
    "y_data = np.sin(x_data) + 0.1 * np.random.randn(500)\n",
    "\n",
    "# 정규화\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(y_data.reshape(-1, 1))\n",
    "\n",
    "# 시퀀스 생성\n",
    "SEQ_LENGTH = 20\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(scaled_data, SEQ_LENGTH)\n",
    "\n",
    "# 훈련/테스트 분할\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train = torch.FloatTensor(X[:train_size])\n",
    "y_train = torch.FloatTensor(y[:train_size])\n",
    "X_test = torch.FloatTensor(X[train_size:])\n",
    "y_test = torch.FloatTensor(y[train_size:])\n",
    "\n",
    "print(f\"훈련 데이터: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"테스트 데이터: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 정의\n",
    "class SineLSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=32, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 모델 생성\n",
    "model = SineLSTM(input_size=1, hidden_size=32, num_layers=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 및 시각화\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_pred = model(X_train).numpy()\n",
    "    test_pred = model(X_test).numpy()\n",
    "\n",
    "# 역정규화\n",
    "train_pred_inv = scaler.inverse_transform(train_pred)\n",
    "test_pred_inv = scaler.inverse_transform(test_pred)\n",
    "y_train_inv = scaler.inverse_transform(y_train.numpy())\n",
    "y_test_inv = scaler.inverse_transform(y_test.numpy())\n",
    "\n",
    "# 시각화\n",
    "fig = go.Figure()\n",
    "\n",
    "# 전체 실제 데이터\n",
    "fig.add_trace(go.Scatter(y=y_data, mode='lines', name='실제값', line=dict(color='blue')))\n",
    "\n",
    "# 테스트 예측\n",
    "test_idx = list(range(train_size + SEQ_LENGTH, len(y_data)))\n",
    "fig.add_trace(go.Scatter(x=test_idx, y=test_pred_inv.flatten(), \n",
    "                          mode='lines', name='LSTM 예측', line=dict(color='red', dash='dash')))\n",
    "\n",
    "fig.add_vline(x=train_size + SEQ_LENGTH, line_dash='dot', line_color='green',\n",
    "              annotation_text='Train/Test')\n",
    "\n",
    "fig.update_layout(title='사인파 LSTM 예측 결과', xaxis_title='시점', yaxis_title='값',\n",
    "                  template='plotly_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. 데이터 정규화 (MinMaxScaler)\n",
    "2. 시퀀스 데이터 생성 (슬라이딩 윈도우)\n",
    "3. LSTM 모델 정의 및 학습\n",
    "4. 예측 후 역정규화\n",
    "\n",
    "**핵심 개념**:\n",
    "- 시계열 예측에서 정규화는 필수\n",
    "- LSTM의 마지막 시점 출력 -> FC -> 예측값\n",
    "\n",
    "**실무 팁**:\n",
    "- 복잡한 시계열은 다층 LSTM 또는 양방향 사용\n",
    "- Dropout 추가로 과적합 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q10. 감성 분석 모델 개선\n",
    "\n",
    "**문제**: SentimentLSTM 모델을 GRU로 변경하고 개선하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비 (본문과 동일)\n",
    "vocab = {\n",
    "    '<PAD>': 0, '<UNK>': 1,\n",
    "    'this': 2, 'movie': 3, 'was': 4, 'is': 5,\n",
    "    'great': 6, 'good': 7, 'bad': 8, 'terrible': 9,\n",
    "    'amazing': 10, 'awful': 11, 'boring': 12, 'exciting': 13,\n",
    "    'the': 14, 'a': 15, 'very': 16, 'really': 17,\n",
    "    'loved': 18, 'hated': 19, 'it': 20, 'film': 21\n",
    "}\n",
    "\n",
    "positive_reviews = [\"this movie was great\", \"the film is amazing\", \"really good movie\",\n",
    "                    \"loved this film\", \"very exciting movie\"]\n",
    "negative_reviews = [\"this movie was bad\", \"the film is terrible\", \"really awful movie\",\n",
    "                    \"hated this film\", \"very boring movie\"]\n",
    "\n",
    "def text_to_indices(text, vocab, max_len=10):\n",
    "    tokens = text.lower().split()\n",
    "    indices = [vocab.get(t, vocab['<UNK>']) for t in tokens]\n",
    "    if len(indices) < max_len:\n",
    "        indices = indices + [vocab['<PAD>']] * (max_len - len(indices))\n",
    "    return indices[:max_len]\n",
    "\n",
    "X_data = [text_to_indices(r, vocab) for r in positive_reviews + negative_reviews]\n",
    "y_data = [1]*5 + [0]*5\n",
    "X_data = X_data * 20\n",
    "y_data = y_data * 20\n",
    "\n",
    "X_tensor = torch.LongTensor(X_data)\n",
    "y_tensor = torch.FloatTensor(y_data).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드: 개선된 GRU 모델\n",
    "class ImprovedSentimentGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        # 임베딩\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        \n",
    "        # GRU (2층, 양방향, Dropout)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # 분류 레이어 (양방향이므로 hidden_size * 2)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 임베딩\n",
    "        embedded = self.embedding(x)  # (batch, seq, embed)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # GRU\n",
    "        gru_out, h_n = self.gru(embedded)\n",
    "        # h_n: (num_layers*2, batch, hidden)\n",
    "        \n",
    "        # 마지막 레이어의 순방향+역방향 결합\n",
    "        forward_h = h_n[-2]  # 순방향 마지막 레이어\n",
    "        backward_h = h_n[-1]  # 역방향 마지막 레이어\n",
    "        hidden = torch.cat([forward_h, backward_h], dim=1)\n",
    "        hidden = self.dropout(hidden)\n",
    "        \n",
    "        # 분류\n",
    "        out = self.fc(hidden)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "# 모델 생성\n",
    "improved_model = ImprovedSentimentGRU(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_dim=32,\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    dropout=0.3\n",
    ")\n",
    "\n",
    "print(improved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(improved_model.parameters(), lr=0.01)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    improved_model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = improved_model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "def predict_improved(text, model, vocab):\n",
    "    model.eval()\n",
    "    indices = text_to_indices(text, vocab)\n",
    "    x = torch.LongTensor([indices])\n",
    "    with torch.no_grad():\n",
    "        prob = model(x).item()\n",
    "    return \"긍정\" if prob > 0.5 else \"부정\", prob\n",
    "\n",
    "test_reviews = [\n",
    "    \"this movie was great\",\n",
    "    \"the film is terrible\",\n",
    "    \"really loved it\",\n",
    "    \"very bad film\",\n",
    "    \"amazing movie\",\n",
    "    \"awful boring film\"\n",
    "]\n",
    "\n",
    "print(\"개선된 GRU 모델 감성 분석 결과:\")\n",
    "print(\"=\"*50)\n",
    "for review in test_reviews:\n",
    "    sentiment, prob = predict_improved(review, improved_model, vocab)\n",
    "    print(f\"'{review}'\")\n",
    "    print(f\"  -> {sentiment} (확률: {prob:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**개선 사항**:\n",
    "1. **LSTM -> GRU**: 파라미터 감소, 학습 속도 향상\n",
    "2. **Dropout 추가**: 과적합 방지\n",
    "3. **2층 구조**: 더 복잡한 패턴 학습\n",
    "4. **양방향 유지**: 텍스트 분류에 효과적\n",
    "\n",
    "**핵심 개념**:\n",
    "- GRU는 LSTM보다 25% 적은 파라미터로 비슷한 성능\n",
    "- 다층 RNN에서는 레이어 사이에 dropout 적용 가능\n",
    "- 양방향 출력은 마지막 레이어의 순방향+역방향 결합\n",
    "\n",
    "**실무 팁**:\n",
    "- 실제로는 사전 학습된 임베딩(Word2Vec, FastText) 사용\n",
    "- 긴 텍스트는 BERT 같은 Transformer 모델이 더 효과적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 학습 정리\n",
    "\n",
    "### 핵심 개념 요약\n",
    "\n",
    "| 퀴즈 | 핵심 개념 | 실무 포인트 |\n",
    "|------|----------|------------|\n",
    "| Q1 | RNN 출력 shape | batch_first, num_layers 이해 |\n",
    "| Q2 | Hidden State | outputs[:,-1,:] == h_n[-1] |\n",
    "| Q3 | 시퀀스 데이터 | 순서의 의미 |\n",
    "| Q4 | LSTM 게이트 | Forget, Input, Output |\n",
    "| Q5 | GRU vs LSTM | 파라미터 75%, 비슷한 성능 |\n",
    "| Q6 | 양방향 RNN | 출력 차원 2배 |\n",
    "| Q7 | 시퀀스 생성 | 슬라이딩 윈도우 |\n",
    "| Q8 | Embedding | 정수 -> 벡터 변환 |\n",
    "| Q9 | 시계열 예측 | 정규화, LSTM, 시각화 |\n",
    "| Q10 | 모델 개선 | GRU, Dropout, 다층 |\n",
    "\n",
    "### 실전 팁\n",
    "\n",
    "1. **모델 선택**: GRU로 시작, 성능 부족 시 LSTM\n",
    "2. **전처리**: 시계열은 정규화 필수, 텍스트는 토큰화+임베딩\n",
    "3. **과적합 방지**: Dropout, Early Stopping\n",
    "4. **시각화**: 예측 vs 실제 비교로 모델 성능 직관적 파악"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
