{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day16_0: PyTorch 기초 (Tensor & Autograd)\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "**Part 1: 기초**\n",
    "1. PyTorch 텐서 생성 및 기본 연산 이해하기\n",
    "2. 텐서의 shape, dtype, device 속성 다루기\n",
    "3. NumPy와 PyTorch 텐서 변환하기\n",
    "4. GPU 가속(CUDA) 개념 이해하기\n",
    "5. 텐서 인덱싱과 슬라이싱 활용하기\n",
    "\n",
    "**Part 2: 심화**\n",
    "1. Autograd(자동 미분) 원리 이해하기\n",
    "2. requires_grad와 backward() 활용하기\n",
    "3. nn.Module로 신경망 정의하기\n",
    "4. Dataset과 DataLoader로 데이터 공급하기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 왜 이것을 배우나요?\n",
    "\n",
    "| 개념 | 실무 활용 | 예시 |\n",
    "|------|----------|------|\n",
    "| Tensor | 딥러닝 데이터 표현 | 이미지, 텍스트, 시계열 데이터 |\n",
    "| Autograd | 자동 그래디언트 계산 | 역전파 학습 자동화 |\n",
    "| nn.Module | 신경망 구조 정의 | MLP, CNN, RNN 모델 설계 |\n",
    "| DataLoader | 효율적 데이터 공급 | 배치 처리, 셔플링 |\n",
    "\n",
    "**분석가 관점**: PyTorch는 연구와 프로덕션 모두에서 가장 인기 있는 딥러닝 프레임워크입니다. 직관적인 Python 스타일과 동적 계산 그래프로 디버깅이 쉽습니다!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: 기초\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 PyTorch 소개\n",
    "\n",
    "### 딥러닝 프레임워크 비교\n",
    "\n",
    "| 구분 | PyTorch | TensorFlow |\n",
    "|------|---------|------------|\n",
    "| 개발사 | Meta (Facebook) | Google |\n",
    "| 계산 그래프 | 동적 (Define-by-Run) | 정적 (TF1) / 동적 (TF2) |\n",
    "| 디버깅 | Python 스타일 (쉬움) | 상대적으로 복잡 |\n",
    "| 연구 | 학계에서 선호 | 산업에서 선호 |\n",
    "| 장점 | 직관적, 빠른 프로토타입 | 대규모 배포 용이 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 2.10.0+cpu\n",
      "CUDA 사용 가능: False\n",
      "CPU 모드로 실행됩니다.\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 설치 확인\n",
    "import torch\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "\n",
    "# CUDA (GPU) 사용 가능 여부\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU 이름: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CPU 모드로 실행됩니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 텐서 생성\n",
    "\n",
    "### 텐서(Tensor)란?\n",
    "\n",
    "- 다차원 배열 (NumPy의 ndarray와 유사)\n",
    "- GPU에서 연산 가능\n",
    "- 자동 미분 지원\n",
    "\n",
    "```\n",
    "스칼라(0D) -> 벡터(1D) -> 행렬(2D) -> 텐서(3D+)\n",
    "    5         [1,2,3]     [[1,2],[3,4]]   [[[1,2],[3,4]],[[5,6],[7,8]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스칼라: 5, shape: torch.Size([])\n",
      "벡터: tensor([1, 2, 3]), shape: torch.Size([3])\n",
      "행렬:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]]), shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# 1. torch.tensor() - 직접 값 지정\n",
    "scalar = torch.tensor(5)               # 스칼라 (0차원)\n",
    "vector = torch.tensor([1, 2, 3])       # 벡터 (1차원)\n",
    "matrix = torch.tensor([[1, 2], [3, 4]])  # 행렬 (2차원)\n",
    "\n",
    "print(f\"스칼라: {scalar}, shape: {scalar.shape}\")\n",
    "print(f\"벡터: {vector}, shape: {vector.shape}\")\n",
    "print(f\"행렬:\\n{matrix}, shape: {matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros (3x4):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "\n",
      "ones (2x3):\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "rand (0~1 균등):\n",
      "tensor([[0.7438, 0.9228],\n",
      "        [0.4340, 0.1418]])\n",
      "\n",
      "randn (정규 분포):\n",
      "tensor([[ 0.5078,  0.0319],\n",
      "        [ 0.3879, -0.8526]])\n"
     ]
    }
   ],
   "source": [
    "# 2. 특수 텐서 생성 함수\n",
    "zeros = torch.zeros(3, 4)          # 0으로 채운 3x4 텐서\n",
    "ones = torch.ones(2, 3)            # 1로 채운 2x3 텐서\n",
    "rand = torch.rand(2, 2)            # 0~1 균등 분포\n",
    "randn = torch.randn(2, 2)          # 표준 정규 분포\n",
    "\n",
    "print(f\"zeros (3x4):\\n{zeros}\")\n",
    "print(f\"\\nones (2x3):\\n{ones}\")\n",
    "print(f\"\\nrand (0~1 균등):\\n{rand}\")\n",
    "print(f\"\\nrandn (정규 분포):\\n{randn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arange(0, 10, 2): tensor([0, 2, 4, 6, 8])\n",
      "linspace(0, 1, 5): tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# 3. 범위/간격 텐서\n",
    "arange = torch.arange(0, 10, 2)    # 0부터 10 미만, 간격 2\n",
    "linspace = torch.linspace(0, 1, 5) # 0~1을 5등분\n",
    "\n",
    "print(f\"arange(0, 10, 2): {arange}\")\n",
    "print(f\"linspace(0, 1, 5): {linspace}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 x:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "zeros_like:\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "ones_like:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "rand_like:\n",
      "tensor([[0.8241, 0.4220],\n",
      "        [0.9190, 0.3229]])\n"
     ]
    }
   ],
   "source": [
    "# 4. 기존 텐서와 같은 shape/dtype으로 생성\n",
    "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "\n",
    "zeros_like = torch.zeros_like(x)   # x와 같은 shape, 0으로 채움\n",
    "ones_like = torch.ones_like(x)     # x와 같은 shape, 1로 채움\n",
    "rand_like = torch.rand_like(x)     # x와 같은 shape, 랜덤\n",
    "\n",
    "print(f\"원본 x:\\n{x}\")\n",
    "print(f\"zeros_like:\\n{zeros_like}\")\n",
    "print(f\"ones_like:\\n{ones_like}\")\n",
    "print(f\"rand_like:\\n{rand_like}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실무 예시: 딥러닝 입력 데이터 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터 shape: torch.Size([32, 10])\n",
      "레이블 shape: torch.Size([32])\n",
      "\n",
      "첫 5개 샘플의 처음 3개 특성:\n",
      "tensor([[ 1.1621, -1.3109,  0.9629],\n",
      "        [ 1.0694, -0.7104,  0.9507],\n",
      "        [-1.1149, -1.7858,  2.2661],\n",
      "        [-1.5933, -1.7404,  0.4149],\n",
      "        [ 0.1163, -0.2101, -1.9077]])\n",
      "\n",
      "첫 10개 레이블: tensor([0, 0, 1, 0, 1, 1, 0, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# 배치 데이터 시뮬레이션 (batch_size=32, features=10)\n",
    "batch_size = 32\n",
    "num_features = 10\n",
    "\n",
    "# 입력 데이터 (정규 분포)\n",
    "X_batch = torch.randn(batch_size, num_features)\n",
    "\n",
    "# 레이블 (0 또는 1)\n",
    "y_batch = torch.randint(0, 2, (batch_size,))\n",
    "\n",
    "print(f\"입력 데이터 shape: {X_batch.shape}\")\n",
    "print(f\"레이블 shape: {y_batch.shape}\")\n",
    "print(f\"\\n첫 5개 샘플의 처음 3개 특성:\\n{X_batch[:5, :3]}\")\n",
    "print(f\"\\n첫 10개 레이블: {y_batch[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 텐서 속성\n",
    "\n",
    "### shape, dtype, device\n",
    "\n",
    "텐서의 3가지 핵심 속성:\n",
    "- **shape**: 각 차원의 크기\n",
    "- **dtype**: 데이터 타입\n",
    "- **device**: CPU 또는 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([3, 4, 5])\n",
      "Size: torch.Size([3, 4, 5])\n",
      "Dtype: torch.float32\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 텐서 생성\n",
    "t = torch.randn(3, 4, 5)\n",
    "\n",
    "# 속성 확인\n",
    "print(f\"Shape: {t.shape}\")       # torch.Size([3, 4, 5])\n",
    "print(f\"Size: {t.size()}\")       # shape와 동일\n",
    "print(f\"Dtype: {t.dtype}\")       # torch.float32 (기본값)\n",
    "print(f\"Device: {t.device}\")     # cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64: tensor([1, 2, 3]), dtype: torch.int64\n",
      "float32: tensor([1., 2., 3.]), dtype: torch.float32\n",
      "bool: tensor([ True, False,  True]), dtype: torch.bool\n"
     ]
    }
   ],
   "source": [
    "# 데이터 타입 지정\n",
    "int_tensor = torch.tensor([1, 2, 3], dtype=torch.int64)\n",
    "float_tensor = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "bool_tensor = torch.tensor([True, False, True], dtype=torch.bool)\n",
    "\n",
    "print(f\"int64: {int_tensor}, dtype: {int_tensor.dtype}\")\n",
    "print(f\"float32: {float_tensor}, dtype: {float_tensor.dtype}\")\n",
    "print(f\"bool: {bool_tensor}, dtype: {bool_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본: tensor([1, 2, 3]), dtype: torch.int64\n",
      "float: tensor([1., 2., 3.]), dtype: torch.float32\n",
      "double: tensor([1., 2., 3.], dtype=torch.float64), dtype: torch.float64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 타입 변환\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(f\"원본: {x}, dtype: {x.dtype}\")\n",
    "\n",
    "# float으로 변환\n",
    "x_float = x.float()  # 또는 x.to(torch.float32)\n",
    "print(f\"float: {x_float}, dtype: {x_float.dtype}\")\n",
    "\n",
    "# double로 변환\n",
    "x_double = x.double()  # 또는 x.to(torch.float64)\n",
    "print(f\"double: {x_double}, dtype: {x_double.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실무 예시: 딥러닝에서 자주 사용되는 dtype\n",
    "\n",
    "| dtype | 용도 | 메모리 |\n",
    "|-------|-----|--------|\n",
    "| float32 | 기본 학습 | 4 bytes |\n",
    "| float16 | 혼합 정밀도 학습 | 2 bytes |\n",
    "| int64 | 인덱스, 레이블 | 8 bytes |\n",
    "| bool | 마스크 | 1 byte |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 GPU 가속 (CUDA)\n",
    "\n",
    "### to() 메서드로 device 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 device: cpu\n"
     ]
    }
   ],
   "source": [
    "# device 설정 (GPU 있으면 cuda, 없으면 cpu)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"사용 device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 device: cpu\n",
      "이동 후 device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 텐서를 device로 이동\n",
    "x = torch.randn(3, 3)\n",
    "print(f\"원본 device: {x.device}\")\n",
    "\n",
    "# GPU로 이동 (GPU 있는 경우)\n",
    "x_device = x.to(device)\n",
    "print(f\"이동 후 device: {x_device.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "직접 생성: cpu\n",
      "CPU로 이동: cpu\n"
     ]
    }
   ],
   "source": [
    "# 텐서 생성 시 바로 device 지정\n",
    "y = torch.randn(3, 3, device=device)\n",
    "print(f\"직접 생성: {y.device}\")\n",
    "\n",
    "# CPU로 다시 이동 (결과 확인용)\n",
    "y_cpu = y.cpu()\n",
    "print(f\"CPU로 이동: {y_cpu.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주의: device가 다른 텐서끼리 연산 불가!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연산 성공! 결과 shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# device 불일치 오류 예시\n",
    "a = torch.randn(3, 3)  # CPU\n",
    "b = torch.randn(3, 3, device=device)  # GPU (있는 경우)\n",
    "\n",
    "if a.device != b.device:\n",
    "    print(f\"주의: a({a.device})와 b({b.device})는 device가 다릅니다!\")\n",
    "    print(\"연산 전에 같은 device로 이동해야 합니다.\")\n",
    "    \n",
    "    # 같은 device로 이동 후 연산\n",
    "    a_device = a.to(device)\n",
    "    result = a_device + b\n",
    "    print(f\"연산 성공! 결과 shape: {result.shape}\")\n",
    "else:\n",
    "    result = a + b\n",
    "    print(f\"연산 성공! 결과 shape: {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.5 NumPy와 PyTorch 변환\n",
    "\n",
    "### 양방향 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy 배열:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "PyTorch 텐서:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# NumPy -> PyTorch\n",
    "np_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "tensor_from_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(f\"NumPy 배열:\\n{np_array}\")\n",
    "print(f\"PyTorch 텐서:\\n{tensor_from_np}\")\n",
    "print(f\"dtype: {tensor_from_np.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 텐서:\n",
      "tensor([[-0.3785, -0.3274,  1.9146],\n",
      "        [ 0.9086,  0.9919,  1.5895]])\n",
      "NumPy 배열:\n",
      "[[-0.3784864  -0.32738006  1.9146153 ]\n",
      " [ 0.90861654  0.9918682   1.5895311 ]]\n",
      "type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# PyTorch -> NumPy\n",
    "tensor = torch.randn(2, 3)\n",
    "np_from_tensor = tensor.numpy()\n",
    "\n",
    "print(f\"PyTorch 텐서:\\n{tensor}\")\n",
    "print(f\"NumPy 배열:\\n{np_from_tensor}\")\n",
    "print(f\"type: {type(np_from_tensor)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주의: 메모리 공유!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환 전 NumPy: [1. 2. 3.]\n",
      "변환 전 Tensor: tensor([1., 2., 3.])\n",
      "\n",
      "수정 후 NumPy: [100.   2.   3.]\n",
      "수정 후 Tensor: tensor([100.,   2.,   3.])  # 같이 변경됨!\n"
     ]
    }
   ],
   "source": [
    "# from_numpy는 메모리를 공유합니다!\n",
    "np_arr = np.array([1, 2, 3], dtype=np.float32)\n",
    "tensor = torch.from_numpy(np_arr)\n",
    "\n",
    "print(f\"변환 전 NumPy: {np_arr}\")\n",
    "print(f\"변환 전 Tensor: {tensor}\")\n",
    "\n",
    "# NumPy 배열 수정\n",
    "np_arr[0] = 100\n",
    "\n",
    "print(f\"\\n수정 후 NumPy: {np_arr}\")\n",
    "print(f\"수정 후 Tensor: {tensor}  # 같이 변경됨!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: [100.   2.   3.]\n",
      "Tensor: tensor([1., 2., 3.])  # 독립적\n"
     ]
    }
   ],
   "source": [
    "# 복사본 만들기 (메모리 공유 방지)\n",
    "np_arr = np.array([1, 2, 3], dtype=np.float32)\n",
    "tensor = torch.tensor(np_arr)  # tensor()는 복사본 생성\n",
    "\n",
    "np_arr[0] = 100\n",
    "\n",
    "print(f\"NumPy: {np_arr}\")\n",
    "print(f\"Tensor: {tensor}  # 독립적\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.6 텐서 연산\n",
    "\n",
    "### 기본 산술 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b:\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "\n",
      "a - b:\n",
      "tensor([[-4., -4.],\n",
      "        [-4., -4.]])\n",
      "\n",
      "a * b (요소별):\n",
      "tensor([[ 5., 12.],\n",
      "        [21., 32.]])\n",
      "\n",
      "a / b:\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
    "\n",
    "# 요소별 연산\n",
    "print(f\"a + b:\\n{a + b}\")\n",
    "print(f\"\\na - b:\\n{a - b}\")\n",
    "print(f\"\\na * b (요소별):\\n{a * b}\")\n",
    "print(f\"\\na / b:\\n{a / b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"txc-formula\" src=\"https://t1.daumcdn.net/cfile/tistory/25111F4D58333A5B07\" width=\"481\" height=\"202\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul(a, b):\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n"
     ]
    }
   ],
   "source": [
    "# 행렬 곱 (Matrix Multiplication)\n",
    "# 방법 1: torch.matmul()\n",
    "matmul_result = torch.matmul(a, b)\n",
    "print(f\"matmul(a, b):\\n{matmul_result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a @ b:\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n"
     ]
    }
   ],
   "source": [
    "# 방법 2: @ 연산자 (Python 3.5+)\n",
    "at_result = a @ b\n",
    "print(f\"\\na @ b:\\n{at_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a.mm(b):\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n"
     ]
    }
   ],
   "source": [
    "# 방법 3: tensor.mm() (2D only)\n",
    "mm_result = a.mm(b)\n",
    "print(f\"\\na.mm(b):\\n{mm_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 집계 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서 x:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "sum: 21.0\n",
      "mean: 3.5\n",
      "max: 6.0\n",
      "min: 1.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "print(f\"텐서 x:\\n{x}\")\n",
    "\n",
    "# 전체 집계\n",
    "print(f\"\\nsum: {x.sum()}\")\n",
    "print(f\"mean: {x.mean()}\")\n",
    "print(f\"max: {x.max()}\")\n",
    "print(f\"min: {x.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행 방향 합 (dim=0): tensor([5., 7., 9.])\n",
      "열 방향 합 (dim=1): tensor([ 6., 15.])\n"
     ]
    }
   ],
   "source": [
    "# 축(dim) 기준 집계\n",
    "print(f\"행 방향 합 (dim=0): {x.sum(dim=0)}\")\n",
    "print(f\"열 방향 합 (dim=1): {x.sum(dim=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전체 argmax: 5\n",
      "열 방향 argmax (dim=1): tensor([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# argmax: 최댓값의 인덱스\n",
    "print(f\"\\n전체 argmax: {x.argmax()}\")\n",
    "print(f\"열 방향 argmax (dim=1): {x.argmax(dim=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 형태 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), shape: torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12)\n",
    "print(f\"원본: {x}, shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reshape(3, 4):\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# reshape: 형태 변경\n",
    "x_3x4 = x.reshape(3, 4)\n",
    "print(f\"\\nreshape(3, 4):\\n{x_3x4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "view(2, 6):\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# view: reshape와 유사 (연속 메모리 필요)\n",
    "x_2x6 = x.view(2, 6)\n",
    "print(f\"\\nview(2, 6):\\n{x_2x6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reshape(4, -1):\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# -1: 자동 계산\n",
    "x_auto = x.reshape(4, -1)  # 4 x ? -> 4 x 3\n",
    "print(f\"\\nreshape(4, -1):\\n{x_auto}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# 차원 추가/제거\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(f\"원본 shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsqueeze(0): torch.Size([1, 3])\n",
      "unsqueeze(1): torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze: 차원 추가\n",
    "x_unsq0 = x.unsqueeze(0)  # (3,) -> (1, 3)\n",
    "x_unsq1 = x.unsqueeze(1)  # (3,) -> (3, 1)\n",
    "print(f\"unsqueeze(0): {x_unsq0.shape}\")\n",
    "print(f\"unsqueeze(1): {x_unsq1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "squeeze 전: torch.Size([1, 3, 1])\n",
      "squeeze 후: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# squeeze: 크기 1인 차원 제거\n",
    "y = torch.zeros(1, 3, 1)\n",
    "y_sq = y.squeeze()\n",
    "print(f\"\\nsqueeze 전: {y.shape}\")\n",
    "print(f\"squeeze 후: {y_sq.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.7 텐서 인덱싱과 슬라이싱\n",
    "\n",
    "### NumPy와 동일한 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서 x:\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4],\n",
    "                  [5, 6, 7, 8],\n",
    "                  [9, 10, 11, 12]])\n",
    "print(f\"텐서 x:\\n{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[0]: tensor([1, 2, 3, 4])\n",
      "x[0, 0]: 1\n",
      "x[-1]: tensor([ 9, 10, 11, 12])\n"
     ]
    }
   ],
   "source": [
    "# 기본 인덱싱\n",
    "print(f\"x[0]: {x[0]}\")\n",
    "print(f\"x[0, 0]: {x[0, 0]}\")\n",
    "print(f\"x[-1]: {x[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[:2]: tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      "x[:, 1:3]:\n",
      "tensor([[ 2,  3],\n",
      "        [ 6,  7],\n",
      "        [10, 11]])\n",
      "x[1:, 2:]:\n",
      "tensor([[ 7,  8],\n",
      "        [11, 12]])\n"
     ]
    }
   ],
   "source": [
    "# 슬라이싱\n",
    "print(f\"x[:2]: {x[:2]}\")\n",
    "print(f\"x[:, 1:3]:\\n{x[:, 1:3]}\")\n",
    "print(f\"x[1:, 2:]:\\n{x[1:, 2:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마스크 (x > 5):\n",
      "tensor([[False, False, False, False],\n",
      "        [False,  True,  True,  True],\n",
      "        [ True,  True,  True,  True]])\n",
      "\n",
      "5보다 큰 값: tensor([ 6,  7,  8,  9, 10, 11, 12])\n"
     ]
    }
   ],
   "source": [
    "# 조건 인덱싱 (Boolean Indexing)\n",
    "mask = x > 5\n",
    "print(f\"마스크 (x > 5):\\n{mask}\")\n",
    "print(f\"\\n5보다 큰 값: {x[mask]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[indices] (0, 2번 행):\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "# 팬시 인덱싱\n",
    "indices = torch.tensor([0, 2])\n",
    "print(f\"x[indices] (0, 2번 행):\\n{x[indices]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실무 예시: 배치에서 특정 샘플 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 shape: torch.Size([8, 5])\n",
      "레이블: tensor([0, 1, 0, 1, 0, 1, 1, 0])\n",
      "\n",
      "클래스 1 샘플 shape: torch.Size([4, 5])\n",
      "클래스 1 샘플:\n",
      "tensor([[-0.8626, -1.3503, -1.1156,  1.0007,  1.4669],\n",
      "        [-0.4152, -0.2736, -1.2951,  2.0733,  2.5136],\n",
      "        [ 0.2303,  1.1035, -0.8891, -2.0318, -0.9704],\n",
      "        [-1.0282,  0.2923, -0.5353, -2.2283, -0.7770]])\n"
     ]
    }
   ],
   "source": [
    "# 배치 데이터 (batch_size=8, features=5)\n",
    "batch = torch.randn(8, 5)\n",
    "labels = torch.tensor([0, 1, 0, 1, 0, 1, 1, 0])\n",
    "\n",
    "print(f\"배치 shape: {batch.shape}\")\n",
    "print(f\"레이블: {labels}\")\n",
    "\n",
    "# 클래스 1인 샘플만 추출\n",
    "class1_samples = batch[labels == 1]\n",
    "print(f\"\\n클래스 1 샘플 shape: {class1_samples.shape}\")\n",
    "print(f\"클래스 1 샘플:\\n{class1_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: 심화\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 Autograd (자동 미분)\n",
    "\n",
    "### 역전파의 핵심\n",
    "\n",
    "**Autograd**: 텐서 연산의 그래디언트(미분값)를 자동으로 계산\n",
    "\n",
    "```\n",
    "순전파 (Forward):  x -> f(x) -> y -> g(y) -> z\n",
    "역전파 (Backward): dz/dx <- dz/dy <- dz/dz=1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([2., 3.], requires_grad=True)\n",
      "requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "# requires_grad=True: 그래디언트 추적 활성화\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "print(f\"x: {x}\")\n",
    "print(f\"requires_grad: {x.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = x^2 + 3x = tensor([10., 18.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 연산 수행 (계산 그래프 생성)\n",
    "y = x ** 2 + 3 * x  # y = x^2 + 3x\n",
    "print(f\"y = x^2 + 3x = {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = sum(y) = 28.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 스칼라로 변환 (backward는 스칼라에 대해 호출)\n",
    "z = y.sum()  # z = y[0] + y[1]\n",
    "print(f\"z = sum(y) = {z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dz/dx = tensor([7., 9.])\n",
      "수동 계산: 2*tensor([2., 3.]) + 3 = tensor([7., 9.])\n"
     ]
    }
   ],
   "source": [
    "# backward(): 그래디언트 계산\n",
    "z.backward()\n",
    "\n",
    "# x.grad: dz/dx\n",
    "# y = x^2 + 3x -> dy/dx = 2x + 3\n",
    "# x = [2, 3] -> dy/dx = [7, 9]\n",
    "print(f\"dz/dx = {x.grad}\")\n",
    "print(f\"수동 계산: 2*{x.data} + 3 = {2*x.data + 3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래디언트 누적 주의!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 backward 후 grad: tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "# 그래디언트는 누적됩니다!\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "# 첫 번째 backward\n",
    "y1 = x * 2\n",
    "y1.backward()\n",
    "print(f\"첫 번째 backward 후 grad: {x.grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 번째 backward 후 grad: tensor([5.])  # 2 + 3 = 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 두 번째 backward (누적됨!)\n",
    "y2 = x * 3\n",
    "y2.backward()\n",
    "print(f\"두 번째 backward 후 grad: {x.grad}  # 2 + 3 = 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: grad = tensor([1.])\n",
      "Iteration 2: grad = tensor([2.])\n",
      "Iteration 3: grad = tensor([3.])\n"
     ]
    }
   ],
   "source": [
    "# 해결: 매 iteration마다 grad 초기화\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "for i in range(3):\n",
    "    # 그래디언트 초기화\n",
    "    if x.grad is not None:\n",
    "        x.grad.zero_()\n",
    "    \n",
    "    y = x * (i + 1)\n",
    "    y.backward()\n",
    "    print(f\"Iteration {i+1}: grad = {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실무 예시: 간단한 경사 하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경사 하강법으로 w=2, b=1 찾기\n",
      "========================================\n",
      "Epoch   0: loss=2.4578, w=0.1439, b=0.2043\n",
      "Epoch  20: loss=0.0744, w=1.5618, b=1.0122\n",
      "Epoch  40: loss=0.0115, w=1.8686, b=1.0215\n",
      "Epoch  60: loss=0.0086, w=1.9350, b=1.0216\n",
      "Epoch  80: loss=0.0084, w=1.9494, b=1.0216\n",
      "\n",
      "최종 결과: w=1.9524 (목표: 2.0), b=1.0216 (목표: 1.0)\n"
     ]
    }
   ],
   "source": [
    "# 목표: y = 2x + 1의 기울기(w)와 절편(b) 찾기\n",
    "# 데이터 생성\n",
    "torch.manual_seed(42)\n",
    "X = torch.linspace(-1, 1, 20).reshape(-1, 1)  # (20, 1)\n",
    "y_true = 2 * X + 1 + 0.1 * torch.randn_like(X)  # y = 2x + 1 + noise\n",
    "\n",
    "# 학습할 파라미터 (초기값)\n",
    "w = torch.tensor([0.0], requires_grad=True)\n",
    "b = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "print(\"경사 하강법으로 w=2, b=1 찾기\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "for epoch in range(100):\n",
    "    # 순전파: 예측\n",
    "    y_pred = w * X + b\n",
    "    \n",
    "    # 손실 계산: MSE\n",
    "    loss = ((y_pred - y_true) ** 2).mean()\n",
    "    \n",
    "    # 역전파: 그래디언트 계산\n",
    "    loss.backward()\n",
    "    \n",
    "    # 파라미터 업데이트 (no_grad 안에서!)\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "        b -= learning_rate * b.grad\n",
    "    \n",
    "    # 그래디언트 초기화\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch:3d}: loss={loss.item():.4f}, w={w.item():.4f}, b={b.item():.4f}\")\n",
    "\n",
    "print(f\"\\n최종 결과: w={w.item():.4f} (목표: 2.0), b={b.item():.4f} (목표: 1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 nn.Module로 신경망 정의\n",
    "\n",
    "### nn.Module 기초\n",
    "\n",
    "PyTorch의 모든 신경망은 `nn.Module`을 상속받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel(\n",
      "  (linear): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 간단한 선형 모델\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # 레이어 정의\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 순전파 정의\n",
    "        return self.linear(x)\n",
    "\n",
    "# 모델 생성\n",
    "model = LinearModel(input_dim=10, output_dim=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 파라미터:\n",
      "  linear.weight: shape=torch.Size([1, 10])\n",
      "  linear.bias: shape=torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# 모델 파라미터 확인\n",
    "print(\"모델 파라미터:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"  {name}: shape={param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 shape: torch.Size([5, 10])\n",
      "출력 shape: torch.Size([5, 1])\n",
      "출력:\n",
      "tensor([[-0.1248],\n",
      "        [ 0.6581],\n",
      "        [ 0.4286],\n",
      "        [-0.2371],\n",
      "        [ 0.2150]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 순전파 테스트\n",
    "x = torch.randn(5, 10)  # 배치 5개, 특성 10개\n",
    "output = model(x)       # forward() 자동 호출\n",
    "print(f\"입력 shape: {x.shape}\")\n",
    "print(f\"출력 shape: {output.shape}\")\n",
    "print(f\"출력:\\n{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다층 퍼셉트론 (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=10, out_features=32, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # 레이어 정의\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)    # 입력 -> 은닉\n",
    "        self.relu = nn.ReLU()                          # 활성화 함수\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)   # 은닉 -> 출력\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)      # 선형 변환\n",
    "        x = self.relu(x)     # 활성화\n",
    "        x = self.fc2(x)      # 선형 변환\n",
    "        return x\n",
    "\n",
    "# MLP 생성\n",
    "mlp = MLP(input_dim=10, hidden_dim=32, output_dim=2)\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# nn.Sequential로 더 간단하게\n",
    "mlp_sequential = nn.Sequential(\n",
    "    nn.Linear(10, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 2)\n",
    ")\n",
    "print(mlp_sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: torch.Size([4, 10])\n",
      "출력: torch.Size([4, 2])\n",
      "출력 값:\n",
      "tensor([[ 0.3187, -0.5776],\n",
      "        [-0.0047, -0.2838],\n",
      "        [-0.1196, -0.6236],\n",
      "        [-0.0337, -0.5949]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 테스트\n",
    "x = torch.randn(4, 10)\n",
    "output = mlp_sequential(x)\n",
    "print(f\"입력: {x.shape}\")\n",
    "print(f\"출력: {output.shape}\")\n",
    "print(f\"출력 값:\\n{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 Dataset과 DataLoader\n",
    "\n",
    "### Dataset 클래스\n",
    "\n",
    "데이터를 관리하는 추상 클래스. `__len__`과 `__getitem__` 구현 필요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 크기: 100\n",
      "첫 번째 샘플: X=torch.Size([5]), y=0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# 데이터 생성\n",
    "X_data = torch.randn(100, 5)  # 100개 샘플, 5개 특성\n",
    "y_data = torch.randint(0, 2, (100,))  # 이진 레이블\n",
    "\n",
    "# Dataset 생성\n",
    "dataset = SimpleDataset(X_data, y_data)\n",
    "print(f\"데이터셋 크기: {len(dataset)}\")\n",
    "print(f\"첫 번째 샘플: X={dataset[0][0].shape}, y={dataset[0][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader: 배치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 수: 6\n",
      "Batch 0: X=torch.Size([16, 5]), y=torch.Size([16])\n",
      "Batch 1: X=torch.Size([16, 5]), y=torch.Size([16])\n",
      "Batch 2: X=torch.Size([16, 5]), y=torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader 생성\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16,   # 배치 크기\n",
    "    shuffle=True,    # 셔플 여부\n",
    "    drop_last=True   # 마지막 불완전한 배치 버림\n",
    ")\n",
    "\n",
    "print(f\"배치 수: {len(dataloader)}\")\n",
    "\n",
    "# 배치 순회\n",
    "for batch_idx, (X_batch, y_batch) in enumerate(dataloader):\n",
    "    if batch_idx < 3:  # 처음 3개 배치만\n",
    "        print(f\"Batch {batch_idx}: X={X_batch.shape}, y={y_batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 학습 루프 (Training Loop)\n",
    "\n",
    "### 전체 흐름\n",
    "\n",
    "```python\n",
    "for epoch in range(epochs):\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        # 1. 순전파\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        \n",
    "        # 2. 역전파\n",
    "        optimizer.zero_grad()  # 그래디언트 초기화\n",
    "        loss.backward()        # 그래디언트 계산\n",
    "        optimizer.step()       # 파라미터 업데이트\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 전 파라미터:\n",
      "  weight: 0.1564\n",
      "  bias: -0.8799\n"
     ]
    }
   ],
   "source": [
    "# 선형 회귀 예제: y = 2x + 1 학습\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 데이터 생성\n",
    "X_train = torch.linspace(-2, 2, 100).reshape(-1, 1)\n",
    "y_train = 2 * X_train + 1 + 0.1 * torch.randn_like(X_train)\n",
    "\n",
    "# Dataset, DataLoader\n",
    "train_dataset = SimpleDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# 모델, 손실 함수, 옵티마이저\n",
    "model = nn.Linear(1, 1)  # 입력 1, 출력 1\n",
    "criterion = nn.MSELoss()  # 평균 제곱 오차\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "print(\"학습 전 파라미터:\")\n",
    "print(f\"  weight: {model.weight.data.item():.4f}\")\n",
    "print(f\"  bias: {model.bias.data.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0: Loss=2.7674\n",
      "Epoch  10: Loss=0.0096\n",
      "Epoch  20: Loss=0.0099\n",
      "Epoch  30: Loss=0.0110\n",
      "Epoch  40: Loss=0.0100\n",
      "\n",
      "학습 후 파라미터:\n",
      "  weight: 2.0017 (목표: 2.0)\n",
      "  bias: 0.9913 (목표: 1.0)\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "epochs = 50\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # 1. 순전파\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        \n",
    "        # 2. 역전파\n",
    "        optimizer.zero_grad()  # 그래디언트 초기화\n",
    "        loss.backward()        # 그래디언트 계산\n",
    "        optimizer.step()       # 파라미터 업데이트\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch:3d}: Loss={avg_loss:.4f}\")\n",
    "\n",
    "print(\"\\n학습 후 파라미터:\")\n",
    "print(f\"  weight: {model.weight.data.item():.4f} (목표: 2.0)\")\n",
    "print(f\"  bias: {model.bias.data.item():.4f} (목표: 1.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Epoch=%{x}<br>Loss=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDE=",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "SZIk+aEjBkBJkiRRN8KvP7dt2+aYD4k/AAAAQKrIhD+SJEmyCOqFP27bti2CSIU/AAAAsKPEgj8lSZKUMFqEP9u2bQtxaoQ/AAAAsLmlhT9JkiR5P5GDP9u2bbs584U/kiRJknYlgz9u27ZNVmOFP27btl1SYYQ/t23bZuKsgz9u27bd4FWEP5IkSWJdl4Y/AAAAMCzvgz9u27ZtE5iGP7dt2wbJVIQ/SZIkOcGBhj/btm0rFD+EP27btg3uzIU/SZIkae70gz9u27Y9WTaFP0mSJAmS94I/27Zti19tgz+SJEliMfmCP5IkSfJAhIU/kiRJMn+Ehj+3bdsGumeEPwAAAMAvVIM/JUmSlFifhD9JkiRpx52FP5IkSTLnt4I/JUmSBOPwgj/btm1LgaWCPwAAAKDNtoM/btu2fQbRgz+SJElSwYeEPyVJkuQm+YU/AAAAeFi6hD8lSZLkDk2EP0mSJPmvKoM/btu2LUXuhD/btm0LeH6EP7dt28aV6IQ/JUmSBA+2hj8lSZKUTECDPw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "학습 손실 곡선"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "MSE Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 곡선 시각화 (Plotly)\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "loss_df = pd.DataFrame({\n",
    "    'Epoch': range(epochs),\n",
    "    'Loss': losses\n",
    "})\n",
    "\n",
    "fig = px.line(loss_df, x='Epoch', y='Loss', title='학습 손실 곡선')\n",
    "fig.update_layout(\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='MSE Loss',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실무 예시: 이진 분류 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터: torch.Size([16512, 8])\n",
      "테스트 데이터: torch.Size([4128, 8])\n"
     ]
    }
   ],
   "source": [
    "# California Housing 데이터로 고가/저가 분류\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "# 데이터 로드\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "\n",
    "median_price = np.median(housing.target)\n",
    "y = (housing.target > median_price).astype(int)  # 고가: 1, 저가: 0\n",
    "\n",
    "# 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 텐서 변환\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "print(f\"훈련 데이터: {X_train_t.shape}\")\n",
    "print(f\"테스트 데이터: {X_test_t.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryClassifier(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=16, out_features=1, bias=True)\n",
      "    (6): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 이진 분류 모델\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()  # 확률 출력\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 모델 생성\n",
    "model = BinaryClassifier(input_dim=8)\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0: Loss=0.4227\n",
      "Epoch   5: Loss=0.3327\n",
      "Epoch  10: Loss=0.3251\n",
      "Epoch  15: Loss=0.3082\n",
      "Epoch  20: Loss=0.3082\n",
      "Epoch  25: Loss=0.3075\n"
     ]
    }
   ],
   "source": [
    "# DataLoader\n",
    "train_dataset = SimpleDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 학습\n",
    "epochs = 30\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # 학습 모드\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    train_losses.append(epoch_loss / len(train_loader))\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch:3d}: Loss={train_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "테스트 정확도: 87.72%\n"
     ]
    }
   ],
   "source": [
    "# 평가\n",
    "model.eval()  # 평가 모드\n",
    "with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "    y_pred_proba = model(X_test_t)\n",
    "    y_pred = (y_pred_proba > 0.5).float()\n",
    "    \n",
    "    accuracy = (y_pred == y_test_t).float().mean()\n",
    "    print(f\"\\n테스트 정확도: {accuracy.item():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 퀴즈\n",
    "\n",
    "**난이도**: (쉬움) ~ (어려움)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. 텐서 생성하기 (기본)\n",
    "\n",
    "**문제**: 다음 조건에 맞는 텐서를 생성하세요.\n",
    "\n",
    "1. 3x4 크기의 모든 요소가 1인 텐서\n",
    "2. 0부터 9까지의 정수 텐서\n",
    "3. 2x3 크기의 표준 정규 분포 랜덤 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. 텐서 속성 확인 (기본)\n",
    "\n",
    "**문제**: 아래 텐서의 shape, dtype, device를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. 텐서 연산 (기본)\n",
    "\n",
    "**문제**: 두 행렬 A와 B의 행렬 곱을 계산하세요.\n",
    "\n",
    "```python\n",
    "A = [[1, 2], [3, 4]]\n",
    "B = [[5, 6], [7, 8]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "B = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. NumPy 변환 (응용)\n",
    "\n",
    "**문제**: NumPy 배열을 PyTorch 텐서로 변환하고, 다시 NumPy로 변환하세요. 메모리 공유 여부를 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "np_array = np.array([1.0, 2.0, 3.0])\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. GPU 이동 (응용)\n",
    "\n",
    "**문제**: 텐서를 GPU로 이동하고 (GPU가 없으면 CPU 유지), device를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(3, 3)\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. 텐서 인덱싱 (응용)\n",
    "\n",
    "**문제**: 아래 텐서에서 5보다 큰 값만 추출하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[1, 8, 3], [4, 2, 9], [7, 6, 5]])\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Autograd 이해 (복합)\n",
    "\n",
    "**문제**: y = x^3 + 2x^2 + 1에서 x=2일 때 dy/dx를 Autograd로 계산하세요.\n",
    "\n",
    "힌트: dy/dx = 3x^2 + 4x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. nn.Module 정의 (복합)\n",
    "\n",
    "**문제**: 3개의 은닉층을 가진 MLP를 정의하세요.\n",
    "\n",
    "- 입력: 10\n",
    "- 은닉층: 64 -> 32 -> 16\n",
    "- 출력: 2\n",
    "- 활성화: ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. Dataset과 DataLoader (종합)\n",
    "\n",
    "**문제**: 1000개의 랜덤 샘플(특성 5개)과 레이블로 Dataset을 만들고, batch_size=32인 DataLoader를 생성하세요. 첫 번째 배치를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. 학습 루프 작성 (종합)\n",
    "\n",
    "**문제**: 아래 데이터로 선형 회귀 모델을 학습하세요.\n",
    "\n",
    "요구사항:\n",
    "1. y = 3x - 2의 관계를 학습\n",
    "2. nn.Linear 모델 사용\n",
    "3. MSE 손실, SGD 옵티마이저\n",
    "4. 100 에포크 학습 후 weight와 bias 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 데이터 생성\n",
    "torch.manual_seed(42)\n",
    "X = torch.linspace(-1, 1, 100).reshape(-1, 1)\n",
    "y = 3 * X - 2 + 0.1 * torch.randn_like(X)\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 학습 정리\n",
    "\n",
    "### Part 1: 기초 핵심 요약\n",
    "\n",
    "| 개념 | 핵심 함수 | 실무 활용 |\n",
    "|-----|----------|----------|\n",
    "| 텐서 생성 | torch.tensor(), zeros(), ones(), rand() | 데이터 초기화 |\n",
    "| 속성 | shape, dtype, device | 디버깅, 호환성 확인 |\n",
    "| NumPy 변환 | from_numpy(), .numpy() | 데이터 전처리 연동 |\n",
    "| GPU 이동 | .to(device), .cuda(), .cpu() | 학습 가속 |\n",
    "| 인덱싱 | 슬라이싱, Boolean indexing | 배치 추출, 필터링 |\n",
    "\n",
    "### Part 2: 심화 핵심 요약\n",
    "\n",
    "| 개념 | 핵심 메서드 | 언제 사용? |\n",
    "|-----|-----------|----------|\n",
    "| Autograd | requires_grad=True, backward() | 그래디언트 자동 계산 |\n",
    "| nn.Module | __init__(), forward() | 신경망 정의 |\n",
    "| Dataset | __len__(), __getitem__() | 데이터 관리 |\n",
    "| DataLoader | batch_size, shuffle | 배치 처리 |\n",
    "\n",
    "### 학습 루프 핵심 패턴\n",
    "\n",
    "```python\n",
    "for epoch in range(epochs):\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        output = model(X_batch)           # 순전파\n",
    "        loss = criterion(output, y_batch) # 손실 계산\n",
    "        \n",
    "        optimizer.zero_grad()  # 그래디언트 초기화\n",
    "        loss.backward()        # 역전파\n",
    "        optimizer.step()       # 파라미터 업데이트\n",
    "```\n",
    "\n",
    "### 실무 팁\n",
    "\n",
    "1. **device 일관성**: 모든 텐서와 모델이 같은 device에 있는지 확인\n",
    "2. **grad 초기화**: 매 iteration마다 `optimizer.zero_grad()` 필수\n",
    "3. **eval() 모드**: 평가 시 `model.eval()` + `torch.no_grad()`\n",
    "4. **dtype 주의**: 연산 전 dtype 일치 확인\n",
    "5. **메모리 관리**: 불필요한 텐서는 `del`로 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
