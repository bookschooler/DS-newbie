{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day17_0: CNN (í•©ì„±ê³± ì‹ ê²½ë§) - ì •ë‹µ\n",
    "\n",
    "## ğŸ“š ì‹¤ìŠµ í€´ì¦ˆ ì •ë‹µ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³µí†µ ì„í¬íŠ¸\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q1. Conv2d ì¶œë ¥ í¬ê¸° ê³„ì‚° â­\n",
    "\n",
    "**ë¬¸ì œ**: 64x64 í¬ê¸°ì˜ RGB ì´ë¯¸ì§€ì— ë‹¤ìŒ Conv2dë¥¼ ì ìš©í–ˆì„ ë•Œ ì¶œë ¥ í¬ê¸°ë¥¼ ê³„ì‚°í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# ì¶œë ¥ í¬ê¸° ê³„ì‚° ê³µì‹: (ì…ë ¥ + 2*padding - kernel) / stride + 1\n",
    "def calc_output_size(input_size, kernel_size, stride, padding):\n",
    "    return (input_size + 2 * padding - kernel_size) // stride + 1\n",
    "\n",
    "# ì£¼ì–´ì§„ ì¡°ê±´\n",
    "input_size = 64\n",
    "kernel_size = 5\n",
    "stride = 2\n",
    "padding = 2\n",
    "\n",
    "# ê³„ì‚°\n",
    "output_size = calc_output_size(input_size, kernel_size, stride, padding)\n",
    "print(f\"ê³„ì‚°: ({input_size} + 2*{padding} - {kernel_size}) / {stride} + 1 = {output_size}\")\n",
    "\n",
    "# ì‹¤ì œ í™•ì¸\n",
    "conv = nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=2)\n",
    "dummy_input = torch.randn(1, 3, 64, 64)\n",
    "output = conv(dummy_input)\n",
    "print(f\"\\nì‹¤ì œ ì¶œë ¥: {output.shape}\")\n",
    "print(f\"ì¶œë ¥ shape: (1, 32, {output_size}, {output_size})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- Conv2d ì¶œë ¥ í¬ê¸° ê³µì‹ ì ìš©: (ì…ë ¥ + 2*padding - kernel) / stride + 1\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- `kernel_size=5`: 5x5 í¬ê¸° í•„í„°\n",
    "- `stride=2`: 2ì¹¸ì”© ì´ë™ (ì¶œë ¥ í¬ê¸° ì ˆë°˜)\n",
    "- `padding=2`: ê°€ì¥ìë¦¬ì— 2ì¹¸ íŒ¨ë”© ì¶”ê°€\n",
    "\n",
    "**ê³„ì‚° ê³¼ì •**:\n",
    "- (64 + 4 - 5) / 2 + 1 = 63 / 2 + 1 = 31 + 1 = 32\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- `padding = (kernel_size - 1) / 2`ì¼ ë•Œ ì¶œë ¥ í¬ê¸°ê°€ ì…ë ¥/strideì™€ ê°™ì•„ì§\n",
    "- stride=2ëŠ” í”í•œ ë‹¤ìš´ìƒ˜í”Œë§ ë°©ë²•\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Max Pooling íš¨ê³¼ â­\n",
    "\n",
    "**ë¬¸ì œ**: 4x4 íŠ¹ì§• ë§µì— 2x2 Max Pooling (stride=2)ì„ ì ìš©í•œ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# ì…ë ¥ íŠ¹ì§• ë§µ\n",
    "feature_map = torch.tensor([[1, 3, 2, 4],\n",
    "                            [5, 6, 7, 8],\n",
    "                            [3, 2, 1, 0],\n",
    "                            [9, 8, 7, 6]], dtype=torch.float32)\n",
    "\n",
    "# (ë°°ì¹˜, ì±„ë„) ì°¨ì› ì¶”ê°€\n",
    "feature_map_4d = feature_map.unsqueeze(0).unsqueeze(0)  # (1, 1, 4, 4)\n",
    "\n",
    "# Max Pooling ì ìš©\n",
    "max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "output = max_pool(feature_map_4d)\n",
    "\n",
    "print(\"ì…ë ¥ íŠ¹ì§• ë§µ:\")\n",
    "print(feature_map)\n",
    "print(f\"\\nì…ë ¥ shape: {feature_map.shape}\")\n",
    "\n",
    "print(\"\\n2x2 Max Pooling ê²°ê³¼:\")\n",
    "print(output.squeeze())\n",
    "print(f\"\\nì¶œë ¥ shape: {output.squeeze().shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- 2x2 ì˜ì—­ì—ì„œ ìµœëŒ“ê°’ì„ ì„ íƒ\n",
    "- stride=2ë¡œ ê²¹ì¹˜ì§€ ì•Šê²Œ ì´ë™\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ì¢Œìƒë‹¨ 2x2 ì˜ì—­ [1,3,5,6] -> max = 6\n",
    "- ìš°ìƒë‹¨ 2x2 ì˜ì—­ [2,4,7,8] -> max = 8\n",
    "- ì¢Œí•˜ë‹¨ 2x2 ì˜ì—­ [3,2,9,8] -> max = 9\n",
    "- ìš°í•˜ë‹¨ 2x2 ì˜ì—­ [1,0,7,6] -> max = 7\n",
    "\n",
    "**ê²°ê³¼**: [[6, 8], [9, 7]]\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- Max Poolingì€ ê°€ì¥ ê°•í•œ íŠ¹ì§•ë§Œ ë‚¨ê¹€\n",
    "- Average Poolingë³´ë‹¤ íŠ¹ì§• ë³´ì¡´ì— ìœ ë¦¬\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. ì´ë¯¸ì§€ ì •ê·œí™” â­â­\n",
    "\n",
    "**ë¬¸ì œ**: 0-255 ë²”ìœ„ì˜ ì´ë¯¸ì§€ë¥¼ [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# 0-255 ë²”ìœ„ ì´ë¯¸ì§€ (ì‹œë®¬ë ˆì´ì…˜)\n",
    "raw_image = torch.randint(0, 256, (3, 32, 32), dtype=torch.float32)\n",
    "\n",
    "# ë°©ë²• 1: ìˆ˜ë™ ê³„ì‚°\n",
    "# ë¨¼ì € [0, 1]ë¡œ ë³€í™˜ í›„ [-1, 1]ë¡œ ì¡°ì •\n",
    "normalized_image = (raw_image / 255.0 - 0.5) / 0.5\n",
    "\n",
    "# ë˜ëŠ” í•œ ë²ˆì—: (x - 127.5) / 127.5\n",
    "normalized_image_v2 = (raw_image - 127.5) / 127.5\n",
    "\n",
    "print(f\"ì›ë³¸ ë²”ìœ„: [{raw_image.min():.0f}, {raw_image.max():.0f}]\")\n",
    "print(f\"ì •ê·œí™” í›„ ë²”ìœ„: [{normalized_image.min():.4f}, {normalized_image.max():.4f}]\")\n",
    "\n",
    "# ê²€ì¦\n",
    "print(f\"\\n0 -> {(0 / 255.0 - 0.5) / 0.5:.4f}\")\n",
    "print(f\"127.5 -> {(127.5 / 255.0 - 0.5) / 0.5:.4f}\")\n",
    "print(f\"255 -> {(255 / 255.0 - 0.5) / 0.5:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- 2ë‹¨ê³„: [0, 255] -> [0, 1] -> [-1, 1]\n",
    "- ë˜ëŠ” ì§ì ‘: (x - 127.5) / 127.5\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- `/255`: [0, 1] ë²”ìœ„ë¡œ ë³€í™˜\n",
    "- `-0.5`: [âˆ’0.5, 0.5] ë²”ìœ„ë¡œ ì´ë™\n",
    "- `/0.5`: [-1, 1] ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼\n",
    "\n",
    "**ëŒ€ì•ˆ - transforms ì‚¬ìš©**:\n",
    "```python\n",
    "transforms.Normalize((0.5,), (0.5,))  # ì´ë¯¸ [0,1]ì¸ í…ì„œì— ì ìš©\n",
    "```\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ToTensor()ëŠ” ìë™ìœ¼ë¡œ [0, 255] -> [0, 1] ë³€í™˜\n",
    "- Normalize()ëŠ” (x - mean) / std ì ìš©\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. CNN ì•„í‚¤í…ì²˜ ë¶„ì„ â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ CNN ëª¨ë¸ì˜ ê° ë ˆì´ì–´ ì¶œë ¥ shapeë¥¼ ê³„ì‚°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, 3, padding=1),    # (1, 16, 32, 32)\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),                 # (1, 16, 16, 16)\n",
    "    nn.Conv2d(16, 32, 3, padding=1),   # (1, 32, 16, 16)\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),                 # (1, 32, 8, 8)\n",
    "    nn.Flatten(),                       # (1, 2048)\n",
    ")\n",
    "\n",
    "# ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ ì‹¤ì œ shape í™•ì¸\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "print(f\"ì…ë ¥: {x.shape}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, layer in enumerate(model):\n",
    "    x = layer(x)\n",
    "    print(f\"{layer.__class__.__name__}: {x.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- ê° ë ˆì´ì–´ë³„ë¡œ ì¶œë ¥ shape ì¶”ì \n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "1. Conv2d(3, 16, 3, padding=1): ì±„ë„ 3->16, í¬ê¸° ìœ ì§€ (padding=1)\n",
    "2. ReLU: shape ë³€í™” ì—†ìŒ\n",
    "3. MaxPool2d(2,2): ê³µê°„ í¬ê¸° ì ˆë°˜ (32->16)\n",
    "4. Conv2d(16, 32, 3, padding=1): ì±„ë„ 16->32, í¬ê¸° ìœ ì§€\n",
    "5. MaxPool2d(2,2): ê³µê°„ í¬ê¸° ì ˆë°˜ (16->8)\n",
    "6. Flatten: (1, 32, 8, 8) -> (1, 2048)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë””ë²„ê¹… ì‹œ ì¤‘ê°„ ì¶œë ¥ shape í™•ì¸ í•„ìˆ˜\n",
    "- Flatten í›„ Linear ì…ë ¥ í¬ê¸° = C * H * W\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Data Augmentation ì ìš© â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ì–‘í•œ ì¦ê°• ê¸°ë²•ì„ í¬í•¨í•˜ëŠ” transform íŒŒì´í”„ë¼ì¸ì„ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    # 1. ë¬´ì‘ìœ„ í¬ë¡­ (32x32, padding=4)\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    \n",
    "    # 2. ë¬´ì‘ìœ„ ìˆ˜í‰ ë’¤ì§‘ê¸°\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    \n",
    "    # 3. ë¬´ì‘ìœ„ íšŒì „ (ìµœëŒ€ 15ë„)\n",
    "    transforms.RandomRotation(15),\n",
    "    \n",
    "    # 4. í…ì„œ ë³€í™˜\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    # 5. ì •ê·œí™” (mean=0.5, std=0.5)\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "print(\"Data Augmentation íŒŒì´í”„ë¼ì¸:\")\n",
    "print(train_transform)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "from PIL import Image\n",
    "dummy_pil = Image.new('RGB', (32, 32), color='red')\n",
    "augmented = train_transform(dummy_pil)\n",
    "print(f\"\\nì¦ê°• í›„ shape: {augmented.shape}\")\n",
    "print(f\"ê°’ ë²”ìœ„: [{augmented.min():.4f}, {augmented.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- transforms.Composeë¡œ ì—¬ëŸ¬ ë³€í™˜ ì—°ê²°\n",
    "- ìˆœì„œ ì¤‘ìš”: ê¸°í•˜ ë³€í™˜ -> ToTensor -> ì •ê·œí™”\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- RandomCrop(32, padding=4): ë¨¼ì € 40x40ìœ¼ë¡œ íŒ¨ë”© í›„ 32x32 í¬ë¡­\n",
    "- RandomHorizontalFlip(): ê¸°ë³¸ 50% í™•ë¥ \n",
    "- RandomRotation(15): -15 ~ +15ë„ íšŒì „\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "```python\n",
    "transforms.ColorJitter(brightness=0.2)  # ë°ê¸° ë³€í™˜\n",
    "transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))  # ì´ë™\n",
    "```\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ToTensor()ëŠ” PIL Image ì…ë ¥ í•„ìš”\n",
    "- NormalizeëŠ” ToTensor ì´í›„ì— ì ìš©\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. torchvision ë°ì´í„°ì…‹ ë¡œë“œ â­â­\n",
    "\n",
    "**ë¬¸ì œ**: MNIST ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³ , ì²« ë²ˆì§¸ ì´ë¯¸ì§€ì˜ shapeì™€ ë ˆì´ë¸”ì„ ì¶œë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# MNIST ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST í†µê³„\n",
    "])\n",
    "\n",
    "mnist_dataset = torchvision.datasets.MNIST(\n",
    "    root='./datasets',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# ì²« ë²ˆì§¸ ì´ë¯¸ì§€ í™•ì¸\n",
    "image, label = mnist_dataset[0]\n",
    "\n",
    "print(f\"ë°ì´í„°ì…‹ í¬ê¸°: {len(mnist_dataset)}\")\n",
    "print(f\"ì´ë¯¸ì§€ shape: {image.shape}\")\n",
    "print(f\"ë ˆì´ë¸”: {label}\")\n",
    "print(f\"í”½ì…€ ê°’ ë²”ìœ„: [{image.min():.4f}, {image.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- torchvision.datasets ì‚¬ìš©\n",
    "- download=Trueë¡œ ìë™ ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- MNIST: 28x28 í‘ë°± ì†ê¸€ì”¨ ìˆ«ì (0-9)\n",
    "- shape: (1, 28, 28) - 1ì±„ë„, 28x28\n",
    "- 60,000ê°œ í›ˆë ¨ ì´ë¯¸ì§€, 10,000ê°œ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "**MNIST vs CIFAR-10**:\n",
    "| ë°ì´í„°ì…‹ | ì´ë¯¸ì§€ í¬ê¸° | ì±„ë„ | í´ë˜ìŠ¤ |\n",
    "|---------|-----------|------|--------|\n",
    "| MNIST | 28x28 | 1 | 10 (ìˆ«ì) |\n",
    "| CIFAR-10 | 32x32 | 3 | 10 (ê°ì²´) |\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì •ê·œí™” ê°’ì€ ë°ì´í„°ì…‹ë³„ë¡œ ë‹¤ë¦„\n",
    "- MNIST: mean=0.1307, std=0.3081\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Transfer Learning ì„¤ì • â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì‚¬ì „ í•™ìŠµëœ ResNet18ì„ 5ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ì— ì ìš©í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# 1. ì‚¬ì „ í•™ìŠµëœ ResNet18 ë¡œë“œ\n",
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# 2. ëª¨ë“  íŒŒë¼ë¯¸í„° ë™ê²°\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 3. ë§ˆì§€ë§‰ FC ë ˆì´ì–´ êµì²´ (5ê°œ í´ë˜ìŠ¤ìš©)\n",
    "num_features = model.fc.in_features  # 512\n",
    "model.fc = nn.Linear(num_features, 5)\n",
    "\n",
    "# í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° í™•ì¸\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"ì „ì²´ íŒŒë¼ë¯¸í„°: {total_params:,}\")\n",
    "print(f\"í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,}\")\n",
    "print(f\"ë™ê²°ëœ íŒŒë¼ë¯¸í„°: {total_params - trainable_params:,}\")\n",
    "print(f\"\\nìƒˆ FC ë ˆì´ì–´: {model.fc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ - í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë§Œ ì¶œë ¥\n",
    "print(\"í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"  {name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ë¡œë“œ\n",
    "2. ëª¨ë“  ë ˆì´ì–´ ë™ê²° (requires_grad=False)\n",
    "3. ë§ˆì§€ë§‰ FC ë ˆì´ì–´ë§Œ ìƒˆë¡œ ì •ì˜\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- Feature Extraction: ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ëŠ” íŠ¹ì§• ì¶”ì¶œê¸°ë¡œ ì‚¬ìš©\n",
    "- ìƒˆ FC ë ˆì´ì–´ë§Œ í•™ìŠµ\n",
    "- í•™ìŠµ íŒŒë¼ë¯¸í„°: weight(512*5) + bias(5) = 2,565ê°œ\n",
    "\n",
    "**ëŒ€ì•ˆ - ë” ë³µì¡í•œ FC**:\n",
    "```python\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256, 5)\n",
    ")\n",
    "```\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë°ì´í„°ê°€ ë§¤ìš° ì ì„ ë•Œ Feature Extraction ê¶Œì¥\n",
    "- ìƒˆ FC ë ˆì´ì–´ëŠ” ìë™ìœ¼ë¡œ requires_grad=True\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. Fine-tuning êµ¬í˜„ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ResNet18ì—ì„œ layer4ì™€ fc ë ˆì´ì–´ë§Œ í•™ìŠµ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# 1. ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ë¡œë“œ\n",
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# 2. ëª¨ë“  íŒŒë¼ë¯¸í„° ë™ê²°\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 3. layer4 ë™ê²° í•´ì œ\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 4. FC ë ˆì´ì–´ êµì²´ (ìƒˆ ë ˆì´ì–´ëŠ” ìë™ìœ¼ë¡œ requires_grad=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "# íŒŒë¼ë¯¸í„° í†µê³„\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"ì „ì²´ íŒŒë¼ë¯¸í„°: {total_params:,}\")\n",
    "print(f\"í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,}\")\n",
    "print(f\"í•™ìŠµ ë¹„ìœ¨: {trainable_params/total_params:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ê°€ëŠ¥í•œ ë ˆì´ì–´ í™•ì¸\n",
    "print(\"í•™ìŠµ ê°€ëŠ¥í•œ ë ˆì´ì–´:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"  {name}: {param.numel():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. ì „ì²´ ë™ê²°\n",
    "2. layer4 í•´ì œ\n",
    "3. FC êµì²´\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- Fine-tuning: ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ë¥¼ ì‹œì‘ì ìœ¼ë¡œ ì¬í•™ìŠµ\n",
    "- ë³´í†µ ë§ˆì§€ë§‰ ëª‡ ê°œ ë ˆì´ì–´ë§Œ í•™ìŠµ\n",
    "- ë‚®ì€ í•™ìŠµë¥  í•„ìˆ˜ (ê¸°ì¡´ ê°€ì¤‘ì¹˜ íŒŒê´´ ë°©ì§€)\n",
    "\n",
    "**ResNet18 êµ¬ì¡°**:\n",
    "```\n",
    "conv1 -> bn1 -> relu -> maxpool\n",
    "-> layer1 -> layer2 -> layer3 -> layer4\n",
    "-> avgpool -> fc\n",
    "```\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë°ì´í„°ê°€ ì–´ëŠ ì •ë„ ìˆìœ¼ë©´ Fine-tuning ì¶”ì²œ\n",
    "- í•™ìŠµë¥ : Feature Extractionë³´ë‹¤ 10ë°° ë‚®ê²Œ (1e-4 ì •ë„)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. ì»¤ìŠ¤í…€ CNN ëª¨ë¸ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì£¼ì–´ì§„ ì¡°ê±´ì˜ CNN ëª¨ë¸ì„ ì •ì˜í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Conv ë¸”ë¡ 1: (1, 28, 28) -> (32, 14, 14)\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Conv ë¸”ë¡ 2: (32, 14, 14) -> (64, 7, 7)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Conv ë¸”ë¡ 3: (64, 7, 7) -> (128, 3, 3)\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Global Average Pooling: (128, 3, 3) -> (128, 1, 1)\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # ì¶œë ¥ ë ˆì´ì–´\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° í…ŒìŠ¤íŠ¸\n",
    "model = CustomCNN(num_classes=10)\n",
    "print(model)\n",
    "\n",
    "# ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸\n",
    "dummy_input = torch.randn(4, 1, 28, 28)\n",
    "output = model(dummy_input)\n",
    "print(f\"\\nì…ë ¥: {dummy_input.shape}\")\n",
    "print(f\"ì¶œë ¥: {output.shape}\")\n",
    "print(f\"\\nì´ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- Conv Block: Conv -> BatchNorm -> ReLU -> MaxPool\n",
    "- GAPë¡œ ê³µê°„ ì°¨ì› ì œê±°\n",
    "- ë‹¨ìˆœí•œ FC ë ˆì´ì–´ë¡œ ë¶„ë¥˜\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- BatchNorm: í•™ìŠµ ì•ˆì •í™”, ë¹ ë¥¸ ìˆ˜ë ´\n",
    "- Global Average Pooling: FC íŒŒë¼ë¯¸í„° ëŒ€í­ ê°ì†Œ\n",
    "- ì±„ë„ ìˆ˜ ì¦ê°€, ê³µê°„ í¬ê¸° ê°ì†Œ íŒ¨í„´\n",
    "\n",
    "**Shape ì¶”ì **:\n",
    "- ì…ë ¥: (1, 28, 28)\n",
    "- Block1 í›„: (32, 14, 14)\n",
    "- Block2 í›„: (64, 7, 7)\n",
    "- Block3 í›„: (128, 3, 3)\n",
    "- GAP í›„: (128, 1, 1) = 128\n",
    "- FC: 128 -> 10\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- BatchNormì€ Conv ì§í›„, í™œì„±í™” í•¨ìˆ˜ ì§ì „ì— ë°°ì¹˜\n",
    "- GAP ì‚¬ìš© ì‹œ FC ì…ë ¥ í¬ê¸°ê°€ ì±„ë„ ìˆ˜ì™€ ë™ì¼\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: CIFAR-10 ë°ì´í„°ì…‹ìœ¼ë¡œ CNNì„ í•™ìŠµí•˜ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ - Part 1: ë°ì´í„° ì¤€ë¹„\n",
    "\n",
    "# 1. Data Augmentation í¬í•¨ ì „ì²˜ë¦¬\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "# 2. ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "data_path = './datasets'\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=data_path, train=True, download=True, transform=train_transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=data_path, train=False, download=True, transform=test_transform\n",
    ")\n",
    "\n",
    "# 3. DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_dataset)}, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_dataset)}\")\n",
    "print(f\"í›ˆë ¨ ë°°ì¹˜: {len(train_loader)}, í…ŒìŠ¤íŠ¸ ë°°ì¹˜: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ - Part 2: ëª¨ë¸ ì •ì˜\n",
    "\n",
    "class CIFAR10CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # Block 2\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # Block 3\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CIFAR10CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ - Part 3: í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ - Part 4: í•™ìŠµ ì‹¤í–‰ (3 ì—í¬í¬)\n",
    "\n",
    "epochs = 3\n",
    "history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"í•™ìŠµ ì‹œì‘!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(test_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}: \"\n",
    "          f\"Train Loss={train_loss:.4f}, Acc={train_acc:.2f}% | \"\n",
    "          f\"Test Loss={test_loss:.4f}, Acc={test_acc:.2f}%\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ - Part 5: í•™ìŠµ ê³¡ì„  ì‹œê°í™” (Plotly)\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df['epoch'] = range(1, epochs + 1)\n",
    "\n",
    "# ì„œë¸Œí”Œë¡¯ ìƒì„±\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=['ì†ì‹¤ (Loss)', 'ì •í™•ë„ (Accuracy)']\n",
    ")\n",
    "\n",
    "# ì†ì‹¤ ê³¡ì„ \n",
    "fig.add_trace(\n",
    "    go.Scatter(x=history_df['epoch'], y=history_df['train_loss'], \n",
    "               name='Train Loss', line=dict(color='blue')),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=history_df['epoch'], y=history_df['test_loss'], \n",
    "               name='Test Loss', line=dict(color='red', dash='dash')),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# ì •í™•ë„ ê³¡ì„ \n",
    "fig.add_trace(\n",
    "    go.Scatter(x=history_df['epoch'], y=history_df['train_acc'], \n",
    "               name='Train Acc', line=dict(color='green')),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=history_df['epoch'], y=history_df['test_acc'], \n",
    "               name='Test Acc', line=dict(color='orange', dash='dash')),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
    "fig.update_layout(\n",
    "    title='CIFAR-10 CNN í•™ìŠµ ê³¡ì„ ',\n",
    "    height=400,\n",
    "    showlegend=True\n",
    ")\n",
    "fig.update_xaxes(title_text='Epoch', row=1, col=1)\n",
    "fig.update_xaxes(title_text='Epoch', row=1, col=2)\n",
    "fig.update_yaxes(title_text='Loss', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Accuracy (%)', row=1, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬ì¡°**:\n",
    "1. **ë°ì´í„° ì¤€ë¹„**: Augmentation + ì •ê·œí™” + DataLoader\n",
    "2. **ëª¨ë¸ ì •ì˜**: Conv-BN-ReLU-Pool íŒ¨í„´\n",
    "3. **í•™ìŠµ í•¨ìˆ˜**: train/eval ëª¨ë“œ ë¶„ë¦¬\n",
    "4. **í•™ìŠµ ì‹¤í–‰**: ì—í¬í¬ ë£¨í”„\n",
    "5. **ì‹œê°í™”**: Plotlyë¡œ í•™ìŠµ ê³¡ì„ \n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- BatchNorm: ê° Conv í›„ì— ì ìš©\n",
    "- Dropout: ê³¼ì í•© ë°©ì§€ (Conv ë¸”ë¡: 0.25, FC: 0.5)\n",
    "- Adam ì˜µí‹°ë§ˆì´ì €: ìë™ í•™ìŠµë¥  ì¡°ì •\n",
    "\n",
    "**ëª¨ë¸ êµ¬ì¡°**:\n",
    "```\n",
    "ì…ë ¥ (3, 32, 32)\n",
    "-> Block1 (32, 16, 16)\n",
    "-> Block2 (64, 8, 8)  \n",
    "-> Block3 (128, 4, 4)\n",
    "-> Flatten (2048)\n",
    "-> FC (256) -> FC (10)\n",
    "```\n",
    "\n",
    "**ì¶”ê°€ ê°œì„  ë°©ë²•**:\n",
    "1. ë” ë§ì€ ì—í¬í¬ í•™ìŠµ (50-100)\n",
    "2. Learning Rate Scheduler ì¶”ê°€\n",
    "3. ë” ê°•í•œ Data Augmentation\n",
    "4. Transfer Learning (ResNet ë“±)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- 3 ì—í¬í¬ëŠ” ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©, ì‹¤ì œë¡œëŠ” 50+ ì—í¬í¬ í•„ìš”\n",
    "- Early Stoppingìœ¼ë¡œ ê³¼ì í•© ë°©ì§€\n",
    "- í•™ìŠµ ê³¡ì„ ìœ¼ë¡œ ê³¼ì í•©/ê³¼ì†Œì í•© ì§„ë‹¨\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "### CNN í•µì‹¬ ê°œë… ìš”ì•½\n",
    "\n",
    "| ê°œë… | í•µì‹¬ | ì‹¤ë¬´ íŒ |\n",
    "|-----|------|--------|\n",
    "| Conv2d | ì§€ì—­ íŠ¹ì§• ì¶”ì¶œ | padding=(k-1)/2ë¡œ í¬ê¸° ìœ ì§€ |\n",
    "| MaxPool | ë‹¤ìš´ìƒ˜í”Œë§ | 2x2, stride=2ê°€ í‘œì¤€ |\n",
    "| BatchNorm | í•™ìŠµ ì•ˆì •í™” | Conv ì§í›„ ì ìš© |\n",
    "| Dropout | ê³¼ì í•© ë°©ì§€ | Conv: 0.25, FC: 0.5 |\n",
    "| GAP | íŒŒë¼ë¯¸í„° ê°ì†Œ | FC ëŒ€ì‹  ì‚¬ìš© ê°€ëŠ¥ |\n",
    "\n",
    "### ì „ì´ í•™ìŠµ ì „ëµ\n",
    "\n",
    "| ìƒí™© | ì „ëµ | ì„¤ì • |\n",
    "|-----|------|------|\n",
    "| ë°ì´í„° ë§¤ìš° ì ìŒ | Feature Extraction | ì „ì²´ ë™ê²°, FCë§Œ í•™ìŠµ |\n",
    "| ë°ì´í„° ì ë‹¹ | Fine-tuning | ë’·ë¶€ë¶„ í•´ì œ, ë‚®ì€ LR |\n",
    "| ë°ì´í„° ì¶©ë¶„ | ì „ì²´ ì¬í•™ìŠµ | ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ë¡œ ì´ˆê¸°í™” |\n",
    "\n",
    "### ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "- [ ] Data Augmentation ì ìš© (í›ˆë ¨ ë°ì´í„°)\n",
    "- [ ] ì ì ˆí•œ ì •ê·œí™” (ë°ì´í„°ì…‹ë³„ í†µê³„)\n",
    "- [ ] BatchNorm ì‚¬ìš©\n",
    "- [ ] Dropout ì ìš©\n",
    "- [ ] í•™ìŠµ ê³¡ì„  ëª¨ë‹ˆí„°ë§\n",
    "- [ ] Early Stopping ê³ ë ¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
