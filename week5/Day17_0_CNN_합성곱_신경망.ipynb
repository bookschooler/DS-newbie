{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day17_0: CNN (í•©ì„±ê³± ì‹ ê²½ë§)\n",
    "\n",
    "## ğŸ“š í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "**Part 1: ê¸°ì´ˆ**\n",
    "1. ì´ë¯¸ì§€ ë°ì´í„°ì˜ íŠ¹ì„± ì´í•´í•˜ê¸°\n",
    "2. í•©ì„±ê³±(Convolution) ì—°ì‚° ì´í•´í•˜ê¸°\n",
    "3. Poolingê³¼ Padding ì´í•´í•˜ê¸°\n",
    "4. CNN ì•„í‚¤í…ì²˜ êµ¬ì¡° íŒŒì•…í•˜ê¸°\n",
    "5. torchvisionìœ¼ë¡œ ì´ë¯¸ì§€ ë°ì´í„° ë‹¤ë£¨ê¸°\n",
    "\n",
    "**Part 2: ì‹¬í™”**\n",
    "1. Data Augmentation ì ìš©í•˜ê¸°\n",
    "2. ìœ ëª… CNN ì•„í‚¤í…ì²˜ (LeNet, VGG, ResNet) ì†Œê°œ\n",
    "3. Transfer Learning í™œìš©í•˜ê¸°\n",
    "4. CIFAR-10 ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹¤ìŠµ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ì™œ ì´ê²ƒì„ ë°°ìš°ë‚˜ìš”?\n",
    "\n",
    "| ê°œë… | ì‹¤ë¬´ í™œìš© | ì˜ˆì‹œ |\n",
    "|------|----------|------|\n",
    "| CNN | ì´ë¯¸ì§€ ë¶„ë¥˜/íƒì§€ | ì œí’ˆ ê²°í•¨ ê²€ì‚¬, ì˜ë£Œ ì˜ìƒ ë¶„ì„ |\n",
    "| Conv Layer | íŠ¹ì§• ì¶”ì¶œ | ì—£ì§€, ì§ˆê°, íŒ¨í„´ ì¸ì‹ |\n",
    "| Pooling | ì°¨ì› ì¶•ì†Œ | ê³„ì‚° íš¨ìœ¨í™”, ìœ„ì¹˜ ë¶ˆë³€ì„± |\n",
    "| Transfer Learning | ë¹ ë¥¸ ëª¨ë¸ ê°œë°œ | ì ì€ ë°ì´í„°ë¡œ ê³ ì„±ëŠ¥ ë‹¬ì„± |\n",
    "\n",
    "**ë¶„ì„ê°€ ê´€ì **: CNNì€ ì»´í“¨í„° ë¹„ì „ì˜ ê¸°ë°˜ ê¸°ìˆ ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ ë¶„ë¥˜, ê°ì²´ íƒì§€, ì„¸ê·¸ë©˜í…Œì´ì…˜ ë“± ê±°ì˜ ëª¨ë“  ì‹œê° AI ê³¼ì œì—ì„œ CNN ë˜ëŠ” CNN ê¸°ë°˜ ì•„í‚¤í…ì²˜ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: ê¸°ì´ˆ\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 ì´ë¯¸ì§€ ë°ì´í„°ì˜ íŠ¹ì„±\n",
    "\n",
    "### ì´ë¯¸ì§€ëŠ” 3D í…ì„œ\n",
    "\n",
    "ì´ë¯¸ì§€ ë°ì´í„°ëŠ” (ì±„ë„, ë†’ì´, ë„ˆë¹„) ë˜ëŠ” (C, H, W) í˜•íƒœì˜ 3ì°¨ì› í…ì„œì…ë‹ˆë‹¤.\n",
    "\n",
    "| ì´ë¯¸ì§€ ìœ í˜• | ì±„ë„ ìˆ˜ | ì„¤ëª… |\n",
    "|------------|--------|------|\n",
    "| í‘ë°± (Grayscale) | 1 | ë°ê¸° ì •ë³´ë§Œ |\n",
    "| ì»¬ëŸ¬ (RGB) | 3 | Red, Green, Blue |\n",
    "| RGBA | 4 | RGB + íˆ¬ëª…ë„ |\n",
    "\n",
    "```\n",
    "í‘ë°± ì´ë¯¸ì§€: (1, H, W)\n",
    "ì»¬ëŸ¬ ì´ë¯¸ì§€: (3, H, W)\n",
    "ë°°ì¹˜ ë°ì´í„°: (N, C, H, W)  # N = ë°°ì¹˜ í¬ê¸°\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í‘ë°± ì´ë¯¸ì§€ shape: torch.Size([1, 1, 28, 28])\n",
      "ì»¬ëŸ¬ ì´ë¯¸ì§€ shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "í‘ë°± ì´ë¯¸ì§€ ì´ í”½ì…€ ìˆ˜: 784\n",
      "ì»¬ëŸ¬ ì´ë¯¸ì§€ ì´ í”½ì…€ ìˆ˜: 150528\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# ì´ë¯¸ì§€ í…ì„œ ì˜ˆì‹œ\n",
    "# (ë°°ì¹˜, ì±„ë„, ë†’ì´, ë„ˆë¹„)\n",
    "grayscale_image = torch.randn(1, 1, 28, 28)  # í‘ë°± 28x28\n",
    "color_image = torch.randn(1, 3, 224, 224)    # RGB 224x224\n",
    "\n",
    "print(f\"í‘ë°± ì´ë¯¸ì§€ shape: {grayscale_image.shape}\")\n",
    "print(f\"ì»¬ëŸ¬ ì´ë¯¸ì§€ shape: {color_image.shape}\")\n",
    "print(f\"\\ní‘ë°± ì´ë¯¸ì§€ ì´ í”½ì…€ ìˆ˜: {grayscale_image.numel()}\")\n",
    "print(f\"ì»¬ëŸ¬ ì´ë¯¸ì§€ ì´ í”½ì…€ ìˆ˜: {color_image.numel()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì™œ DNNìœ¼ë¡œëŠ” ì´ë¯¸ì§€ ì²˜ë¦¬ê°€ ì–´ë ¤ìš¸ê¹Œ?\n",
    "\n",
    "1. **íŒŒë¼ë¯¸í„° í­ë°œ**: 224x224x3 ì´ë¯¸ì§€ë¥¼ í¼ì¹˜ë©´ 150,528ê°œ ì…ë ¥! ì²« ì€ë‹‰ì¸µ 1000ê°œë§Œ í•´ë„ 1.5ì–µ ê°œ íŒŒë¼ë¯¸í„°\n",
    "2. **ê³µê°„ ì •ë³´ ì†ì‹¤**: ì´ë¯¸ì§€ë¥¼ 1Dë¡œ í¼ì¹˜ë©´ ì¸ì ‘ í”½ì…€ ê´€ê³„(ì—£ì§€, ì§ˆê°) ì •ë³´ê°€ ì‚¬ë¼ì§\n",
    "3. **ìœ„ì¹˜ ì˜ì¡´ì„±**: DNNì€ ê³ ì–‘ì´ê°€ ì™¼ìª½ì— ìˆë“  ì˜¤ë¥¸ìª½ì— ìˆë“  ë‹¤ë¥¸ íŒ¨í„´ìœ¼ë¡œ ì¸ì‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN ì²« ë ˆì´ì–´ íŒŒë¼ë¯¸í„°: 150,528,000 ê°œ\n",
      "ì•½ 150.5M íŒŒë¼ë¯¸í„°\n"
     ]
    }
   ],
   "source": [
    "# DNNìœ¼ë¡œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œ íŒŒë¼ë¯¸í„° ìˆ˜ ë¹„êµ\n",
    "image_size = 224 * 224 * 3  # ì»¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ 1Dë¡œ í¼ì¹œ í¬ê¸°\n",
    "hidden_neurons = 1000\n",
    "\n",
    "dnn_params = image_size * hidden_neurons  # ì²« ë²ˆì§¸ ë ˆì´ì–´ë§Œ\n",
    "print(f\"DNN ì²« ë ˆì´ì–´ íŒŒë¼ë¯¸í„°: {dnn_params:,} ê°œ\")\n",
    "print(f\"ì•½ {dnn_params / 1e6:.1f}M íŒŒë¼ë¯¸í„°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì´ë¯¸ì§€ ì •ê·œí™”\n",
    "\n",
    "ì‹ ê²½ë§ í•™ìŠµì„ ìœ„í•´ í”½ì…€ ê°’ì„ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "| ë°©ì‹ | ë²”ìœ„ | ìˆ˜ì‹ |\n",
    "|-----|------|------|\n",
    "| [0, 1] ì •ê·œí™” | 0 ~ 1 | pixel / 255 |\n",
    "| [-1, 1] ì •ê·œí™” | -1 ~ 1 | (pixel / 255 - 0.5) / 0.5 |\n",
    "| ImageNet ì •ê·œí™” | í‘œì¤€í™” | (pixel - mean) / std |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ì´ë¯¸ì§€ (0-255):\n",
      "tensor([[ 33.,  63.,  85., 122.],\n",
      "        [240., 113., 204.,  76.],\n",
      "        [ 18.,  44., 250., 168.],\n",
      "        [ 21., 255.,  99., 204.]])\n",
      "\n",
      "[0, 1] ì •ê·œí™”:\n",
      "tensor([[0.1294, 0.2471, 0.3333, 0.4784],\n",
      "        [0.9412, 0.4431, 0.8000, 0.2980],\n",
      "        [0.0706, 0.1725, 0.9804, 0.6588],\n",
      "        [0.0824, 1.0000, 0.3882, 0.8000]])\n",
      "\n",
      "[-1, 1] ì •ê·œí™”:\n",
      "tensor([[-0.7412, -0.5059, -0.3333, -0.0431],\n",
      "        [ 0.8824, -0.1137,  0.6000, -0.4039],\n",
      "        [-0.8588, -0.6549,  0.9608,  0.3176],\n",
      "        [-0.8353,  1.0000, -0.2235,  0.6000]])\n"
     ]
    }
   ],
   "source": [
    "# ì •ê·œí™” ì˜ˆì‹œ\n",
    "# 0-255 ë²”ìœ„ì˜ ì›ë³¸ ì´ë¯¸ì§€ (ì‹œë®¬ë ˆì´ì…˜)\n",
    "raw_image = torch.randint(0, 256, (3, 4, 4), dtype=torch.float32)\n",
    "print(f\"ì›ë³¸ ì´ë¯¸ì§€ (0-255):\\n{raw_image[0]}\")\n",
    "\n",
    "# [0, 1] ì •ê·œí™”\n",
    "normalized_01 = raw_image / 255.0\n",
    "print(f\"\\n[0, 1] ì •ê·œí™”:\\n{normalized_01[0]}\")\n",
    "\n",
    "# [-1, 1] ì •ê·œí™”\n",
    "normalized_11 = (raw_image / 255.0 - 0.5) / 0.5\n",
    "print(f\"\\n[-1, 1] ì •ê·œí™”:\\n{normalized_11[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 í•©ì„±ê³±(Convolution) ì—°ì‚°\n",
    "\n",
    "### í•©ì„±ê³±ì´ë€?\n",
    "\n",
    "**í•©ì„±ê³±**: ì‘ì€ í•„í„°(ì»¤ë„)ë¥¼ ì´ë¯¸ì§€ ìœ„ì—ì„œ ìŠ¬ë¼ì´ë”©í•˜ë©° ìš”ì†Œë³„ ê³±ì˜ í•©ì„ ê³„ì‚°\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FcitQ3T%2FbtsmlifnSA3%2FAAAAAAAAAAAAAAAAAAAAALywDw66YaR6woaoy-blQeVi_wt0l6BnMJ3yfPVDGh3X%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1769871599%26allow_ip%3D%26allow_referer%3D%26signature%3DG0Gb4Xc%252FkZ%252F6tTyfE03JudrjbFw%253D\">\n",
    "\n",
    "```\n",
    "ì…ë ¥ ì´ë¯¸ì§€    í•„í„°(ì»¤ë„)       íŠ¹ì§• ë§µ\n",
    "[1 2 3 4]     [1 0]          [? ? ?]\n",
    "[5 6 7 8]  *  [0 1]    =     [? ? ?]\n",
    "[9 0 1 2]                    [? ? ?]\n",
    "[3 4 5 6]\n",
    "```\n",
    "\n",
    "### í•µì‹¬ ê°œë…\n",
    "\n",
    "| ê°œë… | ì„¤ëª… | ë¹„ìœ  |\n",
    "|-----|------|------|\n",
    "| í•„í„°/ì»¤ë„ | íŠ¹ì • íŒ¨í„´ì„ ê°ì§€í•˜ëŠ” ê°€ì¤‘ì¹˜ í–‰ë ¬ | ë‹ë³´ê¸° |\n",
    "| íŠ¹ì§• ë§µ | í•„í„° ì ìš© ê²°ê³¼, íŠ¹ì§•ì˜ ìœ„ì¹˜ì™€ ê°•ë„ | ì§€ë„ |\n",
    "| ìˆ˜ìš© ì˜ì—­ | í•˜ë‚˜ì˜ ì¶œë ¥ ë‰´ëŸ°ì´ ë³´ëŠ” ì…ë ¥ ì˜ì—­ | ì‹œì•¼ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥ ì´ë¯¸ì§€:\n",
      "tensor([[1., 2., 3., 0., 1.],\n",
      "        [0., 1., 2., 3., 2.],\n",
      "        [1., 0., 1., 0., 1.],\n",
      "        [2., 1., 0., 1., 0.],\n",
      "        [0., 1., 2., 1., 1.]])\n",
      "\n",
      "ìˆ˜ì§ ì—£ì§€ í•„í„°:\n",
      "tensor([[-1.,  0.,  1.],\n",
      "        [-1.,  0.,  1.],\n",
      "        [-1.,  0.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# ê°„ë‹¨í•œ í•©ì„±ê³± ì—°ì‚° ì§ì ‘ êµ¬í˜„\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 5x5 ì…ë ¥ ì´ë¯¸ì§€ (1ì±„ë„)\n",
    "image = torch.tensor([\n",
    "    [1, 2, 3, 0, 1],\n",
    "    [0, 1, 2, 3, 2],\n",
    "    [1, 0, 1, 0, 1],\n",
    "    [2, 1, 0, 1, 0],\n",
    "    [0, 1, 2, 1, 1]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# 3x3 í•„í„° (ìˆ˜ì§ ì—£ì§€ ê²€ì¶œ)\n",
    "vertical_edge_filter = torch.tensor([\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "print(f\"ì…ë ¥ ì´ë¯¸ì§€:\\n{image}\")\n",
    "print(f\"\\nìˆ˜ì§ ì—£ì§€ í•„í„°:\\n{vertical_edge_filter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•©ì„±ê³± ê²°ê³¼ shape: torch.Size([1, 1, 3, 3])\n",
      "\n",
      "íŠ¹ì§• ë§µ:\n",
      "tensor([[ 4.,  0., -2.],\n",
      "        [ 0.,  2.,  0.],\n",
      "        [ 0.,  0., -1.]])\n"
     ]
    }
   ],
   "source": [
    "# Conv2dë¡œ í•©ì„±ê³± ìˆ˜í–‰\n",
    "# (ë°°ì¹˜, ì±„ë„, ë†’ì´, ë„ˆë¹„) í˜•íƒœë¡œ ë³€í™˜\n",
    "image_batch = image.unsqueeze(0).unsqueeze(0)  # (1, 1, 5, 5)\n",
    "filter_batch = vertical_edge_filter.unsqueeze(0).unsqueeze(0)  # (1, 1, 3, 3)\n",
    "\n",
    "# F.conv2dë¡œ ì§ì ‘ í•©ì„±ê³±\n",
    "output = F.conv2d(image_batch, filter_batch)\n",
    "print(f\"í•©ì„±ê³± ê²°ê³¼ shape: {output.shape}\")\n",
    "print(f\"\\níŠ¹ì§• ë§µ:\\n{output.squeeze()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Conv2d ì‚¬ìš©í•˜ê¸°\n",
    "\n",
    "```python\n",
    "nn.Conv2d(\n",
    "    in_channels,   # ì…ë ¥ ì±„ë„ ìˆ˜ (RGBë©´ 3)\n",
    "    out_channels,  # ì¶œë ¥ ì±„ë„ ìˆ˜ = í•„í„° ê°œìˆ˜\n",
    "    kernel_size,   # í•„í„° í¬ê¸° (3ì´ë©´ 3x3)\n",
    "    stride=1,      # í•„í„° ì´ë™ ê°„ê²©\n",
    "    padding=0      # ì…ë ¥ ê°€ì¥ìë¦¬ íŒ¨ë”©\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥ shape: torch.Size([1, 3, 32, 32])\n",
      "ì¶œë ¥ shape: torch.Size([1, 16, 30, 30])\n",
      "\n",
      "ì¶œë ¥ í¬ê¸°ê°€ 30x30ì¸ ì´ìœ : 32 - 3 + 1 = 30 (íŒ¨ë”© ì—†ì´ 3x3 ì»¤ë„)\n"
     ]
    }
   ],
   "source": [
    "# nn.Conv2d ì˜ˆì‹œ\n",
    "# ì…ë ¥: 3ì±„ë„(RGB), ì¶œë ¥: 16ê°œ íŠ¹ì§• ë§µ, 3x3 ì»¤ë„\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n",
    "\n",
    "# ë”ë¯¸ ì…ë ¥: (ë°°ì¹˜=1, ì±„ë„=3, ë†’ì´=32, ë„ˆë¹„=32)\n",
    "dummy_input = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "# í•©ì„±ê³± ìˆ˜í–‰\n",
    "output = conv(dummy_input)\n",
    "\n",
    "print(f\"ì…ë ¥ shape: {dummy_input.shape}\")\n",
    "print(f\"ì¶œë ¥ shape: {output.shape}\")\n",
    "print(f\"\\nì¶œë ¥ í¬ê¸°ê°€ 30x30ì¸ ì´ìœ : 32 - 3 + 1 = 30 (íŒ¨ë”© ì—†ì´ 3x3 ì»¤ë„)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: ë‹¤ì–‘í•œ í•„í„°ë¡œ íŠ¹ì§• ì¶”ì¶œ\n",
    "\n",
    "CNNì€ í•™ìŠµì„ í†µí•´ ìµœì ì˜ í•„í„°ë¥¼ ìë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìˆ˜ì§ ì—£ì§€ í•„í„°:\n",
      "tensor([[-1.,  0.,  1.],\n",
      "        [-1.,  0.,  1.],\n",
      "        [-1.,  0.,  1.]])\n",
      "\n",
      "ìˆ˜í‰ ì—£ì§€ í•„í„°:\n",
      "tensor([[-1., -1., -1.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1.]])\n",
      "\n",
      "Sobel X í•„í„°:\n",
      "tensor([[-1.,  0.,  1.],\n",
      "        [-2.,  0.,  2.],\n",
      "        [-1.,  0.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ì—£ì§€ ê²€ì¶œ í•„í„°\n",
    "# ìˆ˜ì§ ì—£ì§€\n",
    "vertical = torch.tensor([[-1, 0, 1],\n",
    "                         [-1, 0, 1],\n",
    "                         [-1, 0, 1]], dtype=torch.float32)\n",
    "\n",
    "# ìˆ˜í‰ ì—£ì§€\n",
    "horizontal = torch.tensor([[-1, -1, -1],\n",
    "                           [ 0,  0,  0],\n",
    "                           [ 1,  1,  1]], dtype=torch.float32)\n",
    "\n",
    "# Sobel í•„í„° (ì—£ì§€ ê°•ì¡°)\n",
    "sobel_x = torch.tensor([[-1, 0, 1],\n",
    "                        [-2, 0, 2],\n",
    "                        [-1, 0, 1]], dtype=torch.float32)\n",
    "\n",
    "print(\"ìˆ˜ì§ ì—£ì§€ í•„í„°:\")\n",
    "print(vertical)\n",
    "print(\"\\nìˆ˜í‰ ì—£ì§€ í•„í„°:\")\n",
    "print(horizontal)\n",
    "print(\"\\nSobel X í•„í„°:\")\n",
    "print(sobel_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 Paddingê³¼ Stride\n",
    "\n",
    "### Stride (ë³´í­)\n",
    "\n",
    "í•„í„°ê°€ ì´ë™í•˜ëŠ” ê°„ê²©\n",
    "\n",
    "| Stride | íš¨ê³¼ |\n",
    "|--------|------|\n",
    "| 1 | ì¶œë ¥ í¬ê¸° ìœ ì§€ì— ê°€ê¹Œì›€ |\n",
    "| 2 | ì¶œë ¥ í¬ê¸° ì•½ ì ˆë°˜ |\n",
    "| n | ì¶œë ¥ í¬ê¸° ì•½ 1/n |\n",
    "\n",
    "### Padding (íŒ¨ë”©)\n",
    "\n",
    "ì…ë ¥ ì´ë¯¸ì§€ ê°€ì¥ìë¦¬ì— ê°’(ë³´í†µ 0)ì„ ì¶”ê°€\n",
    "\n",
    "| Padding | íš¨ê³¼ |\n",
    "|---------|------|\n",
    "| 0 | ì¶œë ¥ í¬ê¸° ê°ì†Œ |\n",
    "| 'same' | ì¶œë ¥ í¬ê¸° = ì…ë ¥ í¬ê¸° |\n",
    "| (k-1)/2 | 3x3 ì»¤ë„ì´ë©´ padding=1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ë³¸ (s=1, p=0): torch.Size([1, 3, 32, 32]) -> torch.Size([1, 16, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "# Strideì™€ Padding íš¨ê³¼ ë¹„êµ\n",
    "dummy_input = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "# ê¸°ë³¸ (stride=1, padding=0)\n",
    "conv_default = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=0)\n",
    "out_default = conv_default(dummy_input)\n",
    "print(f\"ê¸°ë³¸ (s=1, p=0): {dummy_input.shape} -> {out_default.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŒ¨ë”© (s=1, p=1): torch.Size([1, 3, 32, 32]) -> torch.Size([1, 16, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# padding=1 (ì¶œë ¥ í¬ê¸° ìœ ì§€)\n",
    "conv_padded = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "out_padded = conv_padded(dummy_input)\n",
    "print(f\"íŒ¨ë”© (s=1, p=1): {dummy_input.shape} -> {out_padded.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ¤íŠ¸ë¼ì´ë“œ (s=2, p=1): torch.Size([1, 3, 32, 32]) -> torch.Size([1, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# stride=2 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
    "conv_stride = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1)\n",
    "out_stride = conv_stride(dummy_input)\n",
    "print(f\"ìŠ¤íŠ¸ë¼ì´ë“œ (s=2, p=1): {dummy_input.shape} -> {out_stride.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì¶œë ¥ í¬ê¸° ê³„ì‚° ê³µì‹\n",
    "\n",
    "```\n",
    "ì¶œë ¥ í¬ê¸° = floor((ì…ë ¥ í¬ê¸° + 2*padding - kernel_size) / stride) + 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶œë ¥ í¬ê¸° ê³„ì‚° ì˜ˆì‹œ:\n",
      "==================================================\n",
      "ì…ë ¥=32, ì»¤ë„=3x3, stride=1, padding=0 -> ì¶œë ¥=30\n",
      "ì…ë ¥=32, ì»¤ë„=3x3, stride=1, padding=1 -> ì¶œë ¥=32\n",
      "ì…ë ¥=32, ì»¤ë„=3x3, stride=2, padding=1 -> ì¶œë ¥=16\n",
      "ì…ë ¥=224, ì»¤ë„=7x7, stride=2, padding=3 -> ì¶œë ¥=112\n"
     ]
    }
   ],
   "source": [
    "def calc_output_size(input_size, kernel_size, stride=1, padding=0):\n",
    "    \"\"\"í•©ì„±ê³± ì¶œë ¥ í¬ê¸° ê³„ì‚°\"\"\"\n",
    "    return (input_size + 2 * padding - kernel_size) // stride + 1\n",
    "\n",
    "# ì˜ˆì‹œ ê³„ì‚°\n",
    "examples = [\n",
    "    (32, 3, 1, 0),   # ê¸°ë³¸\n",
    "    (32, 3, 1, 1),   # íŒ¨ë”©ìœ¼ë¡œ í¬ê¸° ìœ ì§€\n",
    "    (32, 3, 2, 1),   # ë‹¤ìš´ìƒ˜í”Œë§\n",
    "    (224, 7, 2, 3),  # ResNet ì²« ë ˆì´ì–´\n",
    "]\n",
    "\n",
    "print(\"ì¶œë ¥ í¬ê¸° ê³„ì‚° ì˜ˆì‹œ:\")\n",
    "print(\"=\"*50)\n",
    "for inp, k, s, p in examples:\n",
    "    out = calc_output_size(inp, k, s, p)\n",
    "    print(f\"ì…ë ¥={inp}, ì»¤ë„={k}x{k}, stride={s}, padding={p} -> ì¶œë ¥={out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 Pooling (í’€ë§)\n",
    "\n",
    "### Poolingì´ë€?\n",
    "\n",
    "**í’€ë§**: íŠ¹ì§• ë§µì˜ í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ë‹¤ìš´ìƒ˜í”Œë§ ì—°ì‚°\n",
    "\n",
    "| ì¢…ë¥˜ | ì—°ì‚° | íŠ¹ì§• |\n",
    "|-----|------|------|\n",
    "| Max Pooling | ì˜ì—­ ë‚´ ìµœëŒ“ê°’ | ê°€ì¥ ê°•í•œ í™œì„±í™” ë³´ì¡´ |\n",
    "| Average Pooling | ì˜ì—­ ë‚´ í‰ê·  | ë¶€ë“œëŸ¬ìš´ ë‹¤ìš´ìƒ˜í”Œë§ |\n",
    "| Global Average Pooling | ì „ì²´ í‰ê·  | FC ë ˆì´ì–´ ëŒ€ì²´ ê°€ëŠ¥ |\n",
    "\n",
    "### Poolingì˜ ì¥ì \n",
    "\n",
    "1. **ê³„ì‚°ëŸ‰ ê°ì†Œ**: íŒŒë¼ë¯¸í„° ì—†ì´ ì°¨ì› ì¶•ì†Œ\n",
    "2. **ê³¼ì í•© ë°©ì§€**: ë¶ˆí•„ìš”í•œ ì„¸ë¶€ ì •ë³´ ì œê±°\n",
    "3. **ìœ„ì¹˜ ë¶ˆë³€ì„±**: íŠ¹ì§•ì˜ ì •í™•í•œ ìœ„ì¹˜ë³´ë‹¤ ì¡´ì¬ ì—¬ë¶€ ì¤‘ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥ íŠ¹ì§• ë§µ:\n",
      "tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8.],\n",
      "        [9., 0., 1., 2.],\n",
      "        [3., 4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# Max Pooling vs Average Pooling\n",
    "feature_map = torch.tensor([\n",
    "    [[1, 2, 3, 4],\n",
    "     [5, 6, 7, 8],\n",
    "     [9, 0, 1, 2],\n",
    "     [3, 4, 5, 6]]\n",
    "], dtype=torch.float32).unsqueeze(0)  # (1, 1, 4, 4)\n",
    "\n",
    "print(f\"ì…ë ¥ íŠ¹ì§• ë§µ:\\n{feature_map.squeeze()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2x2 Max Pooling:\n",
      "tensor([[6., 8.],\n",
      "        [9., 6.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2x2 Max Pooling\n",
    "max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "max_pooled = max_pool(feature_map)\n",
    "print(f\"\\n2x2 Max Pooling:\\n{max_pooled.squeeze()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2x2 Average Pooling:\n",
      "tensor([[3.5000, 5.5000],\n",
      "        [4.0000, 3.5000]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2x2 Average Pooling\n",
    "avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "avg_pooled = avg_pool(feature_map)\n",
    "print(f\"\\n2x2 Average Pooling:\\n{avg_pooled.squeeze()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥: torch.Size([1, 16, 7, 7])\n",
      "GAP ì¶œë ¥: torch.Size([1, 16, 1, 1])\n",
      "\n",
      "ì´ë ‡ê²Œ í•˜ë©´ FC ë ˆì´ì–´ ì—†ì´ ë°”ë¡œ ë¶„ë¥˜ ê°€ëŠ¥!\n"
     ]
    }
   ],
   "source": [
    "# Global Average Pooling (GAP)\n",
    "# ê° ì±„ë„ì˜ ì „ì²´ í‰ê·  -> (N, C, H, W) -> (N, C, 1, 1)\n",
    "feature_maps = torch.randn(1, 16, 7, 7)  # 16ê°œ ì±„ë„ì˜ 7x7 íŠ¹ì§• ë§µ\n",
    "\n",
    "gap = nn.AdaptiveAvgPool2d(1)  # ì¶œë ¥ í¬ê¸°ë¥¼ 1x1ë¡œ\n",
    "gap_output = gap(feature_maps)\n",
    "\n",
    "print(f\"ì…ë ¥: {feature_maps.shape}\")\n",
    "print(f\"GAP ì¶œë ¥: {gap_output.shape}\")\n",
    "print(f\"\\nì´ë ‡ê²Œ í•˜ë©´ FC ë ˆì´ì–´ ì—†ì´ ë°”ë¡œ ë¶„ë¥˜ ê°€ëŠ¥!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 ê²½ì‚¬ í•˜ê°•ë²• (Gradient Descent)\n",
    "\n",
    "### ì§ê´€ì  ì´í•´: ì–¸ë• ë‚´ë ¤ê°€ê¸°\n",
    "\n",
    "```\n",
    "ëª©í‘œ: ì†ì‹¤ í•¨ìˆ˜ì˜ ìµœì†Ÿê°’ ì°¾ê¸°\n",
    "ë°©ë²•: í˜„ì¬ ìœ„ì¹˜ì—ì„œ ê°€ì¥ ê°€íŒŒë¥´ê²Œ ë‚´ë ¤ê°€ëŠ” ë°©í–¥ìœ¼ë¡œ ì´ë™\n",
    "\n",
    "ìƒˆ ìœ„ì¹˜ = í˜„ì¬ ìœ„ì¹˜ - í•™ìŠµë¥  * ê¸°ìš¸ê¸°\n",
    "w_new = w_old - lr * dL/dw\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.5 CNN ì•„í‚¤í…ì²˜ êµ¬ì¡°\n",
    "\n",
    "### ì „í˜•ì ì¸ CNN êµ¬ì¡°\n",
    "\n",
    "```mermaid\n",
    " graph LR\n",
    "     A[\"ì…ë ¥ ì´ë¯¸ì§€\"] \n",
    "     B1[Conv]\n",
    "     B2[ReLU]\n",
    "     B3[Pool]\n",
    "     C1[Conv]\n",
    "     C2[ReLU]\n",
    "     C3[Pool]\n",
    "     D[Flatten]\n",
    "     E1[FC]\n",
    "     E2[ReLU]\n",
    "     F[\"ì¶œë ¥ (í´ë˜ìŠ¤ë³„ ì ìˆ˜)\"]\n",
    " \n",
    "     A --> B1 --> B2 --> B3 --> C1 --> C2 --> C3 --> D --> E1 --> E2 --> F\n",
    " \n",
    "     subgraph íŠ¹ì§• ì¶”ì¶œë¶€\n",
    "         B1 --> B2 --> B3\n",
    "         B3 --> C1 --> C2 --> C3\n",
    "     end\n",
    " \n",
    "     subgraph ë¶„ë¥˜ë¶€\n",
    "         D --> E1 --> E2\n",
    "     end\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNì˜ í•µì‹¬ ì•„ì´ë””ì–´\n",
    "\n",
    "1. **ì§€ì—­ ì—°ê²°ì„±**: ê° ë‰´ëŸ°ì´ ì…ë ¥ì˜ ì¼ë¶€ë§Œ ë´„ (ìˆ˜ìš© ì˜ì—­)\n",
    "2. **íŒŒë¼ë¯¸í„° ê³µìœ **: ê°™ì€ í•„í„°ë¥¼ ì „ì²´ ì´ë¯¸ì§€ì— ì ìš©\n",
    "3. **ê³„ì¸µì  í•™ìŠµ**: ì €ìˆ˜ì¤€(ì—£ì§€) â†’ ê³ ìˆ˜ì¤€(ì–¼êµ´) íŠ¹ì§•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°„ë‹¨í•œ CNN ëª¨ë¸ ì •ì˜\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # íŠ¹ì§• ì¶”ì¶œë¶€ (Convolutional Layers)\n",
    "        self.features = nn.Sequential(\n",
    "            # Conv Block 1: (3, 32, 32) -> (32, 16, 16)\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Conv Block 2: (32, 16, 16) -> (64, 8, 8)\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Conv Block 3: (64, 8, 8) -> (128, 4, 4)\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # ë¶„ë¥˜ë¶€ (Fully Connected Layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),  # (128, 4, 4) -> 2048\n",
    "            nn.Linear(128 * 4 * 4, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° í…ŒìŠ¤íŠ¸\n",
    "model = SimpleCNN(num_classes=10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸\n",
    "dummy_input = torch.randn(4, 3, 32, 32)  # ë°°ì¹˜ 4ê°œ, RGB, 32x32\n",
    "output = model(dummy_input)\n",
    "\n",
    "print(f\"ì…ë ¥ shape: {dummy_input.shape}\")\n",
    "print(f\"ì¶œë ¥ shape: {output.shape}\")\n",
    "\n",
    "# íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.6 torchvisionìœ¼ë¡œ ì´ë¯¸ì§€ ë‹¤ë£¨ê¸°\n",
    "\n",
    "### torchvision êµ¬ì„±ìš”ì†Œ\n",
    "\n",
    "| ëª¨ë“ˆ | ì„¤ëª… |\n",
    "|-----|------|\n",
    "| `datasets` | ìœ ëª… ë°ì´í„°ì…‹ (MNIST, CIFAR, ImageNet ë“±) |\n",
    "| `transforms` | ì´ë¯¸ì§€ ì „ì²˜ë¦¬/ì¦ê°• |\n",
    "| `models` | ì‚¬ì „ í•™ìŠµ ëª¨ë¸ (ResNet, VGG ë“±) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ê¸°ë³¸ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # PIL Image -> Tensor (0-255 -> 0-1)\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # [-1, 1] ì •ê·œí™”\n",
    "])\n",
    "\n",
    "print(\"transforms.Compose íŒŒì´í”„ë¼ì¸:\")\n",
    "print(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "# ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ì„¤ì •\n",
    "data_path = './datasets'\n",
    "\n",
    "# í›ˆë ¨ ë°ì´í„°\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=data_path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_dataset)} ìƒ˜í”Œ\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_dataset)} ìƒ˜í”Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 í´ë˜ìŠ¤\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# ë°ì´í„° í™•ì¸\n",
    "image, label = train_dataset[0]\n",
    "print(f\"ì´ë¯¸ì§€ shape: {image.shape}\")\n",
    "print(f\"ë ˆì´ë¸”: {label} ({classes[label]})\")\n",
    "print(f\"í”½ì…€ ê°’ ë²”ìœ„: [{image.min():.2f}, {image.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader ìƒì„±\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0  # ë©€í‹°í”„ë¡œì„¸ì‹±\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"í›ˆë ¨ ë°°ì¹˜ ìˆ˜: {len(train_loader)}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìˆ˜: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ì´ë¯¸ì§€ ì‹œê°í™”\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ì²« ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# ì´ë¯¸ì§€ ì—­ì •ê·œí™” (ì‹œê°í™”ìš©)\n",
    "def denormalize(tensor):\n",
    "    return tensor * 0.5 + 0.5\n",
    "\n",
    "# ì²˜ìŒ 16ê°œ ì´ë¯¸ì§€ í‘œì‹œ\n",
    "fig = make_subplots(rows=2, cols=8, subplot_titles=[classes[labels[i]] for i in range(16)])\n",
    "\n",
    "for i in range(16):\n",
    "    img = denormalize(images[i]).permute(1, 2, 0).numpy()  # (C,H,W) -> (H,W,C)\n",
    "    row = i // 8 + 1\n",
    "    col = i % 8 + 1\n",
    "    fig.add_trace(go.Image(z=(img * 255).astype(np.uint8)), row=row, col=col)\n",
    "\n",
    "fig.update_layout(title='CIFAR-10 ìƒ˜í”Œ ì´ë¯¸ì§€', height=300, showlegend=False)\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: ì‹¬í™”\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 Data Augmentation (ë°ì´í„° ì¦ê°•)\n",
    "\n",
    "### ì™œ ë°ì´í„° ì¦ê°•ì´ í•„ìš”í•œê°€?\n",
    "\n",
    "1. **ë°ì´í„° ë¶€ì¡± í•´ê²°**: ì ì€ ë°ì´í„°ë¡œ ë” ë§ì€ í•™ìŠµ\n",
    "2. **ê³¼ì í•© ë°©ì§€**: ë‹¤ì–‘í•œ ë³€í˜•ì— ê°•ê±´í•œ ëª¨ë¸\n",
    "3. **ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ**: ì‹¤ì œ í™˜ê²½ì˜ ë‹¤ì–‘ì„± ë°˜ì˜\n",
    "\n",
    "### ì£¼ìš” ì¦ê°• ê¸°ë²•\n",
    "\n",
    "| ê¸°ë²• | ì„¤ëª… | transforms í•¨ìˆ˜ |\n",
    "|-----|------|-----------------|\n",
    "| ìˆ˜í‰ ë’¤ì§‘ê¸° | ì¢Œìš° ë°˜ì „ | RandomHorizontalFlip |\n",
    "| íšŒì „ | ê°ë„ íšŒì „ | RandomRotation |\n",
    "| í¬ë¡­ | ë¬´ì‘ìœ„ ìë¥´ê¸° | RandomCrop, RandomResizedCrop |\n",
    "| ìƒ‰ìƒ ë³€í™˜ | ë°ê¸°/ëŒ€ë¹„/ì±„ë„ | ColorJitter |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation íŒŒì´í”„ë¼ì¸\n",
    "train_transform = transforms.Compose([\n",
    "    # ë¬´ì‘ìœ„ ìë¥´ê¸° í›„ ë¦¬ì‚¬ì´ì¦ˆ\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    # 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # ìƒ‰ìƒ ë³€í™˜\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    # í…ì„œ ë³€í™˜\n",
    "    transforms.ToTensor(),\n",
    "    # ì •ê·œí™”\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ìš© (ì¦ê°• ì—†ìŒ)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "print(\"í›ˆë ¨ ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸:\")\n",
    "print(train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¦ê°• íš¨ê³¼ ì‹œê°í™”\n",
    "from PIL import Image\n",
    "\n",
    "# ì›ë³¸ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸° (ì¦ê°• ì „)\n",
    "simple_transform = transforms.Compose([transforms.ToTensor()])\n",
    "simple_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=data_path, train=True, download=False, transform=simple_transform\n",
    ")\n",
    "original_img, label = simple_dataset[0]\n",
    "\n",
    "# PIL Imageë¡œ ë³€í™˜ (ì¦ê°• ì ìš©ì„ ìœ„í•´)\n",
    "pil_img = transforms.ToPILImage()(original_img)\n",
    "\n",
    "# ë‹¤ì–‘í•œ ì¦ê°• ì ìš©\n",
    "augmentations = [\n",
    "    ('ì›ë³¸', transforms.ToTensor()),\n",
    "    ('ìˆ˜í‰ ë’¤ì§‘ê¸°', transforms.Compose([transforms.RandomHorizontalFlip(p=1.0), transforms.ToTensor()])),\n",
    "    ('íšŒì „', transforms.Compose([transforms.RandomRotation(30), transforms.ToTensor()])),\n",
    "    ('ìƒ‰ìƒ ë³€í™˜', transforms.Compose([transforms.ColorJitter(brightness=0.5), transforms.ToTensor()])),\n",
    "]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=4, subplot_titles=[name for name, _ in augmentations])\n",
    "\n",
    "for i, (name, aug_transform) in enumerate(augmentations):\n",
    "    aug_img = aug_transform(pil_img).permute(1, 2, 0).numpy()\n",
    "    fig.add_trace(go.Image(z=(aug_img * 255).astype(np.uint8)), row=1, col=i+1)\n",
    "\n",
    "fig.update_layout(title=f'Data Augmentation íš¨ê³¼ - {classes[label]}', height=200)\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 ìœ ëª… CNN ì•„í‚¤í…ì²˜\n",
    "\n",
    "### CNN ë°œì „ ì—­ì‚¬\n",
    "\n",
    "| ëª¨ë¸ | ë…„ë„ | íŠ¹ì§• | íŒŒë¼ë¯¸í„° |\n",
    "|-----|------|------|----------|\n",
    "| LeNet-5 | 1998 | ìµœì´ˆì˜ ì„±ê³µì  CNN | 60K |\n",
    "| AlexNet | 2012 | ë”¥ëŸ¬ë‹ ë¶€í¥ ì‹œì‘ | 60M |\n",
    "| VGG16 | 2014 | ê¹Šê³  ë‹¨ìˆœí•œ êµ¬ì¡° | 138M |\n",
    "| ResNet | 2015 | Skip Connection | 25M (ResNet-50) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5 ìŠ¤íƒ€ì¼ ëª¨ë¸ (ê°„ë‹¨í•œ êµ¬ì¡°)\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5),    # (3, 32, 32) -> (6, 28, 28)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                # (6, 14, 14)\n",
    "            nn.Conv2d(6, 16, kernel_size=5),   # (16, 10, 10)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)                 # (16, 5, 5)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "lenet = LeNet()\n",
    "print(f\"LeNet íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in lenet.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG ìŠ¤íƒ€ì¼ ë¸”ë¡ (3x3 Conv ë°˜ë³µ)\n",
    "def make_vgg_block(in_channels, out_channels, num_convs):\n",
    "    \"\"\"VGG ìŠ¤íƒ€ì¼ í•©ì„±ê³± ë¸”ë¡\"\"\"\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(2, 2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# ê°„ë‹¨í•œ VGG ìŠ¤íƒ€ì¼ ëª¨ë¸\n",
    "class MiniVGG(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            make_vgg_block(3, 64, 2),      # (64, 16, 16)\n",
    "            make_vgg_block(64, 128, 2),    # (128, 8, 8)\n",
    "            make_vgg_block(128, 256, 2),   # (256, 4, 4)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "vgg = MiniVGG()\n",
    "print(f\"MiniVGG íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in vgg.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNetì˜ í˜ì‹ : Skip Connection (ì”ì°¨ ì—°ê²°)\n",
    "\n",
    "```\n",
    "ê¸°ì¡´:  x -> [Conv -> ReLU -> Conv] -> F(x)\n",
    "ResNet: x -> [Conv -> ReLU -> Conv] + x -> F(x) + x\n",
    "```\n",
    "\n",
    "Skip Connectionì˜ ì¥ì :\n",
    "- ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œ ì™„í™”\n",
    "- ë§¤ìš° ê¹Šì€ ë„¤íŠ¸ì›Œí¬ í•™ìŠµ ê°€ëŠ¥ (100+ layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°„ë‹¨í•œ Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Skip connection (ì°¨ì›ì´ ë‹¤ë¥¼ ê²½ìš° ì¡°ì •)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)  # Skip Connection!\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "block = ResidualBlock(64, 128, stride=2)\n",
    "x = torch.randn(1, 64, 16, 16)\n",
    "out = block(x)\n",
    "print(f\"ì…ë ¥: {x.shape} -> ì¶œë ¥: {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 Transfer Learning (ì „ì´ í•™ìŠµ)\n",
    "\n",
    "### ì „ì´ í•™ìŠµì´ë€?\n",
    "\n",
    "**ì „ì´ í•™ìŠµ**: ëŒ€ê·œëª¨ ë°ì´í„°ì…‹(ImageNet)ìœ¼ë¡œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ê°€ì ¸ì™€ ìƒˆë¡œìš´ ê³¼ì œì— ì ìš©\n",
    "\n",
    "### ë‘ ê°€ì§€ ì „ëµ\n",
    "\n",
    "| ì „ëµ | ì„¤ëª… | ì–¸ì œ ì‚¬ìš©? |\n",
    "|-----|------|----------|\n",
    "| Feature Extraction | ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ ê³ ì •, ë§ˆì§€ë§‰ ë ˆì´ì–´ë§Œ í•™ìŠµ | ë°ì´í„°ê°€ ë§¤ìš° ì ì„ ë•Œ |\n",
    "| Fine-tuning | ì „ì²´ ë˜ëŠ” ì¼ë¶€ ë ˆì´ì–´ ì¬í•™ìŠµ | ë°ì´í„°ê°€ ì–´ëŠ ì •ë„ ìˆì„ ë•Œ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# ì‚¬ì „ í•™ìŠµëœ ResNet18 ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "resnet18 = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "print(\"ResNet18 ë§ˆì§€ë§‰ ë ˆì´ì–´:\")\n",
    "print(resnet18.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction: ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ ê³ ì •\n",
    "# ë§ˆì§€ë§‰ FC ë ˆì´ì–´ë§Œ ìƒˆë¡œ ì •ì˜\n",
    "\n",
    "# 1. ëª¨ë“  íŒŒë¼ë¯¸í„° ë™ê²°\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. ë§ˆì§€ë§‰ FC ë ˆì´ì–´ êµì²´ (10ê°œ í´ë˜ìŠ¤ìš©)\n",
    "num_features = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "print(f\"ìƒˆ FC ë ˆì´ì–´ ì…ë ¥ í¬ê¸°: {num_features}\")\n",
    "print(f\"í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in resnet18.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning: ì¼ë¶€ ë ˆì´ì–´ ë™ê²° í•´ì œ\n",
    "resnet18_ft = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# 1. ëª¨ë“  íŒŒë¼ë¯¸í„° ë™ê²°\n",
    "for param in resnet18_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. ë§ˆì§€ë§‰ ë ˆì´ì–´ë“¤ ë™ê²° í•´ì œ (layer4 + fc)\n",
    "for param in resnet18_ft.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 3. FC ë ˆì´ì–´ êµì²´\n",
    "resnet18_ft.fc = nn.Linear(resnet18_ft.fc.in_features, 10)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in resnet18_ft.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in resnet18_ft.parameters())\n",
    "\n",
    "print(f\"ì „ì²´ íŒŒë¼ë¯¸í„°: {total_params:,}\")\n",
    "print(f\"í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,}\")\n",
    "print(f\"í•™ìŠµ ë¹„ìœ¨: {trainable_params/total_params:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ íŒ: ImageNet ì •ê·œí™”\n",
    "\n",
    "ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ì‚¬ìš© ì‹œ ë°˜ë“œì‹œ ë™ì¼í•œ ì •ê·œí™” ì ìš©!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet ì •ê·œí™” ê°’\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# ì „ì´ í•™ìŠµìš© ì „ì²˜ë¦¬\n",
    "transfer_transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # ResNet ì…ë ¥ í¬ê¸°\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "print(\"ImageNet ì •ê·œí™” ê°’:\")\n",
    "print(f\"Mean: {imagenet_mean}\")\n",
    "print(f\"Std: {imagenet_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 CIFAR-10 ë¶„ë¥˜ ì‹¤ìŠµ\n",
    "\n",
    "### ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "1. ë°ì´í„° ì¤€ë¹„ (ì¦ê°• í¬í•¨)\n",
    "2. ëª¨ë¸ ì •ì˜\n",
    "3. í•™ìŠµ ë£¨í”„\n",
    "4. í‰ê°€ ë° ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ë°ì´í„° ì¤€ë¹„\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))  # CIFAR-10 í†µê³„\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "# ë°ì´í„°ì…‹\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=data_path, train=True, download=True, transform=train_transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=data_path, train=False, download=True, transform=test_transform\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"í›ˆë ¨ ë°°ì¹˜: {len(train_loader)}, í…ŒìŠ¤íŠ¸ ë°°ì¹˜: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ëª¨ë¸ ì •ì˜ (SimpleCNN ì‚¬ìš©)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ì‚¬ìš© device: {device}\")\n",
    "\n",
    "model = SimpleCNN(num_classes=10).to(device)\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. í•™ìŠµ í•¨ìˆ˜\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. í•™ìŠµ ì‹¤í–‰ (5 ì—í¬í¬ë§Œ - ì‹œê°„ ì ˆì•½)\n",
    "epochs = 5\n",
    "history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
    "\n",
    "print(\"í•™ìŠµ ì‹œì‘!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(test_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}: \"\n",
    "          f\"Train Loss={train_loss:.4f}, Train Acc={train_acc:.2f}%, \"\n",
    "          f\"Test Loss={test_loss:.4f}, Test Acc={test_acc:.2f}%\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n",
    "import pandas as pd\n",
    "\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df['epoch'] = range(1, epochs + 1)\n",
    "\n",
    "# ì†ì‹¤ ê³¡ì„ \n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['Loss', 'Accuracy'])\n",
    "\n",
    "fig.add_trace(go.Scatter(x=history_df['epoch'], y=history_df['train_loss'], name='Train Loss'), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=history_df['epoch'], y=history_df['test_loss'], name='Test Loss'), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=history_df['epoch'], y=history_df['train_acc'], name='Train Acc'), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=history_df['epoch'], y=history_df['test_acc'], name='Test Acc'), row=1, col=2)\n",
    "\n",
    "fig.update_layout(title='í•™ìŠµ ê³¡ì„ ', height=400)\n",
    "fig.update_xaxes(title_text='Epoch')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. í˜¼ë™ í–‰ë ¬ (Confusion Matrix)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig = px.imshow(cm, \n",
    "                labels=dict(x=\"ì˜ˆì¸¡\", y=\"ì‹¤ì œ\", color=\"ê°œìˆ˜\"),\n",
    "                x=classes, y=classes,\n",
    "                color_continuous_scale='Blues')\n",
    "fig.update_layout(title='í˜¼ë™ í–‰ë ¬ (Confusion Matrix)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. ì˜ˆì¸¡ ìƒ˜í”Œ ì‹œê°í™”\n",
    "model.eval()\n",
    "images, labels = next(iter(test_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    _, predicted = outputs.max(1)\n",
    "\n",
    "# ì²˜ìŒ 8ê°œ ìƒ˜í”Œ\n",
    "fig = make_subplots(rows=2, cols=4)\n",
    "\n",
    "for i in range(8):\n",
    "    img = images[i].cpu()\n",
    "    # ì—­ì •ê·œí™”\n",
    "    img = img * torch.tensor([0.2470, 0.2435, 0.2616]).view(3, 1, 1) + \\\n",
    "          torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    row = i // 4 + 1\n",
    "    col = i % 4 + 1\n",
    "    fig.add_trace(go.Image(z=(img * 255).astype(np.uint8)), row=row, col=col)\n",
    "    \n",
    "    label = classes[labels[i]]\n",
    "    pred = classes[predicted[i]]\n",
    "    color = 'green' if label == pred else 'red'\n",
    "    fig.add_annotation(x=0.5, y=-0.1, text=f\"{pred}\", \n",
    "                       xref=f\"x{i+1} domain\", yref=f\"y{i+1} domain\",\n",
    "                       showarrow=False, font=dict(color=color))\n",
    "\n",
    "fig.update_layout(title='ì˜ˆì¸¡ ê²°ê³¼ (ì´ˆë¡=ì •ë‹µ, ë¹¨ê°•=ì˜¤ë‹µ)', height=300)\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ ì‹¤ìŠµ í€´ì¦ˆ\n",
    "\n",
    "**ë‚œì´ë„**: â­ (ì‰¬ì›€) ~ â­â­â­â­â­ (ì–´ë ¤ì›€)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Conv2d ì¶œë ¥ í¬ê¸° ê³„ì‚° â­\n",
    "\n",
    "**ë¬¸ì œ**: 64x64 í¬ê¸°ì˜ RGB ì´ë¯¸ì§€ì— ë‹¤ìŒ Conv2dë¥¼ ì ìš©í–ˆì„ ë•Œ ì¶œë ¥ í¬ê¸°ë¥¼ ê³„ì‚°í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Max Pooling íš¨ê³¼ â­\n",
    "\n",
    "**ë¬¸ì œ**: 4x4 íŠ¹ì§• ë§µì— 2x2 Max Pooling (stride=2)ì„ ì ìš©í•œ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "feature_map = torch.tensor([[1, 3, 2, 4],\n",
    "                            [5, 6, 7, 8],\n",
    "                            [3, 2, 1, 0],\n",
    "                            [9, 8, 7, 6]], dtype=torch.float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. ì´ë¯¸ì§€ ì •ê·œí™” â­â­\n",
    "\n",
    "**ë¬¸ì œ**: 0-255 ë²”ìœ„ì˜ ì´ë¯¸ì§€ë¥¼ [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-255 ë²”ìœ„ ì´ë¯¸ì§€ (ì‹œë®¬ë ˆì´ì…˜)\n",
    "raw_image = torch.randint(0, 256, (3, 32, 32), dtype=torch.float32)\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. CNN ì•„í‚¤í…ì²˜ ë¶„ì„ â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ CNN ëª¨ë¸ì˜ ê° ë ˆì´ì–´ ì¶œë ¥ shapeë¥¼ ê³„ì‚°í•˜ì„¸ìš”.\n",
    "\n",
    "ì…ë ¥: (1, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, 3, padding=1),    # ?\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),                 # ?\n",
    "    nn.Conv2d(16, 32, 3, padding=1),   # ?\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),                 # ?\n",
    "    nn.Flatten(),                       # ?\n",
    ")\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Data Augmentation ì ìš© â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ì¦ê°• ê¸°ë²•ì„ í¬í•¨í•˜ëŠ” transform íŒŒì´í”„ë¼ì¸ì„ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "1. ë¬´ì‘ìœ„ í¬ë¡­ (32x32, padding=4)\n",
    "2. ë¬´ì‘ìœ„ ìˆ˜í‰ ë’¤ì§‘ê¸°\n",
    "3. ë¬´ì‘ìœ„ íšŒì „ (ìµœëŒ€ 15ë„)\n",
    "4. í…ì„œ ë³€í™˜\n",
    "5. ì •ê·œí™” (mean=0.5, std=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. torchvision ë°ì´í„°ì…‹ ë¡œë“œ â­â­\n",
    "\n",
    "**ë¬¸ì œ**: MNIST ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³ , ì²« ë²ˆì§¸ ì´ë¯¸ì§€ì˜ shapeì™€ ë ˆì´ë¸”ì„ ì¶œë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Transfer Learning ì„¤ì • â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì‚¬ì „ í•™ìŠµëœ ResNet18ì„ ë¶ˆëŸ¬ì™€ì„œ 5ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œì— ì ìš©í•˜ì„¸ìš”.\n",
    "\n",
    "ìš”êµ¬ì‚¬í•­:\n",
    "1. ëª¨ë“  ë ˆì´ì–´ ë™ê²°\n",
    "2. ë§ˆì§€ë§‰ FC ë ˆì´ì–´ë§Œ 5ê°œ í´ë˜ìŠ¤ìš©ìœ¼ë¡œ êµì²´\n",
    "3. í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. Fine-tuning êµ¬í˜„ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ResNet18ì—ì„œ layer4ì™€ fc ë ˆì´ì–´ë§Œ í•™ìŠµ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. ì»¤ìŠ¤í…€ CNN ëª¨ë¸ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” CNN ëª¨ë¸ì„ ì •ì˜í•˜ì„¸ìš”.\n",
    "\n",
    "- ì…ë ¥: 1ì±„ë„ (í‘ë°±), 28x28\n",
    "- Conv ë¸”ë¡ 3ê°œ (ì±„ë„: 32 -> 64 -> 128)\n",
    "- ê° ë¸”ë¡: Conv -> BatchNorm -> ReLU -> MaxPool\n",
    "- Global Average Pooling\n",
    "- ì¶œë ¥: 10ê°œ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: CIFAR-10 ë°ì´í„°ì…‹ìœ¼ë¡œ CNNì„ í•™ìŠµí•˜ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•˜ì„¸ìš”.\n",
    "\n",
    "ìš”êµ¬ì‚¬í•­:\n",
    "1. Data Augmentation ì ìš© (í›ˆë ¨ ë°ì´í„°)\n",
    "2. ì»¤ìŠ¤í…€ CNN ëª¨ë¸ ì‚¬ìš©\n",
    "3. 3 ì—í¬í¬ í•™ìŠµ\n",
    "4. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì†ì‹¤ ë° ì •í™•ë„ ê¸°ë¡\n",
    "5. Plotlyë¡œ í•™ìŠµ ê³¡ì„  ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "### Part 1: ê¸°ì´ˆ í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ê°œë… | í•µì‹¬ í•¨ìˆ˜ | ì‹¤ë¬´ í™œìš© |\n",
    "|-----|----------|----------|\n",
    "| ì´ë¯¸ì§€ í…ì„œ | (N, C, H, W) | ë°°ì¹˜ ì²˜ë¦¬ |\n",
    "| Conv2d | nn.Conv2d(in, out, kernel) | íŠ¹ì§• ì¶”ì¶œ |\n",
    "| Pooling | nn.MaxPool2d, nn.AvgPool2d | ë‹¤ìš´ìƒ˜í”Œë§ |\n",
    "| Padding/Stride | padding=1, stride=2 | ì¶œë ¥ í¬ê¸° ì¡°ì ˆ |\n",
    "| torchvision | datasets, transforms | ë°ì´í„° ì „ì²˜ë¦¬ |\n",
    "\n",
    "### Part 2: ì‹¬í™” í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ê°œë… | í•µì‹¬ ë©”ì„œë“œ | ì–¸ì œ ì‚¬ìš©? |\n",
    "|-----|-----------|----------|\n",
    "| Data Augmentation | RandomCrop, RandomHorizontalFlip | ê³¼ì í•© ë°©ì§€ |\n",
    "| LeNet/VGG/ResNet | torchvision.models | ê²€ì¦ëœ ì•„í‚¤í…ì²˜ |\n",
    "| Feature Extraction | requires_grad=False | ë°ì´í„° ì ì„ ë•Œ |\n",
    "| Fine-tuning | ì¼ë¶€ ë ˆì´ì–´ í•´ì œ | ë°ì´í„° ì¶©ë¶„í•  ë•Œ |\n",
    "\n",
    "### CNN ì„¤ê³„ í•µì‹¬ íŒ¨í„´\n",
    "\n",
    "```python\n",
    "# íŠ¹ì§• ì¶”ì¶œë¶€\n",
    "for i in range(num_blocks):\n",
    "    Conv2d -> BatchNorm -> ReLU -> MaxPool\n",
    "    (ì±„ë„ ìˆ˜ ì¦ê°€, ê³µê°„ í¬ê¸° ê°ì†Œ)\n",
    "\n",
    "# ë¶„ë¥˜ë¶€\n",
    "Flatten / GlobalAvgPool\n",
    "-> Linear -> ReLU -> Dropout -> Linear\n",
    "```\n",
    "\n",
    "### ğŸ’¡ ì‹¤ë¬´ íŒ\n",
    "\n",
    "1. **ë°ì´í„°ê°€ ì ìœ¼ë©´**: Transfer Learning í•„ìˆ˜\n",
    "2. **ê³¼ì í•© ë¬¸ì œ**: Data Augmentation + Dropout\n",
    "3. **í•™ìŠµì´ ë¶ˆì•ˆì •í•˜ë©´**: BatchNorm ì¶”ê°€\n",
    "4. **ê¸°ìš¸ê¸° ì†Œì‹¤**: Skip Connection (ResNet ìŠ¤íƒ€ì¼)\n",
    "5. **ImageNet ëª¨ë¸ ì‚¬ìš© ì‹œ**: ë°˜ë“œì‹œ ë™ì¼ ì •ê·œí™” ì ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
