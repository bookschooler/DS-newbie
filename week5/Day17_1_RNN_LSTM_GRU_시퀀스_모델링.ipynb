{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day17_1: RNN, LSTM, GRU (시퀀스 모델링)\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "**Part 1: 기초**\n",
    "1. 시퀀스 데이터의 특성 이해하기\n",
    "2. RNN(순환 신경망) 구조 이해하기\n",
    "3. 기울기 소실 문제 이해하기\n",
    "4. LSTM 게이트 메커니즘 이해하기\n",
    "5. GRU 구조 이해하기\n",
    "\n",
    "**Part 2: 심화**\n",
    "1. 양방향 RNN (Bidirectional) 이해하기\n",
    "2. 시계열 예측 실습하기 (주가 예측)\n",
    "3. 텍스트 감성 분석 실습하기 (IMDB)\n",
    "4. Plotly로 예측 결과 시각화하기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 왜 이것을 배우나요?\n",
    "\n",
    "| 개념 | 실무 활용 | 예시 |\n",
    "|------|----------|------|\n",
    "| 시퀀스 데이터 | 순서가 중요한 데이터 처리 | 주가, 텍스트, 센서 데이터 |\n",
    "| RNN | 시간적 패턴 학습 | 음성 인식, 번역 |\n",
    "| LSTM | 장기 의존성 학습 | 긴 문장 이해, 복잡한 시계열 |\n",
    "| GRU | 효율적인 시퀀스 모델링 | 실시간 예측, 모바일 배포 |\n",
    "\n",
    "**분석가 관점**: RNN 계열 모델은 시계열 예측과 자연어 처리의 핵심입니다. LSTM과 GRU는 긴 시퀀스에서도 중요한 정보를 기억할 수 있어, 주가 예측, 감성 분석, 번역 등 다양한 실무에서 활용됩니다!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: 기초\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 시퀀스 데이터란?\n",
    "\n",
    "### 시퀀스 데이터의 특징\n",
    "\n",
    "**시퀀스 데이터**: 데이터 포인트들이 특정 순서로 배열되어 있고, 이 순서가 중요한 의미를 갖는 데이터\n",
    "\n",
    "```\n",
    "시퀀스 데이터 예시:\n",
    "- 시계열: [100, 102, 105, 103, 108] (주가)\n",
    "- 텍스트: [\"오늘\", \"날씨가\", \"정말\", \"좋다\"]\n",
    "- 음성: [0.1, 0.2, 0.15, 0.3, ...] (파형)\n",
    "- 센서: [22.1, 22.3, 22.5, 23.0] (온도)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 데이터 예시: 순서가 중요!\n",
    "sentence1 = [\"고양이가\", \"쥐를\", \"쫓는다\"]\n",
    "sentence2 = [\"쥐가\", \"고양이를\", \"쫓는다\"]\n",
    "\n",
    "print(\"시퀀스 데이터에서 순서의 중요성:\")\n",
    "print(f\"문장 1: {' '.join(sentence1)} (일반적인 상황)\")\n",
    "print(f\"문장 2: {' '.join(sentence2)} (특이한 상황)\")\n",
    "print(\"\\n같은 단어지만 순서가 다르면 의미가 완전히 달라집니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기존 모델(DNN, CNN)의 한계\n",
    "\n",
    "| 모델 | 문제점 |\n",
    "|------|--------|\n",
    "| DNN | 입력을 1차원 벡터로 취급 -> 순서 정보 파괴 |\n",
    "| CNN | 공간적 특징 추출에 특화 -> 시간적 연속성 모델링 어려움 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN의 문제: 순서 정보 손실\n",
    "# \"not good\"과 \"good not\"은 DNN에게 같은 입력으로 보일 수 있음\n",
    "\n",
    "words = {\"good\": [0.8, 0.1], \"not\": [-0.5, 0.3]}  # 간단한 임베딩\n",
    "\n",
    "# DNN 스타일: 모든 단어를 concat해서 입력\n",
    "input1 = np.concatenate([words[\"not\"], words[\"good\"]])  # \"not good\"\n",
    "input2 = np.concatenate([words[\"good\"], words[\"not\"]])  # \"good not\"\n",
    "\n",
    "print(\"DNN 입력 (순서 무시):\")\n",
    "print(f\"'not good': {input1}\")\n",
    "print(f\"'good not': {input2}\")\n",
    "print(\"\\n순서가 바뀌어도 다르게 처리되지만, 순서의 '의미'를 모델이 배우기 어려움\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 RNN (Recurrent Neural Network) 구조\n",
    "\n",
    "### RNN의 핵심 아이디어: 순환 (Recurrence)\n",
    "\n",
    "```\n",
    "기존 DNN:  x -> [신경망] -> y (한 번에 처리)\n",
    "\n",
    "RNN:       x1 -> [RNN] -> h1 (+ y1)\n",
    "              ↓    ↑\n",
    "           x2 -> [RNN] -> h2 (+ y2)  (이전 상태 활용)\n",
    "              ↓    ↑\n",
    "           x3 -> [RNN] -> h3 (+ y3)\n",
    "```\n",
    "\n",
    "### Hidden State (은닉 상태)\n",
    "\n",
    "RNN의 '기억'을 담당하는 핵심 요소입니다.\n",
    "\n",
    "```\n",
    "h_t = tanh(W_hh * h_{t-1} + W_xh * x_t + b_h)\n",
    "\n",
    "- h_t: 현재 시점의 은닉 상태\n",
    "- h_{t-1}: 이전 시점의 은닉 상태\n",
    "- x_t: 현재 시점의 입력\n",
    "- W_hh, W_xh: 가중치 행렬 (모든 시점에서 공유!)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch nn.RNN 기본 사용법\n",
    "batch_size = 2\n",
    "seq_len = 5      # 시퀀스 길이 (예: 5개 단어)\n",
    "input_size = 10  # 입력 차원 (예: 임베딩 차원)\n",
    "hidden_size = 20 # 은닉 상태 차원\n",
    "\n",
    "# RNN 레이어 정의\n",
    "rnn = nn.RNN(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=1,      # RNN 층 수\n",
    "    batch_first=True   # 입력 shape: (batch, seq, feature)\n",
    ")\n",
    "\n",
    "# 더미 입력 데이터\n",
    "x = torch.randn(batch_size, seq_len, input_size)\n",
    "print(f\"입력 shape: {x.shape}\")\n",
    "print(f\"  - batch_size: {batch_size}\")\n",
    "print(f\"  - seq_len: {seq_len}\")\n",
    "print(f\"  - input_size: {input_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 순전파\n",
    "# 초기 은닉 상태 (생략 가능, 기본값 0)\n",
    "h0 = torch.zeros(1, batch_size, hidden_size)  # (num_layers, batch, hidden)\n",
    "\n",
    "# 순전파\n",
    "outputs, h_n = rnn(x, h0)\n",
    "\n",
    "print(f\"\\nRNN 출력:\")\n",
    "print(f\"  outputs shape: {outputs.shape}  # 모든 시점의 은닉 상태\")\n",
    "print(f\"  h_n shape: {h_n.shape}          # 마지막 시점의 은닉 상태\")\n",
    "print(f\"\\noutputs[:, -1, :] == h_n: {torch.allclose(outputs[:, -1, :], h_n.squeeze(0))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실무 예시: RNN 출력 활용 방식\n",
    "\n",
    "| 작업 | 사용하는 출력 | 예시 |\n",
    "|------|-------------|------|\n",
    "| 분류 (Many-to-One) | h_n (마지막 은닉) | 감성 분류 |\n",
    "| 시퀀스 생성 (Many-to-Many) | outputs (모든 은닉) | 번역, 태깅 |\n",
    "| 시계열 예측 | outputs[:, -1, :] | 다음 값 예측 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 모델 예시: 마지막 은닉 상태 -> 클래스 예측\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        outputs, h_n = self.rnn(x)\n",
    "        # h_n: (1, batch, hidden_size) -> (batch, hidden_size)\n",
    "        out = self.fc(h_n.squeeze(0))\n",
    "        return out\n",
    "\n",
    "# 모델 생성\n",
    "classifier = RNNClassifier(input_size=10, hidden_size=20, num_classes=3)\n",
    "sample_input = torch.randn(4, 5, 10)  # batch=4, seq=5, input=10\n",
    "output = classifier(sample_input)\n",
    "print(f\"분류 모델 출력 shape: {output.shape}  # (batch, num_classes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 기울기 소실 문제 (Vanishing Gradient)\n",
    "\n",
    "### 왜 발생하는가?\n",
    "\n",
    "RNN에서 역전파 시 같은 가중치 행렬이 반복적으로 곱해집니다.\n",
    "\n",
    "```\n",
    "역전파 시 그래디언트:\n",
    "dL/dW = dL/dh_T * dh_T/dh_{T-1} * ... * dh_2/dh_1 * dh_1/dW\n",
    "\n",
    "문제:\n",
    "- tanh의 미분값 범위: (0, 1]\n",
    "- 긴 시퀀스에서 미분값이 계속 곱해짐 -> 0에 수렴\n",
    "- 결과: 앞쪽 시점의 정보가 학습되지 않음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기울기 소실 시뮬레이션\n",
    "def simulate_gradient_flow(seq_len, gradient_multiplier=0.5):\n",
    "    \"\"\"시퀀스 길이에 따른 그래디언트 크기 시뮬레이션\"\"\"\n",
    "    gradients = [1.0]  # 마지막 시점의 그래디언트 = 1\n",
    "    for t in range(1, seq_len):\n",
    "        # 역전파: 이전 그래디언트 * 가중치 미분\n",
    "        gradients.append(gradients[-1] * gradient_multiplier)\n",
    "    return gradients[::-1]  # 시간 순서로 뒤집기\n",
    "\n",
    "# 다양한 시퀀스 길이\n",
    "seq_lengths = [10, 30, 50, 100]\n",
    "results = {}\n",
    "\n",
    "for seq_len in seq_lengths:\n",
    "    grads = simulate_gradient_flow(seq_len, gradient_multiplier=0.7)\n",
    "    results[f\"seq={seq_len}\"] = grads\n",
    "    print(f\"시퀀스 길이 {seq_len:3d}: 첫 시점 그래디언트 = {grads[0]:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래디언트 소실 시각화\n",
    "fig = go.Figure()\n",
    "\n",
    "for name, grads in results.items():\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(len(grads))),\n",
    "        y=grads,\n",
    "        mode='lines',\n",
    "        name=name\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='기울기 소실 문제: 시퀀스 길이에 따른 그래디언트 크기',\n",
    "    xaxis_title='시점 (Time Step)',\n",
    "    yaxis_title='그래디언트 크기',\n",
    "    yaxis_type='log',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 장기 의존성 문제 (Long-term Dependency)\n",
    "\n",
    "기울기 소실의 결과: 앞쪽의 중요한 정보가 뒤쪽으로 전달되지 않음\n",
    "\n",
    "```\n",
    "예시: \"나는 프랑스에서 태어났고, ... (많은 문장들) ..., 그래서 [?]어를 잘한다.\"\n",
    "\n",
    "- 정답: 프랑스어\n",
    "- 문제: \"프랑스\"라는 정보가 긴 시퀀스를 지나면서 소실됨\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 LSTM (Long Short-Term Memory)\n",
    "\n",
    "### LSTM의 핵심 아이디어\n",
    "\n",
    "기울기 소실 문제를 해결하기 위해 **게이트 메커니즘**과 **셀 상태(Cell State)**를 도입\n",
    "\n",
    "```\n",
    "LSTM의 3가지 게이트:\n",
    "\n",
    "1. 망각 게이트 (Forget Gate): 이전 기억 중 버릴 것 결정\n",
    "   f_t = sigmoid(W_f * [h_{t-1}, x_t] + b_f)\n",
    "\n",
    "2. 입력 게이트 (Input Gate): 새 정보 중 저장할 것 결정\n",
    "   i_t = sigmoid(W_i * [h_{t-1}, x_t] + b_i)\n",
    "   C_tilde = tanh(W_C * [h_{t-1}, x_t] + b_C)\n",
    "\n",
    "3. 출력 게이트 (Output Gate): 셀 상태 중 출력할 것 결정\n",
    "   o_t = sigmoid(W_o * [h_{t-1}, x_t] + b_o)\n",
    "   h_t = o_t * tanh(C_t)\n",
    "\n",
    "셀 상태 업데이트:\n",
    "   C_t = f_t * C_{t-1} + i_t * C_tilde\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 게이트 시각화를 위한 예시\n",
    "def visualize_gates():\n",
    "    \"\"\"LSTM 게이트 동작 시뮬레이션\"\"\"\n",
    "    # 예시 시나리오: \"나는 고양이를 좋아한다. 강아지도 좋다.\"\n",
    "    time_steps = ['나는', '고양이를', '좋아한다', '.', '강아지도', '좋다', '.']\n",
    "    \n",
    "    # 게이트 값 시뮬레이션 (실제로는 학습됨)\n",
    "    forget_gate = [0.9, 0.8, 0.7, 0.3, 0.9, 0.8, 0.3]  # 마침표에서 많이 잊음\n",
    "    input_gate = [0.9, 0.9, 0.8, 0.1, 0.9, 0.8, 0.1]   # 마침표에서 적게 저장\n",
    "    output_gate = [0.5, 0.8, 0.9, 0.2, 0.8, 0.9, 0.2]  # 동사에서 많이 출력\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Bar(name='Forget Gate', x=time_steps, y=forget_gate, marker_color='red'))\n",
    "    fig.add_trace(go.Bar(name='Input Gate', x=time_steps, y=input_gate, marker_color='green'))\n",
    "    fig.add_trace(go.Bar(name='Output Gate', x=time_steps, y=output_gate, marker_color='blue'))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='LSTM 게이트 동작 시뮬레이션',\n",
    "        xaxis_title='단어 (시점)',\n",
    "        yaxis_title='게이트 값 (0~1)',\n",
    "        barmode='group',\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "fig = visualize_gates()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch nn.LSTM 사용법\n",
    "lstm = nn.LSTM(\n",
    "    input_size=10,\n",
    "    hidden_size=20,\n",
    "    num_layers=1,\n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "# 입력\n",
    "x = torch.randn(2, 5, 10)  # batch=2, seq=5, input=10\n",
    "\n",
    "# 초기 상태: (h_0, c_0) - hidden state와 cell state\n",
    "h0 = torch.zeros(1, 2, 20)  # (num_layers, batch, hidden)\n",
    "c0 = torch.zeros(1, 2, 20)  # cell state\n",
    "\n",
    "# 순전파\n",
    "outputs, (h_n, c_n) = lstm(x, (h0, c0))\n",
    "\n",
    "print(\"LSTM 출력:\")\n",
    "print(f\"  outputs: {outputs.shape}  # 모든 시점의 hidden state\")\n",
    "print(f\"  h_n: {h_n.shape}          # 마지막 hidden state\")\n",
    "print(f\"  c_n: {c_n.shape}          # 마지막 cell state (LSTM 특유)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실무 예시: LSTM으로 긴 시퀀스 학습\n",
    "\n",
    "LSTM은 셀 상태(Cell State)라는 '고속도로'를 통해 정보가 손실 없이 흐를 수 있습니다.\n",
    "\n",
    "```\n",
    "RNN:  정보 흐름이 매 단계 tanh를 거침 -> 소실\n",
    "LSTM: 셀 상태는 덧셈/곱셈만 -> 정보 보존\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.5 GRU (Gated Recurrent Unit)\n",
    "\n",
    "### GRU: LSTM의 간소화 버전\n",
    "\n",
    "LSTM의 3개 게이트를 2개로 줄이고, 셀 상태 없이 은닉 상태만 사용\n",
    "\n",
    "```\n",
    "GRU의 2가지 게이트:\n",
    "\n",
    "1. 리셋 게이트 (Reset Gate): 이전 정보를 얼마나 무시할지\n",
    "   r_t = sigmoid(W_r * [h_{t-1}, x_t] + b_r)\n",
    "\n",
    "2. 업데이트 게이트 (Update Gate): 새 정보와 이전 정보의 비율\n",
    "   z_t = sigmoid(W_z * [h_{t-1}, x_t] + b_z)\n",
    "\n",
    "은닉 상태 업데이트:\n",
    "   h_tilde = tanh(W_h * [r_t * h_{t-1}, x_t] + b_h)\n",
    "   h_t = (1 - z_t) * h_{t-1} + z_t * h_tilde\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM vs GRU 비교표\n",
    "comparison = {\n",
    "    \"구분\": [\"게이트 수\", \"상태\", \"파라미터 수\", \"학습 속도\", \"성능\", \"적합한 상황\"],\n",
    "    \"LSTM\": [\n",
    "        \"3개 (Forget, Input, Output)\",\n",
    "        \"Hidden State + Cell State\",\n",
    "        \"많음 (4 * hidden^2)\",\n",
    "        \"느림\",\n",
    "        \"긴 시퀀스에서 약간 우위\",\n",
    "        \"복잡한 장기 의존성\"\n",
    "    ],\n",
    "    \"GRU\": [\n",
    "        \"2개 (Reset, Update)\",\n",
    "        \"Hidden State만\",\n",
    "        \"적음 (3 * hidden^2)\",\n",
    "        \"빠름\",\n",
    "        \"대부분 LSTM과 비슷\",\n",
    "        \"적은 데이터, 빠른 학습\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison)\n",
    "print(\"LSTM vs GRU 비교\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch nn.GRU 사용법\n",
    "gru = nn.GRU(\n",
    "    input_size=10,\n",
    "    hidden_size=20,\n",
    "    num_layers=1,\n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "# 입력\n",
    "x = torch.randn(2, 5, 10)\n",
    "\n",
    "# 순전파 (GRU는 hidden state만!)\n",
    "outputs, h_n = gru(x)\n",
    "\n",
    "print(\"GRU 출력:\")\n",
    "print(f\"  outputs: {outputs.shape}\")\n",
    "print(f\"  h_n: {h_n.shape}  # cell state 없음!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 수 비교\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "input_size, hidden_size = 100, 256\n",
    "\n",
    "rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "\n",
    "print(f\"파라미터 수 비교 (input={input_size}, hidden={hidden_size}):\")\n",
    "print(f\"  RNN:  {count_params(rnn):,}\")\n",
    "print(f\"  LSTM: {count_params(lstm):,} (RNN의 약 4배)\")\n",
    "print(f\"  GRU:  {count_params(gru):,}  (RNN의 약 3배)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: 심화\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 양방향 RNN (Bidirectional RNN)\n",
    "\n",
    "### 왜 양방향인가?\n",
    "\n",
    "일반 RNN은 **과거 -> 현재** 방향으로만 정보가 흐릅니다.\n",
    "하지만 텍스트에서는 **미래 정보**도 중요할 수 있습니다.\n",
    "\n",
    "```\n",
    "예시: \"나는 ___를 먹었다. 정말 달콤했다.\"\n",
    "- 빈칸을 채우려면 '달콤했다'라는 미래 정보가 필요\n",
    "- 양방향 RNN: 과거 + 미래 정보 모두 활용\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양방향 LSTM\n",
    "bi_lstm = nn.LSTM(\n",
    "    input_size=10,\n",
    "    hidden_size=20,\n",
    "    num_layers=1,\n",
    "    batch_first=True,\n",
    "    bidirectional=True  # 양방향!\n",
    ")\n",
    "\n",
    "x = torch.randn(2, 5, 10)\n",
    "outputs, (h_n, c_n) = bi_lstm(x)\n",
    "\n",
    "print(\"양방향 LSTM 출력:\")\n",
    "print(f\"  outputs: {outputs.shape}  # hidden_size * 2 = 40\")\n",
    "print(f\"  h_n: {h_n.shape}          # (num_layers * 2, batch, hidden)\")\n",
    "print(f\"\\n양방향이므로 출력 차원이 2배!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양방향 LSTM 분류 모델\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        # 양방향이므로 hidden_size * 2\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs, (h_n, c_n) = self.lstm(x)\n",
    "        # 순방향 마지막 + 역방향 마지막 concat\n",
    "        # h_n: (2, batch, hidden)\n",
    "        forward_h = h_n[0]   # 순방향\n",
    "        backward_h = h_n[1]  # 역방향\n",
    "        hidden = torch.cat([forward_h, backward_h], dim=1)\n",
    "        return self.fc(hidden)\n",
    "\n",
    "model = BiLSTMClassifier(10, 20, 3)\n",
    "output = model(torch.randn(4, 5, 10))\n",
    "print(f\"양방향 LSTM 분류 출력: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 시계열 예측 실습 (주가 예측)\n",
    "\n",
    "### 문제 정의\n",
    "\n",
    "과거 N일의 주가로 다음 날 주가를 예측하는 **Many-to-One** 모델\n",
    "\n",
    "```\n",
    "입력: [Day1, Day2, ..., Day30] (30일 주가)\n",
    "출력: [Day31] (다음 날 예측)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주가 데이터 생성 (시뮬레이션)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 트렌드 + 계절성 + 노이즈\n",
    "days = 500\n",
    "trend = np.linspace(100, 150, days)\n",
    "seasonal = 10 * np.sin(np.linspace(0, 8*np.pi, days))\n",
    "noise = np.random.randn(days) * 3\n",
    "stock_price = trend + seasonal + noise\n",
    "\n",
    "# 시각화\n",
    "fig = px.line(\n",
    "    x=range(days), y=stock_price,\n",
    "    title='시뮬레이션 주가 데이터',\n",
    "    labels={'x': '날짜', 'y': '주가'}\n",
    ")\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리: 정규화 + 시퀀스 생성\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 정규화 (0~1)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(stock_price.reshape(-1, 1))\n",
    "\n",
    "# 시퀀스 데이터 생성\n",
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"과거 seq_length일로 다음 날 예측하는 데이터셋 생성\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "SEQ_LENGTH = 30\n",
    "X, y = create_sequences(scaled_data, SEQ_LENGTH)\n",
    "\n",
    "print(f\"시퀀스 데이터:\")\n",
    "print(f\"  X shape: {X.shape}  # (샘플 수, 시퀀스 길이, 특성)\")\n",
    "print(f\"  y shape: {y.shape}  # (샘플 수, 특성)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련/테스트 분할\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# 텐서 변환\n",
    "X_train_t = torch.FloatTensor(X_train)\n",
    "y_train_t = torch.FloatTensor(y_train)\n",
    "X_test_t = torch.FloatTensor(X_test)\n",
    "y_test_t = torch.FloatTensor(y_test)\n",
    "\n",
    "print(f\"훈련 데이터: {X_train_t.shape}\")\n",
    "print(f\"테스트 데이터: {X_test_t.shape}\")\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 시계열 예측 모델\n",
    "class StockPredictor(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=50, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        # 마지막 시점의 출력 사용\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 모델 생성\n",
    "model = StockPredictor(input_size=1, hidden_size=50, num_layers=2).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "epochs = 50\n",
    "train_losses = []\n",
    "\n",
    "X_train_t = X_train_t.to(device)\n",
    "y_train_t = y_train_t.to(device)\n",
    "X_test_t = X_test_t.to(device)\n",
    "y_test_t = y_test_t.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 및 역정규화\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_pred = model(X_train_t).cpu().numpy()\n",
    "    test_pred = model(X_test_t).cpu().numpy()\n",
    "\n",
    "# 역정규화\n",
    "train_pred_inv = scaler.inverse_transform(train_pred)\n",
    "test_pred_inv = scaler.inverse_transform(test_pred)\n",
    "y_train_inv = scaler.inverse_transform(y_train_t.cpu().numpy())\n",
    "y_test_inv = scaler.inverse_transform(y_test_t.cpu().numpy())\n",
    "\n",
    "# 평가 지표\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_test_inv, test_pred_inv)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_inv, test_pred_inv))\n",
    "\n",
    "print(f\"\\n테스트 성능:\")\n",
    "print(f\"  MAE: {mae:.2f}\")\n",
    "print(f\"  RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과 시각화\n",
    "fig = go.Figure()\n",
    "\n",
    "# 전체 실제 데이터\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(len(stock_price))),\n",
    "    y=stock_price,\n",
    "    mode='lines',\n",
    "    name='실제 주가',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "# 테스트 예측\n",
    "test_idx = list(range(train_size + SEQ_LENGTH, len(stock_price)))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_idx,\n",
    "    y=test_pred_inv.flatten(),\n",
    "    mode='lines',\n",
    "    name='LSTM 예측',\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "\n",
    "# 훈련/테스트 분리선\n",
    "fig.add_vline(x=train_size + SEQ_LENGTH, line_dash='dot', line_color='green',\n",
    "              annotation_text='Train/Test 분리')\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'LSTM 주가 예측 결과 (MAE: {mae:.2f}, RMSE: {rmse:.2f})',\n",
    "    xaxis_title='날짜',\n",
    "    yaxis_title='주가',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 텍스트 감성 분석 실습 (IMDB)\n",
    "\n",
    "### 문제 정의\n",
    "\n",
    "영화 리뷰 텍스트를 보고 긍정(1) / 부정(0) 분류\n",
    "\n",
    "```\n",
    "입력: \"This movie was great!\" -> [토큰1, 토큰2, 토큰3, 토큰4]\n",
    "출력: 1 (긍정)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 감성 분류 데이터셋 (IMDB 대신 간단한 예시)\n",
    "# 실제로는 torchtext나 datasets 라이브러리 사용\n",
    "\n",
    "# 간단한 단어 사전\n",
    "vocab = {\n",
    "    '<PAD>': 0, '<UNK>': 1,\n",
    "    'this': 2, 'movie': 3, 'was': 4, 'is': 5,\n",
    "    'great': 6, 'good': 7, 'bad': 8, 'terrible': 9,\n",
    "    'amazing': 10, 'awful': 11, 'boring': 12, 'exciting': 13,\n",
    "    'the': 14, 'a': 15, 'very': 16, 'really': 17,\n",
    "    'loved': 18, 'hated': 19, 'it': 20, 'film': 21\n",
    "}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# 샘플 데이터 생성\n",
    "positive_reviews = [\n",
    "    \"this movie was great\",\n",
    "    \"the film is amazing\",\n",
    "    \"really good movie\",\n",
    "    \"loved this film\",\n",
    "    \"very exciting movie\"\n",
    "]\n",
    "\n",
    "negative_reviews = [\n",
    "    \"this movie was bad\",\n",
    "    \"the film is terrible\",\n",
    "    \"really awful movie\",\n",
    "    \"hated this film\",\n",
    "    \"very boring movie\"\n",
    "]\n",
    "\n",
    "print(f\"어휘 크기: {vocab_size}\")\n",
    "print(f\"긍정 리뷰 예시: {positive_reviews[0]}\")\n",
    "print(f\"부정 리뷰 예시: {negative_reviews[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 -> 토큰 인덱스 변환\n",
    "def text_to_indices(text, vocab, max_len=10):\n",
    "    tokens = text.lower().split()\n",
    "    indices = [vocab.get(t, vocab['<UNK>']) for t in tokens]\n",
    "    # 패딩 또는 자르기\n",
    "    if len(indices) < max_len:\n",
    "        indices = indices + [vocab['<PAD>']] * (max_len - len(indices))\n",
    "    else:\n",
    "        indices = indices[:max_len]\n",
    "    return indices\n",
    "\n",
    "# 데이터셋 준비\n",
    "max_len = 10\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for review in positive_reviews:\n",
    "    X_data.append(text_to_indices(review, vocab, max_len))\n",
    "    y_data.append(1)\n",
    "\n",
    "for review in negative_reviews:\n",
    "    X_data.append(text_to_indices(review, vocab, max_len))\n",
    "    y_data.append(0)\n",
    "\n",
    "# 데이터 증강 (간단히 복제)\n",
    "X_data = X_data * 20  # 100개로 증강\n",
    "y_data = y_data * 20\n",
    "\n",
    "X_tensor = torch.LongTensor(X_data)\n",
    "y_tensor = torch.FloatTensor(y_data).reshape(-1, 1)\n",
    "\n",
    "print(f\"데이터 shape: X={X_tensor.shape}, y={y_tensor.shape}\")\n",
    "print(f\"토큰 예시: {X_tensor[0].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 감성 분류 모델\n",
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        # 임베딩 레이어: 단어 인덱스 -> 벡터\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # 분류 레이어\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)  # 양방향\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len) - 토큰 인덱스\n",
    "        embedded = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
    "        \n",
    "        lstm_out, (h_n, c_n) = self.lstm(embedded)\n",
    "        \n",
    "        # 양방향 마지막 hidden 결합\n",
    "        hidden = torch.cat([h_n[-2], h_n[-1]], dim=1)\n",
    "        \n",
    "        out = self.fc(hidden)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "# 모델 생성\n",
    "sentiment_model = SentimentLSTM(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=32,\n",
    "    hidden_size=64,\n",
    "    num_layers=1\n",
    ").to(device)\n",
    "\n",
    "print(sentiment_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(sentiment_model.parameters(), lr=0.01)\n",
    "\n",
    "# DataLoader\n",
    "dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "epochs = 50\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    sentiment_model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = sentiment_model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    losses.append(total_loss / len(loader))\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 테스트\n",
    "def predict_sentiment(text, model, vocab):\n",
    "    model.eval()\n",
    "    indices = text_to_indices(text, vocab)\n",
    "    x = torch.LongTensor([indices]).to(device)\n",
    "    with torch.no_grad():\n",
    "        prob = model(x).item()\n",
    "    sentiment = \"긍정\" if prob > 0.5 else \"부정\"\n",
    "    return sentiment, prob\n",
    "\n",
    "# 테스트\n",
    "test_reviews = [\n",
    "    \"this movie was great\",\n",
    "    \"the film is terrible\",\n",
    "    \"really loved it\",\n",
    "    \"very bad film\"\n",
    "]\n",
    "\n",
    "print(\"감성 분석 결과:\")\n",
    "print(\"=\"*50)\n",
    "for review in test_reviews:\n",
    "    sentiment, prob = predict_sentiment(review, sentiment_model, vocab)\n",
    "    print(f\"'{review}'\")\n",
    "    print(f\"  -> {sentiment} (확률: {prob:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 Plotly로 예측 결과 시각화\n",
    "\n",
    "### 학습 곡선 및 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주가 예측 학습 곡선\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['주가 예측 LSTM', '감성 분류 LSTM'])\n",
    "\n",
    "# 주가 예측 손실\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=train_losses, mode='lines', name='주가 예측 Loss'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 감성 분류 손실\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=losses, mode='lines', name='감성 분류 Loss'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='Epoch')\n",
    "fig.update_yaxes(title_text='Loss')\n",
    "fig.update_layout(title='LSTM 학습 곡선', height=400, template='plotly_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN vs LSTM vs GRU 비교 (간단한 시퀀스 문제)\n",
    "def train_and_compare(model_type, X_train, y_train, epochs=30):\n",
    "    \"\"\"다양한 시퀀스 모델 훈련 및 비교\"\"\"\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    if model_type == 'RNN':\n",
    "        rnn_layer = nn.RNN(1, 32, batch_first=True)\n",
    "    elif model_type == 'LSTM':\n",
    "        rnn_layer = nn.LSTM(1, 32, batch_first=True)\n",
    "    else:  # GRU\n",
    "        rnn_layer = nn.GRU(1, 32, batch_first=True)\n",
    "    \n",
    "    model = nn.Sequential(\n",
    "        rnn_layer,\n",
    "    )\n",
    "    \n",
    "    fc = nn.Linear(32, 1)\n",
    "    optimizer = optim.Adam(list(model.parameters()) + list(fc.parameters()), lr=0.01)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        if model_type == 'LSTM':\n",
    "            out, (h, c) = model(X_train)\n",
    "        else:\n",
    "            out, h = model(X_train)\n",
    "        \n",
    "        pred = fc(out[:, -1, :])\n",
    "        loss = criterion(pred, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# 비교\n",
    "rnn_losses = train_and_compare('RNN', X_train_t.cpu()[:100], y_train_t.cpu()[:100])\n",
    "lstm_losses = train_and_compare('LSTM', X_train_t.cpu()[:100], y_train_t.cpu()[:100])\n",
    "gru_losses = train_and_compare('GRU', X_train_t.cpu()[:100], y_train_t.cpu()[:100])\n",
    "\n",
    "# 시각화\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=rnn_losses, mode='lines', name='RNN'))\n",
    "fig.add_trace(go.Scatter(y=lstm_losses, mode='lines', name='LSTM'))\n",
    "fig.add_trace(go.Scatter(y=gru_losses, mode='lines', name='GRU'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='RNN vs LSTM vs GRU 학습 곡선 비교',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Loss',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 퀴즈\n",
    "\n",
    "**난이도**: (쉬움) ~ (어려움)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. RNN 출력 shape 계산하기\n",
    "\n",
    "**문제**: 다음 RNN의 출력 shape을 계산하세요.\n",
    "\n",
    "```python\n",
    "rnn = nn.RNN(input_size=50, hidden_size=100, num_layers=2, batch_first=True)\n",
    "x = torch.randn(16, 20, 50)  # batch=16, seq=20, input=50\n",
    "outputs, h_n = rnn(x)\n",
    "```\n",
    "\n",
    "outputs와 h_n의 shape은?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Hidden State 이해하기\n",
    "\n",
    "**문제**: RNN의 마지막 시점 출력(outputs[:, -1, :])과 h_n이 같은지 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. 시퀀스 데이터 특성\n",
    "\n",
    "**문제**: 다음 중 시퀀스 데이터가 아닌 것을 고르고 이유를 설명하세요.\n",
    "\n",
    "1. 일별 주가\n",
    "2. 영화 리뷰 텍스트\n",
    "3. 학생들의 키와 몸무게\n",
    "4. 음성 파형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답과 이유를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. LSTM 게이트 이해하기\n",
    "\n",
    "**문제**: LSTM의 3가지 게이트(Forget, Input, Output)의 역할을 각각 한 문장으로 설명하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답을 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. GRU와 LSTM 차이\n",
    "\n",
    "**문제**: GRU가 LSTM보다 파라미터 수가 적은 이유를 설명하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답을 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. 양방향 RNN\n",
    "\n",
    "**문제**: 양방향 LSTM을 정의하고, 출력 shape을 확인하세요.\n",
    "\n",
    "- input_size=30, hidden_size=64, num_layers=1\n",
    "- 입력: batch=8, seq=15, input=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. 시계열 데이터 전처리\n",
    "\n",
    "**문제**: 아래 주가 데이터로 시퀀스 길이 5인 학습 데이터를 생성하세요.\n",
    "\n",
    "```python\n",
    "prices = [100, 102, 105, 103, 108, 110, 107, 112, 115, 113]\n",
    "```\n",
    "\n",
    "힌트: 5일 데이터로 다음 날 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "prices = [100, 102, 105, 103, 108, 110, 107, 112, 115, 113]\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. 임베딩 레이어 이해\n",
    "\n",
    "**문제**: 어휘 크기 1000, 임베딩 차원 64인 Embedding 레이어를 생성하고, 배치 크기 4, 시퀀스 길이 10인 입력의 출력 shape을 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. 주가 예측 LSTM 구현\n",
    "\n",
    "**문제**: 아래 사인파 데이터로 다음 값을 예측하는 LSTM 모델을 구현하고 학습하세요.\n",
    "\n",
    "요구사항:\n",
    "1. 시퀀스 길이: 20\n",
    "2. LSTM hidden_size: 32\n",
    "3. 30 에포크 학습\n",
    "4. 예측 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# 사인파 데이터\n",
    "x = np.linspace(0, 20*np.pi, 500)\n",
    "y = np.sin(x)\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. 감성 분석 모델 개선\n",
    "\n",
    "**문제**: 본문의 SentimentLSTM 모델을 개선하세요.\n",
    "\n",
    "요구사항:\n",
    "1. GRU로 변경\n",
    "2. Dropout 추가 (0.3)\n",
    "3. 2층 구조로 변경\n",
    "4. 학습 후 테스트 리뷰에 대한 예측 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 학습 정리\n",
    "\n",
    "### Part 1: 기초 핵심 요약\n",
    "\n",
    "| 개념 | 핵심 내용 | 실무 활용 |\n",
    "|-----|----------|----------|\n",
    "| 시퀀스 데이터 | 순서가 중요한 데이터 | 시계열, 텍스트, 음성 |\n",
    "| RNN | h_t = f(h_{t-1}, x_t) | 순차 패턴 학습 |\n",
    "| 기울기 소실 | 긴 시퀀스에서 학습 어려움 | LSTM/GRU로 해결 |\n",
    "| LSTM | 3개 게이트 + Cell State | 장기 의존성 학습 |\n",
    "| GRU | 2개 게이트 (간소화) | 빠른 학습, 적은 데이터 |\n",
    "\n",
    "### Part 2: 심화 핵심 요약\n",
    "\n",
    "| 개념 | 핵심 내용 | 언제 사용? |\n",
    "|-----|----------|----------|\n",
    "| 양방향 RNN | 과거 + 미래 정보 활용 | 텍스트 분류, NER |\n",
    "| 시계열 예측 | Many-to-One | 주가, 날씨 예측 |\n",
    "| 감성 분석 | Embedding + LSTM | 리뷰 분류 |\n",
    "| 시각화 | Plotly | 예측 vs 실제 비교 |\n",
    "\n",
    "### RNN 계열 모델 선택 가이드\n",
    "\n",
    "```\n",
    "1. 기본 시작: GRU (빠르고 간단)\n",
    "2. 성능 부족 시: LSTM으로 전환\n",
    "3. 텍스트 분류: Bidirectional 추가\n",
    "4. 시계열 예측: 단방향으로 충분\n",
    "```\n",
    "\n",
    "### 실무 팁\n",
    "\n",
    "1. **데이터 정규화**: 시계열 데이터는 반드시 정규화 (MinMaxScaler 또는 StandardScaler)\n",
    "2. **시퀀스 길이**: 너무 길면 학습 어려움, 도메인에 맞게 설정\n",
    "3. **Dropout**: 과적합 방지, 0.2~0.5 사이\n",
    "4. **Gradient Clipping**: 기울기 폭발 방지 (torch.nn.utils.clip_grad_norm_)\n",
    "5. **Early Stopping**: 검증 손실 기반 조기 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
