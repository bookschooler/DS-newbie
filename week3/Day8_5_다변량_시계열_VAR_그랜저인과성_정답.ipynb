{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day8_5: ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë¶„ì„ (VAR + ê·¸ëœì € ì¸ê³¼ì„±) - ì •ë‹µ\n",
    "\n",
    "---\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ Day8_5 ì‹¤ìŠµ í€´ì¦ˆì˜ ì •ë‹µê³¼ ìƒì„¸ í’€ì´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ì‹œê³„ì—´ ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller, grangercausalitytests\n",
    "\n",
    "# ê²½ê³  ìˆ¨ê¸°ê¸°\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ìŠµì— ì‚¬ìš©í•  ë°ì´í„° ìƒì„±\n",
    "np.random.seed(42)\n",
    "\n",
    "# ë‚ ì§œ ì¸ë±ìŠ¤ ìƒì„±\n",
    "dates = pd.date_range(start='2010-01-01', periods=150, freq='MS')\n",
    "\n",
    "# Money: ì¶”ì„¸ + ëœë¤\n",
    "money_trend = np.linspace(1000, 2500, 150)\n",
    "money = money_trend + np.cumsum(np.random.randn(150) * 30)\n",
    "\n",
    "# Spending: Moneyì— ì§€ì—° ë°˜ì‘ + ìì²´ íŠ¸ë Œë“œ\n",
    "spending_trend = np.linspace(800, 1800, 150)\n",
    "spending = spending_trend + 0.3 * np.roll(money, 3) + np.cumsum(np.random.randn(150) * 20)\n",
    "\n",
    "# DataFrame ìƒì„±\n",
    "df_econ = pd.DataFrame({\n",
    "    'Money': money,\n",
    "    'Spending': spending\n",
    "}, index=dates)\n",
    "\n",
    "# ì°¨ë¶„ ë°ì´í„°\n",
    "df_diff = df_econ.diff().dropna()\n",
    "\n",
    "print(\"ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(f\"ì›ë³¸ ë°ì´í„°: {len(df_econ)}ê°œ\")\n",
    "print(f\"ì°¨ë¶„ ë°ì´í„°: {len(df_diff)}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## í€´ì¦ˆ 1 â­ - ì •ë‹µ\n",
    "\n",
    "**ë¬¸ì œ**: ìƒê´€ê´€ê³„ì™€ ì¸ê³¼ê´€ê³„ì˜ ì°¨ì´ì ì„ ì„¤ëª…í•˜ê³ , ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •ì˜ ê·€ë¬´ê°€ì„¤ì„ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 1 ì •ë‹µ\n",
    "\n",
    "# ìƒê´€ê´€ê³„: ë‘ ë³€ìˆ˜ê°€ í•¨ê»˜ \"ì›€ì§ì´\"ëŠ” ê²ƒ\n",
    "# ì¸ê³¼ê´€ê³„: í•œ ë³€ìˆ˜ê°€ ë‹¤ë¥¸ ë³€ìˆ˜ì— \"ì˜í–¥\"ì„ ì£¼ëŠ” ê²ƒ\n",
    "\n",
    "# ê·¸ëœì € ì¸ê³¼ì„± ê·€ë¬´ê°€ì„¤ (H0):\n",
    "# \"Xê°€ Yë¥¼ ê·¸ëœì €-'ì›ì¸'í•˜ì§€ ì•ŠëŠ”ë‹¤\"\n",
    "# = \"Xì˜ ê³¼ê±°ê°’ì´ Y ì˜ˆì¸¡ì— 'ë„ì›€'ì´ ì•ˆ ëœë‹¤\"\n",
    "\n",
    "# ì •ë‹µ ì¶œë ¥\n",
    "print(\"=\" * 60)\n",
    "print(\"ìƒê´€ê´€ê³„ vs ì¸ê³¼ê´€ê³„\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"1. ìƒê´€ê´€ê³„ (Correlation):\")\n",
    "print(\"   - ë‘ ë³€ìˆ˜ê°€ í•¨ê»˜ 'ì›€ì§ì´ëŠ”' ê²ƒ\")\n",
    "print(\"   - ì˜ˆ: ì•„ì´ìŠ¤í¬ë¦¼ íŒë§¤ëŸ‰ â†” ìµì‚¬ ì‚¬ê³  (ì—¬ë¦„ì´ë¼ëŠ” ìˆ¨ì€ ë³€ìˆ˜)\")\n",
    "print(\"   - Xê°€ ì¦ê°€í•  ë•Œ Yë„ ì¦ê°€/ê°ì†Œí•˜ëŠ” 'íŒ¨í„´'\")\n",
    "print()\n",
    "print(\"2. ì¸ê³¼ê´€ê³„ (Causality):\")\n",
    "print(\"   - í•œ ë³€ìˆ˜ê°€ ë‹¤ë¥¸ ë³€ìˆ˜ì— 'ì˜í–¥'ì„ ì£¼ëŠ” ê²ƒ\")\n",
    "print(\"   - ì˜ˆ: ê´‘ê³ ë¹„ â†’ ë§¤ì¶œ (ê´‘ê³ ê°€ ë§¤ì¶œì„ ì¼ìœ¼í‚´)\")\n",
    "print(\"   - Xì˜ ë³€í™”ê°€ Yì˜ ë³€í™”ë¥¼ 'ì•¼ê¸°'í•¨\")\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"ê·¸ëœì € ì¸ê³¼ì„± ê·€ë¬´ê°€ì„¤ (H0)\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"ê·€ë¬´ê°€ì„¤ H0: 'Xê°€ Yë¥¼ ê·¸ëœì €-ì›ì¸í•˜ì§€ ì•ŠëŠ”ë‹¤'\")\n",
    "print(\"           = 'Xì˜ ê³¼ê±°ê°’ì´ Y ì˜ˆì¸¡ì— ë„ì›€ì´ ì•ˆ ëœë‹¤'\")\n",
    "print()\n",
    "print(\"ëŒ€ë¦½ê°€ì„¤ H1: 'Xê°€ Yë¥¼ ê·¸ëœì €-ì›ì¸í•œë‹¤'\")\n",
    "print(\"           = 'Xì˜ ê³¼ê±°ê°’ì´ Y ì˜ˆì¸¡ì— ìœ ì˜ë¯¸í•œ ì •ë³´ë¥¼ ì œê³µí•œë‹¤'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸: ê°œë… ì •ë¦¬ í™•ì¸\n",
    "correlation_definition = \"ë‘ ë³€ìˆ˜ê°€ í•¨ê»˜ ì›€ì§ì´ëŠ” ê²ƒ\"\n",
    "causality_definition = \"í•œ ë³€ìˆ˜ê°€ ë‹¤ë¥¸ ë³€ìˆ˜ì— ì˜í–¥ì„ ì£¼ëŠ” ê²ƒ\"\n",
    "h0_granger = \"Xì˜ ê³¼ê±°ê°’ì´ Y ì˜ˆì¸¡ì— ë„ì›€ì´ ì•ˆ ëœë‹¤\"\n",
    "\n",
    "assert \"ì›€ì§\" in correlation_definition, \"ìƒê´€ê´€ê³„ëŠ” í•¨ê»˜ ì›€ì§ì´ëŠ” ê²ƒ\"\n",
    "assert \"ì˜í–¥\" in causality_definition, \"ì¸ê³¼ê´€ê³„ëŠ” ì˜í–¥ì„ ì£¼ëŠ” ê²ƒ\"\n",
    "assert \"ì˜ˆì¸¡\" in h0_granger and \"ë„ì›€\" in h0_granger, \"ê·€ë¬´ê°€ì„¤ í™•ì¸\"\n",
    "\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- ìƒê´€ê´€ê³„ëŠ” \"íŒ¨í„´\"ì´ê³  ì¸ê³¼ê´€ê³„ëŠ” \"ë©”ì»¤ë‹ˆì¦˜\"ì…ë‹ˆë‹¤\n",
    "- ê·¸ëœì € ê²€ì •ì€ \"ì˜ˆì¸¡ ì¸ê³¼ì„±\"ì„ ê²€ì •í•©ë‹ˆë‹¤ (ì§„ì§œ ì¸ê³¼ê´€ê³„ëŠ” ì•„ë‹˜)\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "1. ìƒê´€ê´€ê³„: í†µê³„ì  ì—°ê´€ì„± (í•¨ê»˜ ì›€ì§ì„)\n",
    "2. ì¸ê³¼ê´€ê³„: ì›ì¸-ê²°ê³¼ ê´€ê³„ (ì˜í–¥ì„ ë¯¸ì¹¨)\n",
    "3. ê·¸ëœì € ì¸ê³¼ì„±: ì‹œê°„ì  ì„ í–‰ê´€ê³„ ê¸°ë°˜ ì˜ˆì¸¡ë ¥ ê²€ì •\n",
    "\n",
    "**ì£¼ì˜ì‚¬í•­**:\n",
    "- \"correlation does not imply causation\" - ìƒê´€ê´€ê³„ê°€ ì¸ê³¼ê´€ê³„ë¥¼ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ\n",
    "- ê·¸ëœì € ì¸ê³¼ì„±ë„ ì—„ë°€í•œ ì¸ê³¼ê´€ê³„ëŠ” ì•„ë‹˜ (ìˆ¨ì€ ë³€ìˆ˜ ê°€ëŠ¥)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## í€´ì¦ˆ 2 â­ - ì •ë‹µ\n",
    "\n",
    "**ë¬¸ì œ**: ê·¸ëœì € ì¸ê³¼ì„± ê²€ì • ê²°ê³¼ p-valueê°€ 0.03ì´ ë‚˜ì™”ìŠµë‹ˆë‹¤. ì´ ê²°ê³¼ë¥¼ ì–´ë–»ê²Œ í•´ì„í•´ì•¼ í•˜ë‚˜ìš”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 2 ì •ë‹µ\n",
    "\n",
    "# p-value = 0.03 í•´ì„\n",
    "p_value = 0.03\n",
    "alpha = 0.05  # ìœ ì˜ìˆ˜ì¤€\n",
    "\n",
    "if p_value < alpha:  # p_valueê°€ alphaë³´ë‹¤ \"ì‘ìœ¼ë©´\"\n",
    "    result = \"ê·€ë¬´ê°€ì„¤ ê¸°ê°\"  # ê·€ë¬´ê°€ì„¤ì„ \"ê¸°ê°\"í•œë‹¤\n",
    "    interpretation = \"Xê°€ Yë¥¼ ê·¸ëœì €-ì›ì¸í•œë‹¤\"  # \"ì›ì¸í•œë‹¤\"\n",
    "else:\n",
    "    result = \"ê·€ë¬´ê°€ì„¤ ì±„íƒ\"  # ê·€ë¬´ê°€ì„¤ì„ \"ì±„íƒ\"í•œë‹¤\n",
    "    interpretation = \"ì¸ê³¼ê´€ê³„ ì—†ìŒ\"  # \"ì—†ìŒ\"\n",
    "\n",
    "print(f\"p-value: {p_value}\")\n",
    "print(f\"ìœ ì˜ìˆ˜ì¤€(alpha): {alpha}\")\n",
    "print(f\"ë¹„êµ: {p_value} < {alpha} = {p_value < alpha}\")\n",
    "print()\n",
    "print(f\"ê²°ê³¼: {result}\")\n",
    "print(f\"í•´ì„: {interpretation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸: ë‹¤ì–‘í•œ p-valueì— ëŒ€í•œ í•´ì„ í•¨ìˆ˜\n",
    "def interpret_granger_pvalue(p_value, alpha=0.05):\n",
    "    \"\"\"ê·¸ëœì € ê²€ì • p-value í•´ì„\"\"\"\n",
    "    if p_value < alpha:\n",
    "        return \"ê·€ë¬´ê°€ì„¤ ê¸°ê° - Xê°€ Yë¥¼ ê·¸ëœì €-ì›ì¸í•¨\"\n",
    "    else:\n",
    "        return \"ê·€ë¬´ê°€ì„¤ ì±„íƒ - ì¸ê³¼ê´€ê³„ ì—†ìŒ\"\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤\n",
    "test_cases = [0.01, 0.03, 0.05, 0.10, 0.50]\n",
    "\n",
    "print(\"=== p-valueë³„ í•´ì„ ===\\n\")\n",
    "for p in test_cases:\n",
    "    print(f\"p-value = {p:.2f}: {interpret_granger_pvalue(p)}\")\n",
    "\n",
    "# ì •ë‹µ ê²€ì¦\n",
    "assert \"ê¸°ê°\" in interpret_granger_pvalue(0.03), \"p=0.03ì€ ê·€ë¬´ê°€ì„¤ ê¸°ê°\"\n",
    "assert \"ì±„íƒ\" in interpret_granger_pvalue(0.10), \"p=0.10ì€ ê·€ë¬´ê°€ì„¤ ì±„íƒ\"\n",
    "print(\"\\ní…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- p-valueì™€ ìœ ì˜ìˆ˜ì¤€(alpha) ë¹„êµ\n",
    "- p < alphaì´ë©´ ê·€ë¬´ê°€ì„¤ ê¸°ê°\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "| p-value | ë¹„êµ | ê²°ê³¼ | í•´ì„ |\n",
    "|---------|------|------|------|\n",
    "| 0.03 | 0.03 < 0.05 | ê·€ë¬´ê°€ì„¤ ê¸°ê° | ì¸ê³¼ê´€ê³„ ìˆìŒ |\n",
    "| 0.10 | 0.10 > 0.05 | ê·€ë¬´ê°€ì„¤ ì±„íƒ | ì¸ê³¼ê´€ê³„ ì—†ìŒ |\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì—¬ëŸ¬ ì‹œì°¨(lag)ì—ì„œ ê²€ì •í•˜ì—¬ ì¼ê´€ëœ ê²°ê³¼ í™•ì¸\n",
    "- ìœ ì˜ìˆ˜ì¤€ì€ ë³´í†µ 0.05 ë˜ëŠ” 0.01 ì‚¬ìš©\n",
    "- ì–‘ë°©í–¥ ê²€ì •ìœ¼ë¡œ í”¼ë“œë°± ê´€ê³„ë„ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## í€´ì¦ˆ 3 â­â­ - ì •ë‹µ\n",
    "\n",
    "**ë¬¸ì œ**: statsmodelsì˜ grangercausalitytests í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •ì„ ìˆ˜í–‰í•˜ì„¸ìš”.\n",
    "\n",
    "ì£¼ì˜: í•¨ìˆ˜ ì…ë ¥ ìˆœì„œëŠ” [Y, X]ì…ë‹ˆë‹¤ (Yë¥¼ ì˜ˆì¸¡í•  ë•Œ Xê°€ ë„ì›€ì´ ë˜ëŠ”ì§€ ê²€ì •)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 3 ì •ë‹µ\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# \"Moneyê°€ Spendingì„ ê·¸ëœì €-ì›ì¸í•˜ëŠ”ê°€?\" ê²€ì •\n",
    "# => Spendingì„ ì˜ˆì¸¡í•  ë•Œ Moneyê°€ ë„ì›€ì´ ë˜ëŠ”ê°€?\n",
    "\n",
    "# í•µì‹¬: grangercausalitytests ì…ë ¥ ìˆœì„œëŠ” [ê²°ê³¼ë³€ìˆ˜(Y), ì›ì¸ë³€ìˆ˜(X)]\n",
    "# \"Xê°€ Yë¥¼ ì›ì¸í•˜ëŠ”ê°€?\" ê²€ì • ì‹œ [Y, X] ìˆœì„œë¡œ ì…ë ¥\n",
    "\n",
    "test_data = df_diff[['Spending', 'Money']]  # [ê²°ê³¼ë³€ìˆ˜, ì›ì¸ë³€ìˆ˜] ìˆœì„œ!\n",
    "\n",
    "# ê²€ì • ìˆ˜í–‰ (maxlag=5)\n",
    "print(\"=== Money â†’ Spending ê·¸ëœì € ì¸ê³¼ì„± ê²€ì • ===\")\n",
    "print(\"(Spendingì„ ì˜ˆì¸¡í•  ë•Œ Moneyê°€ ë„ì›€ì´ ë˜ëŠ”ì§€ ê²€ì •)\\n\")\n",
    "\n",
    "results = grangercausalitytests(test_data, maxlag=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸: ê²°ê³¼ ì •ë¦¬\n",
    "print(\"\\n=== p-value ìš”ì•½ ===\")\n",
    "for lag in range(1, 6):\n",
    "    p_val = results[lag][0]['ssr_ftest'][1]\n",
    "    sig = \"***\" if p_val < 0.01 else \"**\" if p_val < 0.05 else \"*\" if p_val < 0.1 else \"\"\n",
    "    print(f\"Lag {lag}: p-value = {p_val:.4f} {sig}\")\n",
    "\n",
    "# ê²€ì¦: resultsê°€ dictì´ê³  lagë³„ ê²°ê³¼ê°€ ìˆì–´ì•¼ í•¨\n",
    "assert isinstance(results, dict), \"ê²°ê³¼ëŠ” dictionaryì—¬ì•¼ í•¨\"\n",
    "assert len(results) == 5, \"maxlag=5ì´ë¯€ë¡œ 5ê°œ ê²°ê³¼\"\n",
    "print(\"\\ní…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- `grangercausalitytests(data, maxlag)`ì˜ data ìˆœì„œê°€ ì¤‘ìš”\n",
    "- \"Xê°€ Yë¥¼ ì›ì¸í•˜ëŠ”ê°€?\" ê²€ì • ì‹œ `data = [[Y, X]]` ìˆœì„œ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "```python\n",
    "# Money â†’ Spending ê²€ì • (Moneyê°€ Spendingì„ ì›ì¸í•˜ëŠ”ê°€?)\n",
    "grangercausalitytests(df[['Spending', 'Money']], maxlag=5)\n",
    "#                       â†‘ ê²°ê³¼ë³€ìˆ˜   â†‘ ì›ì¸ë³€ìˆ˜\n",
    "```\n",
    "\n",
    "**ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜**:\n",
    "- [ì›ì¸, ê²°ê³¼] ìˆœì„œë¡œ ì˜ëª» ì…ë ¥í•˜ëŠ” ê²½ìš°\n",
    "- ì •ìƒì„± í™•ë³´ ì—†ì´ ì›ë³¸ ë°ì´í„°ë¡œ ê²€ì •í•˜ëŠ” ê²½ìš°\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ê²°ê³¼ì—ì„œ `ssr_ftest`ì˜ p-valueë¥¼ ì£¼ë¡œ ì‚¬ìš©\n",
    "- ì—¬ëŸ¬ ì‹œì°¨ ì¤‘ ì¼ê´€ë˜ê²Œ ìœ ì˜í•œì§€ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## í€´ì¦ˆ 4 â­â­ - ì •ë‹µ\n",
    "\n",
    "**ë¬¸ì œ**: VAR ëª¨ë¸ê³¼ ARIMA ëª¨ë¸ì˜ ì°¨ì´ì ì„ ì½”ë“œë¡œ ë¹„êµí•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 4 ì •ë‹µ\n",
    "\n",
    "# ARIMA: ë‹¨ë³€ëŸ‰ (1ê°œ ë³€ìˆ˜)\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# arima_model = ARIMA(df['Money'], order=(1,1,1))  # ë‹¨ì¼ ì—´\n",
    "\n",
    "# VAR: ë‹¤ë³€ëŸ‰ (2ê°œ ì´ìƒ ë³€ìˆ˜)\n",
    "from statsmodels.tsa.api import VAR\n",
    "# var_model = VAR(df[['Money', 'Spending']])  # ì—¬ëŸ¬ ì—´\n",
    "\n",
    "# VARì˜ ì¥ì ì€?\n",
    "# ë³€ìˆ˜ ê°„ \"ìƒí˜¸ì‘ìš©\"ì„ ë°˜ì˜í•˜ì—¬ ì˜ˆì¸¡\n",
    "\n",
    "# ë¹„êµ í…Œì´ë¸” ì¶œë ¥\n",
    "print(\"=\" * 70)\n",
    "print(\"ARIMA vs VAR ë¹„êµ\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"{'íŠ¹ì„±':<20} {'ARIMA (ë‹¨ë³€ëŸ‰)':<25} {'VAR (ë‹¤ë³€ëŸ‰)'}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'ë³€ìˆ˜ ìˆ˜':<20} {'1ê°œ':<25} {'2ê°œ ì´ìƒ'}\")\n",
    "print(f\"{'ì˜ˆì¸¡ ëŒ€ìƒ':<20} {'Yì˜ ë¯¸ë˜ê°’ë§Œ':<25} {'Y1, Y2, ... ëª¨ë‘'}\")\n",
    "print(f\"{'ìƒí˜¸ì‘ìš©':<20} {'ì—†ìŒ':<25} {'ë³€ìˆ˜ ê°„ ì˜í–¥ ë°˜ì˜'}\")\n",
    "print(f\"{'í™œìš© ì˜ˆì‹œ':<20} {'ë‹¨ì¼ KPI ì˜ˆì¸¡':<25} {'ì—°ê´€ ì§€í‘œ ë™ì‹œ ì˜ˆì¸¡'}\")\n",
    "print(f\"{'ì½”ë“œ ì…ë ¥':<20} {'df[col]':<25} {'df[[col1, col2, ...]]}'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸: ì‹¤ì œ ì½”ë“œ ì˜ˆì‹œ\n",
    "print(\"=== ARIMA ì½”ë“œ ì˜ˆì‹œ ===\")\n",
    "print(\"from statsmodels.tsa.arima.model import ARIMA\")\n",
    "print(\"model = ARIMA(df['Money'], order=(1,1,1))\")\n",
    "print(\"fitted = model.fit()\")\n",
    "print(\"forecast = fitted.forecast(steps=5)  # Moneyë§Œ ì˜ˆì¸¡\")\n",
    "print()\n",
    "\n",
    "print(\"=== VAR ì½”ë“œ ì˜ˆì‹œ ===\")\n",
    "print(\"from statsmodels.tsa.api import VAR\")\n",
    "print(\"model = VAR(df[['Money', 'Spending']])\")\n",
    "print(\"fitted = model.fit(maxlags=5)\")\n",
    "print(\"forecast = fitted.forecast(y=last_obs, steps=5)  # ë‘˜ ë‹¤ ì˜ˆì¸¡\")\n",
    "\n",
    "# ê²€ì¦\n",
    "var_advantage = \"ë³€ìˆ˜ ê°„ ìƒí˜¸ì‘ìš©ì„ ë°˜ì˜í•˜ì—¬ ì˜ˆì¸¡\"\n",
    "assert \"ìƒí˜¸ì‘ìš©\" in var_advantage, \"VARì˜ í•µì‹¬ ì¥ì \"\n",
    "print(\"\\ní…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- ARIMA: ë‹¨ì¼ ì‹œê³„ì—´ì˜ ìê¸°íšŒê·€ + ì°¨ë¶„ + ì´ë™í‰ê· \n",
    "- VAR: ì—¬ëŸ¬ ì‹œê³„ì—´ ê°„ ìƒí˜¸ ì˜ì¡´ì„± ëª¨ë¸ë§\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "| ëª¨ë¸ | ìˆ˜ì‹ (ê°„ëµí™”) |\n",
    "|------|-------------|\n",
    "| ARIMA | Y(t) = f(Y(t-1), Y(t-2), ..., error) |\n",
    "| VAR | Y1(t) = f(Y1(t-1), Y2(t-1), ...)  <br> Y2(t) = f(Y1(t-1), Y2(t-1), ...) |\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë…ë¦½ì ì¸ ë‹¨ì¼ KPI ì˜ˆì¸¡: ARIMA\n",
    "- ì„œë¡œ ì˜í–¥ì£¼ëŠ” ì—¬ëŸ¬ ë³€ìˆ˜ ì˜ˆì¸¡: VAR\n",
    "- VARë„ ì •ìƒ ì‹œê³„ì—´ í•„ìš” (ì°¨ë¶„ ì ìš©)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## í€´ì¦ˆ 5 â­â­ - ì •ë‹µ\n",
    "\n",
    "**ë¬¸ì œ**: VAR ëª¨ë¸ì˜ ìµœì  ì‹œì°¨(lag)ë¥¼ ì„ íƒí•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 5 ì •ë‹µ\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "# VAR ëª¨ë¸ ìƒì„±\n",
    "model = VAR(df_diff)\n",
    "\n",
    "# ìµœì  ì‹œì°¨ ì„ íƒ\n",
    "lag_selection = model.select_order(maxlags=15)  # select_order ë©”ì„œë“œ\n",
    "\n",
    "# AIC ê¸°ì¤€ ìµœì  ì‹œì°¨\n",
    "optimal_lag = lag_selection.aic  # .aic ì†ì„±\n",
    "print(f\"AIC ê¸°ì¤€ ìµœì  ì‹œì°¨: {optimal_lag}\")\n",
    "\n",
    "# BIC ê¸°ì¤€ ìµœì  ì‹œì°¨\n",
    "optimal_lag_bic = lag_selection.bic  # .bic ì†ì„±\n",
    "print(f\"BIC ê¸°ì¤€ ìµœì  ì‹œì°¨: {optimal_lag_bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸: ì „ì²´ ì‹œì°¨ ì„ íƒ ê²°ê³¼ í™•ì¸\n",
    "print(\"=== ì‹œì°¨ ì„ íƒ ìƒì„¸ ê²°ê³¼ ===\")\n",
    "print(lag_selection.summary())\n",
    "\n",
    "# ê²€ì¦\n",
    "assert hasattr(lag_selection, 'aic'), \"AIC ì†ì„± í•„ìš”\"\n",
    "assert hasattr(lag_selection, 'bic'), \"BIC ì†ì„± í•„ìš”\"\n",
    "assert hasattr(lag_selection, 'hqic'), \"HQIC ì†ì„±ë„ ìˆìŒ\"\n",
    "assert hasattr(lag_selection, 'fpe'), \"FPE ì†ì„±ë„ ìˆìŒ\"\n",
    "print(\"\\ní…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. `VAR(data)` ëª¨ë¸ ê°ì²´ ìƒì„±\n",
    "2. `.select_order(maxlags=N)` ë©”ì„œë“œë¡œ ì‹œì°¨ ì„ íƒ\n",
    "3. `.aic`, `.bic` ë“± ì†ì„±ìœ¼ë¡œ ìµœì  ì‹œì°¨ í™•ì¸\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "| ê¸°ì¤€ | íŠ¹ì§• | ì†ì„± |\n",
    "|------|------|------|\n",
    "| AIC | ê³¼ì í•© í—ˆìš©ì  | `.aic` |\n",
    "| BIC | ë‹¨ìˆœ ëª¨ë¸ ì„ í˜¸ | `.bic` |\n",
    "| HQIC | ì¤‘ê°„ | `.hqic` |\n",
    "| FPE | ì˜ˆì¸¡ì˜¤ì°¨ ìµœì†Œí™” | `.fpe` |\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- AICì™€ BICê°€ ë‹¤ë¥´ë©´ í•´ì„ ê°€ëŠ¥í•œ ì‹œì°¨ ì„ íƒ\n",
    "- ì‹œì°¨ê°€ ë„ˆë¬´ í¬ë©´ ê³¼ì í•©, ë„ˆë¬´ ì‘ìœ¼ë©´ ì •ë³´ ì†ì‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## í€´ì¦ˆ 6 â­â­â­ - ì •ë‹µ\n",
    "\n",
    "**ë¬¸ì œ**: VAR ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ì „ì²´ ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 6 ì •ë‹µ\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "# 1. ë°ì´í„° ë¶„í• \n",
    "n_test = 12\n",
    "train = df_diff[:-n_test]  # í›ˆë ¨ ë°ì´í„°\n",
    "test = df_diff[-n_test:]   # í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°: {len(train)}ê°œ\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test)}ê°œ\")\n",
    "\n",
    "# 2. VAR ëª¨ë¸ í•™ìŠµ\n",
    "model = VAR(train)  # í›ˆë ¨ ë°ì´í„°ë¡œ ëª¨ë¸ ìƒì„±\n",
    "\n",
    "# ìµœì  ì‹œì°¨ ì„ íƒ\n",
    "optimal_lag = model.select_order(maxlags=15).aic\n",
    "print(f\"ìµœì  ì‹œì°¨: {optimal_lag}\")\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "fitted = model.fit(optimal_lag)  # ìµœì  ì‹œì°¨ë¡œ fit\n",
    "\n",
    "# 3. ì˜ˆì¸¡ (forecast ë©”ì„œë“œ ì‚¬ìš©)\n",
    "lag_order = fitted.k_ar  # í•™ìŠµëœ ì‹œì°¨ ìˆ˜\n",
    "forecast_input = train.values[-lag_order:]  # ë§ˆì§€ë§‰ lag_orderê°œ ë°ì´í„°\n",
    "forecast = fitted.forecast(y=forecast_input, steps=n_test)  # n_test ê¸°ê°„ ì˜ˆì¸¡\n",
    "\n",
    "print(f\"\\nì˜ˆì¸¡ shape: {forecast.shape}\")\n",
    "print(f\"ì˜ˆì¸¡ ê²°ê³¼ (ì²« 5ê°œ):\")\n",
    "print(forecast[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸: ì˜ˆì¸¡ ê²°ê³¼ ê²€ì¦\n",
    "assert forecast.shape[0] == n_test, f\"ì˜ˆì¸¡ ê°œìˆ˜ê°€ {n_test}ê°œì—¬ì•¼ í•¨\"\n",
    "assert forecast.shape[1] == len(df_diff.columns), \"ë³€ìˆ˜ ê°œìˆ˜ê°€ ì¼ì¹˜í•´ì•¼ í•¨\"\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "df_forecast = pd.DataFrame(\n",
    "    forecast,\n",
    "    index=test.index,\n",
    "    columns=[f\"{col}_pred\" for col in df_diff.columns]\n",
    ")\n",
    "print(\"=== ì˜ˆì¸¡ ê²°ê³¼ DataFrame ===\")\n",
    "print(df_forecast.head())\n",
    "print(\"\\ní…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• \n",
    "2. `VAR(train)` â†’ `.fit(lag)` ìˆœì„œë¡œ í•™ìŠµ\n",
    "3. `forecast(y=last_obs, steps=n)` ë©”ì„œë“œë¡œ ì˜ˆì¸¡\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "```python\n",
    "# VAR ì˜ˆì¸¡ì— í•„ìš”í•œ ê²ƒ\n",
    "lag_order = fitted.k_ar           # í•™ìŠµëœ ì‹œì°¨ ìˆ˜\n",
    "forecast_input = train.values[-lag_order:]  # ë§ˆì§€ë§‰ lagê°œ ê´€ì¸¡ê°’\n",
    "forecast = fitted.forecast(y=forecast_input, steps=n)\n",
    "```\n",
    "\n",
    "**ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜**:\n",
    "- `forecast()`ì— y íŒŒë¼ë¯¸í„° ëˆ„ë½\n",
    "- ì˜ëª»ëœ lag_order ì‚¬ìš©\n",
    "- í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬í•¨í•˜ì—¬ í•™ìŠµ\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì°¨ë¶„ ë°ì´í„°ë¡œ í•™ìŠµ/ì˜ˆì¸¡ í›„ ì—­ë³€í™˜ í•„ìš”\n",
    "- stepsëŠ” í…ŒìŠ¤íŠ¸ ê¸°ê°„ì— ë§ì¶¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## í€´ì¦ˆ 7 â­â­â­ - ì •ë‹µ\n",
    "\n",
    "**ë¬¸ì œ**: yfinanceë¥¼ ì‚¬ìš©í•˜ì—¬ 2ê°œ ì¢…ëª©ì˜ ì£¼ê°€ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì–‘ë°©í–¥ ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •ì„ ìˆ˜í–‰í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 7 ì •ë‹µ\n",
    "import yfinance as yf\n",
    "\n",
    "# 1. ë°ì´í„° ìˆ˜ì§‘ (í•œêµ­ ì£¼ì‹)\n",
    "print(\"ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...\")\n",
    "naver = yf.download('035420.KS', period='2y')['Close']\n",
    "kakao = yf.download('035720.KS', period='2y')['Close']\n",
    "\n",
    "# 2. DataFrame ê²°í•©\n",
    "df_stock = pd.DataFrame({\n",
    "    'NAVER': naver,\n",
    "    'KAKAO': kakao\n",
    "}).dropna()\n",
    "\n",
    "print(f\"\\në°ì´í„° ê¸°ê°„: {df_stock.index[0].date()} ~ {df_stock.index[-1].date()}\")\n",
    "print(f\"ë°ì´í„° ê°œìˆ˜: {len(df_stock)}ê°œ\")\n",
    "\n",
    "# ìˆ˜ìµë¥ ë¡œ ë³€í™˜ (ì •ìƒì„± í™•ë³´)\n",
    "df_returns = df_stock.pct_change().dropna() * 100  # ë°±ë¶„ìœ¨\n",
    "\n",
    "# ì •ìƒì„± í™•ì¸\n",
    "print(\"\\n=== ì •ìƒì„± ê²€ì • ===\")\n",
    "for col in df_returns.columns:\n",
    "    adf_result = adfuller(df_returns[col])\n",
    "    print(f\"{col}: ADF={adf_result[0]:.4f}, p-value={adf_result[1]:.4f} -> {'ì •ìƒ' if adf_result[1] < 0.05 else 'ë¹„ì •ìƒ'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ì–‘ë°©í–¥ ê·¸ëœì € ê²€ì •\n",
    "def simple_granger_test(data, cause, effect, maxlag=5):\n",
    "    \"\"\"ê°„ë‹¨í•œ ê·¸ëœì € ê²€ì • ê²°ê³¼ ìš”ì•½\"\"\"\n",
    "    print(f\"\\n=== {cause} â†’ {effect} ê·¸ëœì € ê²€ì • ===\")\n",
    "    test_data = data[[effect, cause]].dropna()  # [ê²°ê³¼, ì›ì¸] ìˆœì„œ\n",
    "    results = grangercausalitytests(test_data, maxlag=maxlag, verbose=False)\n",
    "    \n",
    "    min_p = 1.0\n",
    "    best_lag = 1\n",
    "    \n",
    "    for lag in range(1, maxlag + 1):\n",
    "        p_val = results[lag][0]['ssr_ftest'][1]\n",
    "        sig = \"***\" if p_val < 0.01 else \"**\" if p_val < 0.05 else \"*\" if p_val < 0.1 else \"\"\n",
    "        print(f\"  Lag {lag}: p = {p_val:.4f} {sig}\")\n",
    "        if p_val < min_p:\n",
    "            min_p = p_val\n",
    "            best_lag = lag\n",
    "    \n",
    "    if min_p < 0.05:\n",
    "        print(f\"  => ê²°ë¡ : {cause}ê°€ {effect}ë¥¼ ê·¸ëœì €-ì›ì¸í•¨ (lag={best_lag}, p={min_p:.4f})\")\n",
    "    else:\n",
    "        print(f\"  => ê²°ë¡ : ì¸ê³¼ê´€ê³„ ì—†ìŒ (p >= 0.05)\")\n",
    "    \n",
    "    return min_p\n",
    "\n",
    "# ì–‘ë°©í–¥ ê²€ì • ìˆ˜í–‰\n",
    "p1 = simple_granger_test(df_returns, 'NAVER', 'KAKAO')  # NAVER â†’ KAKAO\n",
    "p2 = simple_granger_test(df_returns, 'KAKAO', 'NAVER')  # KAKAO â†’ NAVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸: ê²€ì • ì™„ë£Œ í™•ì¸\n",
    "assert 'NAVER' in df_returns.columns, \"NAVER ë°ì´í„° í•„ìš”\"\n",
    "assert 'KAKAO' in df_returns.columns, \"KAKAO ë°ì´í„° í•„ìš”\"\n",
    "assert len(df_returns) > 100, \"ì¶©ë¶„í•œ ë°ì´í„° í•„ìš”\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ì–‘ë°©í–¥ ê·¸ëœì € ì¸ê³¼ì„± ê²€ì • ì™„ë£Œ!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"NAVER â†’ KAKAO: {'ì¸ê³¼ê´€ê³„ ìˆìŒ' if p1 < 0.05 else 'ì¸ê³¼ê´€ê³„ ì—†ìŒ'}\")\n",
    "print(f\"KAKAO â†’ NAVER: {'ì¸ê³¼ê´€ê³„ ìˆìŒ' if p2 < 0.05 else 'ì¸ê³¼ê´€ê³„ ì—†ìŒ'}\")\n",
    "\n",
    "print(\"\\ní…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. yfinanceë¡œ ì£¼ê°€ ìˆ˜ì§‘ (í•œêµ­ ì¢…ëª©ì€ `.KS` ì ‘ë¯¸ì‚¬)\n",
    "2. ìˆ˜ìµë¥ ë¡œ ë³€í™˜ (`.pct_change()`) - ì •ìƒì„± í™•ë³´\n",
    "3. ì–‘ë°©í–¥ ê²€ì •: Aâ†’B, Bâ†’A ëª¨ë‘ í™•ì¸\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ìˆ˜ìµë¥  ë³€í™˜ ì´ìœ : ì£¼ê°€ëŠ” ë¹„ì •ìƒ, ìˆ˜ìµë¥ ì€ ì •ìƒ\n",
    "- ì–‘ë°©í–¥ ê²€ì •ìœ¼ë¡œ ìƒí˜¸ ì˜í–¥ íŒŒì•…\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë™ì¼ ì—…ì¢… ì¢…ëª© ê°„ ë¦¬ë“œ-ë˜ê·¸ ê´€ê³„ ë¶„ì„\n",
    "- íš¨ìœ¨ì  ì‹œì¥ì—ì„œëŠ” ì¸ê³¼ê´€ê³„ ì•½í•  ìˆ˜ ìˆìŒ\n",
    "- ê·¸ëœì € ì¸ê³¼ì„± â‰  íˆ¬ì ìˆ˜ìµ ë³´ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## í€´ì¦ˆ 8 â­â­â­â­ - ì •ë‹µ\n",
    "\n",
    "**ë¬¸ì œ**: ì°¨ë¶„ëœ VAR ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì›ë³¸ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 8 ì •ë‹µ\n",
    "\n",
    "def invert_difference(original_series, forecast_diff):\n",
    "    \"\"\"\n",
    "    ì°¨ë¶„ëœ ì˜ˆì¸¡ê°’ì„ ì›ë³¸ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    original_series : pd.Series\n",
    "        ì›ë³¸ ì‹œê³„ì—´ (ì°¨ë¶„ ì „)\n",
    "    forecast_diff : np.array\n",
    "        ì°¨ë¶„ëœ ì˜ˆì¸¡ê°’\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.array : ì›ë³¸ ìŠ¤ì¼€ì¼ ì˜ˆì¸¡ê°’\n",
    "    \"\"\"\n",
    "    # ë§ˆì§€ë§‰ ì›ë³¸ê°’\n",
    "    last_value = original_series.iloc[-1]  # iloc[-1]ë¡œ ë§ˆì§€ë§‰ ê°’ ê°€ì ¸ì˜¤ê¸°\n",
    "    \n",
    "    # ëˆ„ì í•©ìœ¼ë¡œ ì—­ë³€í™˜\n",
    "    # diff(t) = Y(t) - Y(t-1) ì´ë¯€ë¡œ\n",
    "    # Y(t) = Y(t-1) + diff(t)\n",
    "    # => Y(t) = last_value + cumsum(diff[1:t])\n",
    "    forecast_original = np.cumsum(forecast_diff) + last_value  # cumsum() ì‚¬ìš©\n",
    "    \n",
    "    return forecast_original\n",
    "\n",
    "# í•¨ìˆ˜ ì •ì˜ í™•ì¸\n",
    "print(\"invert_difference í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 1: ê°„ë‹¨í•œ ì˜ˆì œ\n",
    "print(\"=== í…ŒìŠ¤íŠ¸ 1: ê°„ë‹¨í•œ ì˜ˆì œ ===\")\n",
    "original = pd.Series([100, 110, 125, 140])  # ì›ë³¸ ì‹œê³„ì—´\n",
    "diff_forecast = np.array([15, 12, 18])  # ì˜ˆì¸¡ëœ ì°¨ë¶„\n",
    "\n",
    "result = invert_difference(original, diff_forecast)\n",
    "\n",
    "print(f\"ì›ë³¸ ì‹œê³„ì—´: {original.values}\")\n",
    "print(f\"ë§ˆì§€ë§‰ ê°’: {original.iloc[-1]}\")\n",
    "print(f\"ì˜ˆì¸¡ëœ ì°¨ë¶„: {diff_forecast}\")\n",
    "print(f\"ì—­ë³€í™˜ ê²°ê³¼: {result}\")\n",
    "\n",
    "# ê²€ì¦\n",
    "# 140 + 15 = 155, 155 + 12 = 167, 167 + 18 = 185\n",
    "expected = np.array([155, 167, 185])\n",
    "assert np.allclose(result, expected), f\"ì˜ˆìƒ: {expected}, ì‹¤ì œ: {result}\"\n",
    "print(f\"ì˜ˆìƒê°’: {expected}\")\n",
    "print(\"í…ŒìŠ¤íŠ¸ 1 í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 2: ì‹¤ì œ VAR ì˜ˆì¸¡ì— ì ìš©\n",
    "print(\"\\n=== í…ŒìŠ¤íŠ¸ 2: VAR ì˜ˆì¸¡ ì—­ë³€í™˜ ===\")\n",
    "\n",
    "# VAR ì˜ˆì¸¡ (ì°¨ë¶„ ë°ì´í„°)\n",
    "n_test = 12\n",
    "train_diff = df_diff[:-n_test]\n",
    "train_orig = df_econ[:-n_test]\n",
    "\n",
    "model = VAR(train_diff)\n",
    "fitted = model.fit(model.select_order(maxlags=10).aic)\n",
    "\n",
    "lag_order = fitted.k_ar\n",
    "forecast_diff = fitted.forecast(y=train_diff.values[-lag_order:], steps=n_test)\n",
    "\n",
    "# ê° ë³€ìˆ˜ì— ì—­ë³€í™˜ ì ìš©\n",
    "forecast_original = {}\n",
    "for i, col in enumerate(train_diff.columns):\n",
    "    forecast_original[col] = invert_difference(\n",
    "        train_orig[col], \n",
    "        forecast_diff[:, i]\n",
    "    )\n",
    "    print(f\"{col} ì—­ë³€í™˜ ì™„ë£Œ\")\n",
    "\n",
    "print(\"\\ní…ŒìŠ¤íŠ¸ 2 í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- 1ì°¨ ì°¨ë¶„: `diff(t) = Y(t) - Y(t-1)`\n",
    "- ì—­ë³€í™˜: `Y(t) = Y(t-1) + diff(t)`\n",
    "- ì—°ì† ì—­ë³€í™˜: `cumsum(diff) + last_value`\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "```\n",
    "ì›ë³¸:    100, 110, 125, 140 (ë§ˆì§€ë§‰=140)\n",
    "ì°¨ë¶„ì˜ˆì¸¡: 15, 12, 18\n",
    "\n",
    "ì—­ë³€í™˜:\n",
    "  t1: 140 + 15 = 155\n",
    "  t2: 155 + 12 = 167  (= 140 + 15 + 12)\n",
    "  t3: 167 + 18 = 185  (= 140 + 15 + 12 + 18)\n",
    "\n",
    "=> cumsum([15, 12, 18]) + 140 = [15, 27, 45] + 140 = [155, 167, 185]\n",
    "```\n",
    "\n",
    "**ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜**:\n",
    "- `iloc[-1]` ëŒ€ì‹  `[-1]` ì‚¬ìš© (ì¸ë±ìŠ¤ ë¬¸ì œ)\n",
    "- ë‹¤ì¤‘ ì°¨ë¶„ ì‹œ ìˆœì„œ í˜¼ë™\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- 2ì°¨ ì°¨ë¶„ì´ë©´ ì—­ë³€í™˜ë„ 2ë²ˆ\n",
    "- DataFrame ì „ì²´ì— ì ìš©í•˜ë ¤ë©´ ì—´ë³„ë¡œ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## í€´ì¦ˆ 9 â­â­â­â­ - ì •ë‹µ\n",
    "\n",
    "**ë¬¸ì œ**: ì—¬ëŸ¬ ë³€ìˆ˜ì— ëŒ€í•œ ê·¸ëœì € ì¸ê³¼ì„± ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 9 ì •ë‹µ\n",
    "\n",
    "def granger_matrix(data, variables, maxlag=5, significance=0.05):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë³€ìˆ˜ ê°„ ê·¸ëœì € ì¸ê³¼ì„± ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        ì‹œê³„ì—´ ë°ì´í„° (ì •ìƒì„± í™•ë³´ í•„ìš”)\n",
    "    variables : list\n",
    "        ë¶„ì„í•  ë³€ìˆ˜ ëª©ë¡\n",
    "    maxlag : int\n",
    "        ê²€ì •í•  ìµœëŒ€ ì‹œì°¨\n",
    "    significance : float\n",
    "        ìœ ì˜ìˆ˜ì¤€\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : ì¸ê³¼ì„± ë§¤íŠ¸ë¦­ìŠ¤ (í–‰: ì›ì¸, ì—´: ê²°ê³¼)\n",
    "                   ê°’ì€ ìµœì†Œ p-value\n",
    "    \"\"\"\n",
    "    n = len(variables)\n",
    "    matrix = np.ones((n, n))  # 1ë¡œ ì´ˆê¸°í™” (ëŒ€ê°ì„ ì€ NaN ì²˜ë¦¬í•  ì˜ˆì •)\n",
    "    \n",
    "    for i, cause in enumerate(variables):\n",
    "        for j, effect in enumerate(variables):\n",
    "            if i == j:\n",
    "                # ìê¸° ìì‹ : NaN\n",
    "                matrix[i, j] = np.nan\n",
    "            else:\n",
    "                try:\n",
    "                    # ê·¸ëœì € ê²€ì • ìˆ˜í–‰\n",
    "                    # ì…ë ¥ ìˆœì„œ: [ê²°ê³¼ë³€ìˆ˜, ì›ì¸ë³€ìˆ˜]\n",
    "                    test_data = data[[effect, cause]].dropna()\n",
    "                    results = grangercausalitytests(test_data, maxlag=maxlag, verbose=False)\n",
    "                    \n",
    "                    # ëª¨ë“  ì‹œì°¨ì—ì„œ ìµœì†Œ p-value ì°¾ê¸°\n",
    "                    min_p = min([results[lag][0]['ssr_ftest'][1] for lag in range(1, maxlag+1)])\n",
    "                    matrix[i, j] = min_p\n",
    "                except:\n",
    "                    matrix[i, j] = np.nan\n",
    "    \n",
    "    # DataFrameìœ¼ë¡œ ë³€í™˜ (í–‰: ì›ì¸, ì—´: ê²°ê³¼)\n",
    "    result_df = pd.DataFrame(\n",
    "        matrix, \n",
    "        index=[f\"{v} â†’\" for v in variables],  # ì›ì¸\n",
    "        columns=variables  # ê²°ê³¼\n",
    "    )\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "print(\"granger_matrix í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 1: 2ë³€ìˆ˜ ë°ì´í„°\n",
    "print(\"=== í…ŒìŠ¤íŠ¸ 1: ê²½ì œ ë°ì´í„° (2ë³€ìˆ˜) ===\")\n",
    "matrix_econ = granger_matrix(df_diff, ['Money', 'Spending'], maxlag=5)\n",
    "print(matrix_econ.round(4))\n",
    "print(\"\\ní•´ì„: í–‰(ì›ì¸) â†’ ì—´(ê²°ê³¼)ì˜ p-value\")\n",
    "print(\"p < 0.05ì´ë©´ ì¸ê³¼ê´€ê³„ ìˆìŒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 2: 3ë³€ìˆ˜ ì´ìƒ ë°ì´í„° (ì£¼ì‹ ìˆ˜ìµë¥ )\n",
    "import yfinance as yf\n",
    "\n",
    "print(\"\\n=== í…ŒìŠ¤íŠ¸ 2: ì£¼ì‹ ìˆ˜ìµë¥  (3ë³€ìˆ˜) ===\")\n",
    "\n",
    "# ë°ì´í„° ìˆ˜ì§‘\n",
    "symbols = {'SAMSUNG': '005930.KS', 'SKHYNIX': '000660.KS', 'LG': '066570.KS'}\n",
    "stock_data = {}\n",
    "\n",
    "print(\"ë°ì´í„° ìˆ˜ì§‘ ì¤‘...\")\n",
    "for name, ticker in symbols.items():\n",
    "    stock_data[name] = yf.download(ticker, period='2y', progress=False)['Close']\n",
    "\n",
    "df_stocks = pd.DataFrame(stock_data).dropna()\n",
    "df_stock_returns = df_stocks.pct_change().dropna() * 100\n",
    "\n",
    "# ê·¸ëœì € ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±\n",
    "matrix_stocks = granger_matrix(df_stock_returns, list(symbols.keys()), maxlag=5)\n",
    "print(\"\\nê·¸ëœì € ì¸ê³¼ì„± ë§¤íŠ¸ë¦­ìŠ¤ (p-values):\")\n",
    "print(matrix_stocks.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”: Heatmap\n",
    "def plot_granger_heatmap(matrix, title=\"ê·¸ëœì € ì¸ê³¼ì„± ë§¤íŠ¸ë¦­ìŠ¤\"):\n",
    "    \"\"\"ê·¸ëœì € ë§¤íŠ¸ë¦­ìŠ¤ íˆíŠ¸ë§µ ì‹œê°í™”\"\"\"\n",
    "    # NaNì„ 1ë¡œ ëŒ€ì²´ (ëŒ€ê°ì„ )\n",
    "    matrix_plot = matrix.fillna(1)\n",
    "    \n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=matrix_plot.values,\n",
    "        x=matrix_plot.columns,\n",
    "        y=matrix_plot.index,\n",
    "        colorscale='RdYlGn_r',  # ë¹¨ê°„ìƒ‰ì´ ë‚®ì€ p-value (ìœ ì˜)\n",
    "        zmin=0, zmax=0.1,  # 0~0.1 ë²”ìœ„\n",
    "        text=matrix_plot.round(3).values,\n",
    "        texttemplate='%{text}',\n",
    "        textfont={'size': 12},\n",
    "        hoverongaps=False,\n",
    "        colorbar=dict(title='p-value')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='ê²°ê³¼ ë³€ìˆ˜ (Effect)',\n",
    "        yaxis_title='ì›ì¸ ë³€ìˆ˜ (Cause)',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = plot_granger_heatmap(matrix_stocks, \"ì£¼ì‹ ê·¸ëœì € ì¸ê³¼ì„± (p < 0.05ì´ë©´ ìœ ì˜)\")\n",
    "fig.show()\n",
    "\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. N x N ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (N = ë³€ìˆ˜ ê°œìˆ˜)\n",
    "2. ëª¨ë“  (ì›ì¸, ê²°ê³¼) ìŒì— ëŒ€í•´ ê·¸ëœì € ê²€ì •\n",
    "3. ìµœì†Œ p-valueë¥¼ ë§¤íŠ¸ë¦­ìŠ¤ì— ì €ì¥\n",
    "4. ëŒ€ê°ì„ (ìê¸° ìì‹ )ì€ NaN ì²˜ë¦¬\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "```\n",
    "ë§¤íŠ¸ë¦­ìŠ¤ í•´ì„:\n",
    "       Money  Spending\n",
    "Money â†’   NaN    0.02   <- Moneyê°€ Spendingì„ ì›ì¸í•¨ (p=0.02)\n",
    "Spendingâ†’ 0.15    NaN   <- Spendingì€ Moneyë¥¼ ì›ì¸í•˜ì§€ ì•ŠìŒ\n",
    "```\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”í•˜ë©´ íŒ¨í„´ íŒŒì•… ìš©ì´\n",
    "- p < 0.05ì¸ ì…€ë§Œ ì¸ê³¼ê´€ê³„ ì¡´ì¬\n",
    "- ì–‘ë°©í–¥ ëª¨ë‘ ìœ ì˜í•˜ë©´ í”¼ë“œë°± ê´€ê³„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## í€´ì¦ˆ 10 â­â­â­â­â­ - ì •ë‹µ\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ 10 ì •ë‹µ\n",
    "\n",
    "class MultivariateAnalyzer:\n",
    "    \"\"\"\n",
    "    ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë¶„ì„ íŒŒì´í”„ë¼ì¸\n",
    "    \n",
    "    VAR ëª¨ë¸ í•™ìŠµ, ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •, ì˜ˆì¸¡ ë° ì‹œê°í™”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, maxlag=15):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        maxlag : int\n",
    "            ìµœì  ì‹œì°¨ íƒìƒ‰ ì‹œ ìµœëŒ€ ì‹œì°¨\n",
    "        \"\"\"\n",
    "        self.maxlag = maxlag\n",
    "        self.model = None\n",
    "        self.fitted = None\n",
    "        self.data_original = None\n",
    "        self.data_diff = None\n",
    "        self.train_original = None\n",
    "        self.train_diff = None\n",
    "        self.test_original = None\n",
    "        self.test_diff = None\n",
    "        self.forecast_diff = None\n",
    "        self.forecast_original = None\n",
    "        self.optimal_lag = None\n",
    "        self.n_test = None\n",
    "    \n",
    "    def fit(self, data, test_size=12):\n",
    "        \"\"\"\n",
    "        ë°ì´í„° ë¶„í• , ì •ìƒì„± ë³€í™˜, VAR í•™ìŠµ\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pd.DataFrame\n",
    "            ì›ë³¸ ì‹œê³„ì—´ ë°ì´í„° (ì—¬ëŸ¬ ì—´)\n",
    "        test_size : int\n",
    "            í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°\n",
    "        \"\"\"\n",
    "        self.n_test = test_size\n",
    "        self.data_original = data.copy()\n",
    "        \n",
    "        # 1. ì •ìƒì„± ë³€í™˜ (1ì°¨ ì°¨ë¶„)\n",
    "        self.data_diff = data.diff().dropna()\n",
    "        \n",
    "        # 2. ë°ì´í„° ë¶„í• \n",
    "        self.train_original = data.iloc[:-test_size]\n",
    "        self.test_original = data.iloc[-test_size:]\n",
    "        self.train_diff = self.data_diff.iloc[:-test_size]\n",
    "        self.test_diff = self.data_diff.iloc[-test_size:]\n",
    "        \n",
    "        # 3. VAR ëª¨ë¸ í•™ìŠµ\n",
    "        self.model = VAR(self.train_diff)\n",
    "        self.optimal_lag = self.model.select_order(maxlags=self.maxlag).aic\n",
    "        self.fitted = self.model.fit(self.optimal_lag)\n",
    "        \n",
    "        print(f\"=== VAR ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ===\")\n",
    "        print(f\"ë³€ìˆ˜: {list(data.columns)}\")\n",
    "        print(f\"í›ˆë ¨ ë°ì´í„°: {len(self.train_diff)}ê°œ\")\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(self.test_diff)}ê°œ\")\n",
    "        print(f\"ìµœì  ì‹œì°¨ (AIC): {self.optimal_lag}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def granger_test(self, cause, effect, maxlag=None):\n",
    "        \"\"\"\n",
    "        ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        cause : str\n",
    "            ì›ì¸ ë³€ìˆ˜\n",
    "        effect : str\n",
    "            ê²°ê³¼ ë³€ìˆ˜\n",
    "        maxlag : int\n",
    "            ìµœëŒ€ ì‹œì°¨ (Noneì´ë©´ self.maxlag ì‚¬ìš©)\n",
    "        \"\"\"\n",
    "        if maxlag is None:\n",
    "            maxlag = min(self.maxlag, 10)\n",
    "        \n",
    "        print(f\"\\n=== ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •: {cause} â†’ {effect} ===\")\n",
    "        \n",
    "        # [ê²°ê³¼, ì›ì¸] ìˆœì„œë¡œ ì…ë ¥\n",
    "        test_data = self.data_diff[[effect, cause]].dropna()\n",
    "        results = grangercausalitytests(test_data, maxlag=maxlag, verbose=False)\n",
    "        \n",
    "        # ê²°ê³¼ ì •ë¦¬\n",
    "        print(f\"{'Lag':<5} {'F-stat':<12} {'p-value':<12} {'ìœ ì˜ì„±'}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        min_p = 1.0\n",
    "        best_lag = 1\n",
    "        \n",
    "        for lag in range(1, maxlag + 1):\n",
    "            f_stat = results[lag][0]['ssr_ftest'][0]\n",
    "            p_val = results[lag][0]['ssr_ftest'][1]\n",
    "            sig = \"***\" if p_val < 0.01 else \"**\" if p_val < 0.05 else \"*\" if p_val < 0.1 else \"\"\n",
    "            print(f\"{lag:<5} {f_stat:<12.4f} {p_val:<12.4f} {sig}\")\n",
    "            \n",
    "            if p_val < min_p:\n",
    "                min_p = p_val\n",
    "                best_lag = lag\n",
    "        \n",
    "        print(f\"\\nê²°ë¡ : \", end=\"\")\n",
    "        if min_p < 0.05:\n",
    "            print(f\"{cause}ê°€ {effect}ë¥¼ ê·¸ëœì €-ì›ì¸í•¨ (lag={best_lag}, p={min_p:.4f})\")\n",
    "        else:\n",
    "            print(f\"ì¸ê³¼ê´€ê³„ ì—†ìŒ (p >= 0.05)\")\n",
    "        \n",
    "        return {'min_p': min_p, 'best_lag': best_lag, 'results': results}\n",
    "    \n",
    "    def predict(self, steps=None):\n",
    "        \"\"\"\n",
    "        VAR ì˜ˆì¸¡ (ì›ë³¸ ìŠ¤ì¼€ì¼ ë°˜í™˜)\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        steps : int\n",
    "            ì˜ˆì¸¡ ê¸°ê°„ (Noneì´ë©´ test_size ì‚¬ìš©)\n",
    "        \"\"\"\n",
    "        if steps is None:\n",
    "            steps = self.n_test\n",
    "        \n",
    "        # ì°¨ë¶„ ì˜ˆì¸¡\n",
    "        lag_order = self.fitted.k_ar\n",
    "        forecast_input = self.train_diff.values[-lag_order:]\n",
    "        self.forecast_diff = self.fitted.forecast(y=forecast_input, steps=steps)\n",
    "        \n",
    "        # ì›ë³¸ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜\n",
    "        last_values = self.train_original.iloc[-1].values\n",
    "        self.forecast_original = np.cumsum(self.forecast_diff, axis=0) + last_values\n",
    "        \n",
    "        # DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "        forecast_index = self.test_original.index[:steps] if steps <= len(self.test_original) \\\n",
    "                        else pd.date_range(self.test_original.index[0], periods=steps, freq='MS')\n",
    "        \n",
    "        forecast_df = pd.DataFrame(\n",
    "            self.forecast_original,\n",
    "            index=forecast_index,\n",
    "            columns=[f\"{col}_forecast\" for col in self.train_original.columns]\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n=== {steps}ê¸°ê°„ ì˜ˆì¸¡ ì™„ë£Œ ===\")\n",
    "        print(forecast_df.head())\n",
    "        \n",
    "        return forecast_df\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€ (MAE, RMSE, MAPE)\n",
    "        \"\"\"\n",
    "        if self.forecast_original is None:\n",
    "            print(\"ë¨¼ì € predict()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "            return None\n",
    "        \n",
    "        metrics = {}\n",
    "        print(\"\\n=== ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€ ===\")\n",
    "        \n",
    "        for i, col in enumerate(self.train_original.columns):\n",
    "            actual = self.test_original[col].values[:len(self.forecast_original)]\n",
    "            predicted = self.forecast_original[:, i]\n",
    "            \n",
    "            mae = np.mean(np.abs(actual - predicted))\n",
    "            rmse = np.sqrt(np.mean((actual - predicted) ** 2))\n",
    "            mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "            \n",
    "            metrics[col] = {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
    "            \n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  MAE:  {mae:.2f}\")\n",
    "            print(f\"  RMSE: {rmse:.2f}\")\n",
    "            print(f\"  MAPE: {mape:.2f}%\")\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def plot(self):\n",
    "        \"\"\"\n",
    "        ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
    "        \"\"\"\n",
    "        if self.forecast_original is None:\n",
    "            print(\"ë¨¼ì € predict()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "            return None\n",
    "        \n",
    "        n_vars = len(self.train_original.columns)\n",
    "        fig = make_subplots(rows=n_vars, cols=1, shared_xaxes=True,\n",
    "                           subplot_titles=list(self.train_original.columns))\n",
    "        \n",
    "        colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "        \n",
    "        for i, col in enumerate(self.train_original.columns):\n",
    "            color = colors[i % len(colors)]\n",
    "            \n",
    "            # ì‹¤ì œ ê°’ (ì „ì²´)\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=self.data_original.index,\n",
    "                y=self.data_original[col],\n",
    "                mode='lines', name=f'{col} ì‹¤ì œ',\n",
    "                line=dict(color=color)\n",
    "            ), row=i+1, col=1)\n",
    "            \n",
    "            # ì˜ˆì¸¡ ê°’\n",
    "            forecast_index = self.test_original.index[:len(self.forecast_original)]\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=forecast_index,\n",
    "                y=self.forecast_original[:, i],\n",
    "                mode='lines', name=f'{col} ì˜ˆì¸¡',\n",
    "                line=dict(color=color, dash='dash')\n",
    "            ), row=i+1, col=1)\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='VAR ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼',\n",
    "            height=300 * n_vars,\n",
    "            showlegend=True\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "\n",
    "print(\"MultivariateAnalyzer í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸: ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "print(\"=\" * 70)\n",
    "print(\"MultivariateAnalyzer ì „ì²´ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "analyzer = MultivariateAnalyzer(maxlag=15)\n",
    "\n",
    "# 2. ëª¨ë¸ í•™ìŠµ\n",
    "analyzer.fit(df_econ, test_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ê·¸ëœì € ì¸ê³¼ì„± ê²€ì •\n",
    "granger_result = analyzer.granger_test('Money', 'Spending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ì˜ˆì¸¡\n",
    "forecast_df = analyzer.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. ì„±ëŠ¥ í‰ê°€\n",
    "metrics = analyzer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. ì‹œê°í™”\n",
    "fig = analyzer.plot()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸: í´ë˜ìŠ¤ ì†ì„± ê²€ì¦\n",
    "assert analyzer.fitted is not None, \"ëª¨ë¸ í•™ìŠµ í•„ìš”\"\n",
    "assert analyzer.forecast_original is not None, \"ì˜ˆì¸¡ í•„ìš”\"\n",
    "assert isinstance(metrics, dict), \"ë©”íŠ¸ë¦­ì€ dict\"\n",
    "\n",
    "# ë©”ì„œë“œ ì¡´ì¬ í™•ì¸\n",
    "assert hasattr(analyzer, 'fit'), \"fit ë©”ì„œë“œ í•„ìš”\"\n",
    "assert hasattr(analyzer, 'granger_test'), \"granger_test ë©”ì„œë“œ í•„ìš”\"\n",
    "assert hasattr(analyzer, 'predict'), \"predict ë©”ì„œë“œ í•„ìš”\"\n",
    "assert hasattr(analyzer, 'evaluate'), \"evaluate ë©”ì„œë“œ í•„ìš”\"\n",
    "assert hasattr(analyzer, 'plot'), \"plot ë©”ì„œë“œ í•„ìš”\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. í´ë˜ìŠ¤ë¡œ ìƒíƒœ(data, model, forecast) ê´€ë¦¬\n",
    "2. íŒŒì´í”„ë¼ì¸: fit â†’ granger_test â†’ predict â†’ evaluate â†’ plot\n",
    "3. ìë™ ì°¨ë¶„ ë° ì—­ë³€í™˜ ì²˜ë¦¬\n",
    "\n",
    "**í•µì‹¬ ë©”ì„œë“œ**:\n",
    "| ë©”ì„œë“œ | ê¸°ëŠ¥ | ì…ë ¥ | ì¶œë ¥ |\n",
    "|--------|------|------|------|\n",
    "| `fit()` | í•™ìŠµ | ì›ë³¸ ë°ì´í„° | self |\n",
    "| `granger_test()` | ì¸ê³¼ì„± ê²€ì • | ì›ì¸, ê²°ê³¼ | p-value |\n",
    "| `predict()` | ì˜ˆì¸¡ | steps | ì›ë³¸ ìŠ¤ì¼€ì¼ ì˜ˆì¸¡ |\n",
    "| `evaluate()` | ì„±ëŠ¥ í‰ê°€ | - | MAE, RMSE, MAPE |\n",
    "| `plot()` | ì‹œê°í™” | - | Plotly Figure |\n",
    "\n",
    "**í™•ì¥ ì•„ì´ë””ì–´**:\n",
    "- `granger_matrix()` ë©”ì„œë“œ ì¶”ê°€\n",
    "- ì¶©ê²©ë°˜ì‘ë¶„ì„(IRF) ì¶”ê°€\n",
    "- ì˜ˆì¸¡êµ¬ê°„ ì¶”ê°€\n",
    "- ë¡¤ë§ ì˜ˆì¸¡ ê¸°ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í€´ì¦ˆ ë‚œì´ë„ë³„ í•µì‹¬ ì •ë¦¬\n",
    "\n",
    "| ë‚œì´ë„ | í€´ì¦ˆ | í•µì‹¬ ê°œë… |\n",
    "|--------|------|----------|\n",
    "| â­ | 1-2 | ìƒê´€/ì¸ê³¼ êµ¬ë¶„, p-value í•´ì„ |\n",
    "| â­â­ | 3-5 | grangercausalitytests, VAR vs ARIMA, select_order |\n",
    "| â­â­â­ | 6-7 | VAR í•™ìŠµ/ì˜ˆì¸¡, ì£¼ì‹ ê·¸ëœì € ë¶„ì„ |\n",
    "| â­â­â­â­ | 8-9 | ì°¨ë¶„ ì—­ë³€í™˜, ê·¸ëœì € ë§¤íŠ¸ë¦­ìŠ¤ |\n",
    "| â­â­â­â­â­ | 10 | MultivariateAnalyzer í´ë˜ìŠ¤ |\n",
    "\n",
    "### ì‹¤ë¬´ í™œìš© ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "- [ ] ì •ìƒì„± í™•ë³´ í›„ ê²€ì •/ëª¨ë¸ë§ (ì°¨ë¶„ í•„ìˆ˜)\n",
    "- [ ] ê·¸ëœì € ê²€ì • ì‹œ [ê²°ê³¼, ì›ì¸] ìˆœì„œ ì£¼ì˜\n",
    "- [ ] ì–‘ë°©í–¥ ê²€ì •ìœ¼ë¡œ í”¼ë“œë°± ê´€ê³„ í™•ì¸\n",
    "- [ ] VAR ì˜ˆì¸¡ í›„ ë°˜ë“œì‹œ ì—­ë³€í™˜\n",
    "- [ ] ê·¸ëœì € ì¸ê³¼ì„± â‰  ì§„ì§œ ì¸ê³¼ê´€ê³„ ëª…ì‹¬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
