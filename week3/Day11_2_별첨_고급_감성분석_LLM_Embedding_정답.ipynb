{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day11_2 ë³„ì²¨: ê³ ê¸‰ ê°ì„± ë¶„ì„ (LLM & Embedding) - ì •ë‹µ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ Day11_2 ë³„ì²¨ í€´ì¦ˆì˜ ì •ë‹µê³¼ í’€ì´ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import time\n",
    "\n",
    "# Google Gemini API\n",
    "try:\n",
    "    from google import genai\n",
    "    from google.genai import types\n",
    "    GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "    client = genai.Client(api_key=GOOGLE_API_KEY) if GOOGLE_API_KEY else None\n",
    "    gemini_available = True\n",
    "except ImportError:\n",
    "    client = None\n",
    "    gemini_available = False\n",
    "\n",
    "# sentence-transformers\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    local_model = SentenceTransformer('jhgan/ko-sbert-nli')\n",
    "    local_embedding_available = True\n",
    "except ImportError:\n",
    "    local_embedding_available = False\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q1. Zero-shot í”„ë¡¬í”„íŠ¸ ì‘ì„±í•˜ê¸° â­\n",
    "\n",
    "**ë¬¸ì œ**: í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ëŠ” Zero-shot í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì •ë‹µ\n",
    "text = \"ì´ ì˜í™” ì •ë§ ì¬ë¯¸ì—†ì–´ìš”. ì‹œê°„ ë‚­ë¹„ì˜€ì–´ìš”.\"\n",
    "\n",
    "prompt = f\"\"\"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µí•˜ì„¸ìš”.\n",
    "\n",
    "í…ìŠ¤íŠ¸: {text}\n",
    "\n",
    "ê°ì„±:\"\"\"\n",
    "\n",
    "print(\"ì‘ì„±ëœ í”„ë¡¬í”„íŠ¸:\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ (APIê°€ ìˆëŠ” ê²½ìš°)\n",
    "if client:\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-exp\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    print(f\"LLM ì‘ë‹µ: {response.text.strip()}\")\n",
    "else:\n",
    "    print(\"ê¸°ëŒ€ ì‘ë‹µ: ë¶€ì •\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q1 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- Zero-shotì€ ì˜ˆì œ ì—†ì´ ë°”ë¡œ ë¶„ë¥˜ ìš”ì²­\n",
    "- ì‘ë‹µ í˜•ì‹ì„ ëª…í™•íˆ ì œí•œ (\"í•˜ë‚˜ë¡œë§Œ ë‹µí•˜ì„¸ìš”\")\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- í”„ë¡¬í”„íŠ¸ëŠ” ëª…í™•í•œ ì§€ì‹œì™€ ì œí•œì´ ì¤‘ìš”\n",
    "- ì‘ë‹µ í˜•ì‹ì„ ì§€ì •í•˜ë©´ íŒŒì‹±ì´ ì‰¬ì›€\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "```python\n",
    "# JSON í˜•ì‹ ìš”ì²­\n",
    "prompt = f'''í…ìŠ¤íŠ¸: {text}\n",
    "ê°ì„±ì„ JSONìœ¼ë¡œ ë‹µí•˜ì„¸ìš”: {{\"sentiment\": \"ê¸ì •/ë¶€ì •/ì¤‘ë¦½\"}}'''\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Few-shot ì˜ˆì œ êµ¬ì„±í•˜ê¸° â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ìŒì‹ì  ë¦¬ë·° ê°ì„± ë¶„ë¥˜ë¥¼ ìœ„í•œ Few-shot ì˜ˆì œë¥¼ 5ê°œ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì •ë‹µ\n",
    "food_examples = [\n",
    "    (\"êµ­ë¬¼ì´ ì§„í•˜ê³  ë©´ë°œì´ ì«„ê¹ƒí•´ìš”. ë§›ìˆì–´ìš”!\", \"ê¸ì •\"),\n",
    "    (\"ì–‘ë„ ë§ê³  ê°€ì„±ë¹„ ìµœê³ ì…ë‹ˆë‹¤. ì¬ë°©ë¬¸ ì˜ì‚¬ 100%!\", \"ê¸ì •\"),\n",
    "    (\"ë„ˆë¬´ ì§œê³  ëŠë¼í•´ìš”. ìœ„ìƒë„ ë³„ë¡œì¸ ê²ƒ ê°™ì•„ìš”.\", \"ë¶€ì •\"),\n",
    "    (\"ì£¼ë¬¸í•œ ì§€ 1ì‹œê°„ì´ ì§€ë‚˜ë„ ì•ˆ ë‚˜ì™€ìš”. ìµœì•…!\", \"ë¶€ì •\"),\n",
    "    (\"í‰ë²”í•´ìš”. íŠ¹ë³„íˆ ë§›ìˆì§€ë„ ë§›ì—†ì§€ë„ ì•Šì•„ìš”.\", \"ì¤‘ë¦½\")\n",
    "]\n",
    "\n",
    "print(\"ìŒì‹ì  ë¦¬ë·° Few-shot ì˜ˆì œ:\")\n",
    "for text, sentiment in food_examples:\n",
    "    print(f\"  [{sentiment}] {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "def create_few_shot_prompt(examples, target_text):\n",
    "    prompt = \"ë‹¤ìŒì€ ìŒì‹ì  ë¦¬ë·°ì˜ ê°ì„± ë¶„ë¥˜ ì˜ˆì‹œì…ë‹ˆë‹¤.\\n\\n\"\n",
    "    \n",
    "    for ex_text, ex_sentiment in examples:\n",
    "        prompt += f\"ë¦¬ë·°: {ex_text}\\nê°ì„±: {ex_sentiment}\\n\\n\"\n",
    "    \n",
    "    prompt += f\"ìœ„ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ë¦¬ë·°ì˜ ê°ì„±ì„ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.\\n\\n\"\n",
    "    prompt += f\"ë¦¬ë·°: {target_text}\\nê°ì„±:\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_review = \"ì‚¼ê²¹ì‚´ì´ ì‹ ì„ í•˜ê³  ë¶ˆë§›ì´ ì¢‹ì•„ìš”!\"\n",
    "prompt = create_few_shot_prompt(food_examples, test_review)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q2 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- ê· í˜• ì¡íŒ ì˜ˆì œ (ê¸ì • 2, ë¶€ì • 2, ì¤‘ë¦½ 1)\n",
    "- ë„ë©”ì¸ íŠ¹í™” í‘œí˜„ ì‚¬ìš© (êµ­ë¬¼, ë©´ë°œ, ê°€ì„±ë¹„ ë“±)\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- Few-shot ì˜ˆì œëŠ” ë‹¤ì–‘í•œ íŒ¨í„´ì„ í¬í•¨í•´ì•¼ í•¨\n",
    "- ì‹¤ì œ ë¦¬ë·° ìŠ¤íƒ€ì¼ê³¼ ìœ ì‚¬í•˜ê²Œ ì‘ì„±\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ê²½ê³„ ì¼€ì´ìŠ¤ ì˜ˆì œ í¬í•¨ (ë³µí•© ê°ì„± ë“±)\n",
    "- ë„ë©”ì¸ ìš©ì–´ í¬í•¨ (ë§›, ì„œë¹„ìŠ¤, ìœ„ìƒ ë“±)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°í•˜ê¸° â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‘ ë²¡í„° Aì™€ Bì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì§ì ‘ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì •ë‹µ\n",
    "def cosine_similarity_manual(A, B):\n",
    "    \"\"\"\n",
    "    ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ìˆ˜ë™ ê³„ì‚°\n",
    "    \n",
    "    cos(A, B) = (A Â· B) / (||A|| Ã— ||B||)\n",
    "    \"\"\"\n",
    "    # ë‚´ì  (dot product)\n",
    "    dot_product = np.dot(A, B)\n",
    "    \n",
    "    # ë…¸ë¦„ (ë²¡í„° í¬ê¸°)\n",
    "    norm_A = np.linalg.norm(A)\n",
    "    norm_B = np.linalg.norm(B)\n",
    "    \n",
    "    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n",
    "    similarity = dot_product / (norm_A * norm_B)\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "A = np.array([1, 2, 3])\n",
    "B = np.array([4, 5, 6])\n",
    "\n",
    "manual_result = cosine_similarity_manual(A, B)\n",
    "sklearn_result = cosine_similarity([A], [B])[0][0]\n",
    "\n",
    "print(f\"A = {A}\")\n",
    "print(f\"B = {B}\")\n",
    "print(f\"\\nìˆ˜ë™ ê³„ì‚° ê²°ê³¼: {manual_result:.6f}\")\n",
    "print(f\"sklearn ê²°ê³¼: {sklearn_result:.6f}\")\n",
    "print(f\"\\nê²°ê³¼ ì¼ì¹˜: {np.isclose(manual_result, sklearn_result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q3 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³µì‹ ê·¸ëŒ€ë¡œ êµ¬í˜„\n",
    "- numpy í•¨ìˆ˜ í™œìš© (dot, linalg.norm)\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ë‚´ì : `A Â· B = a1*b1 + a2*b2 + ...`\n",
    "- ë…¸ë¦„: `||A|| = sqrt(a1Â² + a2Â² + ...)`\n",
    "- ì½”ì‚¬ì¸ ìœ ì‚¬ë„: ë‘ ë²¡í„° ì‚¬ì´ ê°ë„ì˜ ì½”ì‚¬ì¸ ê°’\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "```python\n",
    "# numpyë§Œ ì‚¬ìš©\n",
    "def cosine_sim(A, B):\n",
    "    return np.dot(A, B) / (np.sqrt(np.sum(A**2)) * np.sqrt(np.sum(B**2)))\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. 5ì  ì²™ë„ ê°ì„± ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: LLMì´ 1~5ì ìœ¼ë¡œ ê°ì„±ì„ í‰ê°€í•˜ê³  ì´ìœ ë„ ì„¤ëª…í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì •ë‹µ\n",
    "text = \"ë°°ì†¡ì€ ë¹¨ëëŠ”ë° ì œí’ˆ í’ˆì§ˆì´ ê¸°ëŒ€ì— ëª» ë¯¸ì³ìš”.\"\n",
    "\n",
    "prompt = f\"\"\"ë‹¤ìŒ ê³ ê° ë¦¬ë·°ì˜ ê°ì„±ì„ 1~5ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "í‰ê°€ ê¸°ì¤€:\n",
    "1ì : ë§¤ìš° ë¶€ì • (ë¶ˆë§Œ, í™˜ë¶ˆ ìš”ì²­ ìˆ˜ì¤€)\n",
    "2ì : ë¶€ì • (ì‹¤ë§, ì•„ì‰¬ì›€)\n",
    "3ì : ì¤‘ë¦½ (ë³´í†µ, ë¬´ë‚œí•¨)\n",
    "4ì : ê¸ì • (ë§Œì¡±, ì¢‹ìŒ)\n",
    "5ì : ë§¤ìš° ê¸ì • (ê°ë™, ìµœê³ )\n",
    "\n",
    "ë¦¬ë·°: {text}\n",
    "\n",
    "ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:\n",
    "ì ìˆ˜: [1-5 ì‚¬ì´ ìˆ«ì]\n",
    "ì´ìœ : [í•œ ë¬¸ì¥ìœ¼ë¡œ í‰ê°€ ê·¼ê±°]\"\"\"\n",
    "\n",
    "print(\"ì‘ì„±ëœ í”„ë¡¬í”„íŠ¸:\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "if client:\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-exp\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    print(f\"LLM ì‘ë‹µ:\\n{response.text.strip()}\")\n",
    "else:\n",
    "    print(\"ê¸°ëŒ€ ì‘ë‹µ:\")\n",
    "    print(\"ì ìˆ˜: 3\")\n",
    "    print(\"ì´ìœ : ë°°ì†¡ì€ ê¸ì •ì ì´ë‚˜ í’ˆì§ˆ ë¶ˆë§Œì¡±ìœ¼ë¡œ ì¤‘ë¦½ ìˆ˜ì¤€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q4 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- ëª…í™•í•œ í‰ê°€ ê¸°ì¤€ ì œì‹œ (1~5ì  ê°ê° ì •ì˜)\n",
    "- ì¶œë ¥ í˜•ì‹ ì§€ì •ìœ¼ë¡œ íŒŒì‹± ìš©ì´\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- í”„ë¡¬í”„íŠ¸ì— í‰ê°€ ê¸°ì¤€ì„ ëª…ì‹œí•˜ë©´ ì¼ê´€ì„± í–¥ìƒ\n",
    "- ì´ìœ ë¥¼ í•¨ê»˜ ìš”ì²­í•˜ë©´ í•´ì„ ê°€ëŠ¥ì„± í™•ë³´\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë„ë©”ì¸ì— ë§ëŠ” í‰ê°€ ê¸°ì¤€ ì •ì˜\n",
    "- JSON í˜•ì‹ìœ¼ë¡œ ìš”ì²­í•˜ë©´ íŒŒì‹±ì´ ë” ì‰¬ì›€\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. ì¸¡ë©´(Aspect) ê¸°ë°˜ ê°ì„± ë¶„ì„ í”„ë¡¬í”„íŠ¸ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë¦¬ë·°ì—ì„œ ì—¬ëŸ¬ ì¸¡ë©´ë³„ë¡œ ê°ì„±ì„ ì¶”ì¶œí•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì •ë‹µ\n",
    "text = \"ë°°ì†¡ì€ ë¹ ë¥´ê³  ì¢‹ì•˜ì–´ìš”. ê·¼ë° í’ˆì§ˆì´ ë³„ë¡œê³  ê°€ê²©ë„ ë¹„ì‹¸ë„¤ìš”.\"\n",
    "\n",
    "prompt = f\"\"\"ë‹¤ìŒ ê³ ê° ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ê° ì¸¡ë©´(aspect)ë³„ë¡œ ê°ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë¶„ì„ ê°€ëŠ¥í•œ ì¸¡ë©´: ë°°ì†¡, í’ˆì§ˆ, ê°€ê²©, ì„œë¹„ìŠ¤, ë””ìì¸, ê¸°ëŠ¥ ë“±\n",
    "\n",
    "ë¦¬ë·°: {text}\n",
    "\n",
    "ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš” (ì–¸ê¸‰ëœ ì¸¡ë©´ë§Œ):\n",
    "- [ì¸¡ë©´]: [ê¸ì •/ë¶€ì •/ì¤‘ë¦½]\n",
    "\n",
    "ë§ˆì§€ë§‰ì— ì „ì²´ ê°ì„±ë„ íŒë‹¨í•´ì£¼ì„¸ìš”:\n",
    "ì „ì²´ ê°ì„±: [ê¸ì •/ë¶€ì •/ì¤‘ë¦½]\"\"\"\n",
    "\n",
    "print(\"ì‘ì„±ëœ í”„ë¡¬í”„íŠ¸:\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "if client:\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-exp\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    print(f\"LLM ì‘ë‹µ:\\n{response.text.strip()}\")\n",
    "else:\n",
    "    print(\"ê¸°ëŒ€ ì‘ë‹µ:\")\n",
    "    print(\"- ë°°ì†¡: ê¸ì •\")\n",
    "    print(\"- í’ˆì§ˆ: ë¶€ì •\")\n",
    "    print(\"- ê°€ê²©: ë¶€ì •\")\n",
    "    print(\"ì „ì²´ ê°ì„±: ë¶€ì •\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q5 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- ì¸¡ë©´ ëª©ë¡ ì œì‹œë¡œ ë¶„ì„ ë²”ìœ„ ê°€ì´ë“œ\n",
    "- ì¸¡ë©´ë³„ ê°ì„± + ì „ì²´ ê°ì„± ìš”ì²­\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ABSA (Aspect-Based Sentiment Analysis)\n",
    "- ë‹¨ìˆœ ê¸ì •/ë¶€ì •ë³´ë‹¤ ìƒì„¸í•œ ì¸ì‚¬ì´íŠ¸\n",
    "\n",
    "**ì‹¤ë¬´ í™œìš©**:\n",
    "- ì œí’ˆ ê°œì„ ì  íŒŒì•… (ì–´ë–¤ ì¸¡ë©´ì´ ë¶€ì •ì¸ì§€)\n",
    "- ê²½ìŸì‚¬ ë¹„êµ (ì¸¡ë©´ë³„ ë¹„êµ ê°€ëŠ¥)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. ë°°ì¹˜ ê°ì„± ë¶„ì„ í•¨ìˆ˜ ê°œì„  â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì§„í–‰ë¥  í‘œì‹œì™€ ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ì¶”ê°€í•œ ë°°ì¹˜ ë¶„ì„ í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì •ë‹µ\n",
    "def analyze_batch_improved(texts, max_retries=3, delay=1):\n",
    "    \"\"\"\n",
    "    ê°œì„ ëœ ë°°ì¹˜ ê°ì„± ë¶„ì„ í•¨ìˆ˜\n",
    "    \n",
    "    Parameters:\n",
    "    - texts: í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
    "    - max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜\n",
    "    - delay: API í˜¸ì¶œ ê°„ ëŒ€ê¸° ì‹œê°„\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: ë¶„ì„ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total = len(texts)\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        # ì§„í–‰ë¥  í‘œì‹œ\n",
    "        print(f\"ì§„í–‰ ì¤‘: {i+1}/{total} ({(i+1)/total*100:.1f}%)\", end=\"\\r\")\n",
    "        \n",
    "        sentiment = None\n",
    "        \n",
    "        # ì¬ì‹œë„ ë¡œì§\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                if client:\n",
    "                    prompt = f\"\"\"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µí•˜ì„¸ìš”.\n",
    "í…ìŠ¤íŠ¸: {text}\n",
    "ê°ì„±:\"\"\"\n",
    "                    response = client.models.generate_content(\n",
    "                        model=\"gemini-2.0-flash-exp\",\n",
    "                        contents=prompt\n",
    "                    )\n",
    "                    sentiment = response.text.strip()\n",
    "                    break  # ì„±ê³µí•˜ë©´ ë£¨í”„ ì¢…ë£Œ\n",
    "                else:\n",
    "                    sentiment = \"API ë¯¸ì„¤ì •\"\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"\\n  {i+1}ë²ˆ í•­ëª© ì¬ì‹œë„ {attempt+1}/{max_retries}: {str(e)[:30]}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(delay * 2)  # ì¬ì‹œë„ ì‹œ ëŒ€ê¸° ì‹œê°„ ëŠ˜ë¦¼\n",
    "        \n",
    "        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ\n",
    "        if sentiment is None:\n",
    "            sentiment = \"error\"\n",
    "        \n",
    "        results.append({\n",
    "            \"text\": text,\n",
    "            \"sentiment\": sentiment\n",
    "        })\n",
    "        \n",
    "        # ë‹¤ìŒ í˜¸ì¶œ ì „ ëŒ€ê¸°\n",
    "        if i < total - 1:\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    print(f\"\\nì™„ë£Œ! {total}ê°œ ë¶„ì„ë¨\")\n",
    "    \n",
    "    # ì—ëŸ¬ í†µê³„\n",
    "    errors = sum(1 for r in results if r['sentiment'] == 'error')\n",
    "    if errors > 0:\n",
    "        print(f\"  (ì—ëŸ¬: {errors}ê°œ)\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_texts = [\n",
    "    \"ì¢‹ì•„ìš”!\",\n",
    "    \"ë³„ë¡œì˜ˆìš”.\",\n",
    "    \"ê·¸ëƒ¥ ê·¸ë˜ìš”.\"\n",
    "]\n",
    "\n",
    "results = analyze_batch_improved(test_texts)\n",
    "print(\"\\nê²°ê³¼:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q6 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- `\\r`ë¡œ ê°™ì€ ì¤„ì— ì§„í–‰ë¥  ì—…ë°ì´íŠ¸\n",
    "- try-exceptë¡œ ì—ëŸ¬ ì²˜ë¦¬\n",
    "- for ë£¨í”„ë¡œ ì¬ì‹œë„ êµ¬í˜„\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- API í˜¸ì¶œì€ í•­ìƒ ì‹¤íŒ¨ ê°€ëŠ¥ì„± ê³ ë ¤\n",
    "- ì¬ì‹œë„ ì‹œ ëŒ€ê¸° ì‹œê°„ ëŠ˜ë¦¼ (exponential backoff)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ëŒ€ëŸ‰ ì²˜ë¦¬ ì‹œ ì¤‘ê°„ ê²°ê³¼ ì €ì¥\n",
    "- ë¡œê¹… ì¶”ê°€ë¡œ ë””ë²„ê¹… ìš©ì´\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7. ì„ë² ë”© ê¸°ë°˜ ê°ì„± ê°•ë„ ì¸¡ì • â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ -1 ~ +1 ì—°ì† ê°ì„± ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì •ë‹µ\n",
    "\n",
    "# ì„ë² ë”© í•¨ìˆ˜ ì„ íƒ\n",
    "if local_embedding_available:\n",
    "    def get_embedding(text):\n",
    "        return local_model.encode(text)\n",
    "    print(\"ë¡œì»¬ ì„ë² ë”© ì‚¬ìš©\")\n",
    "else:\n",
    "    def get_embedding(text):\n",
    "        return np.random.randn(768)  # ì‹œë®¬ë ˆì´ì…˜\n",
    "    print(\"ì‹œë®¬ë ˆì´ì…˜ ì„ë² ë”© ì‚¬ìš©\")\n",
    "\n",
    "\n",
    "def calculate_sentiment_score(text, pos_ref_emb, neg_ref_emb):\n",
    "    \"\"\"\n",
    "    ì„ë² ë”© ê¸°ë°˜ ê°ì„± ì ìˆ˜ ê³„ì‚° (-1 ~ +1)\n",
    "    \n",
    "    Parameters:\n",
    "    - text: ë¶„ì„í•  í…ìŠ¤íŠ¸\n",
    "    - pos_ref_emb: ê¸ì • ì°¸ì¡° ì„ë² ë”©\n",
    "    - neg_ref_emb: ë¶€ì • ì°¸ì¡° ì„ë² ë”©\n",
    "    \n",
    "    Returns:\n",
    "    - float: ê°ì„± ì ìˆ˜ (-1: ë§¤ìš° ë¶€ì •, +1: ë§¤ìš° ê¸ì •)\n",
    "    \"\"\"\n",
    "    # ëŒ€ìƒ í…ìŠ¤íŠ¸ ì„ë² ë”©\n",
    "    text_emb = get_embedding(text).reshape(1, -1)\n",
    "    \n",
    "    # ê¸ì •/ë¶€ì • ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    pos_sim = cosine_similarity(text_emb, pos_ref_emb.reshape(1, -1))[0][0]\n",
    "    neg_sim = cosine_similarity(text_emb, neg_ref_emb.reshape(1, -1))[0][0]\n",
    "    \n",
    "    # ê°ì„± ì ìˆ˜: ê¸ì • ìœ ì‚¬ë„ - ë¶€ì • ìœ ì‚¬ë„\n",
    "    score = pos_sim - neg_sim\n",
    "    \n",
    "    # -1 ~ +1 ë²”ìœ„ë¡œ í´ë¦¬í•‘ (ì„ íƒì‚¬í•­)\n",
    "    score = max(-1, min(1, score))\n",
    "    \n",
    "    return score, pos_sim, neg_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì°¸ì¡° ì„ë² ë”© ìƒì„±\n",
    "positive_texts = [\"ì •ë§ ì¢‹ì•„ìš”!\", \"ìµœê³ ì˜ˆìš”!\", \"ë§Œì¡±í•©ë‹ˆë‹¤!\"]\n",
    "negative_texts = [\"ë³„ë¡œì˜ˆìš”.\", \"ì‹¤ë§ì…ë‹ˆë‹¤.\", \"ìµœì•…ì´ì—ìš”.\"]\n",
    "\n",
    "# í‰ê·  ì„ë² ë”©\n",
    "pos_embeddings = np.array([get_embedding(t) for t in positive_texts])\n",
    "neg_embeddings = np.array([get_embedding(t) for t in negative_texts])\n",
    "\n",
    "pos_ref = np.mean(pos_embeddings, axis=0)\n",
    "neg_ref = np.mean(neg_embeddings, axis=0)\n",
    "\n",
    "print(\"ì°¸ì¡° ì„ë² ë”© ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "test_reviews = [\n",
    "    \"ì™„ì „ ëŒ€ë°•ì´ì—ìš”! ìµœê³ !\",\n",
    "    \"ê´œì°®ì•„ìš”. ë‚˜ì˜ì§€ ì•Šì•„ìš”.\",\n",
    "    \"ë³„ë¡œì˜ˆìš”. ê¸°ëŒ€ ì´í•˜ì…ë‹ˆë‹¤.\",\n",
    "    \"ìµœì•…ì´ì—ìš”. ëˆ ì•„ê¹Œì›Œìš”.\"\n",
    "]\n",
    "\n",
    "print(\"ê°ì„± ì ìˆ˜ ê³„ì‚° ê²°ê³¼\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for review in test_reviews:\n",
    "    score, pos_sim, neg_sim = calculate_sentiment_score(review, pos_ref, neg_ref)\n",
    "    print(f\"\\në¦¬ë·°: {review}\")\n",
    "    print(f\"  ê¸ì • ìœ ì‚¬ë„: {pos_sim:.3f}\")\n",
    "    print(f\"  ë¶€ì • ìœ ì‚¬ë„: {neg_sim:.3f}\")\n",
    "    print(f\"  ê°ì„± ì ìˆ˜: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q7 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- ê¸ì •/ë¶€ì • ì°¸ì¡° ì„ë² ë”© ìƒì„±\n",
    "- ëŒ€ìƒ í…ìŠ¤íŠ¸ì™€ ê°ê° ìœ ì‚¬ë„ ê³„ì‚°\n",
    "- ì°¨ì´ê°’ìœ¼ë¡œ ì—°ì† ì ìˆ˜ ì‚°ì¶œ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ì„ë² ë”© ê³µê°„ì—ì„œ ê¸ì •/ë¶€ì • ë°©í–¥ ì •ì˜\n",
    "- ìƒëŒ€ì  ìœ ì‚¬ë„ë¡œ ì¤‘ê°„ê°’ë„ í‘œí˜„ ê°€ëŠ¥\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì°¸ì¡° í…ìŠ¤íŠ¸ ë‹¤ì–‘í•˜ê²Œ ì„ ì •\n",
    "- ë„ë©”ì¸ë³„ ì°¸ì¡° ì„¸íŠ¸ êµ¬ì„±\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8. LLM vs ì„ë² ë”© ë¹„êµ ë¶„ì„ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‘ ë°©ì‹ì˜ ê²°ê³¼ë¥¼ ë¹„êµ ì‹œê°í™”í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì •ë‹µ\n",
    "comparison_reviews = [\n",
    "    \"ì™„ì „ ë§Œì¡±í•´ìš”! ìµœê³ ì˜ êµ¬ë§¤ì˜€ì–´ìš”.\",\n",
    "    \"ëˆ ì•„ê¹Œì›Œìš”. ì‹¤ë§ì…ë‹ˆë‹¤.\",\n",
    "    \"ê·¸ëƒ¥ ê·¸ë˜ìš”. ë³´í†µì´ì—ìš”.\",\n",
    "    \"ë°°ì†¡ì€ ë¹¨ëëŠ”ë° í’ˆì§ˆì´...\",\n",
    "    \"ê°€ì„±ë¹„ ì¢‹ì•„ìš”! ì¶”ì²œí•©ë‹ˆë‹¤.\",\n",
    "    \"ê¸°ëŒ€í–ˆëŠ”ë° ë³„ë¡œë„¤ìš”.\",\n",
    "    \"ë‚˜ì˜ì§€ ì•Šì•„ìš”.\",\n",
    "    \"ìµœì•…ì´ì—ìš”. í™˜ë¶ˆí–ˆì–´ìš”.\",\n",
    "    \"ë””ìì¸ ì˜ˆì˜ê³  ê¸°ëŠ¥ë„ ì¢‹ì•„ìš”.\",\n",
    "    \"ê°€ê²©ë§Œ ì¢€ ì €ë ´í•˜ë©´ ì¢‹ê² ì–´ìš”.\"\n",
    "]\n",
    "\n",
    "# ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ (API ì—†ì„ ë•Œ)\n",
    "llm_results = [\"ê¸ì •\", \"ë¶€ì •\", \"ì¤‘ë¦½\", \"ë¶€ì •\", \"ê¸ì •\", \"ë¶€ì •\", \"ì¤‘ë¦½\", \"ë¶€ì •\", \"ê¸ì •\", \"ì¤‘ë¦½\"]\n",
    "emb_results = [\"ê¸ì •\", \"ë¶€ì •\", \"ì¤‘ë¦½\", \"ì¤‘ë¦½\", \"ê¸ì •\", \"ë¶€ì •\", \"ê¸ì •\", \"ë¶€ì •\", \"ê¸ì •\", \"ë¶€ì •\"]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'review': comparison_reviews,\n",
    "    'LLM': llm_results,\n",
    "    'Embedding': emb_results\n",
    "})\n",
    "\n",
    "# ì¼ì¹˜ ì—¬ë¶€\n",
    "comparison_df['ì¼ì¹˜'] = comparison_df['LLM'] == comparison_df['Embedding']\n",
    "\n",
    "print(\"ë¹„êµ ê²°ê³¼:\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¼ì¹˜ìœ¨ ê³„ì‚°\n",
    "agreement_rate = comparison_df['ì¼ì¹˜'].mean() * 100\n",
    "print(f\"\\nì¼ì¹˜ìœ¨: {agreement_rate:.1f}%\")\n",
    "\n",
    "# ë¶ˆì¼ì¹˜ í•­ëª©\n",
    "disagreements = comparison_df[~comparison_df['ì¼ì¹˜']]\n",
    "print(f\"\\në¶ˆì¼ì¹˜ í•­ëª© ({len(disagreements)}ê°œ):\")\n",
    "for _, row in disagreements.iterrows():\n",
    "    print(f\"  ë¦¬ë·°: {row['review'][:30]}...\")\n",
    "    print(f\"    LLM: {row['LLM']}, ì„ë² ë”©: {row['Embedding']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('LLM ë¶„ë¥˜ ë¶„í¬', 'ì„ë² ë”© ë¶„ë¥˜ ë¶„í¬')\n",
    ")\n",
    "\n",
    "colors = {'ê¸ì •': '#2ecc71', 'ë¶€ì •': '#e74c3c', 'ì¤‘ë¦½': '#95a5a6'}\n",
    "\n",
    "# LLM ë¶„í¬\n",
    "llm_counts = comparison_df['LLM'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=llm_counts.index,\n",
    "        y=llm_counts.values,\n",
    "        marker_color=[colors.get(s, '#333') for s in llm_counts.index],\n",
    "        name='LLM'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# ì„ë² ë”© ë¶„í¬\n",
    "emb_counts = comparison_df['Embedding'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=emb_counts.index,\n",
    "        y=emb_counts.values,\n",
    "        marker_color=[colors.get(s, '#333') for s in emb_counts.index],\n",
    "        name='ì„ë² ë”©'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'LLM vs ì„ë² ë”© ë¶„ë¥˜ ë¹„êµ (ì¼ì¹˜ìœ¨: {agreement_rate:.1f}%)',\n",
    "    showlegend=False,\n",
    "    width=800,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q8 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- ë™ì¼ ë°ì´í„°ì— ë‘ ë°©ì‹ ì ìš©\n",
    "- ì¼ì¹˜/ë¶ˆì¼ì¹˜ ë¶„ì„\n",
    "- ì‹œê°í™”ë¡œ íŒ¨í„´ ë¹„êµ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ë°©ì‹ ê°„ ì¼ì¹˜ìœ¨ = ì‹ ë¢°ë„ ì§€í‘œ\n",
    "- ë¶ˆì¼ì¹˜ ì¼€ì´ìŠ¤ = ê²½ê³„ ì‚¬ë¡€ íŒŒì•…\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë¶ˆì¼ì¹˜ ì¼€ì´ìŠ¤ ìˆ˜ë™ ê²€í† \n",
    "- ì•™ìƒë¸”ë¡œ ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9. ì¢…í•© ê°ì„± ë¶„ì„ íŒŒì´í”„ë¼ì¸ â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: LLM + ì„ë² ë”© ì•™ìƒë¸” ë¶„ë¥˜ê¸°ë¥¼ êµ¬í˜„í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì •ë‹µ\n",
    "class AdvancedSentimentAnalyzer:\n",
    "    \"\"\"\n",
    "    ì¢…í•© ê°ì„± ë¶„ì„ê¸°\n",
    "    - LLM (Zero-shot/Few-shot)\n",
    "    - ì„ë² ë”© ê¸°ë°˜\n",
    "    - ì•™ìƒë¸”\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_func=None):\n",
    "        self.embedding_func = embedding_func or get_embedding\n",
    "        self.pos_ref = None\n",
    "        self.neg_ref = None\n",
    "        self.neu_ref = None\n",
    "    \n",
    "    def fit(self, positive_texts, negative_texts, neutral_texts=None):\n",
    "        \"\"\"ì°¸ì¡° ì„ë² ë”© ìƒì„±\"\"\"\n",
    "        pos_embs = np.array([self.embedding_func(t) for t in positive_texts])\n",
    "        neg_embs = np.array([self.embedding_func(t) for t in negative_texts])\n",
    "        \n",
    "        self.pos_ref = np.mean(pos_embs, axis=0)\n",
    "        self.neg_ref = np.mean(neg_embs, axis=0)\n",
    "        \n",
    "        if neutral_texts:\n",
    "            neu_embs = np.array([self.embedding_func(t) for t in neutral_texts])\n",
    "            self.neu_ref = np.mean(neu_embs, axis=0)\n",
    "        \n",
    "        print(\"ì°¸ì¡° ì„ë² ë”© ìƒì„± ì™„ë£Œ\")\n",
    "    \n",
    "    def _analyze_llm(self, text):\n",
    "        \"\"\"LLM ë¶„ì„\"\"\"\n",
    "        if not client:\n",
    "            return None\n",
    "        \n",
    "        prompt = f\"\"\"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µí•˜ì„¸ìš”.\n",
    "í…ìŠ¤íŠ¸: {text}\n",
    "ê°ì„±:\"\"\"\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash-exp\",\n",
    "                contents=prompt\n",
    "            )\n",
    "            return response.text.strip()\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def _analyze_embedding(self, text):\n",
    "        \"\"\"ì„ë² ë”© ë¶„ì„\"\"\"\n",
    "        if self.pos_ref is None:\n",
    "            return None, {}\n",
    "        \n",
    "        text_emb = self.embedding_func(text).reshape(1, -1)\n",
    "        \n",
    "        sims = {\n",
    "            'ê¸ì •': cosine_similarity(text_emb, self.pos_ref.reshape(1, -1))[0][0],\n",
    "            'ë¶€ì •': cosine_similarity(text_emb, self.neg_ref.reshape(1, -1))[0][0]\n",
    "        }\n",
    "        \n",
    "        if self.neu_ref is not None:\n",
    "            sims['ì¤‘ë¦½'] = cosine_similarity(text_emb, self.neu_ref.reshape(1, -1))[0][0]\n",
    "        \n",
    "        prediction = max(sims, key=sims.get)\n",
    "        return prediction, sims\n",
    "    \n",
    "    def analyze(self, text, method='ensemble'):\n",
    "        \"\"\"\n",
    "        í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„\n",
    "        \n",
    "        Parameters:\n",
    "        - text: ë¶„ì„í•  í…ìŠ¤íŠ¸\n",
    "        - method: 'llm', 'embedding', 'ensemble'\n",
    "        \n",
    "        Returns:\n",
    "        - dict: ë¶„ì„ ê²°ê³¼\n",
    "        \"\"\"\n",
    "        result = {'text': text, 'method': method}\n",
    "        \n",
    "        if method == 'llm':\n",
    "            result['prediction'] = self._analyze_llm(text)\n",
    "            result['confidence'] = 'high' if result['prediction'] else 'error'\n",
    "        \n",
    "        elif method == 'embedding':\n",
    "            pred, sims = self._analyze_embedding(text)\n",
    "            result['prediction'] = pred\n",
    "            result['similarities'] = sims\n",
    "            if sims:\n",
    "                max_sim = max(sims.values())\n",
    "                result['confidence'] = 'high' if max_sim > 0.7 else 'medium' if max_sim > 0.5 else 'low'\n",
    "        \n",
    "        elif method == 'ensemble':\n",
    "            llm_pred = self._analyze_llm(text)\n",
    "            emb_pred, sims = self._analyze_embedding(text)\n",
    "            \n",
    "            result['llm_prediction'] = llm_pred\n",
    "            result['embedding_prediction'] = emb_pred\n",
    "            result['similarities'] = sims\n",
    "            \n",
    "            # ì•™ìƒë¸”: ì¼ì¹˜í•˜ë©´ í•´ë‹¹ ê°’, ë¶ˆì¼ì¹˜í•˜ë©´ ì„ë² ë”© ìš°ì„ \n",
    "            if llm_pred == emb_pred:\n",
    "                result['prediction'] = llm_pred\n",
    "                result['confidence'] = 'high'\n",
    "            else:\n",
    "                result['prediction'] = emb_pred or llm_pred\n",
    "                result['confidence'] = 'medium'\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def analyze_batch(self, texts, method='ensemble'):\n",
    "        \"\"\"ë°°ì¹˜ ë¶„ì„\"\"\"\n",
    "        results = []\n",
    "        for i, text in enumerate(texts):\n",
    "            print(f\"ì§„í–‰: {i+1}/{len(texts)}\", end=\"\\r\")\n",
    "            result = self.analyze(text, method)\n",
    "            results.append(result)\n",
    "            if client and method in ['llm', 'ensemble']:\n",
    "                time.sleep(1)\n",
    "        print(f\"\\nì™„ë£Œ: {len(texts)}ê°œ\")\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "analyzer = AdvancedSentimentAnalyzer()\n",
    "\n",
    "# í•™ìŠµ\n",
    "analyzer.fit(\n",
    "    positive_texts=[\"ì¢‹ì•„ìš”!\", \"ìµœê³ ì˜ˆìš”!\", \"ë§Œì¡±í•©ë‹ˆë‹¤!\"],\n",
    "    negative_texts=[\"ë³„ë¡œì˜ˆìš”.\", \"ì‹¤ë§ì…ë‹ˆë‹¤.\", \"ìµœì•…ì´ì—ìš”.\"],\n",
    "    neutral_texts=[\"ê·¸ëƒ¥ ê·¸ë˜ìš”.\", \"ë³´í†µì´ì—ìš”.\", \"ë¬´ë‚œí•´ìš”.\"]\n",
    ")\n",
    "\n",
    "# ë¶„ì„\n",
    "test_text = \"ê°€ê²©ì€ ë¹„ì‹¸ì§€ë§Œ í’ˆì§ˆì´ ì¢‹ì•„ìš”.\"\n",
    "\n",
    "print(\"\\nì„ë² ë”© ë¶„ì„:\")\n",
    "print(analyzer.analyze(test_text, method='embedding'))\n",
    "\n",
    "if client:\n",
    "    print(\"\\nLLM ë¶„ì„:\")\n",
    "    print(analyzer.analyze(test_text, method='llm'))\n",
    "    \n",
    "    print(\"\\nì•™ìƒë¸” ë¶„ì„:\")\n",
    "    print(analyzer.analyze(test_text, method='ensemble'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q9 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- í´ë˜ìŠ¤ë¡œ ìƒíƒœ ê´€ë¦¬ (ì°¸ì¡° ì„ë² ë”©)\n",
    "- ë©”ì„œë“œë³„ ë¶„ì„ ë¡œì§ ë¶„ë¦¬\n",
    "- ì•™ìƒë¸”: ì¼ì¹˜=high, ë¶ˆì¼ì¹˜=medium\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ì•™ìƒë¸”: ì—¬ëŸ¬ ëª¨ë¸ ê²°ê³¼ ì¢…í•©\n",
    "- ì‹ ë¢°ë„: ì¼ì¹˜ ì—¬ë¶€ë¡œ íŒë‹¨\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë¶ˆì¼ì¹˜ ì‹œ ì‚¬ëŒ ê²€í†  í”Œë˜ê·¸\n",
    "- ë„ë©”ì¸ë³„ ê°€ì¤‘ì¹˜ ì¡°ì •\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10. ê°ì„± ë¶„ì„ ëŒ€ì‹œë³´ë“œ â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì¢…í•© ëŒ€ì‹œë³´ë“œë¥¼ ë§Œë“œì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì •ë‹µ\n",
    "dashboard_reviews = [\n",
    "    \"ì •ë§ ì¢‹ì•„ìš”! ë§Œì¡±í•©ë‹ˆë‹¤.\",\n",
    "    \"ë³„ë¡œì˜ˆìš”. ì‹¤ë§ì…ë‹ˆë‹¤.\",\n",
    "    \"ê·¸ëƒ¥ ê·¸ë˜ìš”.\",\n",
    "    \"ìµœê³ ì˜ ì„ íƒì´ì—ˆì–´ìš”!\",\n",
    "    \"ëˆ ì•„ê¹Œì›Œìš”.\",\n",
    "    \"ê°€ê²© ëŒ€ë¹„ ê´œì°®ì•„ìš”.\",\n",
    "    \"ë‹¤ì‹œëŠ” ì•ˆ ì‚´ ê±°ì˜ˆìš”.\",\n",
    "    \"ì¶”ì²œí•©ë‹ˆë‹¤!\",\n",
    "    \"ë³´í†µì´ì—ìš”.\",\n",
    "    \"ì™„ì „ ì‹¤ë§ì´ì—ìš”.\",\n",
    "    \"ê¸°ëŒ€ ì´ìƒì´ì—ìš”!\",\n",
    "    \"ê·¸ëƒ¥ ë¬´ë‚œí•´ìš”.\"\n",
    "]\n",
    "\n",
    "# ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼\n",
    "analysis_results = pd.DataFrame({\n",
    "    'review': dashboard_reviews,\n",
    "    'llm_pred': ['ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½', 'ê¸ì •', 'ë¶€ì •', 'ê¸ì •', 'ë¶€ì •', 'ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •', 'ê¸ì •', 'ì¤‘ë¦½'],\n",
    "    'emb_pred': ['ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½', 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½', 'ë¶€ì •', 'ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •', 'ê¸ì •', 'ê¸ì •'],\n",
    "    'sentiment_score': [0.8, -0.7, 0.1, 0.9, -0.8, 0.3, -0.9, 0.7, 0.0, -0.85, 0.75, 0.15]\n",
    "})\n",
    "\n",
    "# ì•™ìƒë¸” ê²°ê³¼\n",
    "analysis_results['ensemble'] = analysis_results.apply(\n",
    "    lambda row: row['llm_pred'] if row['llm_pred'] == row['emb_pred'] else row['emb_pred'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "analysis_results['agree'] = analysis_results['llm_pred'] == analysis_results['emb_pred']\n",
    "\n",
    "print(\"ë¶„ì„ ë°ì´í„°:\")\n",
    "print(analysis_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€ì‹œë³´ë“œ ìƒì„±\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    specs=[[{'type': 'pie'}, {'type': 'bar'}],\n",
    "           [{'type': 'bar'}, {'type': 'histogram'}]],\n",
    "    subplot_titles=('ì „ì²´ ê°ì„± ë¶„í¬', 'LLM vs ì„ë² ë”© ë¹„êµ',\n",
    "                   'ê°ì„±ë³„ í‰ê·  ì ìˆ˜', 'ê°ì„± ì ìˆ˜ ë¶„í¬')\n",
    ")\n",
    "\n",
    "colors = {'ê¸ì •': '#2ecc71', 'ë¶€ì •': '#e74c3c', 'ì¤‘ë¦½': '#95a5a6'}\n",
    "\n",
    "# 1. ì „ì²´ ê°ì„± ë¶„í¬ (íŒŒì´)\n",
    "ensemble_counts = analysis_results['ensemble'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=ensemble_counts.index,\n",
    "        values=ensemble_counts.values,\n",
    "        marker_colors=[colors.get(s, '#333') for s in ensemble_counts.index],\n",
    "        hole=0.4\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 2. LLM vs ì„ë² ë”© ë¹„êµ (ê·¸ë£¹ ë§‰ëŒ€)\n",
    "llm_counts = analysis_results['llm_pred'].value_counts()\n",
    "emb_counts = analysis_results['emb_pred'].value_counts()\n",
    "\n",
    "for sentiment in ['ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½']:\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=['LLM', 'ì„ë² ë”©'],\n",
    "            y=[llm_counts.get(sentiment, 0), emb_counts.get(sentiment, 0)],\n",
    "            name=sentiment,\n",
    "            marker_color=colors[sentiment],\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# 3. ê°ì„±ë³„ í‰ê·  ì ìˆ˜\n",
    "sentiment_scores = analysis_results.groupby('ensemble')['sentiment_score'].mean()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=sentiment_scores.index,\n",
    "        y=sentiment_scores.values,\n",
    "        marker_color=[colors.get(s, '#333') for s in sentiment_scores.index],\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 4. ê°ì„± ì ìˆ˜ ë¶„í¬ (íˆìŠ¤í† ê·¸ë¨)\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=analysis_results['sentiment_score'],\n",
    "        nbinsx=10,\n",
    "        marker_color='#3498db',\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ê°ì„± ë¶„ì„ ì¢…í•© ëŒ€ì‹œë³´ë“œ',\n",
    "    height=700,\n",
    "    width=1000,\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¸ì‚¬ì´íŠ¸ ë„ì¶œ\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Š ì¸ì‚¬ì´íŠ¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ì¸ì‚¬ì´íŠ¸ 1: ì „ì²´ ê°ì„± ë¶„í¬\n",
    "total = len(analysis_results)\n",
    "positive_rate = (analysis_results['ensemble'] == 'ê¸ì •').sum() / total * 100\n",
    "negative_rate = (analysis_results['ensemble'] == 'ë¶€ì •').sum() / total * 100\n",
    "\n",
    "print(f\"\\n1. ì „ì²´ ê°ì„± ë¶„í¬\")\n",
    "print(f\"   - ê¸ì • ë¹„ìœ¨: {positive_rate:.1f}%\")\n",
    "print(f\"   - ë¶€ì • ë¹„ìœ¨: {negative_rate:.1f}%\")\n",
    "print(f\"   â†’ {'ê¸ì • ìš°ì„¸' if positive_rate > negative_rate else 'ë¶€ì • ìš°ì„¸'}\")\n",
    "\n",
    "# ì¸ì‚¬ì´íŠ¸ 2: LLM vs ì„ë² ë”© ì¼ì¹˜ìœ¨\n",
    "agreement_rate = analysis_results['agree'].mean() * 100\n",
    "print(f\"\\n2. ë°©ë²• ê°„ ì¼ì¹˜ìœ¨: {agreement_rate:.1f}%\")\n",
    "print(f\"   â†’ {'ë†’ì€ ì‹ ë¢°ë„' if agreement_rate >= 80 else 'ê²€í†  í•„ìš” ì¼€ì´ìŠ¤ ìˆìŒ'}\")\n",
    "\n",
    "# ì¸ì‚¬ì´íŠ¸ 3: í‰ê·  ê°ì„± ì ìˆ˜\n",
    "avg_score = analysis_results['sentiment_score'].mean()\n",
    "print(f\"\\n3. í‰ê·  ê°ì„± ì ìˆ˜: {avg_score:.2f}\")\n",
    "print(f\"   â†’ {'ê¸ì •ì  ê²½í–¥' if avg_score > 0 else 'ë¶€ì •ì  ê²½í–¥'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q10 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- make_subplotsë¡œ 2x2 ë ˆì´ì•„ì›ƒ\n",
    "- ë‹¤ì–‘í•œ ì°¨íŠ¸ ìœ í˜• ì¡°í•©\n",
    "- ì¸ì‚¬ì´íŠ¸ ìë™ ë„ì¶œ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ëŒ€ì‹œë³´ë“œ: ì—¬ëŸ¬ ì‹œê°í™” í•œ í™”ë©´ êµ¬ì„±\n",
    "- ì¸ì‚¬ì´íŠ¸: ë°ì´í„°ì—ì„œ ì˜ë¯¸ ì¶”ì¶œ\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- í•µì‹¬ ì§€í‘œ ìƒë‹¨ ë°°ì¹˜\n",
    "- ì•¡ì…˜ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì œê³µ\n",
    "- ì‹œê°„ ë³€í™” ì¶”ì´ ì¶”ê°€ ê³ ë ¤\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "### í€´ì¦ˆ í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| í€´ì¦ˆ | í•µì‹¬ ê°œë… | ë‚œì´ë„ |\n",
    "|------|----------|--------|\n",
    "| Q1 | Zero-shot í”„ë¡¬í”„íŠ¸ ì‘ì„± | â­ |\n",
    "| Q2 | Few-shot ì˜ˆì œ êµ¬ì„± | â­â­ |\n",
    "| Q3 | ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ìˆ˜ì‹ | â­â­ |\n",
    "| Q4 | 5ì  ì²™ë„ í”„ë¡¬í”„íŠ¸ | â­â­â­ |\n",
    "| Q5 | ABSA í”„ë¡¬í”„íŠ¸ | â­â­â­ |\n",
    "| Q6 | ë°°ì¹˜ ì²˜ë¦¬ + ì—ëŸ¬ í•¸ë“¤ë§ | â­â­â­ |\n",
    "| Q7 | ì„ë² ë”© ê°ì„± ì ìˆ˜ | â­â­â­â­ |\n",
    "| Q8 | LLM vs ì„ë² ë”© ë¹„êµ | â­â­â­â­ |\n",
    "| Q9 | ì•™ìƒë¸” ë¶„ë¥˜ê¸° í´ë˜ìŠ¤ | â­â­â­â­â­ |\n",
    "| Q10 | ì¢…í•© ëŒ€ì‹œë³´ë“œ | â­â­â­â­â­ |\n",
    "\n",
    "### ğŸ’¡ ì¢…í•© íŒ\n",
    "\n",
    "1. **í”„ë¡¬í”„íŠ¸ëŠ” ëª…í™•í•˜ê²Œ**: ì¶œë ¥ í˜•ì‹ ì§€ì • í•„ìˆ˜\n",
    "2. **Few-shotì€ ê· í˜• ìˆê²Œ**: ê° í´ë˜ìŠ¤ ì˜ˆì œ í¬í•¨\n",
    "3. **ì„ë² ë”©ì€ ì°¸ì¡°ê°€ í•µì‹¬**: ì¢‹ì€ ì°¸ì¡° = ì¢‹ì€ ë¶„ë¥˜\n",
    "4. **ì•™ìƒë¸”ë¡œ ì‹ ë¢°ë„ í–¥ìƒ**: ì¼ì¹˜=high, ë¶ˆì¼ì¹˜=ê²€í† \n",
    "5. **ì‹œê°í™”ë¡œ ê²€ì¦**: ê²°ê³¼ ë¶„í¬ í•­ìƒ í™•ì¸"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
