{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day9_4: í†µê³„ ì´ë¡  ê¸°ì´ˆ - ì •ë‹µ ë° í’€ì´\n",
    "\n",
    "## ğŸ“š í•™ìŠµ ëª©í‘œ ë³µìŠµ\n",
    "\n",
    "**Part 1: ê¸°ì´ˆ ê°œë… - ëŒ€ìˆ˜ì˜ ë²•ì¹™ê³¼ ì¤‘ì‹¬ê·¹í•œì •ë¦¬**\n",
    "- ëª¨ì§‘ë‹¨, í‘œë³¸, ëª¨ìˆ˜, í†µê³„ëŸ‰\n",
    "- ëŒ€ìˆ˜ì˜ ë²•ì¹™ (LLN)\n",
    "- ì¤‘ì‹¬ê·¹í•œì •ë¦¬ (CLT)\n",
    "- í‘œì¤€ì˜¤ì°¨ (SE)\n",
    "\n",
    "**Part 2: ì‹¬í™” ê°œë… - ê²€ì •ë ¥ê³¼ ì‹¤í—˜ ì„¤ê³„**\n",
    "- Type I/II ì˜¤ë¥˜\n",
    "- ê²€ì •ë ¥ (Power)\n",
    "- íš¨ê³¼ í¬ê¸° (Cohen's d)\n",
    "- í‘œë³¸ í¬ê¸° ê²°ì •\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q1. í‘œì¤€ì˜¤ì°¨ ê³„ì‚° â­\n",
    "\n",
    "**ë¬¸ì œ**: ëª¨ì§‘ë‹¨ í‘œì¤€í¸ì°¨ê°€ 20ì´ê³  í‘œë³¸ í¬ê¸°ê°€ 100ì¼ ë•Œ í‘œì¤€ì˜¤ì°¨(SE)ë¥¼ ê³„ì‚°í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "sigma = 20\n",
    "n = 100\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 ì •ë‹µ\n",
    "sigma = 20  # ëª¨ì§‘ë‹¨ í‘œì¤€í¸ì°¨\n",
    "n = 100     # í‘œë³¸ í¬ê¸°\n",
    "\n",
    "# í‘œì¤€ì˜¤ì°¨ ê³µì‹: SE = sigma / sqrt(n)\n",
    "se = sigma / np.sqrt(n)\n",
    "\n",
    "print(f\"ëª¨ì§‘ë‹¨ í‘œì¤€í¸ì°¨ (sigma): {sigma}\")\n",
    "print(f\"í‘œë³¸ í¬ê¸° (n): {n}\")\n",
    "print(f\"í‘œì¤€ì˜¤ì°¨ (SE): {se}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦\n",
    "assert se == 2.0, \"í‘œì¤€ì˜¤ì°¨ ê³„ì‚° ì˜¤ë¥˜\"\n",
    "print(\"ê²€ì¦ í†µê³¼! SE = 2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q1 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- í‘œì¤€ì˜¤ì°¨ ê³µì‹ SE = Ïƒ/âˆšn ì ìš©\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- í‘œì¤€ì˜¤ì°¨(Standard Error): í‘œë³¸í‰ê· ì˜ í‘œì¤€í¸ì°¨\n",
    "- í‘œë³¸ í¬ê¸°ê°€ ì»¤ì§ˆìˆ˜ë¡ í‘œì¤€ì˜¤ì°¨ ê°ì†Œ\n",
    "- nì´ 4ë°° â†’ SEê°€ ì ˆë°˜\n",
    "\n",
    "**ì‹¤ë¬´ ì˜ë¯¸**:\n",
    "- SE=2ë¼ëŠ” ê²ƒì€ í‘œë³¸í‰ê· ì´ ëª¨í‰ê· ì—ì„œ ì•½ 2ë§Œí¼ ì˜¤ì°¨ë‚  ìˆ˜ ìˆë‹¤ëŠ” ì˜ë¯¸\n",
    "- 95% ì‹ ë¢°êµ¬ê°„: ëª¨í‰ê·  Â± 1.96Ã—SE = ëª¨í‰ê·  Â± 3.92\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. ëŒ€ìˆ˜ì˜ ë²•ì¹™ ì‹œë®¬ë ˆì´ì…˜ â­\n",
    "\n",
    "**ë¬¸ì œ**: ì£¼ì‚¬ìœ„ë¥¼ 2000ë²ˆ ë˜ì ¸ì„œ ëˆ„ì  í‰ê· ì´ ê¸°ëŒ“ê°’(3.5)ì— ìˆ˜ë ´í•˜ëŠ” ê²ƒì„ í™•ì¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 ì •ë‹µ\n",
    "np.random.seed(42)\n",
    "\n",
    "# ì£¼ì‚¬ìœ„ ë˜ì§€ê¸° (1~6)\n",
    "n_rolls = 2000\n",
    "rolls = np.random.randint(1, 7, n_rolls)\n",
    "\n",
    "# ëˆ„ì  í‰ê·  ê³„ì‚°\n",
    "cumulative_means = np.cumsum(rolls) / np.arange(1, n_rolls + 1)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(\"ëŒ€ìˆ˜ì˜ ë²•ì¹™: ì£¼ì‚¬ìœ„ ë˜ì§€ê¸°\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ì£¼ì‚¬ìœ„ ê¸°ëŒ“ê°’: 3.5\")\n",
    "print(f\"\\në˜ì§„ íšŸìˆ˜ë³„ ëˆ„ì  í‰ê· :\")\n",
    "for n in [10, 50, 100, 500, 1000, 2000]:\n",
    "    mean = cumulative_means[n-1]\n",
    "    error = abs(mean - 3.5)\n",
    "    print(f\"  n={n:>4}: í‰ê· ={mean:.4f}, ì˜¤ì°¨={error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "df = pd.DataFrame({\n",
    "    'ë˜ì§„ íšŸìˆ˜': range(1, n_rolls + 1),\n",
    "    'ëˆ„ì  í‰ê· ': cumulative_means\n",
    "})\n",
    "\n",
    "fig = px.line(df, x='ë˜ì§„ íšŸìˆ˜', y='ëˆ„ì  í‰ê· ',\n",
    "              title='ëŒ€ìˆ˜ì˜ ë²•ì¹™: ì£¼ì‚¬ìœ„ 2000ë²ˆ ë˜ì§€ê¸°')\n",
    "fig.add_hline(y=3.5, line_dash=\"dash\", line_color=\"red\",\n",
    "              annotation_text=\"ê¸°ëŒ“ê°’ = 3.5\")\n",
    "fig.update_layout(height=400, width=700)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦: ìµœì¢… í‰ê· ì´ 3.5ì— ê°€ê¹Œìš´ì§€ í™•ì¸\n",
    "final_mean = cumulative_means[-1]\n",
    "assert abs(final_mean - 3.5) < 0.1, \"ëŒ€ìˆ˜ì˜ ë²•ì¹™ ë¯¸ìˆ˜ë ´\"\n",
    "print(f\"ê²€ì¦ í†µê³¼! ìµœì¢… í‰ê·  {final_mean:.4f}ì€ ê¸°ëŒ“ê°’ 3.5ì— ìˆ˜ë ´\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q2 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. `np.random.randint(1, 7, n)`: 1~6 ì‚¬ì´ ì •ìˆ˜ nê°œ ìƒì„±\n",
    "2. `np.cumsum()`: ëˆ„ì  í•©ê³„ ê³„ì‚°\n",
    "3. ëˆ„ì  í•©ê³„ë¥¼ íšŸìˆ˜ë¡œ ë‚˜ëˆ  ëˆ„ì  í‰ê·  ê³„ì‚°\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ëŒ€ìˆ˜ì˜ ë²•ì¹™: nì´ ì»¤ì§ˆìˆ˜ë¡ í‘œë³¸í‰ê·  â†’ ëª¨í‰ê· \n",
    "- ì£¼ì‚¬ìœ„ ê¸°ëŒ“ê°’ = (1+2+3+4+5+6)/6 = 3.5\n",
    "\n",
    "**ê´€ì°° í¬ì¸íŠ¸**:\n",
    "- ì´ˆë°˜(n=10): í‰ê· ì´ í¬ê²Œ ë³€ë™\n",
    "- n=100 ì´í›„: 3.5 ê·¼ì²˜ë¡œ ì•ˆì •í™”\n",
    "- n=2000: ê±°ì˜ 3.5ì— ìˆ˜ë ´\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. ì¤‘ì‹¬ê·¹í•œì •ë¦¬ í™•ì¸ â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì§€ìˆ˜ë¶„í¬(í‰ê· =5)ì—ì„œ í‘œë³¸ í¬ê¸° 50ìœ¼ë¡œ 500ë²ˆ ì¶”ì¶œí•˜ì—¬ í‘œë³¸í‰ê· ì˜ ë¶„í¬ê°€ ì •ê·œë¶„í¬ì— ê°€ê¹Œì›Œì§€ëŠ” ê²ƒì„ í™•ì¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 ì •ë‹µ\n",
    "np.random.seed(42)\n",
    "\n",
    "# ëª¨ì§‘ë‹¨: ì§€ìˆ˜ë¶„í¬ (í‰ê· =5)\n",
    "population = np.random.exponential(scale=5, size=100000)\n",
    "sample_size = 50\n",
    "n_samples = 500\n",
    "\n",
    "# ëª¨ì§‘ë‹¨ í†µê³„\n",
    "pop_mean = np.mean(population)\n",
    "pop_std = np.std(population)\n",
    "\n",
    "print(\"ëª¨ì§‘ë‹¨ ì •ë³´ (ì§€ìˆ˜ë¶„í¬)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ëª¨í‰ê· : {pop_mean:.4f}\")\n",
    "print(f\"ëª¨í‘œì¤€í¸ì°¨: {pop_std:.4f}\")\n",
    "print(f\"ì´ë¡ ì  í‘œì¤€ì˜¤ì°¨: {pop_std/np.sqrt(sample_size):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‘œë³¸í‰ê·  500ê°œ ìƒì„±\n",
    "sample_means = []\n",
    "for _ in range(n_samples):\n",
    "    sample = np.random.choice(population, size=sample_size, replace=True)\n",
    "    sample_means.append(np.mean(sample))\n",
    "\n",
    "# í‘œë³¸í‰ê·  ë¶„í¬ í†µê³„\n",
    "print(f\"\\ní‘œë³¸í‰ê·  ë¶„í¬ (n={sample_size}, {n_samples}ê°œ í‘œë³¸)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"í‘œë³¸í‰ê· ë“¤ì˜ í‰ê· : {np.mean(sample_means):.4f}\")\n",
    "print(f\"í‘œë³¸í‰ê· ë“¤ì˜ í‘œì¤€í¸ì°¨ (SE): {np.std(sample_means):.4f}\")\n",
    "print(f\"ì´ë¡ ì  SE: {pop_std/np.sqrt(sample_size):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”: ëª¨ì§‘ë‹¨ vs í‘œë³¸í‰ê·  ë¶„í¬\n",
    "fig = make_subplots(rows=1, cols=2,\n",
    "                    subplot_titles=['ëª¨ì§‘ë‹¨ (ì§€ìˆ˜ë¶„í¬)', 'í‘œë³¸í‰ê·  ë¶„í¬ (CLT)'])\n",
    "\n",
    "# ëª¨ì§‘ë‹¨ ë¶„í¬\n",
    "fig.add_trace(go.Histogram(x=population[:5000], nbinsx=50, name='ëª¨ì§‘ë‹¨',\n",
    "                           marker_color='blue', opacity=0.7), row=1, col=1)\n",
    "\n",
    "# í‘œë³¸í‰ê·  ë¶„í¬\n",
    "fig.add_trace(go.Histogram(x=sample_means, nbinsx=30, name='í‘œë³¸í‰ê· ',\n",
    "                           marker_color='red', opacity=0.7), row=1, col=2)\n",
    "\n",
    "fig.update_layout(height=400, width=900,\n",
    "                  title_text='ì¤‘ì‹¬ê·¹í•œì •ë¦¬: ë¹„ì •ê·œ ëª¨ì§‘ë‹¨ì—ì„œ ì •ê·œë¶„í¬ í‘œë³¸í‰ê· ')\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nì™¼ìª½: ì§€ìˆ˜ë¶„í¬ (ì˜¤ë¥¸ìª½ ê¼¬ë¦¬)\")\n",
    "print(\"ì˜¤ë¥¸ìª½: í‘œë³¸í‰ê·  ë¶„í¬ (ì¢… ëª¨ì–‘ - ì •ê·œë¶„í¬!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦: ì •ê·œì„± ê²€ì •\n",
    "_, p_value = stats.shapiro(sample_means)\n",
    "print(f\"Shapiro-Wilk ì •ê·œì„± ê²€ì • p-value: {p_value:.4f}\")\n",
    "if p_value > 0.05:\n",
    "    print(\"ê²€ì¦ í†µê³¼! í‘œë³¸í‰ê·  ë¶„í¬ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¦„ (CLT í™•ì¸)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q3 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. ì§€ìˆ˜ë¶„í¬ ëª¨ì§‘ë‹¨ ìƒì„± (ë¹„ì •ê·œë¶„í¬)\n",
    "2. í‘œë³¸ í¬ê¸° 50ìœ¼ë¡œ 500ë²ˆ ì¶”ì¶œ\n",
    "3. ê° í‘œë³¸ì˜ í‰ê·  ê³„ì‚°\n",
    "4. í‘œë³¸í‰ê· ë“¤ì˜ ë¶„í¬ í™•ì¸\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ì¤‘ì‹¬ê·¹í•œì •ë¦¬: ëª¨ì§‘ë‹¨ ë¶„í¬ì™€ ë¬´ê´€í•˜ê²Œ nâ‰¥30ì´ë©´ í‘œë³¸í‰ê· ì€ ì •ê·œë¶„í¬\n",
    "- ì§€ìˆ˜ë¶„í¬ëŠ” ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹œ ë¹„ëŒ€ì¹­ ë¶„í¬\n",
    "- í•˜ì§€ë§Œ í‘œë³¸í‰ê· ì˜ ë¶„í¬ëŠ” ì¢… ëª¨ì–‘ (ì •ê·œë¶„í¬)\n",
    "\n",
    "**ì‹¤ë¬´ ì˜ë¯¸**:\n",
    "- ëª¨ì§‘ë‹¨ ë¶„í¬ë¥¼ ëª°ë¼ë„ í‘œë³¸í‰ê· ìœ¼ë¡œ ì¶”ë¡  ê°€ëŠ¥\n",
    "- t-ê²€ì •, ì‹ ë¢°êµ¬ê°„ ë“± í†µê³„ì  ë°©ë²•ë¡ ì˜ ì´ë¡ ì  ê·¼ê±°\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Type I/II ì˜¤ë¥˜ ì´í•´ â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë°œìƒí•œ ì˜¤ë¥˜ ìœ í˜•ì„ íŒë‹¨í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 ì •ë‹µ\n",
    "\n",
    "# ì˜¤ë¥˜ ìœ í˜• ë¶„ì„\n",
    "scenarios = pd.DataFrame({\n",
    "    'ì‹œë‚˜ë¦¬ì˜¤': [\n",
    "        '1. ë§ˆì¼€íŒ… ìº í˜ì¸ (íš¨ê³¼ ìˆìŒ â†’ ì—†ë‹¤ê³  íŒë‹¨)',\n",
    "        '2. ì‹ ì•½ ìŠ¹ì¸ (íš¨ê³¼ ì—†ìŒ â†’ ìˆë‹¤ê³  íŒë‹¨)',\n",
    "        '3. í’ˆì§ˆê²€ì‚¬ (ë¶ˆëŸ‰í’ˆ â†’ ì •ìƒ í†µê³¼)'\n",
    "    ],\n",
    "    'ì‹¤ì œ ìƒíƒœ': ['íš¨ê³¼ ìˆìŒ (H0 ê±°ì§“)', 'íš¨ê³¼ ì—†ìŒ (H0 ì°¸)', 'ë¶ˆëŸ‰ (H0 ê±°ì§“)'],\n",
    "    'ê²€ì • ê²°ë¡ ': ['íš¨ê³¼ ì—†ìŒ (H0 ì±„íƒ)', 'íš¨ê³¼ ìˆìŒ (H0 ê¸°ê°)', 'ì •ìƒ (H0 ì±„íƒ)'],\n",
    "    'ì˜¤ë¥˜ ìœ í˜•': ['Type II ì˜¤ë¥˜ (Î²)', 'Type I ì˜¤ë¥˜ (Î±)', 'Type II ì˜¤ë¥˜ (Î²)'],\n",
    "    'ê²°ê³¼': [\n",
    "        'ì¢‹ì€ ìº í˜ì¸ì„ ë†“ì¹¨',\n",
    "        'íš¨ê³¼ ì—†ëŠ” ì•½ì´ ì‹œì¥ì— ì¶œì‹œ',\n",
    "        'ë¶ˆëŸ‰í’ˆì´ ê³ ê°ì—ê²Œ ì „ë‹¬'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"ì‹œë‚˜ë¦¬ì˜¤ë³„ ì˜¤ë¥˜ ìœ í˜• ë¶„ì„\")\n",
    "print(\"=\" * 80)\n",
    "print(scenarios.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜¤ë¥˜ ìœ í˜• ìš”ì•½ í…Œì´ë¸”\n",
    "error_matrix = pd.DataFrame({\n",
    "    'ì‹¤ì œ\\\\íŒë‹¨': ['H0 ì°¸ (íš¨ê³¼ ì—†ìŒ)', 'H0 ê±°ì§“ (íš¨ê³¼ ìˆìŒ)'],\n",
    "    'H0 ê¸°ê° (íš¨ê³¼ ìˆë‹¤)': ['Type I (Î±) - ê°€ì§œ ì–‘ì„±', 'ì˜¬ë°”ë¥¸ ê²°ì • (Power)'],\n",
    "    'H0 ì±„íƒ (íš¨ê³¼ ì—†ë‹¤)': ['ì˜¬ë°”ë¥¸ ê²°ì •', 'Type II (Î²) - ê°€ì§œ ìŒì„±']\n",
    "})\n",
    "\n",
    "print(\"\\nì˜¤ë¥˜ ìœ í˜• ë§¤íŠ¸ë¦­ìŠ¤\")\n",
    "print(\"=\" * 60)\n",
    "print(error_matrix.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q4 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. ê° ì‹œë‚˜ë¦¬ì˜¤ì˜ \"ì‹¤ì œ ìƒíƒœ\" í™•ì¸\n",
    "2. \"ê²€ì • ê²°ë¡ \"ê³¼ ë¹„êµ\n",
    "3. ì˜¤ë¥˜ ìœ í˜• íŒë‹¨\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- **Type I ì˜¤ë¥˜ (Î±)**: H0ê°€ ì°¸ì¸ë° ê¸°ê° â†’ \"ìˆëŠ”ë° ìˆë‹¤ê³  (ì˜ëª»)\" â†’ False Positive\n",
    "- **Type II ì˜¤ë¥˜ (Î²)**: H0ê°€ ê±°ì§“ì¸ë° ì±„íƒ â†’ \"ìˆëŠ”ë° ì—†ë‹¤ê³  (ì˜ëª»)\" â†’ False Negative\n",
    "\n",
    "**ì‹œë‚˜ë¦¬ì˜¤ë³„ í•´ì„¤**:\n",
    "1. ìº í˜ì¸ì´ ì‹¤ì œë¡œ íš¨ê³¼ ìˆìŒ â†’ ì—†ë‹¤ê³  íŒë‹¨ â†’ Type II (ë†“ì¹¨)\n",
    "2. ì•½ì´ ì‹¤ì œë¡œ íš¨ê³¼ ì—†ìŒ â†’ ìˆë‹¤ê³  íŒë‹¨ â†’ Type I (ê±°ì§“ ìŠ¹ì¸)\n",
    "3. ì œí’ˆì´ ì‹¤ì œë¡œ ë¶ˆëŸ‰ â†’ ì •ìƒ í†µê³¼ â†’ Type II (ë†“ì¹¨)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Cohen's d ê³„ì‚° â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‘ ê·¸ë£¹ì˜ ë°ì´í„°ë¡œ Cohen's dë¥¼ ê³„ì‚°í•˜ê³  íš¨ê³¼ í¬ê¸°ë¥¼ í•´ì„í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 ì •ë‹µ\n",
    "group_a = [85, 88, 90, 92, 78, 82, 85, 89, 91, 87]\n",
    "group_b = [95, 92, 98, 88, 96, 94, 90, 97, 93, 91]\n",
    "\n",
    "# ê¸°ìˆ í†µê³„\n",
    "mean_a = np.mean(group_a)\n",
    "mean_b = np.mean(group_b)\n",
    "std_a = np.std(group_a, ddof=1)\n",
    "std_b = np.std(group_b, ddof=1)\n",
    "\n",
    "print(\"ê·¸ë£¹ë³„ ê¸°ìˆ í†µê³„\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"ê·¸ë£¹ A: í‰ê· ={mean_a:.2f}, í‘œì¤€í¸ì°¨={std_a:.2f}\")\n",
    "print(f\"ê·¸ë£¹ B: í‰ê· ={mean_b:.2f}, í‘œì¤€í¸ì°¨={std_b:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohen's d ê³„ì‚° í•¨ìˆ˜\n",
    "def cohens_d(group1, group2):\n",
    "    \"\"\"ë‘ ê·¸ë£¹ ê°„ Cohen's d ê³„ì‚°\"\"\"\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1 = np.var(group1, ddof=1)\n",
    "    var2 = np.var(group2, ddof=1)\n",
    "    \n",
    "    # Pooled standard deviation\n",
    "    pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "    \n",
    "    return (np.mean(group1) - np.mean(group2)) / pooled_std\n",
    "\n",
    "# Cohen's d ê³„ì‚°\n",
    "d = cohens_d(group_b, group_a)  # B - A (Bê°€ ë” í¬ë¯€ë¡œ ì–‘ìˆ˜)\n",
    "\n",
    "print(f\"\\nCohen's d = {d:.4f}\")\n",
    "\n",
    "# íš¨ê³¼ í¬ê¸° í•´ì„\n",
    "if abs(d) < 0.2:\n",
    "    interpretation = \"ë¬´ì‹œí•  ìˆ˜ ìˆëŠ” íš¨ê³¼\"\n",
    "elif abs(d) < 0.5:\n",
    "    interpretation = \"ì‘ì€ íš¨ê³¼ (Small)\"\n",
    "elif abs(d) < 0.8:\n",
    "    interpretation = \"ì¤‘ê°„ íš¨ê³¼ (Medium)\"\n",
    "else:\n",
    "    interpretation = \"í° íš¨ê³¼ (Large)\"\n",
    "\n",
    "print(f\"íš¨ê³¼ í¬ê¸° í•´ì„: {interpretation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦: dê°€ ëŒ€ëµ 1.5 ê·¼ì²˜ì¸ì§€ í™•ì¸\n",
    "assert 1.0 < d < 2.0, \"Cohen's d ê³„ì‚° ì˜¤ë¥˜\"\n",
    "print(f\"ê²€ì¦ í†µê³¼! d = {d:.4f}ëŠ” í° íš¨ê³¼(Large)ì— í•´ë‹¹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q5 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. ê° ê·¸ë£¹ì˜ í‰ê· , ë¶„ì‚° ê³„ì‚°\n",
    "2. Pooled í‘œì¤€í¸ì°¨ ê³„ì‚°\n",
    "3. Cohen's d = (M1 - M2) / pooled_std\n",
    "\n",
    "**í•µì‹¬ ê³µì‹**:\n",
    "```\n",
    "pooled_std = sqrt(((n1-1)*s1Â² + (n2-1)*s2Â²) / (n1+n2-2))\n",
    "Cohen's d = (M1 - M2) / pooled_std\n",
    "```\n",
    "\n",
    "**í•´ì„ ê¸°ì¤€ (Cohen, 1988)**:\n",
    "- d < 0.2: ë¬´ì‹œí•  ìˆ˜ ìˆëŠ” íš¨ê³¼\n",
    "- 0.2 â‰¤ d < 0.5: ì‘ì€ íš¨ê³¼\n",
    "- 0.5 â‰¤ d < 0.8: ì¤‘ê°„ íš¨ê³¼\n",
    "- d â‰¥ 0.8: í° íš¨ê³¼\n",
    "\n",
    "**ì‹¤ë¬´ ì˜ë¯¸**:\n",
    "- d â‰ˆ 1.5ëŠ” ë§¤ìš° í° íš¨ê³¼\n",
    "- ë‘ ê·¸ë£¹ ë¶„í¬ê°€ ê±°ì˜ ê²¹ì¹˜ì§€ ì•ŠìŒ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. í‘œë³¸ í¬ê¸° ê²°ì • â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì¤‘ê°„ íš¨ê³¼(d=0.5)ë¥¼ íƒì§€í•˜ê¸° ìœ„í•´ Î±=0.05, Power=0.90ì¼ ë•Œ í•„ìš”í•œ í‘œë³¸ í¬ê¸°ë¥¼ ê³„ì‚°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6 ì •ë‹µ\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "# Power ë¶„ì„ ê°ì²´ ìƒì„±\n",
    "power_analysis = TTestIndPower()\n",
    "\n",
    "# íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "effect_size = 0.5   # ì¤‘ê°„ íš¨ê³¼\n",
    "alpha = 0.05        # ìœ ì˜ìˆ˜ì¤€\n",
    "power = 0.90        # ëª©í‘œ ê²€ì •ë ¥ (90%)\n",
    "\n",
    "# í‘œë³¸ í¬ê¸° ê³„ì‚°\n",
    "sample_size = power_analysis.solve_power(\n",
    "    effect_size=effect_size,\n",
    "    alpha=alpha,\n",
    "    power=power,\n",
    "    alternative='two-sided'\n",
    ")\n",
    "\n",
    "print(\"í‘œë³¸ í¬ê¸° ê³„ì‚° ê²°ê³¼\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"íš¨ê³¼ í¬ê¸° (Cohen's d): {effect_size}\")\n",
    "print(f\"ìœ ì˜ìˆ˜ì¤€ (Î±): {alpha}\")\n",
    "print(f\"ëª©í‘œ ê²€ì •ë ¥: {power*100:.0f}%\")\n",
    "print(f\"\\ní•„ìš” í‘œë³¸ í¬ê¸°: ê° ê·¸ë£¹ {int(np.ceil(sample_size))}ëª…\")\n",
    "print(f\"ì´ í•„ìš” ì¸ì›: {int(np.ceil(sample_size)) * 2}ëª…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% vs 90% ê²€ì •ë ¥ ë¹„êµ\n",
    "sample_80 = power_analysis.solve_power(effect_size=0.5, alpha=0.05, power=0.80)\n",
    "sample_90 = power_analysis.solve_power(effect_size=0.5, alpha=0.05, power=0.90)\n",
    "\n",
    "print(\"\\nê²€ì •ë ¥ë³„ í•„ìš” í‘œë³¸ í¬ê¸° ë¹„êµ\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"80% ê²€ì •ë ¥: ê° ê·¸ë£¹ {int(np.ceil(sample_80))}ëª…\")\n",
    "print(f\"90% ê²€ì •ë ¥: ê° ê·¸ë£¹ {int(np.ceil(sample_90))}ëª…\")\n",
    "print(f\"\\n10%p ê²€ì •ë ¥ í–¥ìƒì— {int(np.ceil(sample_90) - np.ceil(sample_80))}ëª… ì¶”ê°€ í•„ìš”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦\n",
    "assert 80 < sample_size < 90, \"í‘œë³¸ í¬ê¸° ê³„ì‚° ì˜¤ë¥˜\"\n",
    "print(f\"ê²€ì¦ í†µê³¼! 90% ê²€ì •ë ¥ì„ ìœ„í•´ ê° ê·¸ë£¹ ì•½ 86ëª… í•„ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q6 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. `TTestIndPower` ê°ì²´ ìƒì„±\n",
    "2. `solve_power()` ë©”ì„œë“œë¡œ í•„ìš” í‘œë³¸ í¬ê¸° ê³„ì‚°\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- Power ë¶„ì„: íš¨ê³¼ë¥¼ íƒì§€í•  í™•ë¥  ê³„ì‚°\n",
    "- 90% ê²€ì •ë ¥ > 80% ê²€ì •ë ¥ â†’ ë” ë§ì€ í‘œë³¸ í•„ìš”\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- 80%: ìµœì†Œ ê¶Œì¥ ê²€ì •ë ¥\n",
    "- 90%: ì¢€ ë” í™•ì‹¤í•œ ê²°ê³¼ë¥¼ ì›í•  ë•Œ\n",
    "- ë¹„ìš©/ì‹œê°„ vs ê²€ì •ë ¥ íŠ¸ë ˆì´ë“œì˜¤í”„ ê³ ë ¤\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7. ê²€ì •ë ¥ ë¶„ì„ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: íš¨ê³¼ í¬ê¸°ê°€ 0.3, 0.5, 0.8ì¼ ë•Œ í‘œë³¸ í¬ê¸°ì— ë”°ë¥¸ ê²€ì •ë ¥ ë³€í™”ë¥¼ ë¹„êµí•˜ëŠ” ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 ì •ë‹µ\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "power_analysis = TTestIndPower()\n",
    "\n",
    "# ì„¤ì •\n",
    "effect_sizes = [0.3, 0.5, 0.8]\n",
    "n_range = np.arange(10, 201, 5)\n",
    "alpha = 0.05\n",
    "\n",
    "# ê° íš¨ê³¼ í¬ê¸°ë³„ ê²€ì •ë ¥ ê³„ì‚°\n",
    "results = {}\n",
    "for d in effect_sizes:\n",
    "    powers = []\n",
    "    for n in n_range:\n",
    "        p = power_analysis.solve_power(effect_size=d, alpha=alpha, nobs1=n)\n",
    "        powers.append(p)\n",
    "    results[f'd={d}'] = powers\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "df_power = pd.DataFrame(results, index=n_range)\n",
    "df_power.index.name = 'í‘œë³¸ í¬ê¸°'\n",
    "\n",
    "print(\"í‘œë³¸ í¬ê¸°ë³„ ê²€ì •ë ¥ (ì¼ë¶€)\")\n",
    "print(df_power.loc[[20, 50, 100, 200]].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "fig = go.Figure()\n",
    "\n",
    "colors = ['blue', 'green', 'red']\n",
    "for i, d in enumerate(effect_sizes):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=n_range,\n",
    "        y=results[f'd={d}'],\n",
    "        mode='lines',\n",
    "        name=f'íš¨ê³¼í¬ê¸° d={d}',\n",
    "        line=dict(color=colors[i], width=2)\n",
    "    ))\n",
    "\n",
    "# 80% ê²€ì •ë ¥ ê¸°ì¤€ì„ \n",
    "fig.add_hline(y=0.80, line_dash=\"dash\", line_color=\"black\",\n",
    "              annotation_text=\"ëª©í‘œ ê²€ì •ë ¥ 80%\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='íš¨ê³¼ í¬ê¸°ë³„ í‘œë³¸ í¬ê¸°-ê²€ì •ë ¥ ê´€ê³„ (Î±=0.05)',\n",
    "    xaxis_title='ê° ê·¸ë£¹ í‘œë³¸ í¬ê¸°',\n",
    "    yaxis_title='ê²€ì •ë ¥ (Power)',\n",
    "    height=500, width=800,\n",
    "    legend=dict(x=0.7, y=0.3)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê° íš¨ê³¼ í¬ê¸°ë³„ 80% ê²€ì •ë ¥ ë‹¬ì„± í‘œë³¸ í¬ê¸°\n",
    "print(\"\\n80% ê²€ì •ë ¥ ë‹¬ì„±ì— í•„ìš”í•œ í‘œë³¸ í¬ê¸°\")\n",
    "print(\"=\" * 50)\n",
    "for d in effect_sizes:\n",
    "    n = power_analysis.solve_power(effect_size=d, alpha=0.05, power=0.80)\n",
    "    print(f\"íš¨ê³¼í¬ê¸° d={d}: ê° ê·¸ë£¹ {int(np.ceil(n))}ëª…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q7 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. íš¨ê³¼ í¬ê¸°ë³„ ë°˜ë³µë¬¸\n",
    "2. í‘œë³¸ í¬ê¸° ë²”ìœ„ì—ì„œ ê²€ì •ë ¥ ê³„ì‚°\n",
    "3. Plotlyë¡œ 3ê°œ ì„  ê·¸ë˜í”„ ìƒì„±\n",
    "\n",
    "**ê´€ì°° í¬ì¸íŠ¸**:\n",
    "- íš¨ê³¼ í¬ê¸°ê°€ í´ìˆ˜ë¡ ì ì€ í‘œë³¸ìœ¼ë¡œ 80% ê²€ì •ë ¥ ë‹¬ì„±\n",
    "- d=0.8: ì•½ 26ëª…/ê·¸ë£¹\n",
    "- d=0.5: ì•½ 64ëª…/ê·¸ë£¹\n",
    "- d=0.3: ì•½ 176ëª…/ê·¸ë£¹\n",
    "\n",
    "**ì‹¤ë¬´ ì˜ë¯¸**:\n",
    "- ì‘ì€ íš¨ê³¼ë¥¼ íƒì§€í•˜ë ¤ë©´ í° í‘œë³¸ í•„ìš”\n",
    "- ì˜ˆì‚°/ì‹œê°„ ì œì•½ ì‹œ íƒì§€ ê°€ëŠ¥í•œ ìµœì†Œ íš¨ê³¼ í¬ê¸° ì¬ê²€í† \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8. ì¤‘ì‹¬ê·¹í•œì •ë¦¬ ì‹¬í™” â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë² ë¥´ëˆ„ì´ ë¶„í¬(ì„±ê³µ í™•ë¥  p=0.3)ì—ì„œ í‘œë³¸ í¬ê¸°ë³„ í‘œë³¸í‰ê·  ë¶„í¬ë¥¼ ë¹„êµí•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8 ì •ë‹µ\n",
    "np.random.seed(42)\n",
    "\n",
    "p = 0.3  # ì„±ê³µ í™•ë¥ \n",
    "sample_sizes = [5, 15, 30, 100]\n",
    "n_samples = 1000\n",
    "\n",
    "# ì´ë¡ ê°’\n",
    "theoretical_mean = p\n",
    "theoretical_var = p * (1 - p)\n",
    "\n",
    "print(\"ë² ë¥´ëˆ„ì´ ë¶„í¬ ì´ë¡ ê°’\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ëª¨í‰ê· : {theoretical_mean}\")\n",
    "print(f\"ëª¨ë¶„ì‚°: {theoretical_var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê° í‘œë³¸ í¬ê¸°ë³„ í‘œë³¸í‰ê·  ìƒì„±\n",
    "results = {}\n",
    "\n",
    "print(\"\\ní‘œë³¸ í¬ê¸°ë³„ í‘œë³¸í‰ê·  ë¶„í¬ í†µê³„\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'n':<6} {'ì‹¤ì œ í‰ê· ':>10} {'ì´ë¡  í‰ê· ':>10} {'ì‹¤ì œ SE':>10} {'ì´ë¡  SE':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for n in sample_sizes:\n",
    "    sample_means = []\n",
    "    for _ in range(n_samples):\n",
    "        # ë² ë¥´ëˆ„ì´ ë¶„í¬: 0 ë˜ëŠ” 1\n",
    "        sample = np.random.binomial(1, p, size=n)\n",
    "        sample_means.append(np.mean(sample))\n",
    "    \n",
    "    results[n] = sample_means\n",
    "    \n",
    "    # í†µê³„ ê³„ì‚°\n",
    "    actual_mean = np.mean(sample_means)\n",
    "    actual_se = np.std(sample_means)\n",
    "    theoretical_se = np.sqrt(theoretical_var / n)\n",
    "    \n",
    "    print(f\"{n:<6} {actual_mean:>10.4f} {theoretical_mean:>10.4f} {actual_se:>10.4f} {theoretical_se:>10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”: 4ê°œ ì„œë¸Œí”Œë¡¯\n",
    "fig = make_subplots(rows=2, cols=2,\n",
    "                    subplot_titles=[f'n = {n}' for n in sample_sizes])\n",
    "\n",
    "positions = [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
    "\n",
    "for n, pos in zip(sample_sizes, positions):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=results[n], nbinsx=25, name=f'n={n}',\n",
    "                     marker_color='steelblue', opacity=0.7),\n",
    "        row=pos[0], col=pos[1]\n",
    "    )\n",
    "    \n",
    "    # í‰ê· ì„  ì¶”ê°€\n",
    "    fig.add_vline(x=p, line_dash=\"dash\", line_color=\"red\",\n",
    "                  row=pos[0], col=pos[1])\n",
    "\n",
    "fig.update_layout(height=600, width=900,\n",
    "                  title_text='ë² ë¥´ëˆ„ì´ ë¶„í¬(p=0.3)ì˜ í‘œë³¸í‰ê·  ë¶„í¬ (CLT)',\n",
    "                  showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nê´€ì°° í¬ì¸íŠ¸:\")\n",
    "print(\"- n=5: ì´ì‚°ì , ì •ê·œë¶„í¬ ì•„ë‹˜\")\n",
    "print(\"- n=15: ì¢… ëª¨ì–‘ì— ê°€ê¹Œì›Œì§\")\n",
    "print(\"- n=30: ê±°ì˜ ì •ê·œë¶„í¬\")\n",
    "print(\"- n=100: ì™„ì „í•œ ì •ê·œë¶„í¬, SE ë§¤ìš° ì‘ìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q8 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. ë² ë¥´ëˆ„ì´ ë¶„í¬ (0 ë˜ëŠ” 1)ì—ì„œ í‘œë³¸ ì¶”ì¶œ\n",
    "2. ê° í‘œë³¸ í¬ê¸°ë³„ë¡œ 1000ê°œì˜ í‘œë³¸í‰ê·  ìƒì„±\n",
    "3. ì´ë¡ ê°’ê³¼ ì‹¤ì œê°’ ë¹„êµ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ë² ë¥´ëˆ„ì´: ê°€ì¥ ë‹¨ìˆœí•œ ì´ì‚°ë¶„í¬ (0/1)\n",
    "- í‰ê·  = p = 0.3\n",
    "- ë¶„ì‚° = p(1-p) = 0.21\n",
    "- SE = sqrt(p(1-p)/n)\n",
    "\n",
    "**CLT ê´€ì°°**:\n",
    "- n=5: í‘œë³¸í‰ê· ì´ 0, 0.2, 0.4, 0.6, 0.8, 1.0 ì¤‘ í•˜ë‚˜ (ì´ì‚°ì )\n",
    "- n=30: ì¤‘ì‹¬ê·¹í•œì •ë¦¬ ì ìš©, ì—°ì†ì  ì •ê·œë¶„í¬\n",
    "- n=100: í‘œì¤€ì˜¤ì°¨ê°€ ë§¤ìš° ì‘ì•„ì ¸ ì¢ì€ ë¶„í¬\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9. A/B í…ŒìŠ¤íŠ¸ ì„¤ê³„ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì „í™˜ìœ¨ 3% â†’ 3.5% ê°œì„ ì„ ìœ„í•œ A/B í…ŒìŠ¤íŠ¸ë¥¼ ì„¤ê³„í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9 ì •ë‹µ\n",
    "from statsmodels.stats.power import NormalIndPower\n",
    "\n",
    "# ì¡°ê±´ ì„¤ì •\n",
    "baseline_rate = 0.03    # í˜„ì¬ ì „í™˜ìœ¨ 3%\n",
    "target_rate = 0.035     # ëª©í‘œ ì „í™˜ìœ¨ 3.5%\n",
    "daily_traffic = 10000   # ì¼ì¼ íŠ¸ë˜í”½\n",
    "\n",
    "# ìƒëŒ€ì  ê°œì„ ìœ¨\n",
    "relative_lift = (target_rate - baseline_rate) / baseline_rate\n",
    "\n",
    "print(\"A/B í…ŒìŠ¤íŠ¸ ì„¤ê³„\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"í˜„ì¬ ì „í™˜ìœ¨: {baseline_rate:.1%}\")\n",
    "print(f\"ëª©í‘œ ì „í™˜ìœ¨: {target_rate:.1%}\")\n",
    "print(f\"ìƒëŒ€ì  ê°œì„ ìœ¨: {relative_lift:.1%}\")\n",
    "print(f\"ì¼ì¼ íŠ¸ë˜í”½: {daily_traffic:,}ëª…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. íš¨ê³¼ í¬ê¸° ê³„ì‚° (Cohen's h - ë¹„ìœ¨ ë¹„êµìš©)\n",
    "effect_size_h = 2 * (np.arcsin(np.sqrt(target_rate)) - np.arcsin(np.sqrt(baseline_rate)))\n",
    "\n",
    "print(f\"\\n1. íš¨ê³¼ í¬ê¸° (Cohen's h): {effect_size_h:.4f}\")\n",
    "\n",
    "# 2. 80% ê²€ì •ë ¥ í‘œë³¸ í¬ê¸°\n",
    "power_analysis = NormalIndPower()\n",
    "\n",
    "sample_80 = power_analysis.solve_power(\n",
    "    effect_size=effect_size_h,\n",
    "    alpha=0.05,\n",
    "    power=0.80,\n",
    "    alternative='two-sided'\n",
    ")\n",
    "\n",
    "total_sample_80 = int(np.ceil(sample_80)) * 2\n",
    "days_80 = int(np.ceil(total_sample_80 / daily_traffic))\n",
    "\n",
    "print(f\"\\n2. 80% ê²€ì •ë ¥ ê¸°ì¤€\")\n",
    "print(f\"   í•„ìš” í‘œë³¸ í¬ê¸°: ê° ê·¸ë£¹ {int(np.ceil(sample_80)):,}ëª…\")\n",
    "print(f\"   ì´ í•„ìš” ì¸ì›: {total_sample_80:,}ëª…\")\n",
    "print(f\"   ì˜ˆìƒ í…ŒìŠ¤íŠ¸ ê¸°ê°„: {days_80}ì¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 90% ê²€ì •ë ¥ í‘œë³¸ í¬ê¸°\n",
    "sample_90 = power_analysis.solve_power(\n",
    "    effect_size=effect_size_h,\n",
    "    alpha=0.05,\n",
    "    power=0.90,\n",
    "    alternative='two-sided'\n",
    ")\n",
    "\n",
    "total_sample_90 = int(np.ceil(sample_90)) * 2\n",
    "days_90 = int(np.ceil(total_sample_90 / daily_traffic))\n",
    "\n",
    "print(f\"\\n3. 90% ê²€ì •ë ¥ ê¸°ì¤€\")\n",
    "print(f\"   í•„ìš” í‘œë³¸ í¬ê¸°: ê° ê·¸ë£¹ {int(np.ceil(sample_90)):,}ëª…\")\n",
    "print(f\"   ì´ í•„ìš” ì¸ì›: {total_sample_90:,}ëª…\")\n",
    "print(f\"   ì˜ˆìƒ í…ŒìŠ¤íŠ¸ ê¸°ê°„: {days_90}ì¼\")\n",
    "\n",
    "# ì¶”ê°€ í•„ìš” ì¼ìˆ˜\n",
    "additional_days = days_90 - days_80\n",
    "print(f\"\\n90% ê²€ì •ë ¥ì„ ìœ„í•´ {additional_days}ì¼ ì¶”ê°€ í•„ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q9 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. ë¹„ìœ¨ ë¹„êµìš© íš¨ê³¼ í¬ê¸°(Cohen's h) ê³„ì‚°\n",
    "2. NormalIndPowerë¡œ í‘œë³¸ í¬ê¸° ê³„ì‚°\n",
    "3. ì¼ì¼ íŠ¸ë˜í”½ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê¸°ê°„ ì‚°ì¶œ\n",
    "\n",
    "**í•µì‹¬ ê³µì‹**:\n",
    "```\n",
    "Cohen's h = 2 * (arcsin(sqrt(p2)) - arcsin(sqrt(p1)))\n",
    "```\n",
    "\n",
    "**ê²°ê³¼ í•´ì„**:\n",
    "- 3% â†’ 3.5%ëŠ” ì‘ì€ íš¨ê³¼ (h â‰ˆ 0.03)\n",
    "- ì‘ì€ íš¨ê³¼ë¥¼ íƒì§€í•˜ë ¤ë©´ í° í‘œë³¸ í•„ìš”\n",
    "- 80% ê²€ì •ë ¥: ì•½ 2-3ì£¼\n",
    "- 90% ê²€ì •ë ¥: ì•½ 3-4ì£¼\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10. ì¢…í•© ë¶„ì„ í”„ë¡œì íŠ¸ â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì‹ ê·œ ì•± ê¸°ëŠ¥ì˜ ì‚¬ìš©ì ì²´ë¥˜ ì‹œê°„ ì¦ê°€ íš¨ê³¼ë¥¼ ê²€ì¦í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10 ì •ë‹µ\n",
    "np.random.seed(2025)\n",
    "\n",
    "# ì¡°ê±´ ì„¤ì •\n",
    "baseline_mean = 5.0  # ê¸°ì¡´ í‰ê·  ì²´ë¥˜ ì‹œê°„ (ë¶„)\n",
    "expected_mean = 5.5  # ëª©í‘œ í‰ê·  (10% ì¦ê°€)\n",
    "std_dev = 2.0        # í‘œì¤€í¸ì°¨\n",
    "\n",
    "print(\"ì‹ ê·œ ì•± ê¸°ëŠ¥ íš¨ê³¼ ê²€ì¦ ì‹¤í—˜\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ê¸°ì¡´ í‰ê·  ì²´ë¥˜ ì‹œê°„: {baseline_mean}ë¶„\")\n",
    "print(f\"ëª©í‘œ í‰ê·  ì²´ë¥˜ ì‹œê°„: {expected_mean}ë¶„ (+{(expected_mean-baseline_mean)/baseline_mean:.0%})\")\n",
    "print(f\"í‘œì¤€í¸ì°¨: {std_dev}ë¶„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. íš¨ê³¼ í¬ê¸° ê³„ì‚°\n",
    "effect_size = (expected_mean - baseline_mean) / std_dev\n",
    "\n",
    "print(f\"\\n1. íš¨ê³¼ í¬ê¸° ë¶„ì„\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Cohen's d = ({expected_mean} - {baseline_mean}) / {std_dev} = {effect_size:.2f}\")\n",
    "\n",
    "if effect_size < 0.2:\n",
    "    size_label = \"ë§¤ìš° ì‘ìŒ\"\n",
    "elif effect_size < 0.5:\n",
    "    size_label = \"ì‘ìŒ (Small)\"\n",
    "elif effect_size < 0.8:\n",
    "    size_label = \"ì¤‘ê°„ (Medium)\"\n",
    "else:\n",
    "    size_label = \"í¼ (Large)\"\n",
    "print(f\"íš¨ê³¼ í¬ê¸° í•´ì„: {size_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. í‘œë³¸ í¬ê¸° ê³„ì‚°\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "power_analysis = TTestIndPower()\n",
    "required_n = power_analysis.solve_power(\n",
    "    effect_size=effect_size,\n",
    "    alpha=0.05,\n",
    "    power=0.80,\n",
    "    alternative='two-sided'\n",
    ")\n",
    "\n",
    "n_per_group = int(np.ceil(required_n))\n",
    "\n",
    "print(f\"\\n2. í‘œë³¸ í¬ê¸° ê³„ì‚° (80% ê²€ì •ë ¥)\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"í•„ìš” í‘œë³¸ í¬ê¸°: ê° ê·¸ë£¹ {n_per_group}ëª…\")\n",
    "print(f\"ì´ í•„ìš” ì¸ì›: {n_per_group * 2}ëª…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ê°€ìƒ ë°ì´í„° ìƒì„± ë° t-ê²€ì •\n",
    "np.random.seed(2025)\n",
    "\n",
    "# ëŒ€ì¡°êµ° (ê¸°ì¡´ ê¸°ëŠ¥)\n",
    "control = np.random.normal(baseline_mean, std_dev, n_per_group)\n",
    "\n",
    "# ì‹¤í—˜êµ° (ì‹ ê·œ ê¸°ëŠ¥)\n",
    "treatment = np.random.normal(expected_mean, std_dev, n_per_group)\n",
    "\n",
    "# t-ê²€ì • ìˆ˜í–‰\n",
    "t_stat, p_value = stats.ttest_ind(treatment, control)\n",
    "\n",
    "print(f\"\\n3. t-ê²€ì • ê²°ê³¼\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"ëŒ€ì¡°êµ° í‰ê· : {np.mean(control):.2f}ë¶„\")\n",
    "print(f\"ì‹¤í—˜êµ° í‰ê· : {np.mean(treatment):.2f}ë¶„\")\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# ê²°ë¡ \n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"\\nê²°ë¡ : p-value ({p_value:.4f}) < Î± ({alpha})\")\n",
    "    print(\"       â†’ ê·€ë¬´ê°€ì„¤ ê¸°ê°. ì‹ ê·œ ê¸°ëŠ¥ì´ ì²´ë¥˜ ì‹œê°„ ì¦ê°€ì— ìœ ì˜í•œ íš¨ê³¼!\")\n",
    "else:\n",
    "    print(f\"\\nê²°ë¡ : p-value ({p_value:.4f}) >= Î± ({alpha})\")\n",
    "    print(\"       â†’ ê·€ë¬´ê°€ì„¤ ì±„íƒ. í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ì‹œê°í™”\n",
    "fig = go.Figure()\n",
    "\n",
    "# ëŒ€ì¡°êµ° íˆìŠ¤í† ê·¸ë¨\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=control,\n",
    "    name='ëŒ€ì¡°êµ° (ê¸°ì¡´)',\n",
    "    opacity=0.7,\n",
    "    marker_color='blue'\n",
    "))\n",
    "\n",
    "# ì‹¤í—˜êµ° íˆìŠ¤í† ê·¸ë¨\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=treatment,\n",
    "    name='ì‹¤í—˜êµ° (ì‹ ê·œ)',\n",
    "    opacity=0.7,\n",
    "    marker_color='red'\n",
    "))\n",
    "\n",
    "# í‰ê· ì„  ì¶”ê°€\n",
    "fig.add_vline(x=np.mean(control), line_dash=\"dash\", line_color=\"blue\",\n",
    "              annotation_text=f\"ëŒ€ì¡°êµ° í‰ê· : {np.mean(control):.2f}\")\n",
    "fig.add_vline(x=np.mean(treatment), line_dash=\"dash\", line_color=\"red\",\n",
    "              annotation_text=f\"ì‹¤í—˜êµ° í‰ê· : {np.mean(treatment):.2f}\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ì‹ ê·œ ì•± ê¸°ëŠ¥ A/B í…ŒìŠ¤íŠ¸: ì²´ë¥˜ ì‹œê°„ ë¶„í¬ ë¹„êµ',\n",
    "    xaxis_title='ì²´ë¥˜ ì‹œê°„ (ë¶„)',\n",
    "    yaxis_title='ë¹ˆë„',\n",
    "    barmode='overlay',\n",
    "    height=450, width=800\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ\n",
    "# ì‹¤ì œ íš¨ê³¼ í¬ê¸° ê³„ì‚°\n",
    "actual_d = (np.mean(treatment) - np.mean(control)) / np.sqrt(\n",
    "    ((len(control)-1)*np.var(control, ddof=1) + (len(treatment)-1)*np.var(treatment, ddof=1)) / \n",
    "    (len(control)+len(treatment)-2)\n",
    ")\n",
    "\n",
    "# ì‹¤ì œ ê²€ì •ë ¥ ê³„ì‚°\n",
    "actual_power = power_analysis.solve_power(\n",
    "    effect_size=actual_d,\n",
    "    alpha=0.05,\n",
    "    nobs1=n_per_group,\n",
    "    alternative='two-sided'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"5. ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "report = pd.DataFrame({\n",
    "    'ì§€í‘œ': ['í‘œë³¸ í¬ê¸° (ê° ê·¸ë£¹)', 'p-value', 'íš¨ê³¼ í¬ê¸° (Cohen\\'s d)', 'ê²€ì •ë ¥', 'ê²°ë¡ '],\n",
    "    'ê³„íš': [f'{n_per_group}ëª…', f'< 0.05', f'{effect_size:.2f}', '80%', '-'],\n",
    "    'ì‹¤ì œ': [f'{n_per_group}ëª…', f'{p_value:.4f}', f'{actual_d:.2f}', f'{actual_power:.1%}', \n",
    "            'ìœ ì˜í•¨' if p_value < 0.05 else 'ìœ ì˜í•˜ì§€ ì•ŠìŒ']\n",
    "})\n",
    "\n",
    "print(report.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ìµœì¢… ê²°ë¡ \")\n",
    "print(\"=\" * 60)\n",
    "if p_value < 0.05:\n",
    "    improvement = (np.mean(treatment) - np.mean(control)) / np.mean(control) * 100\n",
    "    print(f\"ì‹ ê·œ ì•± ê¸°ëŠ¥ì€ ì‚¬ìš©ì ì²´ë¥˜ ì‹œê°„ì„ ì•½ {improvement:.1f}% ì¦ê°€ì‹œí‚µë‹ˆë‹¤.\")\n",
    "    print(f\"ì´ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ê²°ê³¼ì´ë©° (p={p_value:.4f}),\")\n",
    "    print(f\"íš¨ê³¼ í¬ê¸°ëŠ” {size_label}ì…ë‹ˆë‹¤ (d={actual_d:.2f}).\")\n",
    "    print(\"\\nê¶Œì¥: ì‹ ê·œ ê¸°ëŠ¥ ì „ì²´ ì¶œì‹œ ì§„í–‰\")\n",
    "else:\n",
    "    print(\"ì‹ ê·œ ì•± ê¸°ëŠ¥ì˜ íš¨ê³¼ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    print(\"\\nê¶Œì¥: ê¸°ëŠ¥ ê°œì„  ë˜ëŠ” ì¶”ê°€ í…ŒìŠ¤íŠ¸ í•„ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Q10 í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. íš¨ê³¼ í¬ê¸° ê³„ì‚° (d = ì°¨ì´/í‘œì¤€í¸ì°¨)\n",
    "2. Power ë¶„ì„ìœ¼ë¡œ í‘œë³¸ í¬ê¸° ê²°ì •\n",
    "3. ê°€ìƒ ë°ì´í„° ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)\n",
    "4. t-ê²€ì • ìˆ˜í–‰\n",
    "5. ê²°ê³¼ ì‹œê°í™” ë° í•´ì„\n",
    "\n",
    "**í•µì‹¬ ê°œë… í†µí•©**:\n",
    "- Cohen's dë¡œ íš¨ê³¼ í¬ê¸° ì •ëŸ‰í™”\n",
    "- Power ë¶„ì„ìœ¼ë¡œ ì ì ˆí•œ í‘œë³¸ í¬ê¸° ê²°ì •\n",
    "- t-ê²€ì •ìœ¼ë¡œ í†µê³„ì  ìœ ì˜ì„± í™•ì¸\n",
    "- p-valueì™€ íš¨ê³¼ í¬ê¸° í•¨ê»˜ ë³´ê³ \n",
    "\n",
    "**ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸**:\n",
    "- [ ] íƒì§€í•  ìµœì†Œ íš¨ê³¼ í¬ê¸° ì •ì˜\n",
    "- [ ] í•„ìš” í‘œë³¸ í¬ê¸° ê³„ì‚° (Power ë¶„ì„)\n",
    "- [ ] ë°ì´í„° ìˆ˜ì§‘ ë° ë¬´ì‘ìœ„ ë°°ì •\n",
    "- [ ] ì ì ˆí•œ ê²€ì • ìˆ˜í–‰ (t-test, chi-square ë“±)\n",
    "- [ ] p-value + íš¨ê³¼ í¬ê¸° + ì‹ ë¢°êµ¬ê°„ í•¨ê»˜ ë³´ê³ \n",
    "- [ ] ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì  í•´ì„ ë° ì˜ì‚¬ê²°ì •\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ìµœì¢… í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "### Part 1: ê¸°ì´ˆ ê°œë…\n",
    "\n",
    "| ê°œë… | í•µì‹¬ í¬ì¸íŠ¸ | ê³µì‹/ì¡°ê±´ |\n",
    "|------|------------|----------|\n",
    "| ëŒ€ìˆ˜ì˜ ë²•ì¹™ | nâ†‘ â†’ í‘œë³¸í‰ê·  â†’ ëª¨í‰ê·  | ë§ì´ ê´€ì°°í•˜ë©´ ìˆ˜ë ´ |\n",
    "| ì¤‘ì‹¬ê·¹í•œì •ë¦¬ | í‘œë³¸í‰ê· ì€ ì •ê·œë¶„í¬ | n â‰¥ 30 |\n",
    "| í‘œì¤€ì˜¤ì°¨ | í‘œë³¸í‰ê· ì˜ ë¶ˆí™•ì‹¤ì„± | SE = Ïƒ/âˆšn |\n",
    "\n",
    "### Part 2: ì‹¬í™” ê°œë…\n",
    "\n",
    "| ê°œë… | ì •ì˜ | ì‹¤ë¬´ í™œìš© |\n",
    "|------|------|----------|\n",
    "| Type I ì˜¤ë¥˜ | ì—†ëŠ”ë° ìˆë‹¤ê³  | Î±ë¡œ í†µì œ (0.05) |\n",
    "| Type II ì˜¤ë¥˜ | ìˆëŠ”ë° ì—†ë‹¤ê³  | ê²€ì •ë ¥ìœ¼ë¡œ ê´€ë¦¬ |\n",
    "| ê²€ì •ë ¥ | íš¨ê³¼ ë°œê²¬ í™•ë¥  | 80% ì´ìƒ ê¶Œì¥ |\n",
    "| Cohen's d | íš¨ê³¼ í¬ê¸° | 0.2/0.5/0.8 ê¸°ì¤€ |\n",
    "\n",
    "### ì‹¤ë¬´ ì ìš© ìˆœì„œ\n",
    "\n",
    "```\n",
    "1. íš¨ê³¼ í¬ê¸° ì •ì˜ (ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì )\n",
    "   â†“\n",
    "2. Power ë¶„ì„ â†’ í‘œë³¸ í¬ê¸° ê²°ì •\n",
    "   â†“\n",
    "3. ì‹¤í—˜ ìˆ˜í–‰ ë° ë°ì´í„° ìˆ˜ì§‘\n",
    "   â†“\n",
    "4. í†µê³„ ê²€ì • (t-test ë“±)\n",
    "   â†“\n",
    "5. ê²°ê³¼ í•´ì„ (p-value + íš¨ê³¼ í¬ê¸°)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
