{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day7_0: ì •ì  ìŠ¤í¬ë˜ì´í•‘ (BeautifulSoup) - ì •ë‹µ\n",
    "\n",
    "## ğŸ“š í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "**Part 1: ê¸°ì´ˆ**\n",
    "1. HTML êµ¬ì¡° ì´í•´í•˜ê¸°\n",
    "2. requestsë¡œ ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°\n",
    "3. BeautifulSoup íŒŒì‹± ê¸°ì´ˆ\n",
    "4. find()ì™€ find_all() ì‚¬ìš©ë²• ìµíˆê¸°\n",
    "5. CSS Selector ê¸°ë³¸ ë¬¸ë²• ë°°ìš°ê¸°\n",
    "\n",
    "**Part 2: ì‹¤ì „ í¬ë¡¤ë§**\n",
    "1. CSS Selector ê³ ê¸‰ í™œìš©í•˜ê¸°\n",
    "2. í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œí•˜ê¸°\n",
    "3. í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬í•˜ê¸°\n",
    "4. ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§ êµ¬í˜„í•˜ê¸°\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ì‹¤ìŠµ í€´ì¦ˆ ì •ë‹µ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. HTML íƒœê·¸ ì¶”ì¶œí•˜ê¸° â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ HTMLì—ì„œ `<h1>` íƒœê·¸ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 ì •ë‹µ\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"<html><body><h1>í™˜ì˜í•©ë‹ˆë‹¤</h1></body></html>\"\n",
    "\n",
    "# 1. BeautifulSoupìœ¼ë¡œ íŒŒì‹±\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 2. h1 íƒœê·¸ ì°¾ê¸°\n",
    "h1_tag = soup.find(\"h1\")\n",
    "\n",
    "# 3. í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "result = h1_tag.text\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert result == \"í™˜ì˜í•©ë‹ˆë‹¤\", \"h1 íƒœê·¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨\"\n",
    "print(\"âœ… í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "BeautifulSoupìœ¼ë¡œ HTMLì„ íŒŒì‹±í•œ í›„ `find()` ë©”ì†Œë“œë¡œ h1 íƒœê·¸ë¥¼ ì°¾ê³  `.text` ì†ì„±ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- `BeautifulSoup(html, \"html.parser\")`: HTML ë¬¸ìì—´ íŒŒì‹±\n",
    "- `find(\"íƒœê·¸ëª…\")`: ì²« ë²ˆì§¸ íƒœê·¸ ì°¾ê¸°\n",
    "- `.text`: íƒœê·¸ì˜ í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ\n",
    "\n",
    "**ëŒ€ì•ˆ ì†”ë£¨ì…˜**:\n",
    "```python\n",
    "# select_oneìœ¼ë¡œë„ ê°€ëŠ¥\n",
    "result = soup.select_one(\"h1\").text\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- âŒ `soup.h1` ì§ì ‘ ì ‘ê·¼: ì†ì„± ì˜¤ë¥˜ ê°€ëŠ¥ì„±\n",
    "- âŒ `.string` ì‚¬ìš©: ì¤‘ì²© íƒœê·¸ì—ì„œ None ë°˜í™˜ ê°€ëŠ¥\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "ê°„ë‹¨í•œ íƒœê·¸ëŠ” `find()`ë¡œ, ë³µì¡í•œ ì„ íƒì€ CSS Selectorë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q2. í´ë˜ìŠ¤ë¡œ ìš”ì†Œ ì°¾ê¸° â­â­\n",
    "\n",
    "**ë¬¸ì œ**: `class=\"info\"` ì¸ ëª¨ë“  `<p>` íƒœê·¸ì˜ í…ìŠ¤íŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 ì •ë‹µ\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<div>\n",
    "    <p class=\"info\">ì •ë³´1</p>\n",
    "    <p>ì¼ë°˜ í…ìŠ¤íŠ¸</p>\n",
    "    <p class=\"info\">ì •ë³´2</p>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 1. class=\"info\"ì¸ ëª¨ë“  p íƒœê·¸ ì°¾ê¸°\n",
    "info_tags = soup.find_all(\"p\", class_=\"info\")\n",
    "\n",
    "# 2. í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "result = [tag.text for tag in info_tags]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert result == [\"ì •ë³´1\", \"ì •ë³´2\"], \"í´ë˜ìŠ¤ í•„í„°ë§ ì‹¤íŒ¨\"\n",
    "print(\"âœ… í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "`find_all()`ë¡œ ì¡°ê±´ì— ë§ëŠ” ëª¨ë“  íƒœê·¸ë¥¼ ì°¾ì€ í›„ ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- `find_all(\"p\", class_=\"info\")`: íŠ¹ì • í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ëª¨ë“  p íƒœê·¸\n",
    "- ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜: `[tag.text for tag in tags]`\n",
    "\n",
    "**ëŒ€ì•ˆ ì†”ë£¨ì…˜**:\n",
    "```python\n",
    "# CSS Selector ì‚¬ìš©\n",
    "info_tags = soup.select(\"p.info\")\n",
    "result = [tag.text for tag in info_tags]\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- âŒ `class_` ëŒ€ì‹  `class` ì‚¬ìš©: Python ì˜ˆì•½ì–´ ì¶©ëŒ\n",
    "- âŒ `find()` ì‚¬ìš©: ì²« ë²ˆì§¸ ìš”ì†Œë§Œ ë°˜í™˜\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "ì—¬ëŸ¬ í´ë˜ìŠ¤ê°€ ìˆì„ ë•ŒëŠ” `class_=[\"class1\", \"class2\"]`ë¡œ OR ì¡°ê±´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q3. ë§í¬ ì†ì„± ì¶”ì¶œ â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ëª¨ë“  `<a>` íƒœê·¸ì˜ `href` ì†ì„±ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 ì •ë‹µ\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<nav>\n",
    "    <a href=\"/home\">í™ˆ</a>\n",
    "    <a href=\"/about\">ì†Œê°œ</a>\n",
    "    <a href=\"/contact\">ì—°ë½ì²˜</a>\n",
    "</nav>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 1. ëª¨ë“  a íƒœê·¸ ì°¾ê¸°\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "# 2. href ì†ì„±ë§Œ ì¶”ì¶œ\n",
    "result = [link.get(\"href\") for link in links]\n",
    "# ë˜ëŠ”: result = [link[\"href\"] for link in links]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert result == [\"/home\", \"/about\", \"/contact\"], \"href ì†ì„± ì¶”ì¶œ ì‹¤íŒ¨\"\n",
    "print(\"âœ… í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "ëª¨ë“  a íƒœê·¸ë¥¼ ì°¾ì€ í›„ `.get(\"ì†ì„±ëª…\")` ë©”ì†Œë“œë¡œ href ì†ì„±ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- `tag.get(\"href\")`: ì•ˆì „í•œ ì†ì„± ì¶”ì¶œ (ì—†ìœ¼ë©´ None)\n",
    "- `tag[\"href\"]`: ì§ì ‘ ì ‘ê·¼ (ì—†ìœ¼ë©´ KeyError)\n",
    "\n",
    "**ëŒ€ì•ˆ ì†”ë£¨ì…˜**:\n",
    "```python\n",
    "# CSS Selector ì‚¬ìš©\n",
    "result = [link[\"href\"] for link in soup.select(\"a[href]\")]\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- âŒ `link.href`: ì†ì„± ì ‘ê·¼ ë¶ˆê°€\n",
    "- âŒ href ì—†ëŠ” íƒœê·¸ì— `link[\"href\"]`: KeyError\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "ì†ì„±ì´ ì—†ì„ ìˆ˜ ìˆë‹¤ë©´ `.get(\"href\", ê¸°ë³¸ê°’)` ì‚¬ìš©ì´ ì•ˆì „í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q4. CSS Selector ì‚¬ìš© â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: CSS Selectorë¡œ `class=\"product\"` ì¸ `<div>` ì•ˆì˜ ëª¨ë“  `<h3>` íƒœê·¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 ì •ë‹µ\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<div class=\"product\">\n",
    "    <h3>ìƒí’ˆA</h3>\n",
    "    <p>ì„¤ëª…</p>\n",
    "</div>\n",
    "<div class=\"product\">\n",
    "    <h3>ìƒí’ˆB</h3>\n",
    "    <p>ì„¤ëª…</p>\n",
    "</div>\n",
    "<div class=\"other\">\n",
    "    <h3>ê¸°íƒ€</h3>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 1. CSS Selectorë¡œ div.product ì•ˆì˜ h3 íƒœê·¸ ì°¾ê¸°\n",
    "product_h3 = soup.select(\"div.product h3\")\n",
    "\n",
    "# 2. í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "result = [h3.text for h3 in product_h3]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert result == [\"ìƒí’ˆA\", \"ìƒí’ˆB\"], \"CSS Selector í•„í„°ë§ ì‹¤íŒ¨\"\n",
    "print(\"âœ… í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "CSS Selectorì˜ ìì† ì„ íƒìë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • í´ë˜ìŠ¤ div ë‚´ë¶€ì˜ h3ë§Œ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- `\"div.product h3\"`: product í´ë˜ìŠ¤ë¥¼ ê°€ì§„ divì˜ ëª¨ë“  í›„ì† h3\n",
    "- ë„ì–´ì“°ê¸°: ìì† ì„ íƒì (ëª¨ë“  í›„ì†)\n",
    "- `>`: ì§ê³„ ìì‹ë§Œ ì„ íƒ\n",
    "\n",
    "**ëŒ€ì•ˆ ì†”ë£¨ì…˜**:\n",
    "```python\n",
    "# ì§ê³„ ìì‹ë§Œ ì„ íƒ (ë” ì •í™•)\n",
    "result = [h3.text for h3 in soup.select(\"div.product > h3\")]\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- âŒ `\"div.product.h3\"`: ì (.)ì€ í´ë˜ìŠ¤ ì—°ê²°\n",
    "- âŒ `\"div product h3\"`: class ì•ì— ì  í•„ìˆ˜\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "ë³µì¡í•œ êµ¬ì¡°ì—ì„œëŠ” CSS Selectorê°€ find_allë³´ë‹¤ ì§ê´€ì ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q5. ìƒí’ˆ ì •ë³´ êµ¬ì¡°í™” â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ê° ìƒí’ˆì˜ ì´ë¦„ê³¼ ê°€ê²©ì„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 ì •ë‹µ\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<div class=\"item\">\n",
    "    <span class=\"name\">ë…¸íŠ¸ë¶</span>\n",
    "    <span class=\"price\">1500000</span>\n",
    "</div>\n",
    "<div class=\"item\">\n",
    "    <span class=\"name\">ë§ˆìš°ìŠ¤</span>\n",
    "    <span class=\"price\">30000</span>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 1. ëª¨ë“  item div ì°¾ê¸°\n",
    "items = soup.find_all(\"div\", class_=\"item\")\n",
    "\n",
    "# 2. ê° itemì—ì„œ nameê³¼ price ì¶”ì¶œí•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
    "result = []\n",
    "for item in items:\n",
    "    product = {\n",
    "        \"name\": item.find(\"span\", class_=\"name\").text,\n",
    "        \"price\": item.find(\"span\", class_=\"price\").text\n",
    "    }\n",
    "    result.append(product)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "expected = [\n",
    "    {\"name\": \"ë…¸íŠ¸ë¶\", \"price\": \"1500000\"},\n",
    "    {\"name\": \"ë§ˆìš°ìŠ¤\", \"price\": \"30000\"}\n",
    "]\n",
    "assert result == expected, \"ìƒí’ˆ ì •ë³´ êµ¬ì¡°í™” ì‹¤íŒ¨\"\n",
    "print(\"âœ… í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. ìƒìœ„ ì»¨í…Œì´ë„ˆ(item)ë¥¼ ëª¨ë‘ ì°¾ê¸°\n",
    "2. ê° ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ name, price ì¶”ì¶œ\n",
    "3. ë”•ì…”ë„ˆë¦¬ë¡œ êµ¬ì¡°í™”í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ê³„ì¸µì  íŒŒì‹±: ìƒìœ„ ìš”ì†Œ â†’ í•˜ìœ„ ìš”ì†Œ\n",
    "- ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°í™”: ë°ì´í„° ê´€ë¦¬ ìš©ì´\n",
    "\n",
    "**ëŒ€ì•ˆ ì†”ë£¨ì…˜**:\n",
    "```python\n",
    "# ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ ì‚¬ìš©\n",
    "result = [\n",
    "    {\n",
    "        \"name\": item.select_one(\".name\").text,\n",
    "        \"price\": item.select_one(\".price\").text\n",
    "    }\n",
    "    for item in soup.select(\"div.item\")\n",
    "]\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- âŒ ì „ì²´ HTMLì—ì„œ name/price ì§ì ‘ ì¶”ì¶œ: ìˆœì„œ ë¶ˆì¼ì¹˜\n",
    "- âŒ zip() ì‚¬ìš©: ì¤‘ì²© êµ¬ì¡°ì—ì„œ ìœ„í—˜\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "êµ¬ì¡°í™”ëœ ë°ì´í„°ëŠ” ë‚˜ì¤‘ì— pandas DataFrameìœ¼ë¡œ ì‰½ê²Œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q6. ì†ì„± ì„ íƒì í™œìš© â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: `href` ì†ì„±ì´ `https`ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ë§í¬ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6 ì •ë‹µ\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<a href=\"https://example.com\">ì™¸ë¶€ë§í¬1</a>\n",
    "<a href=\"/internal\">ë‚´ë¶€ë§í¬</a>\n",
    "<a href=\"https://google.com\">ì™¸ë¶€ë§í¬2</a>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 1. CSS ì†ì„± ì„ íƒì: hrefê°€ \"https\"ë¡œ ì‹œì‘í•˜ëŠ” a íƒœê·¸\n",
    "external_links = soup.select('a[href^=\"https\"]')\n",
    "\n",
    "# 2. í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "result = [link.text for link in external_links]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert result == [\"ì™¸ë¶€ë§í¬1\", \"ì™¸ë¶€ë§í¬2\"], \"ì†ì„± ì„ íƒì í•„í„°ë§ ì‹¤íŒ¨\"\n",
    "print(\"âœ… í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "CSS ì†ì„± ì„ íƒì `^=`ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ë¬¸ìì—´ë¡œ ì‹œì‘í•˜ëŠ” ì†ì„±ê°’ì„ í•„í„°ë§í•©ë‹ˆë‹¤.\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- `[href^=\"https\"]`: hrefê°€ \"https\"ë¡œ ì‹œì‘\n",
    "- `[href$=\".pdf\"]`: hrefê°€ \".pdf\"ë¡œ ëë‚¨\n",
    "- `[href*=\"keyword\"]`: hrefì— \"keyword\" í¬í•¨\n",
    "\n",
    "**ëŒ€ì•ˆ ì†”ë£¨ì…˜**:\n",
    "```python\n",
    "# find_all + ì¡°ê±´ í•„í„°ë§\n",
    "all_links = soup.find_all(\"a\")\n",
    "result = [\n",
    "    link.text \n",
    "    for link in all_links \n",
    "    if link.get(\"href\", \"\").startswith(\"https\")\n",
    "]\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- âŒ `[href=\"https\"]`: ì •í™•íˆ ì¼ì¹˜ë§Œ ì„ íƒ\n",
    "- âŒ ë”°ì˜´í‘œ ìƒëµ: ë¬¸ë²• ì˜¤ë¥˜\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "ì™¸ë¶€ ë§í¬/ë‚´ë¶€ ë§í¬ ë¶„ë¦¬, ì´ë¯¸ì§€/PDF íŒŒì¼ í•„í„°ë§ ë“±ì— ìœ ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q7. í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: í…Œì´ë¸”ì—ì„œ í—¤ë”ì™€ ë°ì´í„°ë¥¼ pandas DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 ì •ë‹µ\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "table_html = \"\"\"\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr><th>ì´ë¦„</th><th>ë‚˜ì´</th><th>ì§ì—…</th></tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr><td>ê¹€ì² ìˆ˜</td><td>30</td><td>ê°œë°œì</td></tr>\n",
    "        <tr><td>ì´ì˜í¬</td><td>28</td><td>ë””ìì´ë„ˆ</td></tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(table_html, \"html.parser\")\n",
    "\n",
    "# 1. í—¤ë” ì¶”ì¶œ\n",
    "headers = [th.text for th in soup.select(\"thead th\")]\n",
    "print(f\"í—¤ë”: {headers}\")\n",
    "\n",
    "# 2. ë°ì´í„° í–‰ ì¶”ì¶œ\n",
    "rows = []\n",
    "for tr in soup.select(\"tbody tr\"):\n",
    "    cells = [td.text for td in tr.select(\"td\")]\n",
    "    rows.append(cells)\n",
    "print(f\"í–‰ ë°ì´í„°: {rows}\")\n",
    "\n",
    "# 3. DataFrame ìƒì„±\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "print(\"\\nDataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert df.shape == (2, 3), \"DataFrame í¬ê¸° ì˜¤ë¥˜\"\n",
    "assert list(df.columns) == [\"ì´ë¦„\", \"ë‚˜ì´\", \"ì§ì—…\"], \"ì»¬ëŸ¼ëª… ì˜¤ë¥˜\"\n",
    "assert df.iloc[0, 0] == \"ê¹€ì² ìˆ˜\", \"ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜\"\n",
    "print(\"âœ… í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. theadì—ì„œ í—¤ë” ì¶”ì¶œ\n",
    "2. tbodyì˜ ê° trì—ì„œ td ì…€ ì¶”ì¶œ\n",
    "3. pandas DataFrameìœ¼ë¡œ êµ¬ì¡°í™”\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- `soup.select(\"thead th\")`: í…Œì´ë¸” í—¤ë”\n",
    "- `soup.select(\"tbody tr\")`: ë°ì´í„° í–‰\n",
    "- `tr.select(\"td\")`: ê° í–‰ì˜ ì…€\n",
    "- `pd.DataFrame(data, columns)`: DataFrame ìƒì„±\n",
    "\n",
    "**ëŒ€ì•ˆ ì†”ë£¨ì…˜**:\n",
    "```python\n",
    "# pandasì˜ read_html ì‚¬ìš© (ê°„ë‹¨!)\n",
    "df = pd.read_html(table_html)[0]\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- âŒ thì™€ td í˜¼ë™: í—¤ë”ëŠ” th, ë°ì´í„°ëŠ” td\n",
    "- âŒ thead/tbody ìƒëµëœ í…Œì´ë¸”: trë§Œìœ¼ë¡œ ì²˜ë¦¬\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "pandasì˜ `read_html()`ì€ í¸ë¦¬í•˜ì§€ë§Œ, ë³µì¡í•œ í…Œì´ë¸”ì€ BeautifulSoupìœ¼ë¡œ ì§ì ‘ íŒŒì‹±ì´ ì •í™•í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q8. ì•ˆì „í•œ ìš”ì†Œ ì¶”ì¶œ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì—†ì„ ìˆ˜ë„ ìˆëŠ” ìš”ì†Œë¥¼ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8 ì •ë‹µ\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def safe_extract(html, selector):\n",
    "    \"\"\"\n",
    "    ì•ˆì „í•˜ê²Œ ìš”ì†Œì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "    \n",
    "    Args:\n",
    "        html: HTML ë¬¸ìì—´\n",
    "        selector: CSS Selector\n",
    "    \n",
    "    Returns:\n",
    "        ìš”ì†Œì˜ í…ìŠ¤íŠ¸ ë˜ëŠ” \"ì—†ìŒ\"\n",
    "    \"\"\"\n",
    "    # 1. HTML íŒŒì‹±\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # 2. ìš”ì†Œ ì°¾ê¸°\n",
    "    element = soup.select_one(selector)\n",
    "    \n",
    "    # 3. ìš”ì†Œê°€ ìˆìœ¼ë©´ í…ìŠ¤íŠ¸, ì—†ìœ¼ë©´ \"ì—†ìŒ\"\n",
    "    if element:\n",
    "        return element.text\n",
    "    return \"ì—†ìŒ\"\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "html1 = \"<div><p class='desc'>ì„¤ëª…</p></div>\"\n",
    "html2 = \"<div></div>\"\n",
    "\n",
    "result1 = safe_extract(html1, \"p.desc\")\n",
    "result2 = safe_extract(html2, \"p.desc\")\n",
    "\n",
    "print(f\"ê²°ê³¼1: {result1}\")\n",
    "print(f\"ê²°ê³¼2: {result2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert result1 == \"ì„¤ëª…\", \"ìš”ì†Œ ìˆì„ ë•Œ ì¶”ì¶œ ì‹¤íŒ¨\"\n",
    "assert result2 == \"ì—†ìŒ\", \"ìš”ì†Œ ì—†ì„ ë•Œ ê¸°ë³¸ê°’ ì‹¤íŒ¨\"\n",
    "print(\"âœ… í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "`select_one()`ìœ¼ë¡œ ìš”ì†Œë¥¼ ì°¾ê³ , None ì²´í¬ í›„ ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- `select_one()`: ìš”ì†Œ ì—†ìœ¼ë©´ None ë°˜í™˜\n",
    "- `if element:`: None ì²´í¬\n",
    "- ê¸°ë³¸ê°’ ë°˜í™˜: ì—ëŸ¬ ë°©ì§€\n",
    "\n",
    "**ëŒ€ì•ˆ ì†”ë£¨ì…˜**:\n",
    "```python\n",
    "# get_text() ì‚¬ìš©\n",
    "def safe_extract(html, selector):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    element = soup.select_one(selector)\n",
    "    return element.get_text(strip=True) if element else \"ì—†ìŒ\"\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- âŒ None ì²´í¬ ì—†ì´ `.text`: AttributeError\n",
    "- âŒ try-exceptë§Œ ì‚¬ìš©: ë‹¤ë¥¸ ì˜¤ë¥˜ë„ catch\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "í¬ë¡¤ë§ì—ì„œëŠ” í•­ìƒ ìš”ì†Œ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” ì•ˆì „í•œ í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ ì‚¬ìš©í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q9. í˜ì´ì§€ë„¤ì´ì…˜ URL ìƒì„± â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: 1~5í˜ì´ì§€ì˜ URLì„ ìƒì„±í•˜ê³  ê° í˜ì´ì§€ì—ì„œ ìƒí’ˆëª…ì„ ìˆ˜ì§‘í•˜ëŠ” ì‹œë®¬ë ˆì´ì…˜ í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9 ì •ë‹µ\n",
    "\n",
    "import time\n",
    "\n",
    "def crawl_pages(base_url, max_pages=5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ í˜ì´ì§€ë¥¼ ìˆœíšŒí•˜ë©° ë°ì´í„° ìˆ˜ì§‘ (ì‹œë®¬ë ˆì´ì…˜)\n",
    "    \n",
    "    Args:\n",
    "        base_url: ê¸°ë³¸ URL\n",
    "        max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "        ìˆ˜ì§‘ëœ ìƒí’ˆëª… ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    all_products = []\n",
    "    \n",
    "    # 1. í˜ì´ì§€ ìˆœíšŒ\n",
    "    for page in range(1, max_pages + 1):\n",
    "        # 2. URL ìƒì„±\n",
    "        url = f\"{base_url}?page={page}\"\n",
    "        print(f\"í˜ì´ì§€ {page} í¬ë¡¤ë§: {url}\")\n",
    "        \n",
    "        # 3. ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ requests.get(url)\n",
    "        # response = requests.get(url, headers=headers)\n",
    "        # soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        # products = soup.select(\"div.product h3\")\n",
    "        \n",
    "        # 4. ì‹œë®¬ë ˆì´ì…˜: í˜ì´ì§€ë‹¹ 2ê°œ ìƒí’ˆ ìƒì„±\n",
    "        page_products = [\n",
    "            f\"ìƒí’ˆ{page}-1\",\n",
    "            f\"ìƒí’ˆ{page}-2\"\n",
    "        ]\n",
    "        all_products.extend(page_products)\n",
    "        \n",
    "        # 5. Rate Limiting (0.5ì´ˆ ëŒ€ê¸°)\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    return all_products\n",
    "\n",
    "# ì‹¤í–‰\n",
    "base_url = \"https://shop.example.com/products\"\n",
    "result = crawl_pages(base_url, max_pages=5)\n",
    "print(f\"\\nì´ ìˆ˜ì§‘: {len(result)}ê°œ\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "expected = [\n",
    "    \"ìƒí’ˆ1-1\", \"ìƒí’ˆ1-2\", \"ìƒí’ˆ2-1\", \"ìƒí’ˆ2-2\",\n",
    "    \"ìƒí’ˆ3-1\", \"ìƒí’ˆ3-2\", \"ìƒí’ˆ4-1\", \"ìƒí’ˆ4-2\",\n",
    "    \"ìƒí’ˆ5-1\", \"ìƒí’ˆ5-2\"\n",
    "]\n",
    "assert result == expected, \"í˜ì´ì§€ë„¤ì´ì…˜ ìˆ˜ì§‘ ì‹¤íŒ¨\"\n",
    "assert len(result) == 10, \"ì´ ê°œìˆ˜ ì˜¤ë¥˜\"\n",
    "print(\"âœ… í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. í˜ì´ì§€ ë²”ìœ„ ë°˜ë³µ (range)\n",
    "2. ê° í˜ì´ì§€ì˜ URL ìƒì„± (f-string)\n",
    "3. ë°ì´í„° ìˆ˜ì§‘ (ì‹¤ì œë¡œëŠ” requests + BeautifulSoup)\n",
    "4. ê²°ê³¼ ëˆ„ì  (extend)\n",
    "5. Rate Limiting (time.sleep)\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- `f\"{base_url}?page={page}\"`: ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° URL\n",
    "- `extend()`: ë¦¬ìŠ¤íŠ¸ì— ì—¬ëŸ¬ ìš”ì†Œ ì¶”ê°€\n",
    "- `time.sleep(0.5)`: ì„œë²„ ë¶€í•˜ ë°©ì§€\n",
    "\n",
    "**ëŒ€ì•ˆ ì†”ë£¨ì…˜**:\n",
    "```python\n",
    "# ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ (ê°„ë‹¨í•œ ê²½ìš°)\n",
    "all_products = [\n",
    "    f\"ìƒí’ˆ{page}-{i}\"\n",
    "    for page in range(1, 6)\n",
    "    for i in [1, 2]\n",
    "]\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- âŒ Rate Limiting ì—†ì´ ìš”ì²­: IP ì°¨ë‹¨ ìœ„í—˜\n",
    "- âŒ append ëŒ€ì‹  extend: ë¦¬ìŠ¤íŠ¸ ì¤‘ì²©\n",
    "- âŒ ë¬´í•œ ë£¨í”„: ìµœëŒ€ í˜ì´ì§€ ì„¤ì • í•„ìˆ˜\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- í˜ì´ì§€ ë²ˆí˜¸ ëŒ€ì‹  offset/limit ë°©ì‹ë„ í”í•¨\n",
    "- ë§ˆì§€ë§‰ í˜ì´ì§€ ê°ì§€: ë¹ˆ ê²°ê³¼ ë˜ëŠ” \"ë‹¤ìŒ\" ë²„íŠ¼ ì—†ìŒ\n",
    "- ì§„í–‰ ìƒí™© ì €ì¥: ì¤‘ë‹¨ ì‹œ ì¬ì‹œì‘ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q10. ì¢…í•© í¬ë¡¤ë§ í”„ë¡œì íŠ¸ â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: HTMLì—ì„œ ì œí’ˆ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  pandasë¡œ ë¶„ì„í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10 ì •ë‹µ\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "html = \"\"\"\n",
    "<div class=\"product\" data-category=\"ì „ìì œí’ˆ\">\n",
    "    <h4>ë…¸íŠ¸ë¶</h4>\n",
    "    <span class=\"price\">1,500,000</span>\n",
    "</div>\n",
    "<div class=\"product\" data-category=\"ì „ìì œí’ˆ\">\n",
    "    <h4>íƒœë¸”ë¦¿</h4>\n",
    "    <span class=\"price\">800,000</span>\n",
    "</div>\n",
    "<div class=\"product\" data-category=\"ê°€êµ¬\">\n",
    "    <h4>ì±…ìƒ</h4>\n",
    "    <span class=\"price\">300,000</span>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 1. ì œí’ˆ ì •ë³´ ì¶”ì¶œ\n",
    "products = []\n",
    "for product_div in soup.select(\"div.product\"):\n",
    "    product = {\n",
    "        \"ì´ë¦„\": product_div.find(\"h4\").text,\n",
    "        \"ì¹´í…Œê³ ë¦¬\": product_div.get(\"data-category\"),\n",
    "        \"ê°€ê²©\": product_div.find(\"span\", class_=\"price\").text\n",
    "    }\n",
    "    products.append(product)\n",
    "\n",
    "print(\"ìˆ˜ì§‘ëœ ë°ì´í„°:\")\n",
    "for p in products:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DataFrame ìƒì„±\n",
    "df = pd.DataFrame(products)\n",
    "print(\"\\nDataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ê°€ê²© ì •ì œ (ì‰¼í‘œ ì œê±° â†’ ì •ìˆ˜ ë³€í™˜)\n",
    "df[\"ê°€ê²©_ì •ìˆ˜\"] = df[\"ê°€ê²©\"].str.replace(\",\", \"\").astype(int)\n",
    "print(\"\\nê°€ê²© ì •ì œ í›„:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ê°€ê²©\n",
    "category_avg = df.groupby(\"ì¹´í…Œê³ ë¦¬\")[\"ê°€ê²©_ì •ìˆ˜\"].mean()\n",
    "print(\"\\nì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ê°€ê²©:\")\n",
    "for category, avg_price in category_avg.items():\n",
    "    print(f\"  {category}: {avg_price:,.0f}ì›\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. ê°€ì¥ ë¹„ì‹¼ ì œí’ˆ\n",
    "max_price_idx = df[\"ê°€ê²©_ì •ìˆ˜\"].idxmax()\n",
    "most_expensive = df.loc[max_price_idx]\n",
    "\n",
    "print(\"\\nìµœê³ ê°€ ì œí’ˆ:\")\n",
    "print(f\"  ì´ë¦„: {most_expensive['ì´ë¦„']}\")\n",
    "print(f\"  ê°€ê²©: {most_expensive['ê°€ê²©_ì •ìˆ˜']:,}ì›\")\n",
    "print(f\"  ì¹´í…Œê³ ë¦¬: {most_expensive['ì¹´í…Œê³ ë¦¬']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert len(df) == 3, \"ë°ì´í„° ê°œìˆ˜ ì˜¤ë¥˜\"\n",
    "assert df[\"ê°€ê²©_ì •ìˆ˜\"].max() == 1500000, \"ìµœê³ ê°€ ì˜¤ë¥˜\"\n",
    "assert category_avg[\"ì „ìì œí’ˆ\"] == 1150000, \"ì „ìì œí’ˆ í‰ê·  ì˜¤ë¥˜\"\n",
    "assert most_expensive[\"ì´ë¦„\"] == \"ë…¸íŠ¸ë¶\", \"ìµœê³ ê°€ ì œí’ˆëª… ì˜¤ë¥˜\"\n",
    "print(\"\\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±\n",
    "2. ì œí’ˆ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ êµ¬ì¡°í™”\n",
    "3. pandas DataFrame ë³€í™˜\n",
    "4. ë¬¸ìì—´ ê°€ê²© â†’ ì •ìˆ˜ ë³€í™˜\n",
    "5. groupbyë¡œ ì§‘ê³„, idxmaxë¡œ ìµœëŒ“ê°’ ì°¾ê¸°\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- `get(\"data-ì†ì„±\")`: data ì†ì„± ì¶”ì¶œ\n",
    "- `str.replace()`: ë¬¸ìì—´ ì¹˜í™˜\n",
    "- `astype(int)`: íƒ€ì… ë³€í™˜\n",
    "- `groupby().mean()`: ê·¸ë£¹ë³„ í‰ê· \n",
    "- `idxmax()`: ìµœëŒ“ê°’ì˜ ì¸ë±ìŠ¤\n",
    "\n",
    "**ëŒ€ì•ˆ ì†”ë£¨ì…˜**:\n",
    "```python\n",
    "# ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ìœ¼ë¡œ í•œ ë²ˆì—\n",
    "products = [\n",
    "    {\n",
    "        \"ì´ë¦„\": p.select_one(\"h4\").text,\n",
    "        \"ì¹´í…Œê³ ë¦¬\": p[\"data-category\"],\n",
    "        \"ê°€ê²©\": int(p.select_one(\".price\").text.replace(\",\", \"\"))\n",
    "    }\n",
    "    for p in soup.select(\"div.product\")\n",
    "]\n",
    "df = pd.DataFrame(products)\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- âŒ ì‰¼í‘œ ì œê±° ì•ˆ í•¨: ë¬¸ìì—´ë¡œ ë‚¨ì•„ ì§‘ê³„ ë¶ˆê°€\n",
    "- âŒ astype() ì „ì— NaN ì²´í¬ ì•ˆ í•¨: ì—ëŸ¬ ë°œìƒ\n",
    "- âŒ max() vs idxmax() í˜¼ë™: ê°’ vs ì¸ë±ìŠ¤\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- í¬ë¡¤ë§ â†’ êµ¬ì¡°í™” â†’ DataFrame â†’ ë¶„ì„ íŒŒì´í”„ë¼ì¸ í‘œì¤€í™”\n",
    "- ê°€ê²©, ë‚ ì§œ ë“±ì€ í•­ìƒ ì ì ˆí•œ ë°ì´í„° íƒ€ì…ìœ¼ë¡œ ë³€í™˜\n",
    "- ìˆ˜ì§‘ ì§í›„ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ (ëˆ„ë½, ì¤‘ë³µ, ì´ìƒì¹˜)\n",
    "- Plotlyë¡œ ì‹œê°í™”í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "### Part 1: ê¸°ì´ˆ í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ê°œë… | í•µì‹¬ ë©”ì†Œë“œ/ë¬¸ë²• | ì‹¤ë¬´ í™œìš© |\n",
    "|------|----------------|----------|\n",
    "| HTML êµ¬ì¡° | `<íƒœê·¸ ì†ì„±=\"ê°’\">ë‚´ìš©</íƒœê·¸>` | ì›¹í˜ì´ì§€ êµ¬ì¡° ì´í•´ |\n",
    "| requests | `requests.get(url, headers)` | ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° |\n",
    "| BeautifulSoup | `BeautifulSoup(html, \"html.parser\")` | HTML íŒŒì‹± |\n",
    "| find() | `soup.find(\"íƒœê·¸\", class_=\"í´ë˜ìŠ¤\")` | ì²« ìš”ì†Œ ì°¾ê¸° |\n",
    "| find_all() | `soup.find_all(\"íƒœê·¸\")` | ëª¨ë“  ìš”ì†Œ ì°¾ê¸° |\n",
    "| CSS Selector | `soup.select(\"div.class > p\")` | ì •êµí•œ ìš”ì†Œ ì„ íƒ |\n",
    "\n",
    "### Part 2: ì‹¤ì „ í¬ë¡¤ë§ í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ê¸°ë²• | ë¬¸ë²• | ì–¸ì œ ì“°ë‚˜? |\n",
    "|------|------|----------|\n",
    "| ì†ì„± ì„ íƒì | `[href^=\"https\"]` | íŠ¹ì • íŒ¨í„´ URL í•„í„°ë§ |\n",
    "| í…Œì´ë¸” ì¶”ì¶œ | `thead th`, `tbody tr td` | í‘œ ë°ì´í„° êµ¬ì¡°í™” |\n",
    "| pandas ë³€í™˜ | `pd.DataFrame(rows, columns)` | ìˆ˜ì§‘ ë°ì´í„° ë¶„ì„ |\n",
    "| í˜ì´ì§€ë„¤ì´ì…˜ | `for page in range(1, n)` | ì—¬ëŸ¬ í˜ì´ì§€ ìˆœíšŒ |\n",
    "| ì—ëŸ¬ ì²˜ë¦¬ | `try-except`, `response.raise_for_status()` | ì•ˆì •ì ì¸ í¬ë¡¤ëŸ¬ |\n",
    "| Rate Limiting | `time.sleep(ì´ˆ)` | ì„œë²„ ë¶€í•˜ ë°©ì§€ |\n",
    "\n",
    "### ğŸ’¡ ì‹¤ë¬´ íŒ\n",
    "\n",
    "1. **robots.txt í™•ì¸**: í¬ë¡¤ë§ ì „ `{ì‚¬ì´íŠ¸}/robots.txt` í™•ì¸ í•„ìˆ˜\n",
    "2. **User-Agent ì„¤ì •**: ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ë„ë¡ í—¤ë” ì„¤ì •\n",
    "3. **Rate Limiting**: ìš”ì²­ ê°„ ìµœì†Œ 1ì´ˆ ëŒ€ê¸° (time.sleep)\n",
    "4. **ì—ëŸ¬ ì²˜ë¦¬**: try-exceptë¡œ ì•ˆì •ì ì¸ ì½”ë“œ ì‘ì„±\n",
    "5. **ë°ì´í„° ê²€ì¦**: ìˆ˜ì§‘ í›„ ëˆ„ë½/ì˜¤ë¥˜ ë°ì´í„° í™•ì¸\n",
    "6. **ì¦ë¶„ ì €ì¥**: í° ë°ì´í„°ëŠ” ì£¼ê¸°ì ìœ¼ë¡œ íŒŒì¼ ì €ì¥\n",
    "7. **ë²•ì  ê²€í† **: ì €ì‘ê¶Œ, ì´ìš©ì•½ê´€ ì¤€ìˆ˜ í™•ì¸"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
