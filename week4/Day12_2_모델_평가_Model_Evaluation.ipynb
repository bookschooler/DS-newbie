{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day12_2: ëª¨ë¸ í‰ê°€ (Model Evaluation)\n",
    "\n",
    "## ğŸ“š í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "**Part 1: ë¶„ë¥˜ í‰ê°€ ì§€í‘œ**\n",
    "1. Accuracy (ì •í™•ë„) ì´í•´í•˜ê¸°\n",
    "2. Precision (ì •ë°€ë„)ê³¼ Recall (ì¬í˜„ìœ¨) êµ¬ë¶„í•˜ê¸°\n",
    "3. F1-score ê³„ì‚° ì›ë¦¬ íŒŒì•…í•˜ê¸°\n",
    "4. Confusion Matrix (í˜¼ë™í–‰ë ¬) í•´ì„í•˜ê¸°\n",
    "5. Plotlyë¡œ í˜¼ë™í–‰ë ¬ ì‹œê°í™”í•˜ê¸°\n",
    "\n",
    "**Part 2: íšŒê·€ í‰ê°€ ì§€í‘œ ë° ê³¼ì í•© ë°©ì§€**\n",
    "1. MAE, MSE, RMSE ê³„ì‚°í•˜ê¸°\n",
    "2. R-squared (ê²°ì •ê³„ìˆ˜) í•´ì„í•˜ê¸°\n",
    "3. êµì°¨ ê²€ì¦(Cross Validation) ì ìš©í•˜ê¸°\n",
    "4. Learning Curveë¡œ ê³¼ì í•©/ê³¼ì†Œì í•© ì§„ë‹¨í•˜ê¸°\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ì™œ ì´ê²ƒì„ ë°°ìš°ë‚˜ìš”?\n",
    "\n",
    "| ê°œë… | ì‹¤ë¬´ í™œìš© | ì˜ˆì‹œ |\n",
    "|------|----------|------|\n",
    "| ì •í™•ë„ | ì „ì²´ ì„±ëŠ¥ ìš”ì•½ | \"ëª¨ë¸ ì •í™•ë„ 95%\" ë³´ê³  |\n",
    "| ì •ë°€ë„/ì¬í˜„ìœ¨ | ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œ ë§ì¶¤ | ìŠ¤íŒ¸ í•„í„° vs ì•” ì§„ë‹¨ |\n",
    "| F1-score | ë¶ˆê· í˜• ë°ì´í„° í‰ê°€ | ì´íƒˆ ì˜ˆì¸¡ (ì´íƒˆì 5%) |\n",
    "| í˜¼ë™í–‰ë ¬ | ì˜¤ë¶„ë¥˜ ìœ í˜• ë¶„ì„ | FP/FN ë¹„ìš© ê³„ì‚° |\n",
    "| RMSE/MAE | ì˜ˆì¸¡ ì˜¤ì°¨ í¬ê¸° | ê°€ê²© ì˜ˆì¸¡ ì˜¤ì°¨ |\n",
    "| R-squared | ì„¤ëª…ë ¥ í‰ê°€ | \"ëª¨ë¸ì´ ë³€ë™ì˜ 80% ì„¤ëª…\" |\n",
    "| êµì°¨ê²€ì¦ | ê³¼ì í•© ë°©ì§€ | ì•ˆì •ì ì¸ ì„±ëŠ¥ ì¶”ì • |\n",
    "| Learning Curve | ì§„ë‹¨ ì‹œê°í™” | í•™ìŠµ ë°ì´í„° ì–‘ ê²°ì • |\n",
    "\n",
    "**ë¶„ì„ê°€ ê´€ì **: ëª¨ë¸ì„ \"ì–¼ë§ˆë‚˜ ì˜ ë§Œë“¤ì—ˆë‚˜?\"ë¥¼ ìˆ«ìë¡œ ì¦ëª…í•˜ëŠ” ê²ƒì´ í‰ê°€ ì§€í‘œì…ë‹ˆë‹¤. ì–´ë–¤ ì§€í‘œë¥¼ ì„ íƒí•˜ëŠëƒì— ë”°ë¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ê°€ ë‹¬ë¼ì§‘ë‹ˆë‹¤!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# scikit-learn í‰ê°€ ë„êµ¬\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "# ë¶„ë¥˜/íšŒê·€ ëª¨ë¸\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ê²½ê³  ë¬´ì‹œ\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: ë¶„ë¥˜ í‰ê°€ ì§€í‘œ\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 ë°ì´í„° ì¤€ë¹„\n",
    "\n",
    "ìœ ë°©ì•” ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ ë°©ì•” ë°ì´í„° ë¡œë“œ\n",
    "cancer = load_breast_cancer()\n",
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "y = cancer.target  # 0: ì•…ì„±, 1: ì–‘ì„±\n",
    "\n",
    "print(f\"ë°ì´í„° í¬ê¸°: {X.shape}\")\n",
    "print(f\"íƒ€ê²Ÿ ë¶„í¬: ì•…ì„±={sum(y==0)}, ì–‘ì„±={sum(y==1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {X_train.shape[0]}ê°œ\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(f\"ì˜ˆì¸¡ ì™„ë£Œ! ì˜ˆì¸¡ ìƒ˜í”Œ: {y_pred[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 Accuracy (ì •í™•ë„)\n",
    "\n",
    "**ì •í™•ë„ = ë§ì€ ì˜ˆì¸¡ / ì „ì²´ ì˜ˆì¸¡**\n",
    "\n",
    "ê°€ì¥ ì§ê´€ì ì¸ ì§€í‘œì´ì§€ë§Œ, í´ë˜ìŠ¤ ë¶ˆê· í˜• ì‹œ ì˜¤í•´ë¥¼ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •í™•ë„ ê³„ì‚°\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"ì •í™•ë„(Accuracy): {accuracy:.4f} ({accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìˆ˜ë™ ê³„ì‚°ìœ¼ë¡œ ì´í•´í•˜ê¸°\n",
    "correct = sum(y_test == y_pred)\n",
    "total = len(y_test)\n",
    "manual_accuracy = correct / total\n",
    "\n",
    "print(f\"ë§ì€ ì˜ˆì¸¡: {correct}\")\n",
    "print(f\"ì „ì²´ ì˜ˆì¸¡: {total}\")\n",
    "print(f\"ì •í™•ë„: {correct}/{total} = {manual_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: ì •í™•ë„ì˜ í•¨ì • (í´ë˜ìŠ¤ ë¶ˆê· í˜•)\n",
    "\n",
    "ë§Œì•½ 100ëª… ì¤‘ 95ëª…ì´ ì •ìƒ, 5ëª…ì´ ì‚¬ê¸°ê¾¼ì´ë¼ë©´?  \n",
    "\"ëª¨ë‘ ì •ìƒ\"ì´ë¼ê³  ì˜ˆì¸¡í•´ë„ ì •í™•ë„ 95%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶ˆê· í˜• ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜\n",
    "y_true_imbalanced = [0] * 95 + [1] * 5  # 95% ì •ìƒ, 5% ì‚¬ê¸°\n",
    "y_pred_always_zero = [0] * 100          # ë¬´ì¡°ê±´ \"ì •ìƒ\" ì˜ˆì¸¡\n",
    "\n",
    "accuracy_imbalanced = accuracy_score(y_true_imbalanced, y_pred_always_zero)\n",
    "print(f\"ë¶ˆê· í˜• ë°ì´í„°ì—ì„œ 'ëª¨ë‘ ì •ìƒ' ì˜ˆì¸¡ ì •í™•ë„: {accuracy_imbalanced:.2f}\")\n",
    "print(\"=> ì‚¬ê¸°ê¾¼ì„ í•˜ë‚˜ë„ ëª» ì¡ì•˜ëŠ”ë° 95% ì •í™•ë„! í•¨ì •!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 Precisionê³¼ Recall\n",
    "\n",
    "| ì§€í‘œ | ì˜ë¯¸ | ê³µì‹ | ì¤‘ìš”í•œ ê²½ìš° |\n",
    "|------|------|------|------------|\n",
    "| **Precision** (ì •ë°€ë„) | ì–‘ì„± ì˜ˆì¸¡ ì¤‘ ì‹¤ì œ ì–‘ì„± ë¹„ìœ¨ | TP / (TP + FP) | ì˜¤íƒ(FP) ë¹„ìš©ì´ í´ ë•Œ |\n",
    "| **Recall** (ì¬í˜„ìœ¨) | ì‹¤ì œ ì–‘ì„± ì¤‘ ì–‘ì„± ì˜ˆì¸¡ ë¹„ìœ¨ | TP / (TP + FN) | ë¯¸íƒ(FN) ë¹„ìš©ì´ í´ ë•Œ |\n",
    "\n",
    "**ìš©ì–´**:\n",
    "- TP (True Positive): ì–‘ì„±ì„ ì–‘ì„±ìœ¼ë¡œ ë§ì¶¤\n",
    "- FP (False Positive): ìŒì„±ì„ ì–‘ì„±ìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡\n",
    "- FN (False Negative): ì–‘ì„±ì„ ìŒì„±ìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡\n",
    "- TN (True Negative): ìŒì„±ì„ ìŒì„±ìœ¼ë¡œ ë§ì¶¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precisionê³¼ Recall ê³„ì‚°\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision (ì •ë°€ë„): {precision:.4f}\")\n",
    "print(f\"Recall (ì¬í˜„ìœ¨): {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: Precision vs Recall ì„ íƒ ê¸°ì¤€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒí™©ë³„ ì§€í‘œ ì„ íƒ\n",
    "scenarios = [\n",
    "    {\"ë¬¸ì œ\": \"ìŠ¤íŒ¸ ë©”ì¼ í•„í„°\", \"ìš°ì„  ì§€í‘œ\": \"Precision\", \n",
    "     \"ì´ìœ \": \"ì •ìƒ ë©”ì¼ì„ ìŠ¤íŒ¸ìœ¼ë¡œ ì˜¤íƒí•˜ë©´ ì¤‘ìš”í•œ ë©”ì¼ ë†“ì¹¨\"},\n",
    "    {\"ë¬¸ì œ\": \"ì•” ì§„ë‹¨ ìŠ¤í¬ë¦¬ë‹\", \"ìš°ì„  ì§€í‘œ\": \"Recall\", \n",
    "     \"ì´ìœ \": \"ì•”í™˜ìë¥¼ ì •ìƒìœ¼ë¡œ ì˜¤ì§„í•˜ë©´ ì¹˜ë£Œ ê¸°íšŒ ìƒì‹¤\"},\n",
    "    {\"ë¬¸ì œ\": \"ì‹ ìš©ì¹´ë“œ ì‚¬ê¸° íƒì§€\", \"ìš°ì„  ì§€í‘œ\": \"Recall\", \n",
    "     \"ì´ìœ \": \"ì‚¬ê¸°ë¥¼ ë†“ì¹˜ë©´ ê³ ê° í”¼í•´ ë°œìƒ\"},\n",
    "    {\"ë¬¸ì œ\": \"ì¶”ì²œ ì‹œìŠ¤í…œ\", \"ìš°ì„  ì§€í‘œ\": \"Precision\", \n",
    "     \"ì´ìœ \": \"ê´€ì‹¬ ì—†ëŠ” ìƒí’ˆ ì¶”ì²œì€ ì‚¬ìš©ì ê²½í—˜ ì €í•˜\"},\n",
    "]\n",
    "\n",
    "df_scenarios = pd.DataFrame(scenarios)\n",
    "print(df_scenarios.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 F1-Score\n",
    "\n",
    "**F1-score = 2 * (Precision * Recall) / (Precision + Recall)**\n",
    "\n",
    "Precisionê³¼ Recallì˜ ì¡°í™” í‰ê· . ë¶ˆê· í˜• ë°ì´í„°ì—ì„œ ì •í™•ë„ ëŒ€ì‹  ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1-score ê³„ì‚°\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# ìˆ˜ë™ ê³„ì‚°ìœ¼ë¡œ í™•ì¸\n",
    "f1_manual = 2 * (precision * recall) / (precision + recall)\n",
    "print(f\"ìˆ˜ë™ ê³„ì‚°: {f1_manual:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ë¶„ë¥˜ ë¦¬í¬íŠ¸\n",
    "print(\"=\" * 60)\n",
    "print(\"ë¶„ë¥˜ ë¦¬í¬íŠ¸ (Classification Report)\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, y_pred, target_names=['ì•…ì„±(0)', 'ì–‘ì„±(1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.5 Confusion Matrix (í˜¼ë™í–‰ë ¬)\n",
    "\n",
    "ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í•œëˆˆì— ë³´ì—¬ì£¼ëŠ” í‘œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜¼ë™í–‰ë ¬ ê³„ì‚°\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"í˜¼ë™í–‰ë ¬:\")\n",
    "print(cm)\n",
    "print()\n",
    "print(\"í•´ì„:\")\n",
    "print(f\"  TN (ì•…ì„±ì„ ì•…ì„±ìœ¼ë¡œ): {cm[0,0]}\")\n",
    "print(f\"  FP (ì•…ì„±ì„ ì–‘ì„±ìœ¼ë¡œ): {cm[0,1]}\")\n",
    "print(f\"  FN (ì–‘ì„±ì„ ì•…ì„±ìœ¼ë¡œ): {cm[1,0]}\")\n",
    "print(f\"  TP (ì–‘ì„±ì„ ì–‘ì„±ìœ¼ë¡œ): {cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotlyë¡œ í˜¼ë™í–‰ë ¬ ì‹œê°í™”\n",
    "def plot_confusion_matrix(cm, labels=['ì•…ì„±(0)', 'ì–‘ì„±(1)']):\n",
    "    \"\"\"í˜¼ë™í–‰ë ¬ì„ Plotly íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”\"\"\"\n",
    "    # í…ìŠ¤íŠ¸ ì–´ë…¸í…Œì´ì…˜ ìƒì„±\n",
    "    annotations = []\n",
    "    for i in range(len(cm)):\n",
    "        for j in range(len(cm[0])):\n",
    "            annotations.append(\n",
    "                dict(\n",
    "                    x=labels[j], y=labels[i],\n",
    "                    text=str(cm[i][j]),\n",
    "                    showarrow=False,\n",
    "                    font=dict(size=20, color='white' if cm[i][j] > cm.max()/2 else 'black')\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=cm,\n",
    "        x=labels,\n",
    "        y=labels,\n",
    "        colorscale='Blues',\n",
    "        showscale=True\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Confusion Matrix (í˜¼ë™í–‰ë ¬)',\n",
    "        xaxis_title='ì˜ˆì¸¡ê°’ (Predicted)',\n",
    "        yaxis_title='ì‹¤ì œê°’ (Actual)',\n",
    "        annotations=annotations,\n",
    "        width=500, height=450\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = plot_confusion_matrix(cm)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: ì˜¤ë¶„ë¥˜ ë¹„ìš© ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„ìš© ë¶„ì„ (ì•” ì§„ë‹¨ ì‹œë‚˜ë¦¬ì˜¤)\n",
    "fp_cost = 100_000  # FP ë¹„ìš©: ë¶ˆí•„ìš”í•œ ì •ë°€ê²€ì‚¬ ë¹„ìš©\n",
    "fn_cost = 5_000_000  # FN ë¹„ìš©: ì•” í™˜ì ë†“ì¹¨ (ì¹˜ë£Œ ì§€ì—°, ìƒëª… ìœ„í—˜)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "total_fp_cost = fp * fp_cost\n",
    "total_fn_cost = fn * fn_cost\n",
    "total_cost = total_fp_cost + total_fn_cost\n",
    "\n",
    "print(f\"FP ë°œìƒ ê±´ìˆ˜: {fp}ê±´ x {fp_cost:,}ì› = {total_fp_cost:,}ì›\")\n",
    "print(f\"FN ë°œìƒ ê±´ìˆ˜: {fn}ê±´ x {fn_cost:,}ì› = {total_fn_cost:,}ì›\")\n",
    "print(f\"ì´ ì˜¤ë¶„ë¥˜ ë¹„ìš©: {total_cost:,}ì›\")\n",
    "print(\"\\n=> FN ë¹„ìš©ì´ í›¨ì”¬ í¬ë¯€ë¡œ Recallì„ ë†’ì´ëŠ” ê²ƒì´ ì¤‘ìš”!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: íšŒê·€ í‰ê°€ ì§€í‘œ ë° ê³¼ì í•© ë°©ì§€\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 íšŒê·€ ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¹ë‡¨ë³‘ ë°ì´í„° ë¡œë“œ\n",
    "diabetes = load_diabetes()\n",
    "X_reg = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "y_reg = diabetes.target\n",
    "\n",
    "print(f\"ë°ì´í„° í¬ê¸°: {X_reg.shape}\")\n",
    "print(f\"íƒ€ê²Ÿ í†µê³„: í‰ê· ={y_reg.mean():.1f}, í‘œì¤€í¸ì°¨={y_reg.std():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Ridge íšŒê·€ ëª¨ë¸ í•™ìŠµ\n",
    "reg_model = Ridge(alpha=1.0, random_state=42)\n",
    "reg_model.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "y_pred_reg = reg_model.predict(X_test_reg)\n",
    "print(f\"ì˜ˆì¸¡ ì™„ë£Œ! ìƒ˜í”Œ: {y_pred_reg[:5].round(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 MAE, MSE, RMSE\n",
    "\n",
    "| ì§€í‘œ | ê³µì‹ | íŠ¹ì§• |\n",
    "|------|------|------|\n",
    "| **MAE** | í‰ê· (\\|ì‹¤ì œ-ì˜ˆì¸¡\\|) | ì´ìƒì¹˜ì— ëœ ë¯¼ê° |\n",
    "| **MSE** | í‰ê· ((ì‹¤ì œ-ì˜ˆì¸¡)^2) | í° ì˜¤ì°¨ì— ë” í° íŒ¨ë„í‹° |\n",
    "| **RMSE** | sqrt(MSE) | MSEë¥¼ ì›ë˜ ë‹¨ìœ„ë¡œ |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íšŒê·€ í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"MAE  (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨): {mae:.2f}\")\n",
    "print(f\"MSE  (í‰ê·  ì œê³± ì˜¤ì°¨): {mse:.2f}\")\n",
    "print(f\"RMSE (ì œê³±ê·¼ MSE):    {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìˆ˜ë™ ê³„ì‚°ìœ¼ë¡œ ì´í•´í•˜ê¸°\n",
    "errors = y_test_reg - y_pred_reg\n",
    "\n",
    "mae_manual = np.mean(np.abs(errors))\n",
    "mse_manual = np.mean(errors ** 2)\n",
    "rmse_manual = np.sqrt(mse_manual)\n",
    "\n",
    "print(f\"MAE ìˆ˜ë™ê³„ì‚°: {mae_manual:.2f}\")\n",
    "print(f\"MSE ìˆ˜ë™ê³„ì‚°: {mse_manual:.2f}\")\n",
    "print(f\"RMSE ìˆ˜ë™ê³„ì‚°: {rmse_manual:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: ì§€í‘œ ì„ íƒ ê°€ì´ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE vs RMSE ë¹„êµ\n",
    "print(\"ì§€í‘œ ì„ íƒ ê°€ì´ë“œ:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"MAE ì‚¬ìš© ì‹œ:\")\n",
    "print(\"  - ì´ìƒì¹˜ê°€ ë§ì€ ë°ì´í„°\")\n",
    "print(\"  - ì˜¤ì°¨ í¬ê¸°ì— ê· ë“±í•œ ê°€ì¤‘ì¹˜ ë¶€ì—¬\")\n",
    "print(\"  - ì˜ˆ: ë°°ì†¡ ì‹œê°„ ì˜ˆì¸¡ (ê°€ë” ì§€ì—° ë°œìƒ)\")\n",
    "print()\n",
    "print(\"RMSE ì‚¬ìš© ì‹œ:\")\n",
    "print(\"  - í° ì˜¤ì°¨ë¥¼ ë” ê°•í•˜ê²Œ íŒ¨ë„í‹°\")\n",
    "print(\"  - ì˜ˆ: ì£¼ê°€ ì˜ˆì¸¡ (í° ì˜¤ì°¨ = í° ì†ì‹¤)\")\n",
    "print(\"  - ì˜ˆ: ì¬ê³  ì˜ˆì¸¡ (ê³¼ì‰ì¬ê³  ë¹„ìš©)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 R-squared (ê²°ì •ê³„ìˆ˜)\n",
    "\n",
    "**R^2 = 1 - (ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„ì‚° / íƒ€ê²Ÿ ë¶„ì‚°)**\n",
    "\n",
    "- R^2 = 1: ì™„ë²½í•œ ì˜ˆì¸¡\n",
    "- R^2 = 0: í‰ê· ë§Œ ì˜ˆì¸¡í•˜ëŠ” ê²ƒê³¼ ë™ì¼\n",
    "- R^2 < 0: í‰ê· ë³´ë‹¤ ëª»í•œ ì˜ˆì¸¡ (ë§¤ìš° ë‚˜ì¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared ê³„ì‚°\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "print(f\"R-squared: {r2:.4f}\")\n",
    "print(f\"=> ëª¨ë¸ì´ íƒ€ê²Ÿ ë³€ë™ì˜ {r2*100:.1f}%ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ì œ vs ì˜ˆì¸¡ ì‹œê°í™”\n",
    "fig = px.scatter(\n",
    "    x=y_test_reg, y=y_pred_reg,\n",
    "    labels={'x': 'ì‹¤ì œê°’', 'y': 'ì˜ˆì¸¡ê°’'},\n",
    "    title=f'ì‹¤ì œ vs ì˜ˆì¸¡ (RÂ² = {r2:.3f})'\n",
    ")\n",
    "\n",
    "# ì™„ë²½í•œ ì˜ˆì¸¡ì„  (y=x)\n",
    "min_val, max_val = min(y_test_reg), max(y_test_reg)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[min_val, max_val], y=[min_val, max_val],\n",
    "    mode='lines', name='ì™„ë²½í•œ ì˜ˆì¸¡',\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(width=600, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 êµì°¨ ê²€ì¦ (Cross Validation)\n",
    "\n",
    "ë‹¨ì¼ í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• ì˜ ë¬¸ì œ:\n",
    "- ì–´ë–¤ ë¶„í• ì´ëƒì— ë”°ë¼ ì„±ëŠ¥ì´ ë‹¬ë¼ì§\n",
    "- ê³¼ì í•© ì—¬ë¶€ íŒë‹¨ ì–´ë ¤ì›€\n",
    "\n",
    "**K-Fold êµì°¨ ê²€ì¦**:\n",
    "- ë°ì´í„°ë¥¼ Kê°œë¡œ ë‚˜ëˆ  Kë²ˆ í•™ìŠµ/í‰ê°€\n",
    "- í‰ê·  ì„±ëŠ¥ê³¼ í‘œì¤€í¸ì°¨ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶„ë¥˜ ëª¨ë¸ êµì°¨ê²€ì¦ (ì •í™•ë„)\n",
    "cv_scores_clf = cross_val_score(\n",
    "    LogisticRegression(random_state=42, max_iter=1000),\n",
    "    scaler.fit_transform(X), y,\n",
    "    cv=5,  # 5-fold\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(\"ë¶„ë¥˜ ëª¨ë¸ 5-Fold êµì°¨ê²€ì¦ (ì •í™•ë„):\")\n",
    "print(f\"ê° Fold: {cv_scores_clf.round(4)}\")\n",
    "print(f\"í‰ê· : {cv_scores_clf.mean():.4f} (+/- {cv_scores_clf.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íšŒê·€ ëª¨ë¸ êµì°¨ê²€ì¦ (R-squared)\n",
    "cv_scores_reg = cross_val_score(\n",
    "    Ridge(alpha=1.0, random_state=42),\n",
    "    X_reg, y_reg,\n",
    "    cv=5,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "print(\"íšŒê·€ ëª¨ë¸ 5-Fold êµì°¨ê²€ì¦ (RÂ²):\")\n",
    "print(f\"ê° Fold: {cv_scores_reg.round(4)}\")\n",
    "print(f\"í‰ê· : {cv_scores_reg.mean():.4f} (+/- {cv_scores_reg.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: ë‹¤ì–‘í•œ scoring ì˜µì…˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶„ë¥˜ì—ì„œ F1-scoreë¡œ êµì°¨ê²€ì¦\n",
    "cv_f1 = cross_val_score(\n",
    "    LogisticRegression(random_state=42, max_iter=1000),\n",
    "    scaler.fit_transform(X), y,\n",
    "    cv=5,\n",
    "    scoring='f1'  # F1-score\n",
    ")\n",
    "print(f\"F1-score êµì°¨ê²€ì¦: {cv_f1.mean():.4f} (+/- {cv_f1.std()*2:.4f})\")\n",
    "\n",
    "# íšŒê·€ì—ì„œ RMSEë¡œ êµì°¨ê²€ì¦ (negativeì´ë¯€ë¡œ ë¶€í˜¸ ë³€í™˜)\n",
    "cv_rmse = cross_val_score(\n",
    "    Ridge(alpha=1.0),\n",
    "    X_reg, y_reg,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error'\n",
    ")\n",
    "print(f\"RMSE êµì°¨ê²€ì¦: {-cv_rmse.mean():.2f} (+/- {cv_rmse.std()*2:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.5 Learning Curve (í•™ìŠµ ê³¡ì„ )\n",
    "\n",
    "í•™ìŠµ ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "\n",
    "**ì§„ë‹¨ íŒ¨í„´**:\n",
    "- **ê³¼ì†Œì í•©**: í•™ìŠµ/ê²€ì¦ ì ìˆ˜ ëª¨ë‘ ë‚®ìŒ\n",
    "- **ê³¼ì í•©**: í•™ìŠµ ì ìˆ˜ ë†’ê³ , ê²€ì¦ ì ìˆ˜ ë‚®ìŒ (í° ê°­)\n",
    "- **ì í•©**: í•™ìŠµ/ê²€ì¦ ì ìˆ˜ ëª¨ë‘ ë†’ê³ , ê°­ì´ ì‘ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ê³¡ì„  ê³„ì‚°\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    LogisticRegression(random_state=42, max_iter=1000),\n",
    "    scaler.fit_transform(X), y,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# í‰ê· ê³¼ í‘œì¤€í¸ì°¨\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "val_std = val_scores.std(axis=1)\n",
    "\n",
    "print(f\"í•™ìŠµ ë°ì´í„° í¬ê¸°: {train_sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotlyë¡œ Learning Curve ì‹œê°í™”\n",
    "fig = go.Figure()\n",
    "\n",
    "# í•™ìŠµ ì ìˆ˜\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=train_sizes, y=train_mean,\n",
    "    mode='lines+markers',\n",
    "    name='í•™ìŠµ ì ìˆ˜',\n",
    "    line=dict(color='blue'),\n",
    "    error_y=dict(type='data', array=train_std, visible=True)\n",
    "))\n",
    "\n",
    "# ê²€ì¦ ì ìˆ˜\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=train_sizes, y=val_mean,\n",
    "    mode='lines+markers',\n",
    "    name='ê²€ì¦ ì ìˆ˜',\n",
    "    line=dict(color='green'),\n",
    "    error_y=dict(type='data', array=val_std, visible=True)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Learning Curve (í•™ìŠµ ê³¡ì„ )',\n",
    "    xaxis_title='í•™ìŠµ ë°ì´í„° í¬ê¸°',\n",
    "    yaxis_title='ì •í™•ë„',\n",
    "    width=700, height=450,\n",
    "    yaxis=dict(range=[0.9, 1.0])\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: ê³¼ì í•© ëª¨ë¸ vs ì •ìƒ ëª¨ë¸ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³¼ì í•© ëª¨ë¸ (ë³µì¡í•œ Random Forest)\n",
    "train_sizes_of, train_scores_of, val_scores_of = learning_curve(\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42),\n",
    "    scaler.fit_transform(X), y,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# ì •ê·œí™”ëœ ëª¨ë¸ (ì œí•œëœ ê¹Šì´)\n",
    "train_sizes_ok, train_scores_ok, val_scores_ok = learning_curve(\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "    scaler.fit_transform(X), y,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„êµ ì‹œê°í™”\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['ê³¼ì í•© ìœ„í—˜ (ê¹Šì´ ë¬´ì œí•œ)', 'ì •ê·œí™”ë¨ (ê¹Šì´=5)'])\n",
    "\n",
    "# ê³¼ì í•© ëª¨ë¸\n",
    "fig.add_trace(go.Scatter(x=train_sizes_of, y=train_scores_of.mean(axis=1),\n",
    "                         name='í•™ìŠµ(ê³¼ì í•©)', line=dict(color='red')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=train_sizes_of, y=val_scores_of.mean(axis=1),\n",
    "                         name='ê²€ì¦(ê³¼ì í•©)', line=dict(color='red', dash='dash')), row=1, col=1)\n",
    "\n",
    "# ì •ìƒ ëª¨ë¸\n",
    "fig.add_trace(go.Scatter(x=train_sizes_ok, y=train_scores_ok.mean(axis=1),\n",
    "                         name='í•™ìŠµ(ì •ìƒ)', line=dict(color='blue')), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=train_sizes_ok, y=val_scores_ok.mean(axis=1),\n",
    "                         name='ê²€ì¦(ì •ìƒ)', line=dict(color='blue', dash='dash')), row=1, col=2)\n",
    "\n",
    "fig.update_layout(height=400, width=900, title_text='ê³¼ì í•© vs ì •ìƒ ëª¨ë¸ Learning Curve')\n",
    "fig.update_yaxes(range=[0.9, 1.0])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.6 ëª¨ë¸ ë¹„êµ ëŒ€ì‹œë³´ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ëŸ¬ ë¶„ë¥˜ ëª¨ë¸ ë¹„êµ\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    cv_acc = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    cv_f1 = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='f1')\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': f\"{cv_acc.mean():.4f} (+/- {cv_acc.std():.4f})\",\n",
    "        'F1-Score': f\"{cv_f1.mean():.4f} (+/- {cv_f1.std():.4f})\",\n",
    "        'Acc_Mean': cv_acc.mean(),\n",
    "        'F1_Mean': cv_f1.mean()\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df[['Model', 'Accuracy', 'F1-Score']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°ì  ë¹„êµ\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Accuracy',\n",
    "    x=results_df['Model'],\n",
    "    y=results_df['Acc_Mean'],\n",
    "    marker_color='steelblue'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='F1-Score',\n",
    "    x=results_df['Model'],\n",
    "    y=results_df['F1_Mean'],\n",
    "    marker_color='darkorange'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ',\n",
    "    yaxis_title='ì ìˆ˜',\n",
    "    barmode='group',\n",
    "    yaxis=dict(range=[0.9, 1.0]),\n",
    "    width=700, height=400\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ ì‹¤ìŠµ í€´ì¦ˆ\n",
    "\n",
    "**ë‚œì´ë„**: â­ (ì‰¬ì›€) ~ â­â­â­â­â­ (ì–´ë ¤ì›€)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. ì •í™•ë„ ê³„ì‚°í•˜ê¸° â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì •í™•ë„(Accuracy)ë¥¼ ê³„ì‚°í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 1]\n",
    "y_pred = [1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 1]\n",
    "y_pred = [1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. í˜¼ë™í–‰ë ¬ í•´ì„í•˜ê¸° â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Q1ì˜ ë°ì´í„°ë¡œ í˜¼ë™í–‰ë ¬ì„ ë§Œë“¤ê³ , TP, FP, FN, TN ê°’ì„ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "**íŒíŠ¸**: confusion_matrix()ì™€ .ravel() ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Precision/Recall ê³„ì‚°í•˜ê¸° â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Q1ì˜ ë°ì´í„°ë¡œ Precisionê³¼ Recallì„ ê³„ì‚°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. íšŒê·€ ì§€í‘œ ê³„ì‚°í•˜ê¸° â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ìœ¼ë¡œ MAE, RMSE, R-squaredë¥¼ ê³„ì‚°í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "y_true_reg = [100, 150, 200, 180, 220]\n",
    "y_pred_reg = [110, 140, 195, 175, 230]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_reg = [100, 150, 200, 180, 220]\n",
    "y_pred_reg = [110, 140, 195, 175, 230]\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. F1-score ìˆ˜ë™ ê³„ì‚°í•˜ê¸° â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Precision=0.8, Recall=0.6ì¼ ë•Œ F1-scoreë¥¼ ìˆ˜ë™ìœ¼ë¡œ ê³„ì‚°í•˜ì„¸ìš”.\n",
    "\n",
    "**ê³µì‹**: F1 = 2 * (P * R) / (P + R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 0.8\n",
    "recall = 0.6\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. êµì°¨ê²€ì¦ ìˆ˜í–‰í•˜ê¸° â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ìœ ë°©ì•” ë°ì´í„°ì— ëŒ€í•´ RandomForestClassifierë¡œ 5-fold êµì°¨ê²€ì¦ì„ ìˆ˜í–‰í•˜ê³ , í‰ê·  ì •í™•ë„ì™€ í‘œì¤€í¸ì°¨ë¥¼ ì¶œë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ëŠ” ì´ë¯¸ ë¡œë“œë¨: X, y (ìœ ë°©ì•” ë°ì´í„°)\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. ì§€í‘œ ì„ íƒ ë…¼ë¦¬ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ì•„ë˜ ìƒí™©ì—ì„œ ì–´ë–¤ ì§€í‘œë¥¼ ìš°ì„ í•´ì•¼ í•˜ëŠ”ì§€ ë‹µí•˜ê³ , ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "\n",
    "1. ì½”ë¡œë‚˜ ì§„ë‹¨ í‚¤íŠ¸: Precision vs Recall?\n",
    "2. ë‰´ìŠ¤ ì¶”ì²œ ì‹œìŠ¤í…œ: Precision vs Recall?\n",
    "3. ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸: MAE vs RMSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš” (printë¬¸ ë˜ëŠ” ì£¼ì„ìœ¼ë¡œ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. í˜¼ë™í–‰ë ¬ ì‹œê°í™”í•˜ê¸° â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ í˜¼ë™í–‰ë ¬ì„ Plotly íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "cm = np.array([[85, 15], [10, 90]])\n",
    "labels = ['Negative', 'Positive']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.array([[85, 15], [10, 90]])\n",
    "labels = ['Negative', 'Positive']\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. Learning Curve ê·¸ë¦¬ê¸° â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ìœ ë°©ì•” ë°ì´í„°ì— ëŒ€í•´ DecisionTreeClassifierì˜ Learning Curveë¥¼ ê·¸ë¦¬ê³ , ê³¼ì í•© ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. ì¢…í•© ëª¨ë¸ í‰ê°€ ëŒ€ì‹œë³´ë“œ â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ìœ ë°©ì•” ë°ì´í„°ì— ëŒ€í•´ 3ê°œ ëª¨ë¸(Logistic Regression, Random Forest, SVM)ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ëŠ” ëŒ€ì‹œë³´ë“œë¥¼ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "1. 5-fold êµì°¨ê²€ì¦ìœ¼ë¡œ Accuracy, Precision, Recall, F1 ê³„ì‚°\n",
    "2. ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ì •ë¦¬\n",
    "3. ë§‰ëŒ€ ì°¨íŠ¸ë¡œ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "### Part 1: ë¶„ë¥˜ í‰ê°€ ì§€í‘œ í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ì§€í‘œ | ê³µì‹ | ì–¸ì œ ì‚¬ìš©? |\n",
    "|------|------|----------|\n",
    "| **Accuracy** | (TP+TN) / ì „ì²´ | í´ë˜ìŠ¤ ê· í˜• ì‹œ |\n",
    "| **Precision** | TP / (TP+FP) | FP ë¹„ìš©ì´ í´ ë•Œ (ìŠ¤íŒ¸) |\n",
    "| **Recall** | TP / (TP+FN) | FN ë¹„ìš©ì´ í´ ë•Œ (ì•”ì§„ë‹¨) |\n",
    "| **F1-Score** | ì¡°í™”í‰ê· (P,R) | ë¶ˆê· í˜• ë°ì´í„° |\n",
    "| **Confusion Matrix** | 2x2 í‘œ | ì˜¤ë¶„ë¥˜ íŒ¨í„´ ë¶„ì„ |\n",
    "\n",
    "### Part 2: íšŒê·€ í‰ê°€ ì§€í‘œ ë° ê³¼ì í•© ë°©ì§€ í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ì§€í‘œ/ê¸°ë²• | íŠ¹ì§• | í™œìš© |\n",
    "|----------|------|------|\n",
    "| **MAE** | ì ˆëŒ€ ì˜¤ì°¨ í‰ê·  | ì´ìƒì¹˜ì— ëœ ë¯¼ê° |\n",
    "| **RMSE** | ì œê³± ì˜¤ì°¨ â†’ ë£¨íŠ¸ | í° ì˜¤ì°¨ íŒ¨ë„í‹° |\n",
    "| **R-squared** | ì„¤ëª…ë ¥ (0~1) | ëª¨ë¸ ë¹„êµ |\n",
    "| **êµì°¨ê²€ì¦** | K-fold í‰ê·  | ì•ˆì •ì  ì„±ëŠ¥ ì¶”ì • |\n",
    "| **Learning Curve** | í•™ìŠµëŸ‰ vs ì„±ëŠ¥ | ê³¼ì í•© ì§„ë‹¨ |\n",
    "\n",
    "### ğŸ’¡ ì‹¤ë¬´ íŒ\n",
    "\n",
    "1. **ì •í™•ë„ í•¨ì •**: ë¶ˆê· í˜• ë°ì´í„°ì—ì„œ ì •í™•ë„ë§Œ ë³´ë©´ ì•ˆë¨\n",
    "2. **ë¹„ìš© ê¸°ë°˜ ì„ íƒ**: FP/FN ë¹„ìš©ì„ ê³ ë ¤í•´ Precision/Recall ì„ íƒ\n",
    "3. **êµì°¨ê²€ì¦ í•„ìˆ˜**: ë‹¨ì¼ ë¶„í•  ê²°ê³¼ëŠ” ë¶ˆì•ˆì •\n",
    "4. **Learning Curve**: ê³¼ì í•© ì˜ì‹¬ ì‹œ ë°˜ë“œì‹œ í™•ì¸\n",
    "5. **ì—¬ëŸ¬ ì§€í‘œ ì¢…í•©**: í•˜ë‚˜ì˜ ì§€í‘œë§Œ ë³´ì§€ ë§ê³  ì¢…í•© íŒë‹¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
