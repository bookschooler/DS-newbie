{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day15_0: 앙상블 & AutoML (Ensemble & AutoML)\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "**Part 1: 고급 앙상블**\n",
    "1. Voting (Hard/Soft) 앙상블 이해하기\n",
    "2. Stacking 심화 기법 익히기\n",
    "3. Blending 전략 적용하기\n",
    "4. Plotly로 앙상블 모델 비교하기\n",
    "5. 최적 앙상블 조합 찾기\n",
    "\n",
    "**Part 2: AutoML & 모델 해석**\n",
    "1. Optuna를 활용한 하이퍼파라미터 최적화\n",
    "2. Feature Importance 분석하기\n",
    "3. SHAP Values로 모델 해석하기\n",
    "4. Partial Dependence Plot 그리기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 왜 이것을 배우나요?\n",
    "\n",
    "| 개념 | 비즈니스 활용 | 실무 예시 |\n",
    "|------|-------------|----------|\n",
    "| Voting Ensemble | 여러 모델 의견 종합 | 다수결로 안정적 예측 |\n",
    "| Stacking | 모델 결과를 특성으로 활용 | Kaggle 상위권 필수 기법 |\n",
    "| Optuna | 자동 하이퍼파라미터 튜닝 | 수작업 튜닝 대비 5배 효율 |\n",
    "| SHAP | 예측 근거 설명 | 고객/경영진 설득, 규제 대응 |\n",
    "\n",
    "**분석가 관점**: Kaggle 미니 대회 마무리! 앙상블로 성능을 끌어올리고, SHAP로 모델을 설명합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: 고급 앙상블\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 앙상블 개요\n",
    "\n",
    "### 앙상블이란?\n",
    "\n",
    "**앙상블(Ensemble)**: 여러 모델의 예측을 결합하여 더 좋은 성능을 얻는 기법\n",
    "\n",
    "```\n",
    "앙상블 종류\n",
    "├── Bagging: 같은 알고리즘, 다른 데이터 (Random Forest)\n",
    "├── Boosting: 순차적 학습, 오류 보정 (XGBoost, LightGBM)\n",
    "├── Voting: 다른 알고리즘, 투표 결합\n",
    "├── Stacking: 메타 모델로 결합\n",
    "└── Blending: 홀드아웃 기반 스태킹\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, \n",
    "    GradientBoostingClassifier,\n",
    "    VotingClassifier, \n",
    "    StackingClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, \n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"라이브러리 로드 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습용 데이터셋 생성: 고객 이탈 예측\n",
    "np.random.seed(42)\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=6,\n",
    "    n_redundant=2,\n",
    "    n_classes=2,\n",
    "    weights=[0.7, 0.3],  # 불균형 데이터\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 특성명 부여\n",
    "feature_names = [\n",
    "    'tenure', 'monthly_charge', 'total_charge', 'age',\n",
    "    'complaints', 'support_calls', 'contract_length',\n",
    "    'payment_delay', 'usage_score', 'satisfaction'\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['churned'] = y\n",
    "\n",
    "print(f\"데이터셋 크기: {df.shape}\")\n",
    "print(f\"\\n이탈 비율: {df['churned'].mean():.1%}\")\n",
    "print(f\"\\n데이터 미리보기:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X = df.drop('churned', axis=1)\n",
    "y = df['churned']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"훈련 데이터: {X_train.shape[0]}개\")\n",
    "print(f\"테스트 데이터: {X_test.shape[0]}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 Voting Ensemble\n",
    "\n",
    "### Hard Voting vs Soft Voting\n",
    "\n",
    "| 방식 | 설명 | 계산 |\n",
    "|-----|------|-----|\n",
    "| Hard Voting | 다수결 투표 | 가장 많이 예측된 클래스 |\n",
    "| Soft Voting | 확률 평균 | 평균 확률이 높은 클래스 |\n",
    "\n",
    "```\n",
    "예시: 3개 모델 예측\n",
    "- 모델A: 클래스1 (확률 0.9)\n",
    "- 모델B: 클래스0 (확률 0.6)\n",
    "- 모델C: 클래스1 (확률 0.7)\n",
    "\n",
    "Hard Voting: 클래스1 (2:1)\n",
    "Soft Voting: 클래스1 평균 = (0.9 + 0.4 + 0.7) / 3 = 0.67\n",
    "             클래스0 평균 = (0.1 + 0.6 + 0.3) / 3 = 0.33\n",
    "             -> 클래스1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 모델 정의\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'SVM': SVC(probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# 개별 모델 성능 평가\n",
    "individual_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    individual_results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc\n",
    "    })\n",
    "    print(f\"{name}: Accuracy={accuracy:.4f}, AUC={auc:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(individual_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard Voting\n",
    "hard_voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(random_state=42, max_iter=1000)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "hard_voting.fit(X_train_scaled, y_train)\n",
    "y_pred_hard = hard_voting.predict(X_test_scaled)\n",
    "accuracy_hard = accuracy_score(y_test, y_pred_hard)\n",
    "\n",
    "print(f\"Hard Voting Accuracy: {accuracy_hard:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft Voting\n",
    "soft_voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(random_state=42, max_iter=1000)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "soft_voting.fit(X_train_scaled, y_train)\n",
    "y_pred_soft = soft_voting.predict(X_test_scaled)\n",
    "y_proba_soft = soft_voting.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "accuracy_soft = accuracy_score(y_test, y_pred_soft)\n",
    "auc_soft = roc_auc_score(y_test, y_proba_soft)\n",
    "\n",
    "print(f\"Soft Voting Accuracy: {accuracy_soft:.4f}\")\n",
    "print(f\"Soft Voting AUC: {auc_soft:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실무 예시: 가중 Soft Voting\n",
    "\n",
    "성능이 좋은 모델에 더 높은 가중치를 부여합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중 Soft Voting (성능 좋은 모델에 높은 가중치)\n",
    "weighted_voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(random_state=42, max_iter=1000)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[1, 2, 3]  # GB에 가장 높은 가중치\n",
    ")\n",
    "\n",
    "weighted_voting.fit(X_train_scaled, y_train)\n",
    "y_pred_weighted = weighted_voting.predict(X_test_scaled)\n",
    "y_proba_weighted = weighted_voting.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "accuracy_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "auc_weighted = roc_auc_score(y_test, y_proba_weighted)\n",
    "\n",
    "print(f\"Weighted Soft Voting Accuracy: {accuracy_weighted:.4f}\")\n",
    "print(f\"Weighted Soft Voting AUC: {auc_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 Stacking\n",
    "\n",
    "### Stacking 구조\n",
    "\n",
    "```\n",
    "Level 0 (Base Models):\n",
    "  Model1 -> pred1\n",
    "  Model2 -> pred2\n",
    "  Model3 -> pred3\n",
    "      ↓\n",
    "Level 1 (Meta Model):\n",
    "  [pred1, pred2, pred3] -> Final Prediction\n",
    "```\n",
    "\n",
    "**핵심**: 베이스 모델의 예측을 새로운 특성으로 사용하여 메타 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Classifier\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(random_state=42, max_iter=1000)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(random_state=42),\n",
    "    cv=5,  # 5-fold CV로 메타 특성 생성\n",
    "    stack_method='predict_proba',  # 확률 사용\n",
    "    passthrough=False  # 원본 특성 포함 여부\n",
    ")\n",
    "\n",
    "stacking.fit(X_train_scaled, y_train)\n",
    "y_pred_stack = stacking.predict(X_test_scaled)\n",
    "y_proba_stack = stacking.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "accuracy_stack = accuracy_score(y_test, y_pred_stack)\n",
    "auc_stack = roc_auc_score(y_test, y_proba_stack)\n",
    "\n",
    "print(f\"Stacking Accuracy: {accuracy_stack:.4f}\")\n",
    "print(f\"Stacking AUC: {auc_stack:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking + 원본 특성 (passthrough=True)\n",
    "stacking_passthrough = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(random_state=42, max_iter=1000)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "    ],\n",
    "    final_estimator=RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "    cv=5,\n",
    "    passthrough=True  # 원본 특성 포함\n",
    ")\n",
    "\n",
    "stacking_passthrough.fit(X_train_scaled, y_train)\n",
    "y_pred_stack_pt = stacking_passthrough.predict(X_test_scaled)\n",
    "y_proba_stack_pt = stacking_passthrough.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "accuracy_stack_pt = accuracy_score(y_test, y_pred_stack_pt)\n",
    "auc_stack_pt = roc_auc_score(y_test, y_proba_stack_pt)\n",
    "\n",
    "print(f\"Stacking (passthrough) Accuracy: {accuracy_stack_pt:.4f}\")\n",
    "print(f\"Stacking (passthrough) AUC: {auc_stack_pt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 Blending\n",
    "\n",
    "### Blending vs Stacking\n",
    "\n",
    "| 구분 | Stacking | Blending |\n",
    "|-----|----------|----------|\n",
    "| 메타 특성 생성 | K-Fold CV | Holdout 세트 |\n",
    "| 장점 | 모든 데이터 활용 | 구현 간단 |\n",
    "| 단점 | 느림, 복잡 | 데이터 손실 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blending 구현\n",
    "# Step 1: 훈련 데이터를 train/blend로 분할\n",
    "X_train_base, X_blend, y_train_base, y_blend = train_test_split(\n",
    "    X_train_scaled, y_train, test_size=0.3, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Base 훈련: {X_train_base.shape[0]}개\")\n",
    "print(f\"Blend 세트: {X_blend.shape[0]}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: 베이스 모델 훈련 및 Blend 세트 예측\n",
    "base_models = [\n",
    "    ('lr', LogisticRegression(random_state=42, max_iter=1000)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "blend_features = []\n",
    "test_features = []\n",
    "\n",
    "for name, model in base_models:\n",
    "    model.fit(X_train_base, y_train_base)\n",
    "    \n",
    "    # Blend 세트 예측\n",
    "    blend_pred = model.predict_proba(X_blend)[:, 1]\n",
    "    blend_features.append(blend_pred)\n",
    "    \n",
    "    # 테스트 세트 예측\n",
    "    test_pred = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    test_features.append(test_pred)\n",
    "    \n",
    "    print(f\"{name} 훈련 완료\")\n",
    "\n",
    "# 메타 특성 행렬 생성\n",
    "X_blend_meta = np.column_stack(blend_features)\n",
    "X_test_meta = np.column_stack(test_features)\n",
    "\n",
    "print(f\"\\nBlend 메타 특성: {X_blend_meta.shape}\")\n",
    "print(f\"Test 메타 특성: {X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: 메타 모델 훈련\n",
    "meta_model = LogisticRegression(random_state=42)\n",
    "meta_model.fit(X_blend_meta, y_blend)\n",
    "\n",
    "# 최종 예측\n",
    "y_pred_blend = meta_model.predict(X_test_meta)\n",
    "y_proba_blend = meta_model.predict_proba(X_test_meta)[:, 1]\n",
    "\n",
    "accuracy_blend = accuracy_score(y_test, y_pred_blend)\n",
    "auc_blend = roc_auc_score(y_test, y_proba_blend)\n",
    "\n",
    "print(f\"Blending Accuracy: {accuracy_blend:.4f}\")\n",
    "print(f\"Blending AUC: {auc_blend:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.5 Plotly로 앙상블 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모델 성능 비교\n",
    "all_results = [\n",
    "    {'Model': 'Logistic Regression', 'Type': 'Individual', 'AUC': results_df[results_df['Model']=='Logistic Regression']['AUC'].values[0]},\n",
    "    {'Model': 'Random Forest', 'Type': 'Individual', 'AUC': results_df[results_df['Model']=='Random Forest']['AUC'].values[0]},\n",
    "    {'Model': 'Gradient Boosting', 'Type': 'Individual', 'AUC': results_df[results_df['Model']=='Gradient Boosting']['AUC'].values[0]},\n",
    "    {'Model': 'Hard Voting', 'Type': 'Ensemble', 'AUC': accuracy_hard},  # Hard voting은 확률 없음\n",
    "    {'Model': 'Soft Voting', 'Type': 'Ensemble', 'AUC': auc_soft},\n",
    "    {'Model': 'Weighted Voting', 'Type': 'Ensemble', 'AUC': auc_weighted},\n",
    "    {'Model': 'Stacking', 'Type': 'Ensemble', 'AUC': auc_stack},\n",
    "    {'Model': 'Stacking (passthrough)', 'Type': 'Ensemble', 'AUC': auc_stack_pt},\n",
    "    {'Model': 'Blending', 'Type': 'Ensemble', 'AUC': auc_blend}\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame(all_results)\n",
    "comparison_df = comparison_df.sort_values('AUC', ascending=True)\n",
    "\n",
    "# Plotly 시각화\n",
    "fig = px.bar(\n",
    "    comparison_df,\n",
    "    x='AUC',\n",
    "    y='Model',\n",
    "    color='Type',\n",
    "    orientation='h',\n",
    "    title='개별 모델 vs 앙상블 모델 AUC 비교',\n",
    "    color_discrete_map={'Individual': '#636EFA', 'Ensemble': '#EF553B'}\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='AUC Score',\n",
    "    yaxis_title='Model',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이더 차트로 앙상블 비교\n",
    "ensemble_metrics = pd.DataFrame({\n",
    "    'Metric': ['AUC', 'Accuracy', 'Training Speed', 'Interpretability', 'Stability'],\n",
    "    'Voting': [auc_soft, accuracy_soft, 0.9, 0.7, 0.8],\n",
    "    'Stacking': [auc_stack, accuracy_stack, 0.5, 0.4, 0.9],\n",
    "    'Blending': [auc_blend, accuracy_blend, 0.7, 0.5, 0.7]\n",
    "})\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for method in ['Voting', 'Stacking', 'Blending']:\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=ensemble_metrics[method].tolist() + [ensemble_metrics[method].iloc[0]],\n",
    "        theta=ensemble_metrics['Metric'].tolist() + [ensemble_metrics['Metric'].iloc[0]],\n",
    "        fill='toself',\n",
    "        name=method\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(radialaxis=dict(visible=True, range=[0, 1])),\n",
    "    showlegend=True,\n",
    "    title='앙상블 방법 비교 (레이더 차트)',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: AutoML & 모델 해석\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 Optuna를 활용한 하이퍼파라미터 최적화\n",
    "\n",
    "### Optuna란?\n",
    "\n",
    "- 자동 하이퍼파라미터 최적화 프레임워크\n",
    "- 베이지안 최적화 기반\n",
    "- 조기 종료(Pruning) 지원\n",
    "- 시각화 도구 내장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 설치 확인 및 임포트\n",
    "try:\n",
    "    import optuna\n",
    "    from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "    print(f\"Optuna 버전: {optuna.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Optuna 설치가 필요합니다: pip install optuna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna로 Random Forest 튜닝\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective_rf(trial):\n",
    "    \"\"\"Random Forest 최적화 목적 함수\"\"\"\n",
    "    \n",
    "    # 하이퍼파라미터 탐색 공간 정의\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(**params, random_state=42, n_jobs=-1)\n",
    "    \n",
    "    # 5-Fold CV로 AUC 계산\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, \n",
    "                            cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "# 최적화 실행\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "study_rf = optuna.create_study(direction='maximize', study_name='rf_optimization')\n",
    "study_rf.optimize(objective_rf, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n최적 AUC: {study_rf.best_value:.4f}\")\n",
    "print(f\"최적 파라미터: {study_rf.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 모델로 재학습\n",
    "best_rf = RandomForestClassifier(**study_rf.best_params, random_state=42)\n",
    "best_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_best_rf = best_rf.predict(X_test_scaled)\n",
    "y_proba_best_rf = best_rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(f\"최적화된 RF Accuracy: {accuracy_score(y_test, y_pred_best_rf):.4f}\")\n",
    "print(f\"최적화된 RF AUC: {roc_auc_score(y_test, y_proba_best_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 최적화 과정 시각화 (Plotly)\n",
    "trials_df = study_rf.trials_dataframe()\n",
    "\n",
    "fig = px.line(\n",
    "    trials_df,\n",
    "    x='number',\n",
    "    y='value',\n",
    "    title='Optuna 최적화 과정',\n",
    "    labels={'number': 'Trial', 'value': 'AUC Score'}\n",
    ")\n",
    "\n",
    "# 최적점 표시\n",
    "best_trial = trials_df.loc[trials_df['value'].idxmax()]\n",
    "fig.add_scatter(\n",
    "    x=[best_trial['number']],\n",
    "    y=[best_trial['value']],\n",
    "    mode='markers',\n",
    "    marker=dict(size=15, color='red', symbol='star'),\n",
    "    name=f'Best: {best_trial[\"value\"]:.4f}'\n",
    ")\n",
    "\n",
    "fig.update_layout(height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 중요도 시각화\n",
    "param_importance = optuna.importance.get_param_importances(study_rf)\n",
    "\n",
    "importance_df = pd.DataFrame([\n",
    "    {'Parameter': k, 'Importance': v}\n",
    "    for k, v in param_importance.items()\n",
    "]).sort_values('Importance', ascending=True)\n",
    "\n",
    "fig = px.bar(\n",
    "    importance_df,\n",
    "    x='Importance',\n",
    "    y='Parameter',\n",
    "    orientation='h',\n",
    "    title='하이퍼파라미터 중요도 (Optuna)',\n",
    "    color='Importance',\n",
    "    color_continuous_scale='Viridis'\n",
    ")\n",
    "\n",
    "fig.update_layout(height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 Feature Importance 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (Random Forest 기반)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': best_rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "fig = px.bar(\n",
    "    feature_importance,\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    orientation='h',\n",
    "    title='Feature Importance (Random Forest)',\n",
    "    color='Importance',\n",
    "    color_continuous_scale='Blues'\n",
    ")\n",
    "\n",
    "fig.update_layout(height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation Importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    best_rf, X_test_scaled, y_test,\n",
    "    n_repeats=10, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "perm_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': perm_importance.importances_mean,\n",
    "    'Std': perm_importance.importances_std\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "fig = px.bar(\n",
    "    perm_df,\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    orientation='h',\n",
    "    title='Permutation Importance',\n",
    "    error_x='Std',\n",
    "    color='Importance',\n",
    "    color_continuous_scale='Reds'\n",
    ")\n",
    "\n",
    "fig.update_layout(height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 SHAP Values\n",
    "\n",
    "### SHAP이란?\n",
    "\n",
    "**SHAP (SHapley Additive exPlanations)**: 게임 이론의 Shapley Value를 활용한 모델 해석 기법\n",
    "\n",
    "- 각 특성이 예측에 기여한 정도를 정량화\n",
    "- 개별 예측과 전체 모델 모두 해석 가능\n",
    "- 모델에 구애받지 않음 (Model-agnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP 임포트\n",
    "try:\n",
    "    import shap\n",
    "    print(f\"SHAP 버전: {shap.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"SHAP 설치가 필요합니다: pip install shap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP 계산\n",
    "import shap\n",
    "\n",
    "# TreeExplainer (Random Forest용)\n",
    "explainer = shap.TreeExplainer(best_rf)\n",
    "\n",
    "# 테스트 데이터 일부로 SHAP 계산 (속도 위해)\n",
    "X_test_sample = X_test_scaled[:100]\n",
    "shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "print(f\"SHAP values shape: {shap_values[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Summary Plot (Plotly 버전)\n",
    "shap_df = pd.DataFrame(\n",
    "    shap_values[1],  # 이탈 클래스에 대한 SHAP\n",
    "    columns=feature_names\n",
    ")\n",
    "\n",
    "# 평균 절대 SHAP 값\n",
    "mean_abs_shap = shap_df.abs().mean().sort_values(ascending=True)\n",
    "\n",
    "fig = px.bar(\n",
    "    x=mean_abs_shap.values,\n",
    "    y=mean_abs_shap.index,\n",
    "    orientation='h',\n",
    "    title='SHAP Feature Importance (평균 |SHAP|)',\n",
    "    labels={'x': 'Mean |SHAP Value|', 'y': 'Feature'},\n",
    "    color=mean_abs_shap.values,\n",
    "    color_continuous_scale='Plasma'\n",
    ")\n",
    "\n",
    "fig.update_layout(height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Beeswarm Plot (Plotly 버전)\n",
    "# 상위 5개 특성만 시각화\n",
    "top_features = mean_abs_shap.tail(5).index.tolist()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=5, subplot_titles=top_features)\n",
    "\n",
    "for i, feat in enumerate(top_features):\n",
    "    feat_idx = feature_names.index(feat)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=shap_values[1][:, feat_idx],\n",
    "            y=X_test_sample[:, feat_idx],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                color=X_test_sample[:, feat_idx],\n",
    "                colorscale='RdBu',\n",
    "                size=5\n",
    "            ),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=i+1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='SHAP Values vs Feature Values (상위 5개 특성)',\n",
    "    height=400\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 예측 설명 (Waterfall Plot 대신 Bar Plot)\n",
    "sample_idx = 0\n",
    "sample_shap = shap_values[1][sample_idx]\n",
    "\n",
    "explanation_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'SHAP Value': sample_shap,\n",
    "    'Feature Value': X_test_sample[sample_idx]\n",
    "}).sort_values('SHAP Value', key=abs, ascending=False)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "colors = ['red' if x > 0 else 'blue' for x in explanation_df['SHAP Value']]\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=explanation_df['SHAP Value'],\n",
    "    y=explanation_df['Feature'],\n",
    "    orientation='h',\n",
    "    marker_color=colors,\n",
    "    text=[f'{v:.2f}' for v in explanation_df['SHAP Value']],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "actual = y_test.iloc[sample_idx]\n",
    "pred_proba = best_rf.predict_proba(X_test_sample[sample_idx:sample_idx+1])[0][1]\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'개별 예측 설명 (샘플 {sample_idx})<br>실제: {actual}, 예측 확률: {pred_proba:.2%}',\n",
    "    xaxis_title='SHAP Value (이탈 방향: +, 유지 방향: -)',\n",
    "    yaxis_title='Feature',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 Partial Dependence Plot (PDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial Dependence 계산\n",
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "# 상위 2개 특성에 대해 PDP 계산\n",
    "top_2_features = mean_abs_shap.tail(2).index.tolist()\n",
    "top_2_indices = [feature_names.index(f) for f in top_2_features]\n",
    "\n",
    "pd_results = partial_dependence(\n",
    "    best_rf, X_train_scaled, features=top_2_indices,\n",
    "    kind='average', grid_resolution=50\n",
    ")\n",
    "\n",
    "print(f\"PDP 계산 완료: {top_2_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDP 시각화\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=top_2_features)\n",
    "\n",
    "for i, (feat, idx) in enumerate(zip(top_2_features, top_2_indices)):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pd_results['grid_values'][i],\n",
    "            y=pd_results['average'][i],\n",
    "            mode='lines',\n",
    "            name=feat,\n",
    "            line=dict(width=3)\n",
    "        ),\n",
    "        row=1, col=i+1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Partial Dependence Plot (상위 2개 특성)',\n",
    "    height=400\n",
    ")\n",
    "fig.update_yaxes(title_text='Predicted Probability', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Predicted Probability', row=1, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D PDP (두 특성 간 상호작용)\n",
    "pd_2d = partial_dependence(\n",
    "    best_rf, X_train_scaled,\n",
    "    features=[top_2_indices],  # 2D로 조합\n",
    "    kind='average',\n",
    "    grid_resolution=20\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=pd_2d['average'][0],\n",
    "    x=pd_2d['grid_values'][0][0],\n",
    "    y=pd_2d['grid_values'][0][1],\n",
    "    colorscale='RdBu_r'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'2D Partial Dependence: {top_2_features[0]} vs {top_2_features[1]}',\n",
    "    xaxis_title=top_2_features[0],\n",
    "    yaxis_title=top_2_features[1],\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실무 예시: 모델 해석 리포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 해석 요약 리포트\n",
    "print(\"=\" * 60)\n",
    "print(\"모델 해석 요약 리포트\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. 모델 성능\")\n",
    "print(f\"   - AUC: {roc_auc_score(y_test, y_proba_best_rf):.4f}\")\n",
    "print(f\"   - Accuracy: {accuracy_score(y_test, y_pred_best_rf):.4f}\")\n",
    "\n",
    "print(\"\\n2. 상위 중요 특성 (SHAP 기반)\")\n",
    "for i, (feat, val) in enumerate(mean_abs_shap.tail(5).items(), 1):\n",
    "    print(f\"   {i}. {feat}: {val:.4f}\")\n",
    "\n",
    "print(\"\\n3. 비즈니스 인사이트\")\n",
    "top_feat = mean_abs_shap.idxmax()\n",
    "print(f\"   - '{top_feat}'이 이탈 예측에 가장 큰 영향\")\n",
    "print(f\"   - 해당 특성 관리로 이탈 방지 가능\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 퀴즈\n",
    "\n",
    "**난이도**: (쉬움) ~ (어려움)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Hard Voting 이해하기 ⭐\n",
    "\n",
    "**문제**: 3개 모델의 예측이 다음과 같을 때, Hard Voting 결과는?\n",
    "\n",
    "```python\n",
    "model_a_pred = 1\n",
    "model_b_pred = 0\n",
    "model_c_pred = 1\n",
    "```\n",
    "\n",
    "**기대 결과**: 최종 예측 클래스 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_pred = 1\n",
    "model_b_pred = 0\n",
    "model_c_pred = 1\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Soft Voting 계산하기 ⭐⭐\n",
    "\n",
    "**문제**: 3개 모델의 클래스 1 예측 확률이 다음과 같을 때, Soft Voting 결과는?\n",
    "\n",
    "```python\n",
    "proba_a = 0.8  # 모델 A의 클래스 1 확률\n",
    "proba_b = 0.3  # 모델 B의 클래스 1 확률\n",
    "proba_c = 0.6  # 모델 C의 클래스 1 확률\n",
    "```\n",
    "\n",
    "**기대 결과**: 평균 확률과 최종 예측 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_a = 0.8\n",
    "proba_b = 0.3\n",
    "proba_c = 0.6\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. VotingClassifier 구성하기 ⭐⭐\n",
    "\n",
    "**문제**: LogisticRegression과 RandomForest로 Soft Voting 앙상블을 구성하세요.\n",
    "\n",
    "```python\n",
    "# Iris 데이터 사용\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, (iris.target == 2).astype(int)  # 이진 분류\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, (iris.target == 2).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Stacking vs Voting 비교 ⭐⭐⭐\n",
    "\n",
    "**문제**: 같은 베이스 모델로 Stacking과 Voting 성능을 비교하세요.\n",
    "\n",
    "조건:\n",
    "- 베이스 모델: LR, RF, GB\n",
    "- Stacking 메타 모델: LogisticRegression\n",
    "- 위 iris 데이터 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. 가중 Voting 최적화 ⭐⭐⭐\n",
    "\n",
    "**문제**: 개별 모델 성능에 비례하여 가중치를 설정한 Weighted Voting을 구성하세요.\n",
    "\n",
    "```python\n",
    "# 각 모델의 CV 점수\n",
    "lr_score = 0.85\n",
    "rf_score = 0.90\n",
    "gb_score = 0.92\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_score = 0.85\n",
    "rf_score = 0.90\n",
    "gb_score = 0.92\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Optuna 기본 사용 ⭐⭐⭐\n",
    "\n",
    "**문제**: Optuna로 LogisticRegression의 C 파라미터를 최적화하세요.\n",
    "\n",
    "조건:\n",
    "- C 범위: 0.01 ~ 100 (log uniform)\n",
    "- trials: 20회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Feature Importance 비교 ⭐⭐⭐⭐\n",
    "\n",
    "**문제**: Random Forest와 Gradient Boosting의 Feature Importance를 비교하는 Plotly 차트를 만드세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 사용한 데이터 활용\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. SHAP Force Plot 해석 ⭐⭐⭐⭐\n",
    "\n",
    "**문제**: 테스트 데이터의 첫 번째 샘플에 대해 SHAP 값을 계산하고 해석하세요.\n",
    "\n",
    "요구사항:\n",
    "1. 예측 확률 출력\n",
    "2. 상위 3개 영향 특성과 SHAP 값 출력\n",
    "3. 예측에 대한 해석 문장 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 계산한 SHAP 값 활용\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. PDP 그리기 ⭐⭐⭐⭐⭐\n",
    "\n",
    "**문제**: 가장 중요한 특성 1개에 대한 Partial Dependence Plot을 Plotly로 그리세요.\n",
    "\n",
    "추가 요구사항:\n",
    "- 실제 데이터 분포를 rug plot 형태로 하단에 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. 종합: 앙상블 + AutoML + 해석 ⭐⭐⭐⭐⭐\n",
    "\n",
    "**문제**: 다음 파이프라인을 완성하세요.\n",
    "\n",
    "1. Optuna로 RandomForest 최적화 (10 trials)\n",
    "2. 최적 RF + LR + GB로 Stacking 구성\n",
    "3. SHAP로 상위 3개 중요 특성 출력\n",
    "4. 모델 성능 (AUC) 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 학습 정리\n",
    "\n",
    "### Part 1: 고급 앙상블 핵심 요약\n",
    "\n",
    "| 앙상블 기법 | 특징 | 장점 | 단점 |\n",
    "|-----------|------|-----|------|\n",
    "| Hard Voting | 다수결 | 간단, 빠름 | 확률 정보 무시 |\n",
    "| Soft Voting | 확률 평균 | 더 정교한 결합 | 확률 필요 |\n",
    "| Stacking | 메타 모델 | 최고 성능 | 과적합 위험 |\n",
    "| Blending | 홀드아웃 기반 | 구현 간단 | 데이터 손실 |\n",
    "\n",
    "### Part 2: AutoML & 모델 해석 핵심 요약\n",
    "\n",
    "| 도구/기법 | 용도 | 핵심 포인트 |\n",
    "|---------|------|------------|\n",
    "| Optuna | 하이퍼파라미터 최적화 | 베이지안 최적화, 조기 종료 |\n",
    "| Feature Importance | 특성 중요도 | 트리 기반 모델에 내장 |\n",
    "| Permutation Importance | 모델 불가지론적 중요도 | 셔플 후 성능 저하 측정 |\n",
    "| SHAP | 개별 예측 설명 | 게임 이론 기반, 해석 가능 AI |\n",
    "| PDP | 특성-예측 관계 | 다른 특성 고정, 한 특성 변화 |\n",
    "\n",
    "### 실무 팁\n",
    "\n",
    "1. **Voting 먼저**: Stacking 전에 Voting으로 빠르게 테스트\n",
    "2. **다양성 확보**: 앙상블은 다른 알고리즘 조합이 효과적\n",
    "3. **Optuna 시간 관리**: n_trials 대신 timeout 옵션 활용\n",
    "4. **SHAP 필수**: 비즈니스 설명에 필수 (규제 대응)\n",
    "5. **PDP로 검증**: Feature Importance와 방향성 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
