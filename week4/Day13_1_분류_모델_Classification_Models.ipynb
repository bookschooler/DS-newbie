{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day13_1: 분류 모델 (Classification Models)\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "**Part 1: 기본 분류기**\n",
    "1. Logistic Regression의 원리와 적용\n",
    "2. K-Nearest Neighbors (KNN) 이해하기\n",
    "3. Naive Bayes 분류기 활용\n",
    "4. Support Vector Machine (SVM) 기초\n",
    "5. 기본 분류기 성능 비교\n",
    "\n",
    "**Part 2: 트리 기반 모델**\n",
    "1. Decision Tree Classifier 이해\n",
    "2. Random Forest Classifier 활용\n",
    "3. Gradient Boosting Classifier 적용\n",
    "4. 트리 기반 모델 비교 분석\n",
    "\n",
    "**Part 3: 앙상블 기법**\n",
    "1. Voting Classifier (Hard/Soft)\n",
    "2. Bagging 기법 이해\n",
    "3. Boosting 기법 (AdaBoost, XGBoost)\n",
    "4. Stacking 앙상블 구현\n",
    "\n",
    "**Part 4: 불균형 데이터 처리**\n",
    "1. 클래스 불균형 문제 이해\n",
    "2. class_weight 조정 방법\n",
    "3. SMOTE 오버샘플링 적용\n",
    "4. Plotly로 ROC/PR 곡선 시각화\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 왜 이것을 배우나요?\n",
    "\n",
    "| 개념 | 비즈니스 활용 | 실무 예시 |\n",
    "|------|-------------|----------|\n",
    "| 기본 분류기 | 빠른 프로토타이핑 | 스팸 필터, 고객 이탈 예측 |\n",
    "| 트리 기반 모델 | 해석 가능한 예측 | 대출 승인, 보험 심사 |\n",
    "| 앙상블 기법 | 최고 성능 달성 | Kaggle 대회, 프로덕션 모델 |\n",
    "| 불균형 처리 | 희귀 이벤트 탐지 | 사기 탐지, 질병 진단 |\n",
    "\n",
    "**분석가 관점**: Week 4 Kaggle 미니 대회의 핵심! 다양한 분류 알고리즘을 이해하고 앙상블로 성능을 극대화하며, 불균형 데이터(사기 탐지)를 다루는 실전 스킬을 익힙니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: 기본 분류기\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 환경 설정 및 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "# 분류 알고리즘\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    "    VotingClassifier, BaggingClassifier, AdaBoostClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "\n",
    "# 경고 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"라이브러리 로드 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습 데이터: 신용카드 사기 탐지 시뮬레이션 데이터\n",
    "np.random.seed(42)\n",
    "\n",
    "# 정상 거래 (95%)\n",
    "n_normal = 9500\n",
    "normal_data = {\n",
    "    'amount': np.random.exponential(scale=100, size=n_normal),\n",
    "    'hour': np.random.randint(6, 23, n_normal),\n",
    "    'distance_from_home': np.random.exponential(scale=10, size=n_normal),\n",
    "    'ratio_to_median': np.random.uniform(0.5, 2.0, n_normal),\n",
    "    'repeat_retailer': np.random.choice([0, 1], n_normal, p=[0.3, 0.7]),\n",
    "    'used_chip': np.random.choice([0, 1], n_normal, p=[0.2, 0.8]),\n",
    "    'used_pin': np.random.choice([0, 1], n_normal, p=[0.3, 0.7]),\n",
    "    'online_order': np.random.choice([0, 1], n_normal, p=[0.6, 0.4]),\n",
    "    'fraud': np.zeros(n_normal)\n",
    "}\n",
    "\n",
    "# 사기 거래 (5%) - 패턴이 다름\n",
    "n_fraud = 500\n",
    "fraud_data = {\n",
    "    'amount': np.random.exponential(scale=500, size=n_fraud),  # 더 큰 금액\n",
    "    'hour': np.random.choice([0, 1, 2, 3, 4, 5, 23], n_fraud),  # 야간 거래\n",
    "    'distance_from_home': np.random.exponential(scale=100, size=n_fraud),  # 먼 거리\n",
    "    'ratio_to_median': np.random.uniform(3.0, 10.0, n_fraud),  # 평소보다 큰 거래\n",
    "    'repeat_retailer': np.random.choice([0, 1], n_fraud, p=[0.8, 0.2]),  # 새 판매자\n",
    "    'used_chip': np.random.choice([0, 1], n_fraud, p=[0.7, 0.3]),  # 칩 미사용\n",
    "    'used_pin': np.random.choice([0, 1], n_fraud, p=[0.8, 0.2]),  # PIN 미사용\n",
    "    'online_order': np.random.choice([0, 1], n_fraud, p=[0.2, 0.8]),  # 온라인 거래\n",
    "    'fraud': np.ones(n_fraud)\n",
    "}\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df_normal = pd.DataFrame(normal_data)\n",
    "df_fraud = pd.DataFrame(fraud_data)\n",
    "df = pd.concat([df_normal, df_fraud], ignore_index=True)\n",
    "\n",
    "# 데이터 셔플\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"전체 데이터: {len(df)}건\")\n",
    "print(f\"사기 비율: {df['fraud'].mean():.2%}\")\n",
    "print(f\"\\n데이터 미리보기:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성과 타겟 분리\n",
    "feature_cols = ['amount', 'hour', 'distance_from_home', 'ratio_to_median',\n",
    "                'repeat_retailer', 'used_chip', 'used_pin', 'online_order']\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['fraud']\n",
    "\n",
    "# 훈련/테스트 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"훈련 데이터: {X_train.shape[0]}건\")\n",
    "print(f\"테스트 데이터: {X_test.shape[0]}건\")\n",
    "print(f\"훈련 데이터 사기 비율: {y_train.mean():.2%}\")\n",
    "print(f\"테스트 데이터 사기 비율: {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 Logistic Regression\n",
    "\n",
    "### 원리\n",
    "- 선형 결합 결과를 시그모이드 함수로 변환하여 확률 출력\n",
    "- 이진 분류의 기본 베이스라인 모델\n",
    "- 해석 가능성이 높음 (계수 = 특성 중요도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 평가\n",
    "print(\"=\" * 50)\n",
    "print(\"Logistic Regression 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['정상', '사기']))\n",
    "\n",
    "# 계수 확인 (특성 중요도)\n",
    "print(\"\\n특성별 계수 (중요도):\")\n",
    "for feature, coef in sorted(zip(feature_cols, lr_model.coef_[0]), key=lambda x: abs(x[1]), reverse=True):\n",
    "    print(f\"  {feature}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 K-Nearest Neighbors (KNN)\n",
    "\n",
    "### 원리\n",
    "- 가장 가까운 K개 이웃의 다수결로 분류\n",
    "- 비모수적 방법 (데이터 분포 가정 없음)\n",
    "- K 값에 따라 성능 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN (K=5)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "y_proba_knn = knn_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 평가\n",
    "print(\"=\" * 50)\n",
    "print(\"K-Nearest Neighbors (K=5) 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_knn, target_names=['정상', '사기']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K 값에 따른 성능 변화\n",
    "k_values = range(1, 21, 2)\n",
    "k_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train_scaled, y_train, cv=5, scoring='f1')\n",
    "    k_scores.append(scores.mean())\n",
    "\n",
    "# Plotly 시각화\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(k_values), y=k_scores,\n",
    "    mode='lines+markers',\n",
    "    name='F1 Score',\n",
    "    marker=dict(size=10)\n",
    "))\n",
    "\n",
    "best_k = list(k_values)[np.argmax(k_scores)]\n",
    "fig.add_vline(x=best_k, line_dash=\"dash\", line_color=\"red\",\n",
    "              annotation_text=f\"Best K={best_k}\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"KNN: K 값에 따른 F1 Score\",\n",
    "    xaxis_title=\"K (이웃 수)\",\n",
    "    yaxis_title=\"F1 Score (CV)\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\n최적 K: {best_k} (F1: {max(k_scores):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 Naive Bayes\n",
    "\n",
    "### 원리\n",
    "- 베이즈 정리 기반, 특성 간 독립 가정\n",
    "- 매우 빠른 학습/예측\n",
    "- 텍스트 분류에 특히 효과적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_nb = nb_model.predict(X_test_scaled)\n",
    "y_proba_nb = nb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 평가\n",
    "print(\"=\" * 50)\n",
    "print(\"Naive Bayes 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_nb, target_names=['정상', '사기']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.5 Support Vector Machine (SVM)\n",
    "\n",
    "### 원리\n",
    "- 클래스 간 마진을 최대화하는 결정 경계 탐색\n",
    "- 커널 트릭으로 비선형 분류 가능\n",
    "- 고차원 데이터에 효과적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with RBF kernel\n",
    "svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "y_proba_svm = svm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 평가\n",
    "print(\"=\" * 50)\n",
    "print(\"SVM (RBF Kernel) 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_svm, target_names=['정상', '사기']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.6 기본 분류기 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 분류기 성능 비교\n",
    "basic_models = {\n",
    "    'Logistic Regression': (y_pred_lr, y_proba_lr),\n",
    "    'KNN': (y_pred_knn, y_proba_knn),\n",
    "    'Naive Bayes': (y_pred_nb, y_proba_nb),\n",
    "    'SVM': (y_pred_svm, y_proba_svm)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, (y_pred, y_proba) in basic_models.items():\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'AUC': auc(*roc_curve(y_test, y_proba)[:2])\n",
    "    })\n",
    "\n",
    "df_basic_results = pd.DataFrame(results)\n",
    "print(\"기본 분류기 성능 비교:\")\n",
    "print(df_basic_results.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly로 성능 비교 시각화\n",
    "fig = go.Figure()\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC']\n",
    "colors = px.colors.qualitative.Set2\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    fig.add_trace(go.Bar(\n",
    "        name=metric,\n",
    "        x=df_basic_results['Model'],\n",
    "        y=df_basic_results[metric],\n",
    "        marker_color=colors[i],\n",
    "        text=df_basic_results[metric].round(3),\n",
    "        textposition='auto'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"기본 분류기 성능 비교\",\n",
    "    xaxis_title=\"Model\",\n",
    "    yaxis_title=\"Score\",\n",
    "    barmode='group',\n",
    "    template=\"plotly_white\",\n",
    "    legend_title=\"Metric\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: 트리 기반 모델\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 Decision Tree Classifier\n",
    "\n",
    "### 원리\n",
    "- 특성 값으로 데이터를 분할하는 규칙 트리 생성\n",
    "- 높은 해석 가능성 (시각화 가능)\n",
    "- 과적합 경향 (가지치기 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=5,           # 과적합 방지\n",
    "    min_samples_split=20,  # 분할 최소 샘플\n",
    "    random_state=42\n",
    ")\n",
    "dt_model.fit(X_train, y_train)  # 트리는 스케일링 불필요\n",
    "\n",
    "# 예측\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "y_proba_dt = dt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 평가\n",
    "print(\"=\" * 50)\n",
    "print(\"Decision Tree 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_dt, target_names=['정상', '사기']))\n",
    "\n",
    "# 특성 중요도\n",
    "print(\"\\n특성 중요도:\")\n",
    "for feature, importance in sorted(zip(feature_cols, dt_model.feature_importances_), \n",
    "                                   key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 Random Forest Classifier\n",
    "\n",
    "### 원리\n",
    "- 다수의 Decision Tree 앙상블 (Bagging)\n",
    "- 각 트리는 부트스트랩 샘플 + 랜덤 특성 선택\n",
    "- 과적합 방지, 높은 안정성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,      # 트리 개수\n",
    "    max_depth=10,          # 최대 깊이\n",
    "    min_samples_split=10,  # 분할 최소 샘플\n",
    "    n_jobs=-1,             # 병렬 처리\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 평가\n",
    "print(\"=\" * 50)\n",
    "print(\"Random Forest 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['정상', '사기']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 중요도 시각화 (Plotly)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "fig = go.Figure(go.Bar(\n",
    "    x=feature_importance['importance'],\n",
    "    y=feature_importance['feature'],\n",
    "    orientation='h',\n",
    "    marker_color='steelblue',\n",
    "    text=feature_importance['importance'].round(3),\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Random Forest 특성 중요도\",\n",
    "    xaxis_title=\"Importance\",\n",
    "    yaxis_title=\"Feature\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 Gradient Boosting Classifier\n",
    "\n",
    "### 원리\n",
    "- 순차적으로 트리를 추가하며 오차를 줄임\n",
    "- 이전 트리의 잔차(residual)를 학습\n",
    "- 높은 성능, 튜닝 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,      # 부스팅 라운드\n",
    "    learning_rate=0.1,     # 학습률\n",
    "    max_depth=5,           # 트리 깊이\n",
    "    random_state=42\n",
    ")\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "y_proba_gb = gb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 평가\n",
    "print(\"=\" * 50)\n",
    "print(\"Gradient Boosting 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_gb, target_names=['정상', '사기']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 트리 기반 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트리 기반 모델 비교\n",
    "tree_models = {\n",
    "    'Decision Tree': (y_pred_dt, y_proba_dt),\n",
    "    'Random Forest': (y_pred_rf, y_proba_rf),\n",
    "    'Gradient Boosting': (y_pred_gb, y_proba_gb)\n",
    "}\n",
    "\n",
    "tree_results = []\n",
    "for name, (y_pred, y_proba) in tree_models.items():\n",
    "    tree_results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'AUC': auc(*roc_curve(y_test, y_proba)[:2])\n",
    "    })\n",
    "\n",
    "df_tree_results = pd.DataFrame(tree_results)\n",
    "print(\"트리 기반 모델 성능 비교:\")\n",
    "print(df_tree_results.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: 앙상블 기법\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 Voting Classifier\n",
    "\n",
    "### 원리\n",
    "- 여러 모델의 예측을 결합\n",
    "- Hard Voting: 다수결\n",
    "- Soft Voting: 확률 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier (Soft Voting)\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(random_state=42, max_iter=1000)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=50, random_state=42))\n",
    "    ],\n",
    "    voting='soft'  # 확률 기반 결합\n",
    ")\n",
    "\n",
    "# 학습 (Logistic Regression은 스케일링 필요하지만 여기서는 원본 사용)\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_voting = voting_model.predict(X_test)\n",
    "y_proba_voting = voting_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Voting Classifier (Soft) 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_voting, target_names=['정상', '사기']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.2 Bagging\n",
    "\n",
    "### 원리\n",
    "- Bootstrap Aggregating\n",
    "- 부트스트랩 샘플로 여러 모델 학습 후 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging with Decision Tree\n",
    "bagging_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=10),\n",
    "    n_estimators=50,\n",
    "    max_samples=0.8,\n",
    "    max_features=0.8,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_bagging = bagging_model.predict(X_test)\n",
    "y_proba_bagging = bagging_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Bagging 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_bagging, target_names=['정상', '사기']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.3 Boosting (AdaBoost)\n",
    "\n",
    "### 원리\n",
    "- 오분류 샘플에 가중치를 높여 순차 학습\n",
    "- 약한 학습기를 강한 학습기로 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost\n",
    "ada_model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=3),\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "y_proba_ada = ada_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"AdaBoost 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_ada, target_names=['정상', '사기']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.4 Stacking\n",
    "\n",
    "### 원리\n",
    "- 기본 모델들의 예측을 새로운 특성으로 사용\n",
    "- 메타 모델이 최종 예측 수행\n",
    "- 가장 복잡하지만 높은 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Classifier\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=50, random_state=42)),\n",
    "        ('svm', SVC(probability=True, random_state=42))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(random_state=42),\n",
    "    cv=5\n",
    ")\n",
    "stacking_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_stacking = stacking_model.predict(X_test_scaled)\n",
    "y_proba_stacking = stacking_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Stacking 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_stacking, target_names=['정상', '사기']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.5 앙상블 기법 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블 기법 비교\n",
    "ensemble_models = {\n",
    "    'Voting': (y_pred_voting, y_proba_voting),\n",
    "    'Bagging': (y_pred_bagging, y_proba_bagging),\n",
    "    'AdaBoost': (y_pred_ada, y_proba_ada),\n",
    "    'Stacking': (y_pred_stacking, y_proba_stacking)\n",
    "}\n",
    "\n",
    "ensemble_results = []\n",
    "for name, (y_pred, y_proba) in ensemble_models.items():\n",
    "    ensemble_results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'AUC': auc(*roc_curve(y_test, y_proba)[:2])\n",
    "    })\n",
    "\n",
    "df_ensemble_results = pd.DataFrame(ensemble_results)\n",
    "print(\"앙상블 기법 성능 비교:\")\n",
    "print(df_ensemble_results.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: 불균형 데이터 처리\n",
    "\n",
    "---\n",
    "\n",
    "## 4.1 클래스 불균형 문제 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 불균형 확인\n",
    "class_counts = y_train.value_counts()\n",
    "print(\"클래스 분포:\")\n",
    "print(f\"  정상 (0): {class_counts[0]} ({class_counts[0]/len(y_train):.1%})\")\n",
    "print(f\"  사기 (1): {class_counts[1]} ({class_counts[1]/len(y_train):.1%})\")\n",
    "print(f\"\\n불균형 비율: {class_counts[0] / class_counts[1]:.1f}:1\")\n",
    "\n",
    "# Plotly 파이 차트\n",
    "fig = go.Figure(data=[go.Pie(\n",
    "    labels=['정상', '사기'],\n",
    "    values=[class_counts[0], class_counts[1]],\n",
    "    hole=0.4,\n",
    "    marker_colors=['steelblue', 'crimson']\n",
    ")])\n",
    "fig.update_layout(title=\"클래스 분포 (불균형)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.2 class_weight 조정\n",
    "\n",
    "### 원리\n",
    "- 소수 클래스에 높은 가중치 부여\n",
    "- 모델이 소수 클래스 오분류에 더 큰 페널티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight='balanced' 적용\n",
    "lr_balanced = LogisticRegression(\n",
    "    class_weight='balanced',  # 자동 가중치 조정\n",
    "    random_state=42,\n",
    "    max_iter=1000\n",
    ")\n",
    "lr_balanced.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_balanced = lr_balanced.predict(X_test_scaled)\n",
    "y_proba_balanced = lr_balanced.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Logistic Regression (class_weight='balanced') 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_balanced, target_names=['정상', '사기']))\n",
    "\n",
    "# 기존 LR과 비교\n",
    "print(\"\\n기존 LR vs Balanced LR 비교:\")\n",
    "print(f\"  기존 Recall: {recall_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"  Balanced Recall: {recall_score(y_test, y_pred_balanced):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with class_weight\n",
    "rf_balanced = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_balanced.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf_balanced = rf_balanced.predict(X_test)\n",
    "y_proba_rf_balanced = rf_balanced.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Random Forest (class_weight='balanced') 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_rf_balanced, target_names=['정상', '사기']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.3 SMOTE (오버샘플링)\n",
    "\n",
    "### 원리\n",
    "- Synthetic Minority Over-sampling Technique\n",
    "- 소수 클래스의 합성 샘플 생성\n",
    "- K-최근접 이웃 사이에 새 샘플 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE 설치 확인 및 적용\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "    \n",
    "    # SMOTE 적용\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "    \n",
    "    print(\"SMOTE 적용 전후 비교:\")\n",
    "    print(f\"  적용 전: 정상 {sum(y_train==0)}, 사기 {sum(y_train==1)}\")\n",
    "    print(f\"  적용 후: 정상 {sum(y_train_smote==0)}, 사기 {sum(y_train_smote==1)}\")\n",
    "    \n",
    "    # SMOTE + Logistic Regression\n",
    "    lr_smote = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    lr_smote.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    y_pred_smote = lr_smote.predict(X_test_scaled)\n",
    "    y_proba_smote = lr_smote.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"SMOTE + Logistic Regression 결과\")\n",
    "    print(\"=\" * 50)\n",
    "    print(classification_report(y_test, y_pred_smote, target_names=['정상', '사기']))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"imbalanced-learn 라이브러리가 설치되지 않았습니다.\")\n",
    "    print(\"설치: pip install imbalanced-learn\")\n",
    "    y_pred_smote = y_pred_balanced\n",
    "    y_proba_smote = y_proba_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.4 Plotly로 ROC 곡선 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모델의 ROC 곡선 비교\n",
    "all_models = {\n",
    "    'Logistic Regression': y_proba_lr,\n",
    "    'Random Forest': y_proba_rf,\n",
    "    'Gradient Boosting': y_proba_gb,\n",
    "    'Stacking': y_proba_stacking,\n",
    "    'LR (balanced)': y_proba_balanced,\n",
    "    'RF (balanced)': y_proba_rf_balanced\n",
    "}\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "colors = px.colors.qualitative.Set1\n",
    "\n",
    "for i, (name, y_proba) in enumerate(all_models.items()):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=fpr, y=tpr,\n",
    "        mode='lines',\n",
    "        name=f\"{name} (AUC={roc_auc:.3f})\",\n",
    "        line=dict(color=colors[i % len(colors)], width=2)\n",
    "    ))\n",
    "\n",
    "# 대각선 (랜덤 분류기)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 1], y=[0, 1],\n",
    "    mode='lines',\n",
    "    name='Random (AUC=0.5)',\n",
    "    line=dict(color='gray', dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"ROC Curves - 모델 비교\",\n",
    "    xaxis_title=\"False Positive Rate\",\n",
    "    yaxis_title=\"True Positive Rate\",\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(x=0.6, y=0.1),\n",
    "    width=800, height=600\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.5 Plotly로 PR 곡선 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall 곡선 비교\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, (name, y_proba) in enumerate(all_models.items()):\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "    ap = average_precision_score(y_test, y_proba)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=recall, y=precision,\n",
    "        mode='lines',\n",
    "        name=f\"{name} (AP={ap:.3f})\",\n",
    "        line=dict(color=colors[i % len(colors)], width=2)\n",
    "    ))\n",
    "\n",
    "# 베이스라인 (랜덤)\n",
    "baseline = y_test.mean()\n",
    "fig.add_hline(y=baseline, line_dash=\"dash\", line_color=\"gray\",\n",
    "              annotation_text=f\"Baseline ({baseline:.2%})\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Precision-Recall Curves - 모델 비교\",\n",
    "    xaxis_title=\"Recall\",\n",
    "    yaxis_title=\"Precision\",\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(x=0.02, y=0.3),\n",
    "    width=800, height=600\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n불균형 데이터에서는 PR 곡선이 ROC보다 더 유용합니다!\")\n",
    "print(\"AP (Average Precision)가 높을수록 좋은 모델입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.6 최종 모델 성능 종합 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 모델 성능 비교\n",
    "final_models = {\n",
    "    'Logistic Regression': (y_pred_lr, y_proba_lr),\n",
    "    'KNN': (y_pred_knn, y_proba_knn),\n",
    "    'Naive Bayes': (y_pred_nb, y_proba_nb),\n",
    "    'SVM': (y_pred_svm, y_proba_svm),\n",
    "    'Decision Tree': (y_pred_dt, y_proba_dt),\n",
    "    'Random Forest': (y_pred_rf, y_proba_rf),\n",
    "    'Gradient Boosting': (y_pred_gb, y_proba_gb),\n",
    "    'Voting': (y_pred_voting, y_proba_voting),\n",
    "    'Bagging': (y_pred_bagging, y_proba_bagging),\n",
    "    'AdaBoost': (y_pred_ada, y_proba_ada),\n",
    "    'Stacking': (y_pred_stacking, y_proba_stacking),\n",
    "    'LR (balanced)': (y_pred_balanced, y_proba_balanced),\n",
    "    'RF (balanced)': (y_pred_rf_balanced, y_proba_rf_balanced)\n",
    "}\n",
    "\n",
    "final_results = []\n",
    "for name, (y_pred, y_proba) in final_models.items():\n",
    "    final_results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'AUC': auc(*roc_curve(y_test, y_proba)[:2]),\n",
    "        'AP': average_precision_score(y_test, y_proba)\n",
    "    })\n",
    "\n",
    "df_final = pd.DataFrame(final_results).sort_values('F1', ascending=False)\n",
    "print(\"전체 모델 성능 비교 (F1 기준 정렬):\")\n",
    "print(df_final.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 성능 비교 히트맵\n",
    "df_heatmap = df_final.set_index('Model')[['Accuracy', 'Precision', 'Recall', 'F1', 'AUC', 'AP']]\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=df_heatmap.values,\n",
    "    x=df_heatmap.columns,\n",
    "    y=df_heatmap.index,\n",
    "    colorscale='RdYlGn',\n",
    "    text=df_heatmap.values.round(3),\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont={\"size\": 10}\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"모델별 성능 히트맵\",\n",
    "    xaxis_title=\"Metric\",\n",
    "    yaxis_title=\"Model\",\n",
    "    width=800, height=600\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 퀴즈\n",
    "\n",
    "**난이도**: ⭐ (쉬움) ~ ⭐⭐⭐⭐⭐ (어려움)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Logistic Regression 기본 훈련 ⭐\n",
    "\n",
    "**문제**: 아래 데이터로 Logistic Regression 모델을 훈련하고 정확도를 출력하세요.\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "```\n",
    "\n",
    "**기대 결과**: 테스트 정확도 출력 (test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. KNN 모델 K값 실험 ⭐\n",
    "\n",
    "**문제**: K=3, K=5, K=7로 KNN 모델을 훈련하고 각각의 정확도를 비교하세요.\n",
    "\n",
    "**기대 결과**: 각 K값에 대한 정확도 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 위의 breast_cancer 데이터 사용\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Decision Tree 특성 중요도 추출 ⭐⭐\n",
    "\n",
    "**문제**: Decision Tree를 훈련하고 상위 5개 중요 특성을 출력하세요.\n",
    "\n",
    "**기대 결과**: 특성 이름과 중요도 (내림차순)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "feature_names = data.feature_names\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Random Forest vs Decision Tree 비교 ⭐⭐\n",
    "\n",
    "**문제**: Random Forest (n_estimators=100)와 Decision Tree의 성능을 비교하세요.\n",
    "\n",
    "**기대 결과**: 두 모델의 정확도, F1 Score 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Confusion Matrix 계산 ⭐⭐\n",
    "\n",
    "**문제**: 사기 탐지 데이터에서 Random Forest의 Confusion Matrix를 출력하고 TP, FP, TN, FN을 해석하세요.\n",
    "\n",
    "**기대 결과**: Confusion Matrix + 각 값의 의미 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 앞서 훈련한 rf_model 사용\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Voting Classifier 구현 ⭐⭐⭐\n",
    "\n",
    "**문제**: LogisticRegression, RandomForest, GradientBoosting을 결합한 Soft Voting Classifier를 구현하세요.\n",
    "\n",
    "**기대 결과**: Voting Classifier의 정확도와 개별 모델 정확도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, GradientBoostingClassifier\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. class_weight 효과 분석 ⭐⭐⭐\n",
    "\n",
    "**문제**: 사기 탐지 데이터에서 class_weight 적용 전후의 Recall을 비교하세요.\n",
    "\n",
    "**기대 결과**: class_weight 없음 vs 'balanced'의 Recall 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. ROC 곡선 Plotly 시각화 ⭐⭐⭐\n",
    "\n",
    "**문제**: Logistic Regression과 Random Forest의 ROC 곡선을 Plotly로 시각화하세요.\n",
    "\n",
    "**기대 결과**: 두 모델의 ROC 곡선 + AUC 값 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. Stacking Ensemble 구현 ⭐⭐⭐⭐\n",
    "\n",
    "**문제**: 3개의 기본 모델과 메타 모델을 사용한 Stacking Classifier를 구현하세요.\n",
    "\n",
    "조건:\n",
    "- 기본 모델: KNN, Decision Tree, SVM\n",
    "- 메타 모델: Logistic Regression\n",
    "\n",
    "**기대 결과**: Stacking 모델의 정확도와 classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. 종합: 최적 분류 모델 파이프라인 ⭐⭐⭐⭐⭐\n",
    "\n",
    "**문제**: 사기 탐지 데이터에 대해 최적의 분류 파이프라인을 구축하세요.\n",
    "\n",
    "요구사항:\n",
    "1. 최소 3개 모델 비교\n",
    "2. 불균형 처리 기법 적용 (class_weight 또는 SMOTE)\n",
    "3. Plotly로 ROC 곡선과 PR 곡선 시각화\n",
    "4. 최종 추천 모델 선정 및 이유 설명\n",
    "\n",
    "**기대 결과**: 성능 비교표 + 시각화 + 추천 모델 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 학습 정리\n",
    "\n",
    "### Part 1: 기본 분류기 핵심 요약\n",
    "\n",
    "| 모델 | 장점 | 단점 | 사용 시점 |\n",
    "|------|------|------|----------|\n",
    "| Logistic Regression | 해석 가능, 빠름 | 비선형 패턴 약함 | 베이스라인, 해석 중요 |\n",
    "| KNN | 단순, 비모수 | 고차원 취약, 느림 | 소규모 데이터 |\n",
    "| Naive Bayes | 매우 빠름 | 독립 가정 | 텍스트 분류 |\n",
    "| SVM | 고차원 효과적 | 튜닝 필요, 느림 | 중소규모, 복잡한 경계 |\n",
    "\n",
    "### Part 2: 트리 기반 모델 핵심 요약\n",
    "\n",
    "| 모델 | 특징 | 과적합 방지 | 사용 시점 |\n",
    "|------|------|------------|----------|\n",
    "| Decision Tree | 해석 가능, 규칙 추출 | max_depth, min_samples | 규칙 기반 의사결정 |\n",
    "| Random Forest | 안정적, 병렬 처리 | 배깅 앙상블 | 대부분의 정형 데이터 |\n",
    "| Gradient Boosting | 높은 성능 | 학습률, 정규화 | 최고 성능 필요시 |\n",
    "\n",
    "### Part 3: 앙상블 기법 핵심 요약\n",
    "\n",
    "| 기법 | 원리 | 장점 | 적용 |\n",
    "|------|------|------|------|\n",
    "| Voting | 다수결/확률 평균 | 단순, 효과적 | 다양한 모델 결합 |\n",
    "| Bagging | 부트스트랩 앙상블 | 분산 감소 | 과적합 방지 |\n",
    "| Boosting | 순차 오차 학습 | 편향 감소 | 높은 성능 |\n",
    "| Stacking | 메타 모델 결합 | 최고 성능 | Kaggle 대회 |\n",
    "\n",
    "### Part 4: 불균형 데이터 핵심 요약\n",
    "\n",
    "| 기법 | 방식 | 장점 | 주의점 |\n",
    "|------|------|------|--------|\n",
    "| class_weight | 가중치 조정 | 간단, 빠름 | 모델 내장 필요 |\n",
    "| SMOTE | 오버샘플링 | 효과적 | 노이즈 생성 가능 |\n",
    "| 언더샘플링 | 다수 클래스 축소 | 빠름 | 정보 손실 |\n",
    "| 임계값 조정 | 결정 경계 이동 | 유연함 | 최적 임계값 탐색 |\n",
    "\n",
    "### 실무 팁\n",
    "\n",
    "1. **베이스라인 먼저**: Logistic Regression으로 시작, 점진적 복잡화\n",
    "2. **트리 기반 모델 추천**: Random Forest/GradientBoosting이 대부분 잘 작동\n",
    "3. **앙상블은 마지막**: 개별 모델 최적화 후 앙상블 시도\n",
    "4. **불균형 = Recall 중시**: 사기/질병 탐지에서 FN 비용 > FP 비용\n",
    "5. **PR 곡선 사용**: 불균형 데이터에서 ROC보다 PR 곡선이 유용\n",
    "6. **교차 검증 필수**: 단일 split 결과 신뢰 금지\n",
    "7. **특성 중요도 활용**: 모델 해석 및 특성 선택에 활용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
