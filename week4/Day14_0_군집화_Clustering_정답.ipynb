{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day14_0: êµ°ì§‘í™” (Clustering) - ì •ë‹µ ë…¸íŠ¸ë¶\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ Day14_0 ì‹¤ìŠµ í€´ì¦ˆì˜ ì •ë‹µê³¼ ìƒì„¸ í’€ì´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì¤€ë¹„ (ë¬¸ì œ ë…¸íŠ¸ë¶ê³¼ ë™ì¼)\n",
    "np.random.seed(42)\n",
    "n_customers = 500\n",
    "\n",
    "group1 = np.random.multivariate_normal([30, 20], [[50, 10], [10, 100]], 125)\n",
    "group2 = np.random.multivariate_normal([30, 80], [[50, 10], [10, 100]], 125)\n",
    "group3 = np.random.multivariate_normal([80, 20], [[50, 10], [10, 100]], 125)\n",
    "group4 = np.random.multivariate_normal([80, 80], [[50, 10], [10, 100]], 125)\n",
    "\n",
    "customer_data = np.vstack([group1, group2, group3, group4])\n",
    "customer_data = np.clip(customer_data, 1, 100)\n",
    "\n",
    "df_customers = pd.DataFrame({\n",
    "    'CustomerID': range(1, n_customers + 1),\n",
    "    'Annual_Income': customer_data[:, 0].astype(int),\n",
    "    'Spending_Score': customer_data[:, 1].astype(int)\n",
    "})\n",
    "df_customers['Age'] = np.random.randint(18, 70, n_customers)\n",
    "df_customers['Visit_Frequency'] = np.random.randint(1, 30, n_customers)\n",
    "\n",
    "X = df_customers[['Annual_Income', 'Spending_Score']].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(f\"ë°ì´í„° í¬ê¸°: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q1. K-Means ê¸°ë³¸ â­\n",
    "\n",
    "**ë¬¸ì œ**: K=3ìœ¼ë¡œ K-Meansë¥¼ ìˆ˜í–‰í•˜ê³  ê° êµ°ì§‘ì˜ ìƒ˜í”Œ ìˆ˜ë¥¼ ì¶œë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# K=3ìœ¼ë¡œ K-Means ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
    "kmeans_q1 = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "labels_q1 = kmeans_q1.fit_predict(X_scaled)\n",
    "\n",
    "# ê° êµ°ì§‘ì˜ ìƒ˜í”Œ ìˆ˜ ì¶œë ¥\n",
    "print(\"=== K=3 K-Means êµ°ì§‘ë³„ ìƒ˜í”Œ ìˆ˜ ===\")\n",
    "for cluster in range(3):\n",
    "    count = (labels_q1 == cluster).sum()\n",
    "    print(f\"êµ°ì§‘ {cluster}: {count}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert len(set(labels_q1)) == 3, \"êµ°ì§‘ ìˆ˜ê°€ 3ì´ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert len(labels_q1) == 500, \"ëª¨ë“  ìƒ˜í”Œì´ í• ë‹¹ë˜ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- KMeans(n_clusters=3)ìœ¼ë¡œ 3ê°œ êµ°ì§‘ ì§€ì •\n",
    "- fit_predict()ë¡œ í•™ìŠµê³¼ ë ˆì´ë¸” ì˜ˆì¸¡ ë™ì‹œ ìˆ˜í–‰\n",
    "- ë ˆì´ë¸” ë°°ì—´ì—ì„œ ê° ê°’ì˜ ê°œìˆ˜ ì¹´ìš´íŠ¸\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- n_clusters: ìƒì„±í•  êµ°ì§‘ ìˆ˜\n",
    "- random_state: ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ\n",
    "- n_init: ì´ˆê¸°í™” ë°˜ë³µ íšŸìˆ˜ (ë” ì•ˆì •ì ì¸ ê²°ê³¼)\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "```python\n",
    "# pd.Seriesë¡œ ì¹´ìš´íŠ¸\n",
    "pd.Series(labels_q1).value_counts().sort_index()\n",
    "\n",
    "# np.uniqueë¡œ ì¹´ìš´íŠ¸\n",
    "unique, counts = np.unique(labels_q1, return_counts=True)\n",
    "dict(zip(unique, counts))\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ìŠ¤ì¼€ì¼ë§ ì•ˆ í•¨ (ê±°ë¦¬ ê¸°ë°˜ì´ë¯€ë¡œ í•„ìˆ˜)\n",
    "- random_state ë¯¸ì§€ì • (ê²°ê³¼ ì¬í˜„ ë¶ˆê°€)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q2. Inertia ê³„ì‚° â­\n",
    "\n",
    "**ë¬¸ì œ**: K=5ì¸ K-Meansì˜ inertia ê°’ì„ ì¶œë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "# K=5ë¡œ K-Means ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
    "kmeans_q2 = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "kmeans_q2.fit(X_scaled)\n",
    "\n",
    "# Inertia ì¶œë ¥\n",
    "print(f\"K=5 K-Means Inertia: {kmeans_q2.inertia_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert hasattr(kmeans_q2, 'inertia_'), \"ëª¨ë¸ì´ í•™ìŠµë˜ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert kmeans_q2.inertia_ > 0, \"InertiaëŠ” ì–‘ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- K-Means ëª¨ë¸ í•™ìŠµ í›„ inertia_ ì†ì„± ì ‘ê·¼\n",
    "- Inertia = ê° ìƒ˜í”Œê³¼ í•´ë‹¹ êµ°ì§‘ ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬ì˜ ì œê³±í•©\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- Inertia (Within-Cluster Sum of Squares)\n",
    "- ê°’ì´ ì‘ì„ìˆ˜ë¡ êµ°ì§‘ì´ ì¡°ë°€í•¨\n",
    "- Kê°€ ì¦ê°€í•˜ë©´ í•­ìƒ ê°ì†Œ (ê³¼ì í•© ì£¼ì˜)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- Inertia ë‹¨ë…ìœ¼ë¡œëŠ” ìµœì  K ê²°ì • ì–´ë ¤ì›€\n",
    "- Elbow Methodì™€ í•¨ê»˜ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q3. Silhouette Score â­â­\n",
    "\n",
    "**ë¬¸ì œ**: K=4ì¸ K-Meansì˜ Silhouette Scoreë¥¼ ê³„ì‚°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# K=4ë¡œ K-Means ìˆ˜í–‰\n",
    "kmeans_q3 = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "labels_q3 = kmeans_q3.fit_predict(X_scaled)\n",
    "\n",
    "# Silhouette Score ê³„ì‚°\n",
    "sil_score_q3 = silhouette_score(X_scaled, labels_q3)\n",
    "\n",
    "print(f\"K=4 K-Means Silhouette Score: {sil_score_q3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert -1 <= sil_score_q3 <= 1, \"Silhouette ScoreëŠ” -1~1 ë²”ìœ„\"\n",
    "assert sil_score_q3 > 0.3, \"ì¢‹ì€ êµ°ì§‘í™”ëŠ” 0.3 ì´ìƒ\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- êµ°ì§‘í™” ìˆ˜í–‰ í›„ silhouette_score() í•¨ìˆ˜ ì‚¬ìš©\n",
    "- ì…ë ¥: ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„°ì™€ ë ˆì´ë¸”\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- Silhouette Score = (b - a) / max(a, b)\n",
    "- a: ê°™ì€ êµ°ì§‘ ë‚´ í‰ê·  ê±°ë¦¬\n",
    "- b: ê°€ì¥ ê°€ê¹Œìš´ ë‹¤ë¥¸ êµ°ì§‘ê³¼ì˜ í‰ê·  ê±°ë¦¬\n",
    "- ë²”ìœ„: -1 ~ 1 (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)\n",
    "\n",
    "**í•´ì„ ê¸°ì¤€**:\n",
    "- 0.7~1.0: ê°•í•œ êµ¬ì¡°\n",
    "- 0.5~0.7: í•©ë¦¬ì  êµ¬ì¡°\n",
    "- 0.25~0.5: ì•½í•œ êµ¬ì¡°\n",
    "- < 0.25: êµ¬ì¡° ì—†ìŒ ë˜ëŠ” ì˜ëª»ëœ êµ°ì§‘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q4. Elbow Plot ê·¸ë¦¬ê¸° â­â­\n",
    "\n",
    "**ë¬¸ì œ**: K=1~10ì— ëŒ€í•´ inertiaë¥¼ ê³„ì‚°í•˜ê³  px.line()ìœ¼ë¡œ Elbow Plotì„ ê·¸ë¦¬ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "# K=1~10ì— ëŒ€í•´ Inertia ê³„ì‚°\n",
    "K_range = range(1, 11)\n",
    "inertias = []\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans_temp.fit(X_scaled)\n",
    "    inertias.append(kmeans_temp.inertia_)\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ì •ë¦¬\n",
    "elbow_df = pd.DataFrame({\n",
    "    'K': list(K_range),\n",
    "    'Inertia': inertias\n",
    "})\n",
    "\n",
    "# Elbow Plot\n",
    "fig = px.line(elbow_df, x='K', y='Inertia', markers=True,\n",
    "              title='Elbow Method: ìµœì  êµ°ì§‘ ìˆ˜ ì°¾ê¸°')\n",
    "fig.update_layout(xaxis_title='êµ°ì§‘ ìˆ˜ (K)', yaxis_title='Inertia')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert len(inertias) == 10, \"K=1~10 ëª¨ë‘ ê³„ì‚°í•´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert inertias[0] > inertias[-1], \"Kê°€ ì¦ê°€í•˜ë©´ InertiaëŠ” ê°ì†Œ\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")\n",
    "print(f\"\\nKë³„ Inertia:\\n{elbow_df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- for ë£¨í”„ë¡œ K=1~10 ê°ê°ì— ëŒ€í•´ K-Means í•™ìŠµ\n",
    "- ê° ëª¨ë¸ì˜ inertia_ ê°’ ì €ì¥\n",
    "- px.line()ìœ¼ë¡œ êº¾ì€ì„  ê·¸ë˜í”„ ìƒì„±\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- Elbow Method: Inertia ê°ì†Œìœ¨ì´ ê¸‰ê²©íˆ ì¤„ì–´ë“œëŠ” ì§€ì \n",
    "- \"íŒ”ê¿ˆì¹˜\" í˜•íƒœì˜ êº¾ì´ëŠ” ì§€ì ì´ ìµœì  K\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "```python\n",
    "# ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜\n",
    "inertias = [KMeans(n_clusters=k, random_state=42).fit(X_scaled).inertia_ \n",
    "            for k in range(1, 11)]\n",
    "```\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- Elbowê°€ ëª…í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ\n",
    "- Silhouette Scoreì™€ í•¨ê»˜ ì‚¬ìš© ê¶Œì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q5. êµ°ì§‘ ì‹œê°í™” â­â­\n",
    "\n",
    "**ë¬¸ì œ**: K=4 êµ°ì§‘ ê²°ê³¼ë¥¼ px.scatter()ë¡œ ì‹œê°í™”í•˜ì„¸ìš”. (color='Cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "# K=4 K-Means ìˆ˜í–‰\n",
    "kmeans_q5 = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "labels_q5 = kmeans_q5.fit_predict(X_scaled)\n",
    "\n",
    "# DataFrameì— êµ°ì§‘ ë ˆì´ë¸” ì¶”ê°€\n",
    "df_q5 = df_customers.copy()\n",
    "df_q5['Cluster'] = labels_q5.astype(str)  # ë¬¸ìì—´ë¡œ ë³€í™˜ (ë²”ì£¼í˜•)\n",
    "\n",
    "# px.scatterë¡œ ì‹œê°í™”\n",
    "fig = px.scatter(df_q5, x='Annual_Income', y='Spending_Score',\n",
    "                 color='Cluster',\n",
    "                 title='K-Means êµ°ì§‘í™” ê²°ê³¼ (K=4)',\n",
    "                 labels={'Annual_Income': 'ì—°ê°„ ì†Œë“', 'Spending_Score': 'ì†Œë¹„ ì ìˆ˜'},\n",
    "                 color_discrete_sequence=px.colors.qualitative.Set1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert 'Cluster' in df_q5.columns, \"Cluster ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert df_q5['Cluster'].nunique() == 4, \"4ê°œ êµ°ì§‘ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- êµ°ì§‘í™” ê²°ê³¼(ë ˆì´ë¸”)ë¥¼ DataFrameì— ì¶”ê°€\n",
    "- color íŒŒë¼ë¯¸í„°ë¡œ êµ°ì§‘ë³„ ìƒ‰ìƒ êµ¬ë¶„\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ë ˆì´ë¸”ì„ ë¬¸ìì—´ë¡œ ë³€í™˜: ë²”ì£¼í˜•ìœ¼ë¡œ ì¸ì‹\n",
    "- color_discrete_sequence: ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì§€ì •\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "```python\n",
    "# go.Scatterë¡œ ë” ì„¸ë°€í•œ ì œì–´\n",
    "fig = go.Figure()\n",
    "for cluster in range(4):\n",
    "    mask = labels_q5 == cluster\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_q5.loc[mask, 'Annual_Income'],\n",
    "        y=df_q5.loc[mask, 'Spending_Score'],\n",
    "        mode='markers', name=f'êµ°ì§‘ {cluster}'\n",
    "    ))\n",
    "```\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- hover_dataë¡œ ì¶”ê°€ ì •ë³´ í‘œì‹œ\n",
    "- ì¤‘ì‹¬ì ë„ í•¨ê»˜ í‘œì‹œí•˜ë©´ í•´ì„ ìš©ì´"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q6. DBSCAN ì ìš© â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: eps=0.3, min_samples=5ë¡œ DBSCANì„ ìˆ˜í–‰í•˜ê³  êµ°ì§‘ ìˆ˜ì™€ ë…¸ì´ì¦ˆ ìˆ˜ë¥¼ ì¶œë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# DBSCAN ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
    "dbscan_q6 = DBSCAN(eps=0.3, min_samples=5)\n",
    "labels_q6 = dbscan_q6.fit_predict(X_scaled)\n",
    "\n",
    "# êµ°ì§‘ ìˆ˜ ê³„ì‚° (ë…¸ì´ì¦ˆ -1 ì œì™¸)\n",
    "n_clusters_q6 = len(set(labels_q6)) - (1 if -1 in labels_q6 else 0)\n",
    "\n",
    "# ë…¸ì´ì¦ˆ ìˆ˜ ê³„ì‚°\n",
    "n_noise_q6 = (labels_q6 == -1).sum()\n",
    "\n",
    "print(f\"ë°œê²¬ëœ êµ°ì§‘ ìˆ˜: {n_clusters_q6}\")\n",
    "print(f\"ë…¸ì´ì¦ˆ(ì´ìƒì¹˜) ìˆ˜: {n_noise_q6}\")\n",
    "print(f\"\\nêµ°ì§‘ë³„ ìƒ˜í”Œ ìˆ˜:\")\n",
    "for label in sorted(set(labels_q6)):\n",
    "    count = (labels_q6 == label).sum()\n",
    "    name = 'ë…¸ì´ì¦ˆ' if label == -1 else f'êµ°ì§‘ {label}'\n",
    "    print(f\"  {name}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert n_clusters_q6 >= 0, \"êµ°ì§‘ ìˆ˜ëŠ” 0 ì´ìƒ\"\n",
    "assert n_noise_q6 >= 0, \"ë…¸ì´ì¦ˆ ìˆ˜ëŠ” 0 ì´ìƒ\"\n",
    "assert len(labels_q6) == 500, \"ëª¨ë“  ìƒ˜í”Œì´ í• ë‹¹ë˜ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- DBSCAN(eps, min_samples)ë¡œ ëª¨ë¸ ìƒì„±\n",
    "- ë ˆì´ë¸”ì—ì„œ -1ì€ ë…¸ì´ì¦ˆ\n",
    "- set()ìœ¼ë¡œ ê³ ìœ  ë ˆì´ë¸” ì¶”ì¶œ í›„ -1 ì œì™¸\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- eps: ì´ì›ƒ ë°˜ê²½ (epsilon)\n",
    "- min_samples: í•µì‹¬ì (core point)ì´ ë˜ê¸° ìœ„í•œ ìµœì†Œ ì´ì›ƒ ìˆ˜\n",
    "- ë ˆì´ë¸” -1: ì–´ëŠ êµ°ì§‘ì—ë„ ì†í•˜ì§€ ì•ŠëŠ” ë…¸ì´ì¦ˆ\n",
    "\n",
    "**íŒŒë¼ë¯¸í„° íŠœë‹ íŒ**:\n",
    "- epsê°€ ë„ˆë¬´ ì‘ìœ¼ë©´: ëª¨ë“  ì ì´ ë…¸ì´ì¦ˆ\n",
    "- epsê°€ ë„ˆë¬´ í¬ë©´: ëª¨ë“  ì ì´ í•˜ë‚˜ì˜ êµ°ì§‘\n",
    "- k-distance plotìœ¼ë¡œ ìµœì  eps íƒìƒ‰\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ë…¸ì´ì¦ˆ(-1)ë¥¼ êµ°ì§‘ìœ¼ë¡œ ì¹´ìš´íŠ¸\n",
    "- ìŠ¤ì¼€ì¼ë§ ì•ˆ í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q7. ê³„ì¸µì  êµ°ì§‘í™” â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Ward linkageë¡œ 4ê°œ êµ°ì§‘ì˜ ê³„ì¸µì  êµ°ì§‘í™”ë¥¼ ìˆ˜í–‰í•˜ê³  Silhouette Scoreë¥¼ ê³„ì‚°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# ê³„ì¸µì  êµ°ì§‘í™” ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
    "hierarchical_q7 = AgglomerativeClustering(\n",
    "    n_clusters=4, \n",
    "    linkage='ward'  # Ward ë°©ë²•: ë¶„ì‚° ìµœì†Œí™”\n",
    ")\n",
    "labels_q7 = hierarchical_q7.fit_predict(X_scaled)\n",
    "\n",
    "# Silhouette Score ê³„ì‚°\n",
    "sil_score_q7 = silhouette_score(X_scaled, labels_q7)\n",
    "\n",
    "print(f\"ê³„ì¸µì  êµ°ì§‘í™” (Ward, K=4) Silhouette Score: {sil_score_q7:.4f}\")\n",
    "print(f\"\\nêµ°ì§‘ë³„ ìƒ˜í”Œ ìˆ˜:\")\n",
    "for cluster in range(4):\n",
    "    count = (labels_q7 == cluster).sum()\n",
    "    print(f\"  êµ°ì§‘ {cluster}: {count}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert len(set(labels_q7)) == 4, \"4ê°œ êµ°ì§‘ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert -1 <= sil_score_q7 <= 1, \"Silhouette Score ë²”ìœ„ í™•ì¸\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- AgglomerativeClusteringìœ¼ë¡œ ë³‘í•© êµ°ì§‘í™”\n",
    "- linkage='ward': ë¶„ì‚° ì¦ê°€ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©ì‹\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ê³„ì¸µì  êµ°ì§‘í™”: ìƒí–¥ì‹(Agglomerative) ë˜ëŠ” í•˜í–¥ì‹(Divisive)\n",
    "- Linkage ë°©ë²•:\n",
    "  - single: ìµœì†Œ ê±°ë¦¬\n",
    "  - complete: ìµœëŒ€ ê±°ë¦¬\n",
    "  - average: í‰ê·  ê±°ë¦¬\n",
    "  - ward: ë¶„ì‚° ìµœì†Œí™” (ê°€ì¥ ë§ì´ ì‚¬ìš©)\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "```python\n",
    "# scipyë¡œ dendrogram ê·¸ë¦¬ê¸°\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "Z = linkage(X_scaled, method='ward')\n",
    "dendrogram(Z)\n",
    "```\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ëŠ” ëŠë¦¼ (O(n^2) ë˜ëŠ” O(n^3))\n",
    "- ìƒ˜í”Œë§ í›„ ì‚¬ìš© ê¶Œì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q8. GMM í™•ë¥  ë¶„ì„ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: 4ê°œ ì»´í¬ë„ŒíŠ¸ì˜ GMMì„ í•™ìŠµí•˜ê³ , ê°€ì¥ ë¶ˆí™•ì‹¤í•œ ìƒ˜í”Œ 5ê°œ(ìµœëŒ€ í™•ë¥ ì´ ê°€ì¥ ë‚®ì€)ë¥¼ ì°¾ìœ¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# GMM ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
    "gmm_q8 = GaussianMixture(n_components=4, random_state=42)\n",
    "gmm_q8.fit(X_scaled)\n",
    "\n",
    "# ê° ìƒ˜í”Œì˜ êµ°ì§‘ ì†Œì† í™•ë¥ \n",
    "probs_q8 = gmm_q8.predict_proba(X_scaled)\n",
    "\n",
    "# ê° ìƒ˜í”Œì˜ ìµœëŒ€ í™•ë¥  (ê°€ì¥ í™•ì‹ ìˆëŠ” êµ°ì§‘ì— ì†í•  í™•ë¥ )\n",
    "max_probs = probs_q8.max(axis=1)\n",
    "\n",
    "# ìµœëŒ€ í™•ë¥ ì´ ê°€ì¥ ë‚®ì€ 5ê°œ ìƒ˜í”Œ (ê°€ì¥ ë¶ˆí™•ì‹¤í•œ ìƒ˜í”Œ)\n",
    "uncertain_indices = max_probs.argsort()[:5]\n",
    "\n",
    "print(\"=== ê°€ì¥ ë¶ˆí™•ì‹¤í•œ ìƒ˜í”Œ TOP 5 ===\")\n",
    "for rank, idx in enumerate(uncertain_indices, 1):\n",
    "    print(f\"\\n{rank}. ìƒ˜í”Œ {idx}\")\n",
    "    print(f\"   ì†Œë“: {df_customers.loc[idx, 'Annual_Income']}, ì†Œë¹„ì ìˆ˜: {df_customers.loc[idx, 'Spending_Score']}\")\n",
    "    print(f\"   ìµœëŒ€ í™•ë¥ : {max_probs[idx]:.4f}\")\n",
    "    print(f\"   ê° êµ°ì§‘ í™•ë¥ : {probs_q8[idx].round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert probs_q8.shape == (500, 4), \"í™•ë¥  í–‰ë ¬ í¬ê¸° í™•ì¸\"\n",
    "assert len(uncertain_indices) == 5, \"5ê°œ ìƒ˜í”Œ ì¶”ì¶œ\"\n",
    "assert max_probs[uncertain_indices[0]] <= max_probs[uncertain_indices[-1]], \"ì •ë ¬ í™•ì¸\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- GMMì˜ predict_proba()ë¡œ ì†Œì† í™•ë¥  íšë“\n",
    "- ê° í–‰ì—ì„œ ìµœëŒ€ê°’ = ê°€ì¥ í™•ì‹  ìˆëŠ” êµ°ì§‘ í™•ë¥ \n",
    "- argsort()ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ í›„ ì• 5ê°œ ì„ íƒ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- GMMì€ ì†Œí”„íŠ¸ í´ëŸ¬ìŠ¤í„°ë§: í™•ë¥  ê¸°ë°˜ í• ë‹¹\n",
    "- ìµœëŒ€ í™•ë¥ ì´ ë‚®ìŒ = ê²½ê³„ì— ìˆëŠ” ìƒ˜í”Œ\n",
    "- ë¶ˆí™•ì‹¤í•œ ìƒ˜í”Œ = ì—¬ëŸ¬ êµ°ì§‘ì— ê±¸ì³ ìˆìŒ\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "```python\n",
    "# DataFrameìœ¼ë¡œ ì •ë¦¬\n",
    "df_probs = pd.DataFrame(probs_q8, columns=[f'êµ°ì§‘{i}' for i in range(4)])\n",
    "df_probs['max_prob'] = df_probs.max(axis=1)\n",
    "df_probs.nsmallest(5, 'max_prob')\n",
    "```\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë¶ˆí™•ì‹¤í•œ ìƒ˜í”Œì€ ì¶”ê°€ ì¡°ì‚¬ í•„ìš”\n",
    "- ë§ˆì¼€íŒ…ì—ì„œ íƒ€ê²ŸíŒ… ì‹ ì¤‘íˆ ì ‘ê·¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q9. ìµœì  K íƒìƒ‰ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: K=2~8ì— ëŒ€í•´ Silhouette Scoreë¥¼ ê³„ì‚°í•˜ê³ , ìµœì  Kë¥¼ ì°¾ì•„ ì‹œê°í™”í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "# K=2~8ì— ëŒ€í•´ Silhouette Score ê³„ì‚°\n",
    "K_range_q9 = range(2, 9)\n",
    "silhouette_scores_q9 = []\n",
    "\n",
    "for k in K_range_q9:\n",
    "    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels_temp = kmeans_temp.fit_predict(X_scaled)\n",
    "    score = silhouette_score(X_scaled, labels_temp)\n",
    "    silhouette_scores_q9.append(score)\n",
    "    print(f\"K={k}: Silhouette = {score:.4f}\")\n",
    "\n",
    "# ìµœì  K ì°¾ê¸°\n",
    "best_k = list(K_range_q9)[np.argmax(silhouette_scores_q9)]\n",
    "best_score = max(silhouette_scores_q9)\n",
    "\n",
    "print(f\"\\nìµœì  K: {best_k} (Silhouette = {best_score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "fig = px.bar(x=list(K_range_q9), y=silhouette_scores_q9,\n",
    "             title='Kë³„ Silhouette Score (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)',\n",
    "             labels={'x': 'êµ°ì§‘ ìˆ˜ (K)', 'y': 'Silhouette Score'},\n",
    "             color=silhouette_scores_q9,\n",
    "             color_continuous_scale='viridis')\n",
    "\n",
    "# ìµœì  K ê°•ì¡°\n",
    "fig.add_annotation(x=best_k, y=best_score,\n",
    "                   text=f\"ìµœì  K={best_k}\",\n",
    "                   showarrow=True, arrowhead=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert len(silhouette_scores_q9) == 7, \"K=2~8 ì´ 7ê°œ\"\n",
    "assert 2 <= best_k <= 8, \"ìµœì  KëŠ” ë²”ìœ„ ë‚´\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- for ë£¨í”„ë¡œ ê° Kì— ëŒ€í•´ êµ°ì§‘í™” ë° í‰ê°€\n",
    "- argmax()ë¡œ ìµœê³  ì ìˆ˜ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°\n",
    "- px.bar()ë¡œ ë¹„êµ ì‹œê°í™”\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- Silhouette Scoreê°€ ê°€ì¥ ë†’ì€ Kê°€ ìµœì \n",
    "- ë‹¨, ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„ ê°€ëŠ¥ì„±ë„ ê³ ë ¤\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "```python\n",
    "# Elbow + Silhouette ë™ì‹œ ë¹„êµ\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "fig.add_trace(go.Scatter(x=list(K_range), y=inertias), row=1, col=1)\n",
    "fig.add_trace(go.Bar(x=list(K_range), y=silhouettes), row=1, col=2)\n",
    "```\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ìµœì  Kê°€ ì—¬ëŸ¬ ê°œì¼ ìˆ˜ ìˆìŒ\n",
    "- ë„ë©”ì¸ ì§€ì‹ê³¼ í•¨ê»˜ ê²°ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q10. ê³ ê° ì„¸ë¶„í™” ì¢…í•© â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: \n",
    "1. K-Means (K=4)ë¡œ ê³ ê°ì„ ì„¸ë¶„í™”í•˜ê³ \n",
    "2. ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ í‰ê·  ì†Œë“, ì†Œë¹„ì ìˆ˜, ê³ ê° ìˆ˜ë¥¼ DataFrameìœ¼ë¡œ ì •ë¦¬í•˜ê³ \n",
    "3. px.scatter()ë¡œ ì„¸ê·¸ë¨¼íŠ¸ë³„ ì‹œê°í™”ë¥¼ ì™„ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# 1. K-Means (K=4)ë¡œ ê³ ê° ì„¸ë¶„í™”\n",
    "kmeans_q10 = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "labels_q10 = kmeans_q10.fit_predict(X_scaled)\n",
    "\n",
    "# DataFrameì— ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€\n",
    "df_q10 = df_customers.copy()\n",
    "df_q10['Segment'] = labels_q10\n",
    "\n",
    "# 2. ì„¸ê·¸ë¨¼íŠ¸ë³„ í†µê³„ DataFrame\n",
    "segment_stats = df_q10.groupby('Segment').agg({\n",
    "    'Annual_Income': 'mean',\n",
    "    'Spending_Score': 'mean',\n",
    "    'CustomerID': 'count'\n",
    "}).round(1)\n",
    "\n",
    "segment_stats.columns = ['í‰ê·  ì†Œë“', 'í‰ê·  ì†Œë¹„ì ìˆ˜', 'ê³ ê° ìˆ˜']\n",
    "\n",
    "# ì„¸ê·¸ë¨¼íŠ¸ ì´ë¦„ ë¶€ì—¬\n",
    "segment_names_q10 = {}\n",
    "for idx, row in segment_stats.iterrows():\n",
    "    income = 'ê³ ì†Œë“' if row['í‰ê·  ì†Œë“'] > 50 else 'ì €ì†Œë“'\n",
    "    spending = 'ê³ ì†Œë¹„' if row['í‰ê·  ì†Œë¹„ì ìˆ˜'] > 50 else 'ì €ì†Œë¹„'\n",
    "    segment_names_q10[idx] = f\"{income}-{spending}\"\n",
    "\n",
    "segment_stats['ì„¸ê·¸ë¨¼íŠ¸ëª…'] = segment_stats.index.map(segment_names_q10)\n",
    "\n",
    "print(\"=== ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ ê²°ê³¼ ===\")\n",
    "print(segment_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. px.scatter()ë¡œ ì„¸ê·¸ë¨¼íŠ¸ë³„ ì‹œê°í™”\n",
    "df_q10['Segment_Name'] = df_q10['Segment'].map(segment_names_q10)\n",
    "\n",
    "fig = px.scatter(df_q10, x='Annual_Income', y='Spending_Score',\n",
    "                 color='Segment_Name',\n",
    "                 title='ê³ ê° ì„¸ë¶„í™” ê²°ê³¼ (K-Means, K=4)',\n",
    "                 labels={'Annual_Income': 'ì—°ê°„ ì†Œë“ (ì²œë§Œì›)',\n",
    "                        'Spending_Score': 'ì†Œë¹„ ì ìˆ˜',\n",
    "                        'Segment_Name': 'ì„¸ê·¸ë¨¼íŠ¸'},\n",
    "                 hover_data=['CustomerID', 'Age'],\n",
    "                 color_discrete_sequence=px.colors.qualitative.Bold,\n",
    "                 opacity=0.7)\n",
    "\n",
    "# ì¤‘ì‹¬ì  ì¶”ê°€\n",
    "centers_orig_q10 = scaler.inverse_transform(kmeans_q10.cluster_centers_)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=centers_orig_q10[:, 0], y=centers_orig_q10[:, 1],\n",
    "    mode='markers+text',\n",
    "    marker=dict(symbol='x', size=20, color='black', line=dict(width=2)),\n",
    "    text=[f'C{i}' for i in range(4)],\n",
    "    textposition='top center',\n",
    "    name='ì¤‘ì‹¬ì '\n",
    "))\n",
    "\n",
    "fig.update_layout(height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸/ê²€ì¦\n",
    "assert 'Segment' in df_q10.columns, \"Segment ì»¬ëŸ¼ í•„ìš”\"\n",
    "assert len(segment_stats) == 4, \"4ê°œ ì„¸ê·¸ë¨¼íŠ¸\"\n",
    "assert 'í‰ê·  ì†Œë“' in segment_stats.columns, \"í‰ê·  ì†Œë“ ì»¬ëŸ¼ í•„ìš”\"\n",
    "assert 'í‰ê·  ì†Œë¹„ì ìˆ˜' in segment_stats.columns, \"í‰ê·  ì†Œë¹„ì ìˆ˜ ì»¬ëŸ¼ í•„ìš”\"\n",
    "assert 'ê³ ê° ìˆ˜' in segment_stats.columns, \"ê³ ê° ìˆ˜ ì»¬ëŸ¼ í•„ìš”\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. K-Means í•™ìŠµ ë° ë ˆì´ë¸” í• ë‹¹\n",
    "2. groupby()ë¡œ ì„¸ê·¸ë¨¼íŠ¸ë³„ í†µê³„ ê³„ì‚°\n",
    "3. ì„¸ê·¸ë¨¼íŠ¸ íŠ¹ì„±ì— ë”°ë¥¸ ì´ë¦„ ë¶€ì—¬\n",
    "4. px.scatter()ë¡œ ìƒ‰ìƒ êµ¬ë¶„ ì‹œê°í™”\n",
    "5. ì¤‘ì‹¬ì  í‘œì‹œë¡œ í•´ì„ ìš©ì´ì„± í–¥ìƒ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ì„¸ë¶„í™”(Segmentation): ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ìˆ˜ë¦½ì˜ ê¸°ì´ˆ\n",
    "- í”„ë¡œíŒŒì¼ë§: ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ íŠ¹ì„± íŒŒì•…\n",
    "- ì‹œê°í™”: ê²°ê³¼ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì˜ í•µì‹¬\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "```python\n",
    "# ë‹¤ì°¨ì› ë¶„ì„ (3ê°œ ì´ìƒ íŠ¹ì„±)\n",
    "X_multi = df_customers[['Annual_Income', 'Spending_Score', 'Age', 'Visit_Frequency']]\n",
    "X_multi_scaled = StandardScaler().fit_transform(X_multi)\n",
    "# PCAë¡œ 2D ì¶•ì†Œ í›„ ì‹œê°í™”\n",
    "```\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ìŠ¤ì¼€ì¼ë§ ì „ ë°ì´í„°ë¡œ êµ°ì§‘í™”\n",
    "- ì¤‘ì‹¬ì ì„ ìŠ¤ì¼€ì¼ë§ ì—­ë³€í™˜ ì•ˆ í•¨\n",
    "- ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„ ì—†ì´ ìˆ«ìë§Œ ë‚˜ì—´\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì„¸ê·¸ë¨¼íŠ¸ë³„ ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½\n",
    "- ì£¼ê¸°ì ìœ¼ë¡œ ì¬êµ°ì§‘í™”í•˜ì—¬ ë³€í™” ì¶”ì \n",
    "- A/B í…ŒìŠ¤íŠ¸ë¡œ ì „ëµ íš¨ê³¼ ê²€ì¦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š í€´ì¦ˆ ë‚œì´ë„ ë¶„í¬ ìš”ì•½\n",
    "\n",
    "| ë‚œì´ë„ | í€´ì¦ˆ ë²ˆí˜¸ | ì£¼ìš” ê°œë… |\n",
    "|--------|----------|----------|\n",
    "| â­ | Q1, Q2 | K-Means ê¸°ë³¸, Inertia |\n",
    "| â­â­ | Q3, Q4, Q5 | Silhouette, Elbow Plot, ì‹œê°í™” |\n",
    "| â­â­â­ | Q6, Q7 | DBSCAN, ê³„ì¸µì  êµ°ì§‘í™” |\n",
    "| â­â­â­â­ | Q8, Q9 | GMM í™•ë¥ , ìµœì  K íƒìƒ‰ |\n",
    "| â­â­â­â­â­ | Q10 | ê³ ê° ì„¸ë¶„í™” ì¢…í•© í”„ë¡œì íŠ¸ |\n",
    "\n",
    "**ì´ 10ë¬¸ì œ**: 3-3-2-2 ë¶„í¬ ì¤€ìˆ˜"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
