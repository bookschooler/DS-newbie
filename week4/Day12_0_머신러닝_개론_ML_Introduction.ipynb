{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day12_0: 머신러닝 개론 (ML Introduction)\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "**Part 1: ML 기초 개념**\n",
    "1. 머신러닝의 정의와 종류 이해하기\n",
    "2. 지도학습 (Supervised Learning) 개념 이해하기\n",
    "3. 비지도학습 (Unsupervised Learning) 개념 이해하기\n",
    "4. 강화학습 (Reinforcement Learning) 소개\n",
    "5. 분류 vs 회귀 문제 구분하기\n",
    "\n",
    "**Part 2: ML 프로세스**\n",
    "1. ML 워크플로우 전체 이해하기\n",
    "2. 문제 정의와 데이터 준비 단계 이해하기\n",
    "3. 모델 선택과 훈련 과정 이해하기\n",
    "4. 평가와 배포 단계 이해하기\n",
    "\n",
    "**Part 3: scikit-learn 소개**\n",
    "1. scikit-learn 라이브러리 구조 이해하기\n",
    "2. estimator 인터페이스 (fit, predict, transform) 익히기\n",
    "3. 간단한 모델 훈련 실습하기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 왜 이것을 배우나요?\n",
    "\n",
    "| 개념 | 비즈니스 활용 | 실무 예시 |\n",
    "|------|-------------|----------|\n",
    "| 지도학습 | 예측/분류 자동화 | 고객 이탈 예측, 대출 승인 |\n",
    "| 비지도학습 | 패턴 발견 | 고객 세분화, 이상 탐지 |\n",
    "| ML 워크플로우 | 체계적 문제 해결 | Kaggle 대회, 실무 프로젝트 |\n",
    "| scikit-learn | 빠른 프로토타입 | 모델 실험, 성능 비교 |\n",
    "\n",
    "**분석가 관점**: Week 4 Kaggle 미니 대회를 위한 ML 기초! 비즈니스 문제를 데이터로 해결하는 첫걸음입니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: ML 기초 개념\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 머신러닝이란?\n",
    "\n",
    "### 정의\n",
    "\n",
    "**머신러닝(Machine Learning)**: 명시적으로 프로그래밍하지 않고, 데이터로부터 학습하여 패턴을 찾고 예측하는 알고리즘\n",
    "\n",
    "```\n",
    "전통적 프로그래밍: 데이터 + 규칙 -> 결과\n",
    "머신러닝:         데이터 + 결과 -> 규칙(모델)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'무료 이벤트 당첨!' -> 스팸\n",
      "'내일 회의 일정 안내' -> 정상\n",
      "'대출 상담 안내' -> 스팸\n"
     ]
    }
   ],
   "source": [
    "# 전통적 프로그래밍: 규칙을 직접 작성\n",
    "def is_spam_traditional(email_text):\n",
    "    \"\"\"규칙 기반 스팸 필터\"\"\"\n",
    "    spam_keywords = [\"무료\", \"당첨\", \"대출\", \"광고\"]\n",
    "    for keyword in spam_keywords:\n",
    "        if keyword in email_text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# 테스트\n",
    "emails = [\n",
    "    \"무료 이벤트 당첨!\",\n",
    "    \"내일 회의 일정 안내\",\n",
    "    \"대출 상담 안내\"\n",
    "]\n",
    "\n",
    "for email in emails:\n",
    "    result = \"스팸\" if is_spam_traditional(email) else \"정상\"\n",
    "    print(f\"'{email}' -> {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "머신러닝은 이 데이터에서 '스팸의 특징'을 스스로 학습합니다.\n",
      "학습 데이터: 4개\n"
     ]
    }
   ],
   "source": [
    "# 머신러닝 방식: 데이터로부터 규칙을 학습\n",
    "# (실제 모델 학습은 Part 3에서 진행)\n",
    "\n",
    "# 학습 데이터\n",
    "training_data = [\n",
    "    {\"text\": \"무료 경품 이벤트\", \"label\": \"spam\"},\n",
    "    {\"text\": \"회의 일정 변경\", \"label\": \"normal\"},\n",
    "    {\"text\": \"대출 한도 안내\", \"label\": \"spam\"},\n",
    "    {\"text\": \"프로젝트 진행 상황\", \"label\": \"normal\"},\n",
    "]\n",
    "\n",
    "print(\"머신러닝은 이 데이터에서 '스팸의 특징'을 스스로 학습합니다.\")\n",
    "print(f\"학습 데이터: {len(training_data)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실무 예시: 규칙 기반 vs ML 기반\n",
    "\n",
    "| 구분 | 규칙 기반 | ML 기반 |\n",
    "|------|----------|--------|\n",
    "| 스팸 필터 | 키워드 리스트 관리 | 스팸 패턴 자동 학습 |\n",
    "| 대출 심사 | 점수표 기반 | 과거 데이터에서 패턴 학습 |\n",
    "| 상품 추천 | 카테고리 매칭 | 구매 이력 기반 추천 |\n",
    "| 이상 탐지 | 임계값 설정 | 정상 패턴 학습 후 이탈 탐지 |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 머신러닝의 종류\n",
    "\n",
    "### 학습 방식에 따른 분류\n",
    "\n",
    "```\n",
    "머신러닝\n",
    "├── 지도학습 (Supervised Learning)\n",
    "│   ├── 분류 (Classification): 이산형 타겟\n",
    "│   └── 회귀 (Regression): 연속형 타겟\n",
    "├── 비지도학습 (Unsupervised Learning)\n",
    "│   ├── 클러스터링 (Clustering)\n",
    "│   └── 차원 축소 (Dimensionality Reduction)\n",
    "└── 강화학습 (Reinforcement Learning)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "지도학습 (Supervised)\n",
      "  특징: 정답(레이블)이 있는 데이터로 학습\n",
      "  예시: 스팸 분류, 집값 예측, 고객 이탈 예측\n",
      "  키워드: X -> y 예측\n",
      "\n",
      "비지도학습 (Unsupervised)\n",
      "  특징: 정답 없이 데이터의 패턴을 발견\n",
      "  예시: 고객 세분화, 이상 탐지, 토픽 모델링\n",
      "  키워드: 숨겨진 구조 발견\n",
      "\n",
      "강화학습 (Reinforcement)\n",
      "  특징: 환경과 상호작용하며 보상 최대화\n",
      "  예시: 게임 AI, 로봇 제어, 추천 시스템\n",
      "  키워드: 시행착오로 학습\n"
     ]
    }
   ],
   "source": [
    "# 머신러닝 종류 정리\n",
    "ml_types = {\n",
    "    \"지도학습 (Supervised)\": {\n",
    "        \"특징\": \"정답(레이블)이 있는 데이터로 학습\",\n",
    "        \"예시\": [\"스팸 분류\", \"집값 예측\", \"고객 이탈 예측\"],\n",
    "        \"키워드\": \"X -> y 예측\"\n",
    "    },\n",
    "    \"비지도학습 (Unsupervised)\": {\n",
    "        \"특징\": \"정답 없이 데이터의 패턴을 발견\",\n",
    "        \"예시\": [\"고객 세분화\", \"이상 탐지\", \"토픽 모델링\"],\n",
    "        \"키워드\": \"숨겨진 구조 발견\"\n",
    "    },\n",
    "    \"강화학습 (Reinforcement)\": {\n",
    "        \"특징\": \"환경과 상호작용하며 보상 최대화\",\n",
    "        \"예시\": [\"게임 AI\", \"로봇 제어\", \"추천 시스템\"],\n",
    "        \"키워드\": \"시행착오로 학습\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for ml_type, info in ml_types.items():\n",
    "    print(f\"\\n{ml_type}\")\n",
    "    print(f\"  특징: {info['특징']}\")\n",
    "    print(f\"  예시: {', '.join(info['예시'])}\")\n",
    "    print(f\"  키워드: {info['키워드']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 지도학습 (Supervised Learning)\n",
    "\n",
    "### 핵심 개념\n",
    "\n",
    "- **입력(X)**: 특성(feature), 독립변수\n",
    "- **출력(y)**: 타겟(target), 레이블, 종속변수\n",
    "- **목표**: X로부터 y를 예측하는 함수(모델) 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고객 이탈 예측 데이터:\n",
      "----------------------------------------------------------------------\n",
      "    나이     이용기간     월사용액     불만건수     이탈여부\n",
      "----------------------------------------------------------------------\n",
      "    25        6       50        3       이탈\n",
      "    45       36      100        0       유지\n",
      "    35       12       75        2       유지\n",
      "    28        3       45        5       이탈\n"
     ]
    }
   ],
   "source": [
    "# 지도학습 데이터 예시: 고객 이탈 예측\n",
    "customer_data = [\n",
    "    # 특성(X): 나이, 이용기간(월), 월 사용액, 불만건수\n",
    "    # 타겟(y): 이탈 여부 (0: 유지, 1: 이탈)\n",
    "    {\"age\": 25, \"tenure\": 6, \"monthly_charge\": 50, \"complaints\": 3, \"churned\": 1},\n",
    "    {\"age\": 45, \"tenure\": 36, \"monthly_charge\": 100, \"complaints\": 0, \"churned\": 0},\n",
    "    {\"age\": 35, \"tenure\": 12, \"monthly_charge\": 75, \"complaints\": 2, \"churned\": 0},\n",
    "    {\"age\": 28, \"tenure\": 3, \"monthly_charge\": 45, \"complaints\": 5, \"churned\": 1},\n",
    "]\n",
    "\n",
    "print(\"고객 이탈 예측 데이터:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'나이':>6} {'이용기간':>8} {'월사용액':>8} {'불만건수':>8} {'이탈여부':>8}\")\n",
    "print(\"-\" * 70)\n",
    "for c in customer_data:\n",
    "    churn_label = \"이탈\" if c['churned'] == 1 else \"유지\"\n",
    "    print(f\"{c['age']:>6} {c['tenure']:>8} {c['monthly_charge']:>8} {c['complaints']:>8} {churn_label:>8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 (Classification) vs 회귀 (Regression)\n",
    "\n",
    "| 구분 | 분류 | 회귀 |\n",
    "|------|-----|-----|\n",
    "| 타겟 | 이산형 (카테고리) | 연속형 (숫자) |\n",
    "| 예시 | 스팸/정상, 합격/불합격 | 집값, 매출액 |\n",
    "| 평가 | 정확도, F1, AUC | RMSE, MAE, R2 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류(Classification) 문제 예시:\n",
      "  - 이메일 스팸 분류: 스팸/정상 (2개 클래스)\n",
      "  - 고객 이탈 예측: 이탈/유지 (2개 클래스)\n",
      "  - 상품 카테고리 분류: 의류/전자/식품/... (다중 클래스)\n",
      "  - 대출 승인 여부: 승인/거절 (2개 클래스)\n"
     ]
    }
   ],
   "source": [
    "# 분류 문제 예시\n",
    "classification_examples = [\n",
    "    {\"문제\": \"이메일 스팸 분류\", \"타겟\": \"스팸/정상 (2개 클래스)\"},\n",
    "    {\"문제\": \"고객 이탈 예측\", \"타겟\": \"이탈/유지 (2개 클래스)\"},\n",
    "    {\"문제\": \"상품 카테고리 분류\", \"타겟\": \"의류/전자/식품/... (다중 클래스)\"},\n",
    "    {\"문제\": \"대출 승인 여부\", \"타겟\": \"승인/거절 (2개 클래스)\"},\n",
    "]\n",
    "\n",
    "print(\"분류(Classification) 문제 예시:\")\n",
    "for ex in classification_examples:\n",
    "    print(f\"  - {ex['문제']}: {ex['타겟']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회귀(Regression) 문제 예시:\n",
      "  - 주택 가격 예측: 가격 (원)\n",
      "  - 매출 예측: 매출액 (만원)\n",
      "  - 재고 수요 예측: 판매량 (개)\n",
      "  - 고객 생애 가치: LTV (원)\n"
     ]
    }
   ],
   "source": [
    "# 회귀 문제 예시\n",
    "regression_examples = [\n",
    "    {\"문제\": \"주택 가격 예측\", \"타겟\": \"가격 (원)\"},\n",
    "    {\"문제\": \"매출 예측\", \"타겟\": \"매출액 (만원)\"},\n",
    "    {\"문제\": \"재고 수요 예측\", \"타겟\": \"판매량 (개)\"},\n",
    "    {\"문제\": \"고객 생애 가치\", \"타겟\": \"LTV (원)\"},\n",
    "]\n",
    "\n",
    "print(\"회귀(Regression) 문제 예시:\")\n",
    "for ex in regression_examples:\n",
    "    print(f\"  - {ex['문제']}: {ex['타겟']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실무 예시: 문제 유형 판단하기\n",
    "\n",
    "**핵심 질문**: \"예측하려는 타겟이 카테고리인가, 숫자인가?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문제 유형 판단:\n",
      "  '고객 이탈 여부 예측' -> 분류 (Classification)\n",
      "  '다음 달 매출 금액 예측' -> 회귀 (Regression)\n",
      "  '상품 카테고리 분류' -> 분류 (Classification)\n",
      "  '부동산 가격 예측' -> 회귀 (Regression)\n",
      "  '대출 승인 여부' -> 분류 (Classification)\n"
     ]
    }
   ],
   "source": [
    "def classify_problem(target_description):\n",
    "    \"\"\"\n",
    "    타겟 설명을 보고 문제 유형 판단\n",
    "    \"\"\"\n",
    "    # 분류 키워드\n",
    "    classification_keywords = [\"여부\", \"분류\", \"종류\", \"카테고리\", \"예/아니오\", \"합격\", \"불합격\"]\n",
    "    \n",
    "    # 회귀 키워드  \n",
    "    regression_keywords = [\"가격\", \"금액\", \"개수\", \"량\", \"수량\", \"점수\", \"율\"]\n",
    "    \n",
    "    for kw in classification_keywords:\n",
    "        if kw in target_description:\n",
    "            return \"분류 (Classification)\"\n",
    "    \n",
    "    for kw in regression_keywords:\n",
    "        if kw in target_description:\n",
    "            return \"회귀 (Regression)\"\n",
    "    \n",
    "    return \"판단 필요\"\n",
    "\n",
    "# 테스트\n",
    "problems = [\n",
    "    \"고객 이탈 여부 예측\",\n",
    "    \"다음 달 매출 금액 예측\",\n",
    "    \"상품 카테고리 분류\",\n",
    "    \"부동산 가격 예측\",\n",
    "    \"대출 승인 여부\"\n",
    "]\n",
    "\n",
    "print(\"문제 유형 판단:\")\n",
    "for problem in problems:\n",
    "    problem_type = classify_problem(problem)\n",
    "    print(f\"  '{problem}' -> {problem_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 비지도학습 (Unsupervised Learning)\n",
    "\n",
    "### 핵심 개념\n",
    "\n",
    "- **정답(레이블) 없이** 데이터의 숨겨진 패턴을 발견\n",
    "- 주요 유형: 클러스터링, 차원 축소, 이상 탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고객 세분화 (클러스터링)\n",
      "정답 없이 비슷한 특성의 고객을 그룹화합니다.\n",
      "\n",
      "고객 데이터:\n",
      "  고객1: 구매빈도 20회, 평균금액 150,000원\n",
      "  고객2: 구매빈도 2회, 평균금액 500,000원\n",
      "  고객3: 구매빈도 15회, 평균금액 180,000원\n",
      "  고객4: 구매빈도 3회, 평균금액 30,000원\n",
      "  고객5: 구매빈도 1회, 평균금액 450,000원\n",
      "  고객6: 구매빈도 25회, 평균금액 50,000원\n"
     ]
    }
   ],
   "source": [
    "# 비지도학습 예시: 고객 세분화\n",
    "# 정답(레이블) 없이 비슷한 고객끼리 그룹화\n",
    "\n",
    "customers = [\n",
    "    {\"id\": 1, \"purchase_freq\": 20, \"avg_amount\": 150000},  # 고빈도-고액\n",
    "    {\"id\": 2, \"purchase_freq\": 2, \"avg_amount\": 500000},   # 저빈도-고액\n",
    "    {\"id\": 3, \"purchase_freq\": 15, \"avg_amount\": 180000},  # 고빈도-고액\n",
    "    {\"id\": 4, \"purchase_freq\": 3, \"avg_amount\": 30000},    # 저빈도-저액\n",
    "    {\"id\": 5, \"purchase_freq\": 1, \"avg_amount\": 450000},   # 저빈도-고액\n",
    "    {\"id\": 6, \"purchase_freq\": 25, \"avg_amount\": 50000},   # 고빈도-저액\n",
    "]\n",
    "\n",
    "print(\"고객 세분화 (클러스터링)\")\n",
    "print(\"정답 없이 비슷한 특성의 고객을 그룹화합니다.\")\n",
    "print(\"\\n고객 데이터:\")\n",
    "for c in customers:\n",
    "    print(f\"  고객{c['id']}: 구매빈도 {c['purchase_freq']}회, 평균금액 {c['avg_amount']:,}원\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "클러스터링\n",
      "  설명: 비슷한 데이터끼리 그룹화\n",
      "  활용: 고객 세분화, 문서 그룹화, 이미지 분류\n",
      "  알고리즘: K-Means, DBSCAN, Hierarchical\n",
      "\n",
      "차원 축소\n",
      "  설명: 고차원 데이터를 저차원으로 압축\n",
      "  활용: 시각화, 노이즈 제거, 특성 추출\n",
      "  알고리즘: PCA, t-SNE, UMAP\n",
      "\n",
      "이상 탐지\n",
      "  설명: 정상 패턴에서 벗어난 데이터 탐지\n",
      "  활용: 사기 탐지, 장비 고장 예측, 네트워크 침입 탐지\n",
      "  알고리즘: Isolation Forest, One-Class SVM, LOF\n"
     ]
    }
   ],
   "source": [
    "# 비지도학습 활용 사례\n",
    "unsupervised_cases = {\n",
    "    \"클러스터링\": {\n",
    "        \"설명\": \"비슷한 데이터끼리 그룹화\",\n",
    "        \"활용\": [\"고객 세분화\", \"문서 그룹화\", \"이미지 분류\"],\n",
    "        \"알고리즘\": [\"K-Means\", \"DBSCAN\", \"Hierarchical\"]\n",
    "    },\n",
    "    \"차원 축소\": {\n",
    "        \"설명\": \"고차원 데이터를 저차원으로 압축\",\n",
    "        \"활용\": [\"시각화\", \"노이즈 제거\", \"특성 추출\"],\n",
    "        \"알고리즘\": [\"PCA\", \"t-SNE\", \"UMAP\"]\n",
    "    },\n",
    "    \"이상 탐지\": {\n",
    "        \"설명\": \"정상 패턴에서 벗어난 데이터 탐지\",\n",
    "        \"활용\": [\"사기 탐지\", \"장비 고장 예측\", \"네트워크 침입 탐지\"],\n",
    "        \"알고리즘\": [\"Isolation Forest\", \"One-Class SVM\", \"LOF\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "for case_name, info in unsupervised_cases.items():\n",
    "    print(f\"\\n{case_name}\")\n",
    "    print(f\"  설명: {info['설명']}\")\n",
    "    print(f\"  활용: {', '.join(info['활용'])}\")\n",
    "    print(f\"  알고리즘: {', '.join(info['알고리즘'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.5 강화학습 (Reinforcement Learning) 소개\n",
    "\n",
    "### 핵심 개념\n",
    "\n",
    "- **에이전트(Agent)**: 학습 주체\n",
    "- **환경(Environment)**: 에이전트가 상호작용하는 세계\n",
    "- **보상(Reward)**: 행동에 대한 피드백\n",
    "- **목표**: 누적 보상을 최대화하는 정책(Policy) 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "강화학습 비유: 게임 플레이 학습\n",
      "==================================================\n",
      "\n",
      "1. 에이전트: 게임 플레이어 (AI)\n",
      "2. 환경: 게임 화면, 규칙\n",
      "3. 상태: 현재 게임 상황\n",
      "4. 행동: 이동, 점프, 공격 등\n",
      "5. 보상: 점수 획득(+), 사망(-)\n",
      "\n",
      "학습 과정:\n",
      "  시행착오 -> 보상/벌점 -> 전략 개선 -> 반복\n",
      "\n",
      "실무 활용:\n",
      "  - 게임 AI (AlphaGo, Atari)\n",
      "  - 로봇 제어\n",
      "  - 추천 시스템 (탐색/활용 균형)\n",
      "  - 자율 주행\n"
     ]
    }
   ],
   "source": [
    "# 강화학습 개념 (간단한 비유)\n",
    "print(\"강화학습 비유: 게임 플레이 학습\")\n",
    "print(\"=\"*50)\n",
    "print()\n",
    "print(\"1. 에이전트: 게임 플레이어 (AI)\")\n",
    "print(\"2. 환경: 게임 화면, 규칙\")\n",
    "print(\"3. 상태: 현재 게임 상황\")\n",
    "print(\"4. 행동: 이동, 점프, 공격 등\")\n",
    "print(\"5. 보상: 점수 획득(+), 사망(-)\") \n",
    "print()\n",
    "print(\"학습 과정:\")\n",
    "print(\"  시행착오 -> 보상/벌점 -> 전략 개선 -> 반복\")\n",
    "print()\n",
    "print(\"실무 활용:\")\n",
    "print(\"  - 게임 AI (AlphaGo, Atari)\")\n",
    "print(\"  - 로봇 제어\")\n",
    "print(\"  - 추천 시스템 (탐색/활용 균형)\")\n",
    "print(\"  - 자율 주행\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실무 예시: 지도/비지도/강화학습 비교\n",
    "\n",
    "| 구분 | 지도학습 | 비지도학습 | 강화학습 |\n",
    "|------|---------|-----------|----------|\n",
    "| 데이터 | X, y 쌍 | X만 | 환경에서 획득 |\n",
    "| 피드백 | 정답 레이블 | 없음 | 보상 신호 |\n",
    "| 목표 | y 예측 | 패턴 발견 | 보상 최대화 |\n",
    "| 예시 | 스팸 분류 | 고객 세분화 | 게임 AI |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: ML 프로세스 (워크플로우)\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 ML 워크플로우 전체 그림\n",
    "\n",
    "```\n",
    "1. 문제 정의\n",
    "      ↓\n",
    "2. 데이터 수집\n",
    "      ↓\n",
    "3. 데이터 탐색(EDA) & 전처리\n",
    "      ↓\n",
    "4. 특성 엔지니어링\n",
    "      ↓\n",
    "5. 모델 선택 & 훈련\n",
    "      ↓\n",
    "6. 모델 평가\n",
    "      ↓\n",
    "7. 하이퍼파라미터 튜닝\n",
    "      ↓\n",
    "8. 배포 & 모니터링\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML 워크플로우 8단계\n",
      "============================================================\n",
      "\n",
      "1. 문제 정의\n",
      "  핵심 질문: 무엇을 예측/분류할 것인가?\n",
      "  결과물: 문제 유형 (분류/회귀), 평가 지표, 성공 기준\n",
      "\n",
      "2. 데이터 수집\n",
      "  핵심 질문: 필요한 데이터를 어떻게 확보할 것인가?\n",
      "  결과물: 원시 데이터셋 (CSV, DB, API)\n",
      "\n",
      "3. 데이터 탐색 & 전처리\n",
      "  핵심 질문: 데이터의 품질과 특성은?\n",
      "  결과물: 정제된 데이터, EDA 리포트\n",
      "\n",
      "4. 특성 엔지니어링\n",
      "  핵심 질문: 어떤 특성이 예측에 유용한가?\n",
      "  결과물: 학습용 특성 행렬 (X)\n",
      "\n",
      "5. 모델 선택 & 훈련\n",
      "  핵심 질문: 어떤 알고리즘을 사용할 것인가?\n",
      "  결과물: 훈련된 모델\n",
      "\n",
      "6. 모델 평가\n",
      "  핵심 질문: 모델 성능이 충분한가?\n",
      "  결과물: 평가 지표 (정확도, RMSE 등)\n",
      "\n",
      "7. 하이퍼파라미터 튜닝\n",
      "  핵심 질문: 모델을 더 개선할 수 있는가?\n",
      "  결과물: 최적화된 모델\n",
      "\n",
      "8. 배포 & 모니터링\n",
      "  핵심 질문: 실제 환경에서 어떻게 사용할 것인가?\n",
      "  결과물: API, 대시보드, 알림 시스템\n"
     ]
    }
   ],
   "source": [
    "# ML 워크플로우 단계별 설명\n",
    "ml_workflow = [\n",
    "    {\n",
    "        \"단계\": \"1. 문제 정의\",\n",
    "        \"질문\": \"무엇을 예측/분류할 것인가?\",\n",
    "        \"결과물\": \"문제 유형 (분류/회귀), 평가 지표, 성공 기준\"\n",
    "    },\n",
    "    {\n",
    "        \"단계\": \"2. 데이터 수집\",\n",
    "        \"질문\": \"필요한 데이터를 어떻게 확보할 것인가?\",\n",
    "        \"결과물\": \"원시 데이터셋 (CSV, DB, API)\"\n",
    "    },\n",
    "    {\n",
    "        \"단계\": \"3. 데이터 탐색 & 전처리\",\n",
    "        \"질문\": \"데이터의 품질과 특성은?\",\n",
    "        \"결과물\": \"정제된 데이터, EDA 리포트\"\n",
    "    },\n",
    "    {\n",
    "        \"단계\": \"4. 특성 엔지니어링\",\n",
    "        \"질문\": \"어떤 특성이 예측에 유용한가?\",\n",
    "        \"결과물\": \"학습용 특성 행렬 (X)\"\n",
    "    },\n",
    "    {\n",
    "        \"단계\": \"5. 모델 선택 & 훈련\",\n",
    "        \"질문\": \"어떤 알고리즘을 사용할 것인가?\",\n",
    "        \"결과물\": \"훈련된 모델\"\n",
    "    },\n",
    "    {\n",
    "        \"단계\": \"6. 모델 평가\",\n",
    "        \"질문\": \"모델 성능이 충분한가?\",\n",
    "        \"결과물\": \"평가 지표 (정확도, RMSE 등)\"\n",
    "    },\n",
    "    {\n",
    "        \"단계\": \"7. 하이퍼파라미터 튜닝\",\n",
    "        \"질문\": \"모델을 더 개선할 수 있는가?\",\n",
    "        \"결과물\": \"최적화된 모델\"\n",
    "    },\n",
    "    {\n",
    "        \"단계\": \"8. 배포 & 모니터링\",\n",
    "        \"질문\": \"실제 환경에서 어떻게 사용할 것인가?\",\n",
    "        \"결과물\": \"API, 대시보드, 알림 시스템\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ML 워크플로우 8단계\")\n",
    "print(\"=\" * 60)\n",
    "for step in ml_workflow:\n",
    "    print(f\"\\n{step['단계']}\")\n",
    "    print(f\"  핵심 질문: {step['질문']}\")\n",
    "    print(f\"  결과물: {step['결과물']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 문제 정의 (Problem Definition)\n",
    "\n",
    "### 좋은 문제 정의의 조건\n",
    "\n",
    "1. **명확한 비즈니스 목표**: \"고객 이탈을 줄이고 싶다\"\n",
    "2. **측정 가능한 타겟**: \"이탈 여부 (0/1)\"\n",
    "3. **적절한 평가 지표**: \"AUC-ROC 0.8 이상\"\n",
    "4. **데이터 가용성**: \"고객 행동 데이터 확보 가능\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML 문제 정의서: 고객 이탈 예측\n",
      "----------------------------------------\n",
      "비즈니스 목표: 고객 이탈률을 20% 감소시키기\n",
      "예측 타겟: 이탈 여부 (churned: 0/1)\n",
      "문제 유형: 이진 분류 (Binary Classification)\n",
      "평가 지표: AUC-ROC\n",
      "성공 기준: AUC-ROC >= 0.8\n"
     ]
    }
   ],
   "source": [
    "# 문제 정의 템플릿\n",
    "def define_ml_problem(business_goal, target, problem_type, metric, threshold):\n",
    "    \"\"\"\n",
    "    ML 문제 정의 문서 생성\n",
    "    \"\"\"\n",
    "    problem_doc = {\n",
    "        \"비즈니스 목표\": business_goal,\n",
    "        \"예측 타겟\": target,\n",
    "        \"문제 유형\": problem_type,\n",
    "        \"평가 지표\": metric,\n",
    "        \"성공 기준\": f\"{metric} >= {threshold}\"\n",
    "    }\n",
    "    return problem_doc\n",
    "\n",
    "# 예시: 고객 이탈 예측\n",
    "churn_problem = define_ml_problem(\n",
    "    business_goal=\"고객 이탈률을 20% 감소시키기\",\n",
    "    target=\"이탈 여부 (churned: 0/1)\",\n",
    "    problem_type=\"이진 분류 (Binary Classification)\",\n",
    "    metric=\"AUC-ROC\",\n",
    "    threshold=0.8\n",
    ")\n",
    "\n",
    "print(\"ML 문제 정의서: 고객 이탈 예측\")\n",
    "print(\"-\" * 40)\n",
    "for key, value in churn_problem.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ML 문제 정의서: 중고차 가격 예측\n",
      "----------------------------------------\n",
      "비즈니스 목표: 중고차 적정 가격 산정 자동화\n",
      "예측 타겟: 중고차 가격 (만원)\n",
      "문제 유형: 회귀 (Regression)\n",
      "평가 지표: RMSE\n",
      "성공 기준: RMSE >= 500\n"
     ]
    }
   ],
   "source": [
    "# 예시: 중고차 가격 예측 (Week 4 Kaggle 주제 후보)\n",
    "car_price_problem = define_ml_problem(\n",
    "    business_goal=\"중고차 적정 가격 산정 자동화\",\n",
    "    target=\"중고차 가격 (만원)\",\n",
    "    problem_type=\"회귀 (Regression)\",\n",
    "    metric=\"RMSE\",\n",
    "    threshold=500  # 500만원 이내 오차\n",
    ")\n",
    "\n",
    "print(\"\\nML 문제 정의서: 중고차 가격 예측\")\n",
    "print(\"-\" * 40)\n",
    "for key, value in car_price_problem.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 데이터 수집 및 전처리\n",
    "\n",
    "### 데이터 품질 체크리스트\n",
    "\n",
    "- [ ] 결측치(Missing Values) 확인\n",
    "- [ ] 이상치(Outliers) 탐지\n",
    "- [ ] 중복 데이터 제거\n",
    "- [ ] 데이터 타입 확인 및 변환\n",
    "- [ ] 클래스 불균형 확인 (분류 문제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 데이터 (처음 10행):\n",
      "   age  tenure_months  monthly_charge  total_charge  complaints  churned\n",
      "0   58             48       37.787070    313.658482         9.0        0\n",
      "1   48             55       60.469850   4973.297503         9.0        0\n",
      "2   34             23       59.625128   2402.728119         4.0        0\n",
      "3   27             24      113.556513   1469.845675         6.0        0\n",
      "4   40             37      115.472471   4429.120709         3.0        0\n",
      "5   58             35             NaN   3763.821992         0.0        1\n",
      "6   38             44      149.728858   4770.052050         4.0        1\n",
      "7   42             40       62.013722   1720.676493         6.0        1\n",
      "8   30             22      147.193795   2808.548337         9.0        0\n",
      "9   30             27       79.324442   2904.233099         9.0        0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 예시 데이터 생성\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'age': np.random.randint(20, 60, n_samples),\n",
    "    'tenure_months': np.random.randint(1, 60, n_samples),\n",
    "    'monthly_charge': np.random.uniform(30, 150, n_samples),\n",
    "    'total_charge': np.random.uniform(100, 5000, n_samples),\n",
    "    'complaints': np.random.randint(0, 10, n_samples),\n",
    "    'churned': np.random.choice([0, 1], n_samples, p=[0.7, 0.3])\n",
    "})\n",
    "\n",
    "# 결측치 추가 (실제 상황 시뮬레이션)\n",
    "data.loc[5, 'monthly_charge'] = np.nan\n",
    "data.loc[10, 'total_charge'] = np.nan\n",
    "data.loc[15, 'complaints'] = np.nan\n",
    "\n",
    "print(\"샘플 데이터 (처음 10행):\")\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 품질 체크\n",
      "========================================\n",
      "\n",
      "1. 데이터 크기: 100행 x 6열\n",
      "\n",
      "2. 결측치:\n",
      "age               0\n",
      "tenure_months     0\n",
      "monthly_charge    1\n",
      "total_charge      1\n",
      "complaints        1\n",
      "churned           0\n",
      "dtype: int64\n",
      "\n",
      "3. 타겟 분포 (churned):\n",
      "churned\n",
      "0    65\n",
      "1    35\n",
      "Name: count, dtype: int64\n",
      "   이탈 비율: 35.0%\n"
     ]
    }
   ],
   "source": [
    "# 데이터 품질 체크\n",
    "print(\"데이터 품질 체크\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. 기본 정보\n",
    "print(f\"\\n1. 데이터 크기: {data.shape[0]}행 x {data.shape[1]}열\")\n",
    "\n",
    "# 2. 결측치\n",
    "print(f\"\\n2. 결측치:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# 3. 클래스 분포 (타겟 변수)\n",
    "print(f\"\\n3. 타겟 분포 (churned):\")\n",
    "print(data['churned'].value_counts())\n",
    "print(f\"   이탈 비율: {data['churned'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 모델 선택 및 훈련\n",
    "\n",
    "### 알고리즘 선택 가이드\n",
    "\n",
    "| 문제 유형 | 데이터 크기 | 추천 알고리즘 |\n",
    "|----------|-----------|-------------|\n",
    "| 분류 (이진) | 소규모 | Logistic Regression |\n",
    "| 분류 (이진) | 중규모 | Random Forest, XGBoost |\n",
    "| 회귀 | 소규모 | Linear Regression, Ridge |\n",
    "| 회귀 | 중규모 | Random Forest, XGBoost |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "알고리즘 선택 가이드\n",
      "============================================================\n",
      "\n",
      "Logistic Regression\n",
      "  유형: 분류\n",
      "  장점: 해석 가능, 빠른 학습\n",
      "  단점: 비선형 패턴 학습 어려움\n",
      "  추천: 베이스라인, 해석이 중요할 때\n",
      "\n",
      "Decision Tree\n",
      "  유형: 분류/회귀\n",
      "  장점: 직관적, 해석 가능\n",
      "  단점: 과적합 경향\n",
      "  추천: 규칙 기반 의사결정\n",
      "\n",
      "Random Forest\n",
      "  유형: 분류/회귀\n",
      "  장점: 강건함, 과적합 방지\n",
      "  단점: 느린 예측\n",
      "  추천: 대부분의 정형 데이터\n",
      "\n",
      "XGBoost/LightGBM\n",
      "  유형: 분류/회귀\n",
      "  장점: 높은 성능, 빠른 학습\n",
      "  단점: 튜닝 필요\n",
      "  추천: Kaggle 대회, 최고 성능 필요시\n"
     ]
    }
   ],
   "source": [
    "# 알고리즘 선택 가이드\n",
    "algorithm_guide = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"유형\": \"분류\",\n",
    "        \"장점\": \"해석 가능, 빠른 학습\",\n",
    "        \"단점\": \"비선형 패턴 학습 어려움\",\n",
    "        \"추천\": \"베이스라인, 해석이 중요할 때\"\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"유형\": \"분류/회귀\",\n",
    "        \"장점\": \"직관적, 해석 가능\",\n",
    "        \"단점\": \"과적합 경향\",\n",
    "        \"추천\": \"규칙 기반 의사결정\"\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"유형\": \"분류/회귀\",\n",
    "        \"장점\": \"강건함, 과적합 방지\",\n",
    "        \"단점\": \"느린 예측\",\n",
    "        \"추천\": \"대부분의 정형 데이터\"\n",
    "    },\n",
    "    \"XGBoost/LightGBM\": {\n",
    "        \"유형\": \"분류/회귀\",\n",
    "        \"장점\": \"높은 성능, 빠른 학습\",\n",
    "        \"단점\": \"튜닝 필요\",\n",
    "        \"추천\": \"Kaggle 대회, 최고 성능 필요시\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"알고리즘 선택 가이드\")\n",
    "print(\"=\" * 60)\n",
    "for algo, info in algorithm_guide.items():\n",
    "    print(f\"\\n{algo}\")\n",
    "    for key, value in info.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.5 모델 평가\n",
    "\n",
    "### 분류 문제 평가 지표\n",
    "\n",
    "| 지표 | 설명 | 언제 사용? |\n",
    "|-----|------|----------|\n",
    "| Accuracy | 전체 정확도 | 균형 데이터 |\n",
    "| Precision | 양성 예측의 정확도 | FP 비용이 클 때 |\n",
    "| Recall | 실제 양성 탐지율 | FN 비용이 클 때 |\n",
    "| F1 Score | Precision-Recall 조화 | 불균형 데이터 |\n",
    "| AUC-ROC | 분류 성능 종합 | 확률 예측 필요시 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류 평가 지표 이해하기\n",
      "==================================================\n",
      "\n",
      "혼동 행렬 (Confusion Matrix):\n",
      "\n",
      "                 예측\n",
      "              Positive  Negative\n",
      "실제 Positive    TP        FN\n",
      "     Negative    FP        TN\n",
      "\n",
      "TP (True Positive): 이탈 고객을 이탈로 예측 (O)\n",
      "TN (True Negative): 유지 고객을 유지로 예측 (O)\n",
      "FP (False Positive): 유지 고객을 이탈로 예측 (X) - 불필요한 리텐션 비용\n",
      "FN (False Negative): 이탈 고객을 유지로 예측 (X) - 이탈 방치\n",
      "\n",
      "예시 계산 (TP=30, FP=10, TN=50, FN=10):\n",
      "  Accuracy: 80.00%\n",
      "  Precision: 75.00%\n",
      "  Recall: 75.00%\n",
      "  F1 Score: 75.00%\n"
     ]
    }
   ],
   "source": [
    "# 평가 지표 설명\n",
    "print(\"분류 평가 지표 이해하기\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 혼동 행렬 설명\n",
    "print(\"\"\"\n",
    "혼동 행렬 (Confusion Matrix):\n",
    "\n",
    "                 예측\n",
    "              Positive  Negative\n",
    "실제 Positive    TP        FN\n",
    "     Negative    FP        TN\n",
    "\n",
    "TP (True Positive): 이탈 고객을 이탈로 예측 (O)\n",
    "TN (True Negative): 유지 고객을 유지로 예측 (O)\n",
    "FP (False Positive): 유지 고객을 이탈로 예측 (X) - 불필요한 리텐션 비용\n",
    "FN (False Negative): 이탈 고객을 유지로 예측 (X) - 이탈 방치\n",
    "\"\"\")\n",
    "\n",
    "# 지표 계산 예시\n",
    "TP, FP, TN, FN = 30, 10, 50, 10\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"예시 계산 (TP={TP}, FP={FP}, TN={TN}, FN={FN}):\")\n",
    "print(f\"  Accuracy: {accuracy:.2%}\")\n",
    "print(f\"  Precision: {precision:.2%}\")\n",
    "print(f\"  Recall: {recall:.2%}\")\n",
    "print(f\"  F1 Score: {f1:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회귀 문제 평가 지표\n",
    "\n",
    "| 지표 | 설명 | 특징 |\n",
    "|-----|------|------|\n",
    "| MAE | 평균 절대 오차 | 해석 쉬움 |\n",
    "| RMSE | 평균 제곱근 오차 | 큰 오차에 민감 |\n",
    "| R2 | 결정 계수 | 0~1 범위 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회귀 평가 지표 예시\n",
      "========================================\n",
      "실제값: [100 150 200 250 300]\n",
      "예측값: [110 140 220 230 320]\n",
      "\n",
      "MAE: 16.00 (평균 16만원 오차)\n",
      "RMSE: 16.73 (큰 오차에 민감)\n",
      "R2: 94.40% (설명력)\n"
     ]
    }
   ],
   "source": [
    "# 회귀 평가 지표 예시\n",
    "y_true = np.array([100, 150, 200, 250, 300])\n",
    "y_pred = np.array([110, 140, 220, 230, 320])\n",
    "\n",
    "# MAE\n",
    "mae = np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "# R2\n",
    "ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "print(\"회귀 평가 지표 예시\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"실제값: {y_true}\")\n",
    "print(f\"예측값: {y_pred}\")\n",
    "print(f\"\\nMAE: {mae:.2f} (평균 {mae:.0f}만원 오차)\")\n",
    "print(f\"RMSE: {rmse:.2f} (큰 오차에 민감)\")\n",
    "print(f\"R2: {r2:.2%} (설명력)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: scikit-learn 소개\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 scikit-learn 개요\n",
    "\n",
    "### 핵심 특징\n",
    "\n",
    "- Python ML 표준 라이브러리\n",
    "- 일관된 API (fit, predict, transform)\n",
    "- 풍부한 알고리즘 제공\n",
    "- 활발한 커뮤니티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn 버전: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn 임포트\n",
    "import sklearn\n",
    "print(f\"scikit-learn 버전: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn 주요 모듈\n",
      "============================================================\n",
      "\n",
      "sklearn.model_selection\n",
      "  -> 데이터 분할, 교차 검증, 하이퍼파라미터 튜닝\n",
      "\n",
      "sklearn.preprocessing\n",
      "  -> 스케일링, 인코딩, 정규화\n",
      "\n",
      "sklearn.linear_model\n",
      "  -> 선형 회귀, 로지스틱 회귀, Ridge, Lasso\n",
      "\n",
      "sklearn.tree\n",
      "  -> 결정 트리\n",
      "\n",
      "sklearn.ensemble\n",
      "  -> Random Forest, Gradient Boosting, AdaBoost\n",
      "\n",
      "sklearn.metrics\n",
      "  -> 평가 지표 (accuracy, f1, rmse 등)\n",
      "\n",
      "sklearn.pipeline\n",
      "  -> 전처리-모델 파이프라인\n",
      "\n",
      "sklearn.cluster\n",
      "  -> K-Means, DBSCAN 등 클러스터링\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn 주요 모듈\n",
    "sklearn_modules = {\n",
    "    \"sklearn.model_selection\": \"데이터 분할, 교차 검증, 하이퍼파라미터 튜닝\",\n",
    "    \"sklearn.preprocessing\": \"스케일링, 인코딩, 정규화\",\n",
    "    \"sklearn.linear_model\": \"선형 회귀, 로지스틱 회귀, Ridge, Lasso\",\n",
    "    \"sklearn.tree\": \"결정 트리\",\n",
    "    \"sklearn.ensemble\": \"Random Forest, Gradient Boosting, AdaBoost\",\n",
    "    \"sklearn.metrics\": \"평가 지표 (accuracy, f1, rmse 등)\",\n",
    "    \"sklearn.pipeline\": \"전처리-모델 파이프라인\",\n",
    "    \"sklearn.cluster\": \"K-Means, DBSCAN 등 클러스터링\"\n",
    "}\n",
    "\n",
    "print(\"scikit-learn 주요 모듈\")\n",
    "print(\"=\" * 60)\n",
    "for module, description in sklearn_modules.items():\n",
    "    print(f\"\\n{module}\")\n",
    "    print(f\"  -> {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.2 Estimator 인터페이스\n",
    "\n",
    "### 핵심 메서드\n",
    "\n",
    "```python\n",
    "# 모든 scikit-learn 모델의 공통 인터페이스\n",
    "model.fit(X, y)       # 모델 훈련\n",
    "model.predict(X)      # 예측\n",
    "model.score(X, y)     # 평가\n",
    "\n",
    "# 전처리기 (Transformer)\n",
    "scaler.fit(X)         # 변환 규칙 학습\n",
    "scaler.transform(X)   # 변환 적용\n",
    "scaler.fit_transform(X)  # 학습 + 변환 동시\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성(X) shape: (97, 4)\n",
      "타겟(y) shape: (97,)\n",
      "\n",
      "특성 목록: ['age', 'tenure_months', 'monthly_charge', 'complaints']\n"
     ]
    }
   ],
   "source": [
    "# Estimator 인터페이스 예시\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 준비 (앞서 생성한 데이터 사용)\n",
    "# 결측치 제거\n",
    "data_clean = data.dropna()\n",
    "\n",
    "# 특성(X)과 타겟(y) 분리\n",
    "feature_cols = ['age', 'tenure_months', 'monthly_charge', 'complaints']\n",
    "X = data_clean[feature_cols]\n",
    "y = data_clean['churned']\n",
    "\n",
    "print(f\"특성(X) shape: {X.shape}\")\n",
    "print(f\"타겟(y) shape: {y.shape}\")\n",
    "print(f\"\\n특성 목록: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 분할 결과:\n",
      "  훈련 데이터: 77개\n",
      "  테스트 데이터: 20개\n",
      "\n",
      "훈련 데이터 이탈 비율: 35.1%\n",
      "테스트 데이터 이탈 비율: 35.0%\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 분할: train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 테스트 데이터 20%\n",
    "    random_state=42,    # 재현성을 위한 시드\n",
    "    stratify=y          # 클래스 비율 유지\n",
    ")\n",
    "\n",
    "print(\"데이터 분할 결과:\")\n",
    "print(f\"  훈련 데이터: {X_train.shape[0]}개\")\n",
    "print(f\"  테스트 데이터: {X_test.shape[0]}개\")\n",
    "print(f\"\\n훈련 데이터 이탈 비율: {y_train.mean():.1%}\")\n",
    "print(f\"테스트 데이터 이탈 비율: {y_test.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스케일러 학습 완료\n",
      "  평균: [39.24675325 32.77922078 98.85022076  4.38961039]\n",
      "  표준편차: [11.48930145 16.19092529 33.70005444  3.14645067]\n",
      "\n",
      "스케일링 전 (첫 샘플): [ 30.          37.         106.35991418   0.        ]\n",
      "스케일링 후 (첫 샘플): [-0.80481423  0.26068796  0.22283921 -1.39509907]\n"
     ]
    }
   ],
   "source": [
    "# 2. 전처리: StandardScaler (fit + transform)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터로 fit (변환 규칙 학습)\n",
    "scaler.fit(X_train)\n",
    "print(\"스케일러 학습 완료\")\n",
    "print(f\"  평균: {scaler.mean_}\")\n",
    "print(f\"  표준편차: {scaler.scale_}\")\n",
    "\n",
    "# transform 적용\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # 훈련 데이터의 통계로 변환!\n",
    "\n",
    "print(f\"\\n스케일링 전 (첫 샘플): {X_train.iloc[0].values}\")\n",
    "print(f\"스케일링 후 (첫 샘플): {X_train_scaled[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 훈련 완료!\n",
      "\n",
      "모델 계수 (coefficients):\n",
      "  age: 0.3402\n",
      "  tenure_months: 0.3243\n",
      "  monthly_charge: 0.2745\n",
      "  complaints: -0.1759\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델 훈련: fit\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"모델 훈련 완료!\")\n",
    "print(f\"\\n모델 계수 (coefficients):\")\n",
    "for feature, coef in zip(feature_cols, model.coef_[0]):\n",
    "    print(f\"  {feature}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 결과 (처음 10개):\n",
      "  실제: [0 1 0 0 0 1 0 0 1 0]\n",
      "  예측: [0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "이탈 확률 (처음 5개):\n",
      "  샘플 0: 유지 68.97%, 이탈 31.03%\n",
      "  샘플 1: 유지 76.88%, 이탈 23.12%\n",
      "  샘플 2: 유지 71.29%, 이탈 28.71%\n",
      "  샘플 3: 유지 68.13%, 이탈 31.87%\n",
      "  샘플 4: 유지 73.86%, 이탈 26.14%\n"
     ]
    }
   ],
   "source": [
    "# 4. 예측: predict\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"예측 결과 (처음 10개):\")\n",
    "print(f\"  실제: {y_test.values[:10]}\")\n",
    "print(f\"  예측: {y_pred[:10]}\")\n",
    "\n",
    "# 확률 예측\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)\n",
    "print(f\"\\n이탈 확률 (처음 5개):\")\n",
    "for i in range(5):\n",
    "    print(f\"  샘플 {i}: 유지 {y_pred_proba[i][0]:.2%}, 이탈 {y_pred_proba[i][1]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도: 65.00%\n",
      "\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          유지       0.65      1.00      0.79        13\n",
      "          이탈       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.33      0.50      0.39        20\n",
      "weighted avg       0.42      0.65      0.51        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\STA_track\\pypjt\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\Desktop\\STA_track\\pypjt\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\Desktop\\STA_track\\pypjt\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# 5. 평가: score 및 metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 기본 score (정확도)\n",
    "accuracy = model.score(X_test_scaled, y_test)\n",
    "print(f\"테스트 정확도: {accuracy:.2%}\")\n",
    "\n",
    "# 상세 평가 리포트\n",
    "print(\"\\n분류 리포트:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['유지', '이탈']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실무 예시: fit/transform 주의사항\n",
    "\n",
    "**중요**: 테스트 데이터에는 `transform`만 적용! (데이터 누수 방지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 올바른 사용법 vs 잘못된 사용법\n",
    "print(\"fit/transform 올바른 사용법\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\"\"\n",
    "# 올바른 방법\n",
    "scaler.fit(X_train)           # 훈련 데이터로만 fit\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # 훈련 통계로 transform\n",
    "\n",
    "# 잘못된 방법 (데이터 누수!)\n",
    "scaler.fit(X)                 # 전체 데이터로 fit\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "왜 문제인가?\n",
    "- 테스트 데이터의 정보가 전처리에 반영됨\n",
    "- 실제 서비스에서는 미래 데이터를 알 수 없음\n",
    "- 과대평가된 성능으로 이어짐\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.3 간단한 ML 파이프라인 실습\n",
    "\n",
    "### 전체 흐름 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn Pipeline으로 전처리-모델 통합\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 파이프라인 정의\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),           # 전처리\n",
    "    ('classifier', LogisticRegression())    # 모델\n",
    "])\n",
    "\n",
    "# 한 번에 fit!\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 한 번에 predict!\n",
    "y_pred_pipe = pipeline.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "accuracy_pipe = pipeline.score(X_test, y_test)\n",
    "print(f\"파이프라인 정확도: {accuracy_pipe:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인의 장점\n",
    "print(\"Pipeline 장점\")\n",
    "print(\"=\" * 40)\n",
    "print(\"\"\"\n",
    "1. 코드 간결화\n",
    "   - fit/transform 자동 관리\n",
    "   - 데이터 누수 방지\n",
    "\n",
    "2. 재현성\n",
    "   - 전처리 + 모델이 하나의 객체\n",
    "   - 저장/로드 용이\n",
    "\n",
    "3. 교차 검증 호환\n",
    "   - cross_val_score와 함께 사용\n",
    "   - 각 fold에서 올바르게 fit/transform\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 퀴즈\n",
    "\n",
    "**난이도**: (쉬움) ~ (어려움)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. ML 유형 구분하기 \n",
    "\n",
    "**문제**: 다음 문제들이 지도학습인지 비지도학습인지 분류하세요.\n",
    "\n",
    "```python\n",
    "problems = [\n",
    "    \"고객 이탈 예측\",\n",
    "    \"고객 세분화\",\n",
    "    \"스팸 메일 분류\",\n",
    "    \"이상 거래 탐지 (레이블 없음)\"\n",
    "]\n",
    "```\n",
    "\n",
    "**기대 결과**: 각 문제에 대해 \"지도학습\" 또는 \"비지도학습\" 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\n",
    "    \"고객 이탈 예측\",\n",
    "    \"고객 세분화\",\n",
    "    \"스팸 메일 분류\",\n",
    "    \"이상 거래 탐지 (레이블 없음)\"\n",
    "]\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. 분류 vs 회귀 판단 \n",
    "\n",
    "**문제**: 다음 예측 타겟이 분류 문제인지 회귀 문제인지 판단하세요.\n",
    "\n",
    "```python\n",
    "targets = [\n",
    "    \"주택 가격 (만원)\",\n",
    "    \"합격 여부 (합격/불합격)\",\n",
    "    \"판매량 (개)\",\n",
    "    \"고객 등급 (VIP/일반/신규)\"\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\n",
    "    \"주택 가격 (만원)\",\n",
    "    \"합격 여부 (합격/불합격)\",\n",
    "    \"판매량 (개)\",\n",
    "    \"고객 등급 (VIP/일반/신규)\"\n",
    "]\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. ML 워크플로우 순서 \n",
    "\n",
    "**문제**: 다음 ML 단계들을 올바른 순서로 정렬하세요.\n",
    "\n",
    "```python\n",
    "steps = [\n",
    "    \"모델 평가\",\n",
    "    \"데이터 전처리\",\n",
    "    \"문제 정의\",\n",
    "    \"모델 훈련\",\n",
    "    \"데이터 수집\"\n",
    "]\n",
    "```\n",
    "\n",
    "**기대 결과**: 1~5 순서로 정렬된 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    \"모델 평가\",\n",
    "    \"데이터 전처리\",\n",
    "    \"문제 정의\",\n",
    "    \"모델 훈련\",\n",
    "    \"데이터 수집\"\n",
    "]\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Confusion Matrix 이해 \n",
    "\n",
    "**문제**: 아래 혼동 행렬에서 Precision과 Recall을 계산하세요.\n",
    "\n",
    "```\n",
    "TP = 40, FP = 10, TN = 45, FN = 5\n",
    "```\n",
    "\n",
    "**기대 결과**: Precision, Recall 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FP, TN, FN = 40, 10, 45, 5\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. 데이터 분할 \n",
    "\n",
    "**문제**: 아래 데이터를 훈련/테스트로 분할하세요 (테스트 비율 20%, stratify 적용).\n",
    "\n",
    "```python\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]]\n",
    "y = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]]\n",
    "y = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. StandardScaler 적용 \n",
    "\n",
    "**문제**: 아래 데이터에 StandardScaler를 적용하세요. (fit_transform 사용)\n",
    "\n",
    "```python\n",
    "data = [[100, 1], [200, 2], [300, 3], [400, 4], [500, 5]]\n",
    "```\n",
    "\n",
    "**기대 결과**: 스케일링된 데이터와 평균, 표준편차 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "data = [[100, 1], [200, 2], [300, 3], [400, 4], [500, 5]]\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Logistic Regression 훈련 \n",
    "\n",
    "**문제**: Iris 데이터셋에서 이진 분류 모델을 훈련하세요.\n",
    "\n",
    "조건:\n",
    "- setosa(0) vs non-setosa(1) 이진 분류\n",
    "- test_size=0.3\n",
    "- 정확도 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 로드\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = (iris.target != 0).astype(int)  # setosa vs non-setosa\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. Pipeline 구성 \n",
    "\n",
    "**문제**: StandardScaler + LogisticRegression 파이프라인을 구성하고 Iris 데이터에 적용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 준비\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. 모델 평가 지표 \n",
    "\n",
    "**문제**: 다음 예측 결과로 Accuracy, Precision, Recall, F1 Score를 계산하세요.\n",
    "\n",
    "```python\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 1]\n",
    "y_pred = [1, 0, 1, 0, 0, 1, 1, 0, 1, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 1]\n",
    "y_pred = [1, 0, 1, 0, 0, 1, 1, 0, 1, 1]\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. 종합: 고객 이탈 예측 파이프라인 \n",
    "\n",
    "**문제**: 아래 고객 데이터로 이탈 예측 모델을 구축하세요.\n",
    "\n",
    "요구사항:\n",
    "1. 데이터 분할 (test_size=0.2, stratify)\n",
    "2. Pipeline (StandardScaler + LogisticRegression)\n",
    "3. classification_report 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel '.venv (Python 3.13.9)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. listen EFAULT: bad address in system call argument 127.0.0.1:9005"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 고객 데이터 생성\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "\n",
    "customer_df = pd.DataFrame({\n",
    "    'age': np.random.randint(20, 60, n),\n",
    "    'tenure': np.random.randint(1, 60, n),\n",
    "    'monthly_charge': np.random.uniform(30, 150, n),\n",
    "    'complaints': np.random.randint(0, 10, n),\n",
    "    'churned': np.random.choice([0, 1], n, p=[0.7, 0.3])\n",
    "})\n",
    "\n",
    "print(\"데이터 미리보기:\")\n",
    "print(customer_df.head())\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 학습 정리\n",
    "\n",
    "### Part 1: ML 기초 개념 핵심 요약\n",
    "\n",
    "| 개념 | 정의 | 핵심 포인트 |\n",
    "|-----|------|------------|\n",
    "| 머신러닝 | 데이터에서 패턴을 학습하는 알고리즘 | 규칙을 직접 만들지 않고 데이터에서 학습 |\n",
    "| 지도학습 | 레이블이 있는 데이터로 학습 | 분류(이산), 회귀(연속) |\n",
    "| 비지도학습 | 레이블 없이 패턴 발견 | 클러스터링, 차원 축소, 이상 탐지 |\n",
    "| 강화학습 | 보상을 최대화하도록 학습 | 에이전트-환경 상호작용 |\n",
    "\n",
    "### Part 2: ML 프로세스 핵심 요약\n",
    "\n",
    "| 단계 | 핵심 활동 | 결과물 |\n",
    "|-----|----------|--------|\n",
    "| 문제 정의 | 비즈니스 목표 -> ML 문제 변환 | 문제 유형, 평가 지표 |\n",
    "| 데이터 준비 | 수집, 탐색, 전처리 | 정제된 데이터셋 |\n",
    "| 모델링 | 알고리즘 선택, 훈련, 평가 | 훈련된 모델 |\n",
    "| 배포 | 서비스 적용, 모니터링 | API, 대시보드 |\n",
    "\n",
    "### Part 3: scikit-learn 핵심 요약\n",
    "\n",
    "| 메서드 | 용도 | 사용 대상 |\n",
    "|-------|-----|----------|\n",
    "| fit(X, y) | 모델/전처리기 학습 | 훈련 데이터만 |\n",
    "| predict(X) | 예측 수행 | 모델 |\n",
    "| transform(X) | 데이터 변환 | 전처리기 |\n",
    "| fit_transform(X) | 학습 + 변환 | 훈련 데이터 전처리 |\n",
    "| score(X, y) | 성능 평가 | 모델 |\n",
    "\n",
    "### 실무 팁\n",
    "\n",
    "1. **문제 정의가 가장 중요**: 잘못된 문제 정의는 잘못된 모델로 이어짐\n",
    "2. **데이터 품질 > 알고리즘**: Garbage In, Garbage Out\n",
    "3. **베이스라인 먼저**: 복잡한 모델 전에 간단한 모델로 기준선 설정\n",
    "4. **데이터 누수 주의**: fit은 훈련 데이터만, transform은 테스트에도\n",
    "5. **Pipeline 활용**: 전처리-모델을 하나로 묶어 관리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
