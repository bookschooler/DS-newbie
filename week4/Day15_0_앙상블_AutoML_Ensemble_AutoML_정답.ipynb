{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day15_0: 앙상블 & AutoML - 정답 노트북\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    "    VotingClassifier, StackingClassifier\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.datasets import load_iris, make_classification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"라이브러리 로드 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q1. Hard Voting 이해하기 ⭐\n",
    "\n",
    "**문제**: 3개 모델의 예측이 다음과 같을 때, Hard Voting 결과는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제\n",
    "model_a_pred = 1\n",
    "model_b_pred = 0\n",
    "model_c_pred = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "from collections import Counter\n",
    "\n",
    "# 모든 예측을 리스트로\n",
    "predictions = [model_a_pred, model_b_pred, model_c_pred]\n",
    "\n",
    "# 다수결 투표\n",
    "vote_counts = Counter(predictions)\n",
    "hard_voting_result = vote_counts.most_common(1)[0][0]\n",
    "\n",
    "print(f\"각 모델 예측: {predictions}\")\n",
    "print(f\"투표 결과: {dict(vote_counts)}\")\n",
    "print(f\"Hard Voting 최종 예측: {hard_voting_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert hard_voting_result == 1, \"클래스 1이 다수결!\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "- Hard Voting은 각 모델의 예측 클래스를 모아 다수결로 결정\n",
    "- Counter를 사용하여 각 클래스의 투표 수 계산\n",
    "\n",
    "**핵심 개념**:\n",
    "- Hard Voting: 가장 많이 예측된 클래스 선택\n",
    "- 동점일 경우 일반적으로 작은 클래스 반환 (구현에 따라 다름)\n",
    "\n",
    "**대안**:\n",
    "```python\n",
    "# numpy로 구현\n",
    "import numpy as np\n",
    "predictions = np.array([1, 0, 1])\n",
    "result = np.bincount(predictions).argmax()\n",
    "```\n",
    "\n",
    "**실무 팁**: Hard Voting은 확률 정보를 활용하지 못하므로, Soft Voting을 더 권장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q2. Soft Voting 계산하기 ⭐⭐\n",
    "\n",
    "**문제**: 3개 모델의 클래스 1 예측 확률로 Soft Voting 결과 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제\n",
    "proba_a = 0.8  # 모델 A의 클래스 1 확률\n",
    "proba_b = 0.3  # 모델 B의 클래스 1 확률\n",
    "proba_c = 0.6  # 모델 C의 클래스 1 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "# 클래스 1 평균 확률\n",
    "avg_proba_class1 = (proba_a + proba_b + proba_c) / 3\n",
    "\n",
    "# 클래스 0 평균 확률\n",
    "avg_proba_class0 = 1 - avg_proba_class1\n",
    "\n",
    "# 최종 예측 (0.5 기준)\n",
    "soft_voting_result = 1 if avg_proba_class1 >= 0.5 else 0\n",
    "\n",
    "print(f\"각 모델 클래스1 확률: {proba_a}, {proba_b}, {proba_c}\")\n",
    "print(f\"평균 클래스0 확률: {avg_proba_class0:.4f}\")\n",
    "print(f\"평균 클래스1 확률: {avg_proba_class1:.4f}\")\n",
    "print(f\"Soft Voting 최종 예측: {soft_voting_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert abs(avg_proba_class1 - 0.5667) < 0.01, \"평균 확률 계산 확인\"\n",
    "assert soft_voting_result == 1, \"클래스 1이 선택되어야 함\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "- 각 모델의 클래스별 확률을 평균\n",
    "- 평균 확률이 높은 클래스를 선택\n",
    "\n",
    "**핵심 개념**:\n",
    "- Soft Voting은 확률을 평균하여 더 정교한 결합\n",
    "- 불확실한 예측(확률 0.5 근처)의 영향을 줄일 수 있음\n",
    "\n",
    "**대안**:\n",
    "```python\n",
    "# numpy 활용\n",
    "probas = np.array([proba_a, proba_b, proba_c])\n",
    "avg_proba = probas.mean()\n",
    "```\n",
    "\n",
    "**실무 팁**: 모델 성능에 따라 가중치를 다르게 부여하면 성능 향상 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q3. VotingClassifier 구성하기 ⭐⭐\n",
    "\n",
    "**문제**: LogisticRegression과 RandomForest로 Soft Voting 앙상블 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 - 데이터 준비\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, (iris.target == 2).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "# 개별 모델 정의\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Soft Voting 앙상블 구성\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr),\n",
    "        ('rf', rf)\n",
    "    ],\n",
    "    voting='soft'  # Soft Voting\n",
    ")\n",
    "\n",
    "# 학습 및 예측\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Soft Voting 정확도: {accuracy:.4f}\")\n",
    "\n",
    "# 개별 모델 성능 비교\n",
    "for name, model in [('LR', lr), ('RF', rf)]:\n",
    "    model.fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    print(f\"{name} 정확도: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert accuracy >= 0.9, \"정확도 90% 이상\"\n",
    "assert hasattr(voting_clf, 'predict_proba'), \"Soft Voting은 predict_proba 지원\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. 개별 모델을 튜플 리스트로 구성 `(이름, 모델)`\n",
    "2. `voting='soft'`로 Soft Voting 지정\n",
    "3. fit/predict 일반 모델처럼 사용\n",
    "\n",
    "**핵심 개념**:\n",
    "- estimators: (이름, 모델) 튜플 리스트\n",
    "- voting: 'hard' 또는 'soft'\n",
    "- Soft Voting 시 모든 모델이 predict_proba 지원해야 함\n",
    "\n",
    "**흔한 실수**:\n",
    "- SVM은 기본적으로 확률 미지원 -> `probability=True` 필요\n",
    "- estimators에 이름 누락\n",
    "\n",
    "**실무 팁**: 다양한 알고리즘 조합이 성능 향상에 효과적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q4. Stacking vs Voting 비교 ⭐⭐⭐\n",
    "\n",
    "**문제**: 같은 베이스 모델로 Stacking과 Voting 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier\n",
    "\n",
    "# 베이스 모델 정의\n",
    "base_estimators = [\n",
    "    ('lr', LogisticRegression(random_state=42, max_iter=1000)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=50, random_state=42))\n",
    "]\n",
    "\n",
    "# Voting Classifier\n",
    "voting = VotingClassifier(\n",
    "    estimators=base_estimators,\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Stacking Classifier\n",
    "stacking = StackingClassifier(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=LogisticRegression(random_state=42),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# 학습 및 평가\n",
    "results = {}\n",
    "\n",
    "for name, model in [('Voting', voting), ('Stacking', stacking)]:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    print(f\"{name} 정확도: {accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\n성능 차이: {abs(results['Voting'] - results['Stacking']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert 'Voting' in results and 'Stacking' in results\n",
    "assert all(v >= 0.8 for v in results.values()), \"모든 모델 80% 이상\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. 동일한 베이스 모델로 Voting, Stacking 구성\n",
    "2. Stacking은 final_estimator(메타 모델) 추가 필요\n",
    "3. 동일 데이터로 성능 비교\n",
    "\n",
    "**핵심 개념**:\n",
    "- Voting: 단순 평균/다수결\n",
    "- Stacking: 베이스 모델 예측을 특성으로 메타 모델 학습\n",
    "- cv 파라미터: 메타 특성 생성 시 교차 검증 폴드 수\n",
    "\n",
    "**대안**:\n",
    "```python\n",
    "# passthrough=True로 원본 특성 포함\n",
    "stacking = StackingClassifier(..., passthrough=True)\n",
    "```\n",
    "\n",
    "**실무 팁**: Stacking이 항상 좋은 것은 아님. 과적합 위험 고려"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q5. 가중 Voting 최적화 ⭐⭐⭐\n",
    "\n",
    "**문제**: 개별 모델 성능에 비례하여 가중치 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제\n",
    "lr_score = 0.85\n",
    "rf_score = 0.90\n",
    "gb_score = 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "# 점수를 가중치로 변환 (정규화)\n",
    "scores = [lr_score, rf_score, gb_score]\n",
    "total_score = sum(scores)\n",
    "weights = [s / total_score for s in scores]\n",
    "\n",
    "# 또는 원래 점수를 그대로 가중치로 사용\n",
    "weights_raw = [lr_score, rf_score, gb_score]\n",
    "\n",
    "print(f\"정규화 가중치: {[f'{w:.3f}' for w in weights]}\")\n",
    "print(f\"원래 점수 가중치: {weights_raw}\")\n",
    "\n",
    "# Weighted Voting 구성\n",
    "weighted_voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(random_state=42, max_iter=1000)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=50, random_state=42))\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=weights_raw  # 성능 비례 가중치\n",
    ")\n",
    "\n",
    "weighted_voting.fit(X_train, y_train)\n",
    "y_pred_weighted = weighted_voting.predict(X_test)\n",
    "accuracy_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "\n",
    "print(f\"\\nWeighted Voting 정확도: {accuracy_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert len(weights) == 3, \"3개 모델 가중치\"\n",
    "assert weights_raw[2] == max(weights_raw), \"GB가 가장 높은 가중치\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. 각 모델의 CV 성능을 가중치로 사용\n",
    "2. weights 파라미터에 리스트로 전달\n",
    "3. 성능 좋은 모델의 영향력 증가\n",
    "\n",
    "**핵심 개념**:\n",
    "- weights: estimators 순서대로 가중치 리스트\n",
    "- 정규화 여부는 선택 (sklearn은 자동 처리)\n",
    "- 극단적 가중치는 피하는 것이 좋음\n",
    "\n",
    "**실무 팁**: 가중치는 CV 점수 기반으로 설정하되, 최적 가중치는 실험으로 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q6. Optuna 기본 사용 ⭐⭐⭐\n",
    "\n",
    "**문제**: Optuna로 LogisticRegression의 C 파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 목적 함수 정의\n",
    "def objective_lr(trial):\n",
    "    \"\"\"LogisticRegression C 파라미터 최적화\"\"\"\n",
    "    \n",
    "    # C 파라미터 탐색 (log uniform)\n",
    "    C = trial.suggest_float('C', 0.01, 100, log=True)\n",
    "    \n",
    "    model = LogisticRegression(C=C, random_state=42, max_iter=1000)\n",
    "    \n",
    "    # 5-Fold CV\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "# 최적화 실행\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_lr, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n최적 C 값: {study.best_params['C']:.4f}\")\n",
    "print(f\"최적 CV 정확도: {study.best_value:.4f}\")\n",
    "\n",
    "# 최적 모델로 테스트\n",
    "best_lr = LogisticRegression(C=study.best_params['C'], random_state=42, max_iter=1000)\n",
    "best_lr.fit(X_train, y_train)\n",
    "test_accuracy = accuracy_score(y_test, best_lr.predict(X_test))\n",
    "print(f\"테스트 정확도: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert 0.01 <= study.best_params['C'] <= 100, \"C 범위 확인\"\n",
    "assert study.best_value >= 0.8, \"CV 정확도 80% 이상\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. objective 함수 정의 (trial 객체 받음)\n",
    "2. trial.suggest_xxx로 파라미터 탐색 공간 정의\n",
    "3. create_study + optimize로 최적화 실행\n",
    "\n",
    "**핵심 개념**:\n",
    "- `suggest_float(name, low, high, log=True)`: 로그 스케일 탐색\n",
    "- direction='maximize': 최대화 목표 (minimize도 가능)\n",
    "- study.best_params: 최적 파라미터 딕셔너리\n",
    "\n",
    "**대안**:\n",
    "```python\n",
    "# 정수 파라미터\n",
    "n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "\n",
    "# 카테고리 파라미터\n",
    "solver = trial.suggest_categorical('solver', ['lbfgs', 'saga'])\n",
    "```\n",
    "\n",
    "**실무 팁**: n_trials 대신 timeout으로 시간 제한 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q7. Feature Importance 비교 ⭐⭐⭐⭐\n",
    "\n",
    "**문제**: Random Forest와 Gradient Boosting의 Feature Importance 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "# 더 복잡한 데이터셋 사용\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X_imp, y_imp = make_classification(\n",
    "    n_samples=500, n_features=8, n_informative=5,\n",
    "    n_redundant=2, random_state=42\n",
    ")\n",
    "feature_names = [f'Feature_{i}' for i in range(8)]\n",
    "\n",
    "X_train_imp, X_test_imp, y_train_imp, y_test_imp = train_test_split(\n",
    "    X_imp, y_imp, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf.fit(X_train_imp, y_train_imp)\n",
    "gb.fit(X_train_imp, y_train_imp)\n",
    "\n",
    "# Feature Importance 추출\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'RF_Importance': rf.feature_importances_,\n",
    "    'GB_Importance': gb.feature_importances_\n",
    "})\n",
    "\n",
    "# 시각화\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['Random Forest', 'Gradient Boosting'])\n",
    "\n",
    "# RF\n",
    "rf_sorted = importance_df.sort_values('RF_Importance', ascending=True)\n",
    "fig.add_trace(\n",
    "    go.Bar(x=rf_sorted['RF_Importance'], y=rf_sorted['Feature'], \n",
    "           orientation='h', marker_color='blue', name='RF'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# GB\n",
    "gb_sorted = importance_df.sort_values('GB_Importance', ascending=True)\n",
    "fig.add_trace(\n",
    "    go.Bar(x=gb_sorted['GB_Importance'], y=gb_sorted['Feature'], \n",
    "           orientation='h', marker_color='green', name='GB'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(title='Feature Importance 비교', height=400, showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nFeature Importance 순위 비교:\")\n",
    "print(importance_df.sort_values('RF_Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert 'RF_Importance' in importance_df.columns\n",
    "assert 'GB_Importance' in importance_df.columns\n",
    "assert importance_df['RF_Importance'].sum() - 1.0 < 0.01, \"RF 중요도 합=1\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. 두 모델 학습 후 feature_importances_ 추출\n",
    "2. DataFrame으로 정리\n",
    "3. Plotly subplot으로 나란히 시각화\n",
    "\n",
    "**핵심 개념**:\n",
    "- feature_importances_: 트리 기반 모델 내장 속성\n",
    "- RF: 불순도 감소 기반\n",
    "- GB: 손실 감소 기반\n",
    "\n",
    "**실무 팁**: 두 모델의 순위가 다를 수 있음 - Permutation Importance로 검증 권장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q8. SHAP Force Plot 해석 ⭐⭐⭐⭐\n",
    "\n",
    "**문제**: 테스트 데이터 첫 번째 샘플에 대한 SHAP 값 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "import shap\n",
    "\n",
    "# SHAP 계산\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_test_imp[:10])  # 처음 10개만\n",
    "\n",
    "# 첫 번째 샘플 분석\n",
    "sample_idx = 0\n",
    "sample_shap = shap_values[1][sample_idx]  # 클래스 1에 대한 SHAP\n",
    "\n",
    "# 예측 확률\n",
    "pred_proba = rf.predict_proba(X_test_imp[sample_idx:sample_idx+1])[0]\n",
    "actual = y_test_imp[sample_idx]\n",
    "\n",
    "print(f\"샘플 {sample_idx} 분석\")\n",
    "print(f\"=\"*50)\n",
    "print(f\"실제 레이블: {actual}\")\n",
    "print(f\"예측 확률: 클래스0={pred_proba[0]:.2%}, 클래스1={pred_proba[1]:.2%}\")\n",
    "\n",
    "# 상위 3개 영향 특성\n",
    "shap_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'SHAP_Value': sample_shap,\n",
    "    'Feature_Value': X_test_imp[sample_idx]\n",
    "}).sort_values('SHAP_Value', key=abs, ascending=False)\n",
    "\n",
    "print(f\"\\n상위 3개 영향 특성:\")\n",
    "for i, row in shap_df.head(3).iterrows():\n",
    "    direction = \"이탈 방향(+)\" if row['SHAP_Value'] > 0 else \"유지 방향(-)\"\n",
    "    print(f\"  {row['Feature']}: SHAP={row['SHAP_Value']:.4f} ({direction})\")\n",
    "\n",
    "# 해석 문장\n",
    "top_feat = shap_df.iloc[0]\n",
    "print(f\"\\n해석: '{top_feat['Feature']}'가 예측에 가장 큰 영향을 미쳤으며, \")\n",
    "print(f\"       이 특성의 값이 높아서 {'이탈' if top_feat['SHAP_Value'] > 0 else '유지'} 확률을 높였습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert len(sample_shap) == 8, \"8개 특성\"\n",
    "assert shap_df.shape[0] == 8, \"모든 특성 포함\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. TreeExplainer로 SHAP 계산\n",
    "2. 특정 샘플의 SHAP 값 추출\n",
    "3. 절대값 기준 정렬로 상위 특성 식별\n",
    "4. 부호로 영향 방향 해석\n",
    "\n",
    "**핵심 개념**:\n",
    "- SHAP > 0: 클래스 1(이탈) 방향 기여\n",
    "- SHAP < 0: 클래스 0(유지) 방향 기여\n",
    "- 절대값 크기: 영향력 정도\n",
    "\n",
    "**실무 팁**: SHAP 값의 합 + 기대값 = 예측 확률 (로그오즈)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q9. PDP 그리기 ⭐⭐⭐⭐⭐\n",
    "\n",
    "**문제**: 가장 중요한 특성의 PDP + rug plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "# 가장 중요한 특성 찾기\n",
    "top_feature_idx = rf.feature_importances_.argmax()\n",
    "top_feature_name = feature_names[top_feature_idx]\n",
    "\n",
    "print(f\"가장 중요한 특성: {top_feature_name}\")\n",
    "\n",
    "# PDP 계산\n",
    "pd_result = partial_dependence(\n",
    "    rf, X_train_imp, features=[top_feature_idx],\n",
    "    kind='average', grid_resolution=50\n",
    ")\n",
    "\n",
    "# 시각화\n",
    "fig = go.Figure()\n",
    "\n",
    "# PDP 라인\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=pd_result['grid_values'][0],\n",
    "    y=pd_result['average'][0],\n",
    "    mode='lines',\n",
    "    name='PDP',\n",
    "    line=dict(width=3, color='blue')\n",
    "))\n",
    "\n",
    "# Rug plot (데이터 분포)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=X_train_imp[:, top_feature_idx],\n",
    "    y=[pd_result['average'][0].min()] * len(X_train_imp),\n",
    "    mode='markers',\n",
    "    name='Data Distribution',\n",
    "    marker=dict(symbol='line-ns', size=10, color='gray', opacity=0.3)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Partial Dependence Plot: {top_feature_name}',\n",
    "    xaxis_title=top_feature_name,\n",
    "    yaxis_title='Predicted Probability',\n",
    "    height=450\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert pd_result['average'][0].shape[0] == 50, \"grid_resolution=50\"\n",
    "assert top_feature_name in feature_names, \"유효한 특성명\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. Feature Importance로 가장 중요한 특성 식별\n",
    "2. partial_dependence로 PDP 계산\n",
    "3. Plotly로 라인 + rug plot 시각화\n",
    "\n",
    "**핵심 개념**:\n",
    "- PDP: 다른 특성 고정, 한 특성 변화 시 예측 변화\n",
    "- Rug plot: 실제 데이터 분포 표시\n",
    "- 데이터가 없는 영역의 PDP는 신뢰도 낮음\n",
    "\n",
    "**실무 팁**: ICE plot(Individual Conditional Expectation)으로 개별 샘플 확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q10. 종합: 앙상블 + AutoML + 해석 ⭐⭐⭐⭐⭐\n",
    "\n",
    "**문제**: 전체 파이프라인 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "import optuna\n",
    "import shap\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# 데이터 준비\n",
    "X_full, y_full = make_classification(\n",
    "    n_samples=800, n_features=10, n_informative=6,\n",
    "    n_redundant=2, random_state=42\n",
    ")\n",
    "feat_names = [f'Feature_{i}' for i in range(10)]\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_full, y_full, test_size=0.2, random_state=42, stratify=y_full\n",
    ")\n",
    "\n",
    "print(\"Step 1: Optuna로 RandomForest 최적화\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Step 1: Optuna 최적화\n",
    "def objective_rf_full(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 150),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10)\n",
    "    }\n",
    "    model = RandomForestClassifier(**params, random_state=42)\n",
    "    scores = cross_val_score(model, X_tr, y_tr, cv=3, scoring='roc_auc')\n",
    "    return scores.mean()\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_full = optuna.create_study(direction='maximize')\n",
    "study_full.optimize(objective_rf_full, n_trials=10, show_progress_bar=True)\n",
    "\n",
    "print(f\"최적 파라미터: {study_full.best_params}\")\n",
    "print(f\"최적 CV AUC: {study_full.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Stacking 구성\n",
    "print(\"\\nStep 2: 최적 RF + LR + GB로 Stacking\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_rf_model = RandomForestClassifier(**study_full.best_params, random_state=42)\n",
    "\n",
    "stacking_final = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(random_state=42, max_iter=1000)),\n",
    "        ('rf_opt', best_rf_model),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=50, random_state=42))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(random_state=42),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "stacking_final.fit(X_tr, y_tr)\n",
    "y_pred_final = stacking_final.predict(X_te)\n",
    "y_proba_final = stacking_final.predict_proba(X_te)[:, 1]\n",
    "\n",
    "auc_final = roc_auc_score(y_te, y_proba_final)\n",
    "acc_final = accuracy_score(y_te, y_pred_final)\n",
    "\n",
    "print(f\"Stacking AUC: {auc_final:.4f}\")\n",
    "print(f\"Stacking Accuracy: {acc_final:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: SHAP 분석\n",
    "print(\"\\nStep 3: SHAP로 상위 3개 중요 특성\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 최적 RF 모델로 SHAP 계산\n",
    "best_rf_model.fit(X_tr, y_tr)\n",
    "explainer_final = shap.TreeExplainer(best_rf_model)\n",
    "shap_vals = explainer_final.shap_values(X_te[:50])\n",
    "\n",
    "# 평균 절대 SHAP\n",
    "mean_shap = np.abs(shap_vals[1]).mean(axis=0)\n",
    "shap_importance = pd.DataFrame({\n",
    "    'Feature': feat_names,\n",
    "    'Mean_SHAP': mean_shap\n",
    "}).sort_values('Mean_SHAP', ascending=False)\n",
    "\n",
    "print(\"상위 3개 중요 특성:\")\n",
    "for i, row in shap_importance.head(3).iterrows():\n",
    "    print(f\"  {row['Feature']}: {row['Mean_SHAP']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 요약\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"최종 요약\")\n",
    "print(\"=\"*50)\n",
    "print(f\"최적 RF 파라미터: {study_full.best_params}\")\n",
    "print(f\"Stacking AUC: {auc_final:.4f}\")\n",
    "print(f\"상위 중요 특성: {', '.join(shap_importance.head(3)['Feature'].tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert study_full.best_value >= 0.7, \"Optuna 최적화 성공\"\n",
    "assert auc_final >= 0.8, \"Stacking AUC 80% 이상\"\n",
    "assert shap_importance.shape[0] == 10, \"모든 특성 SHAP 계산\"\n",
    "print(\"모든 테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. Optuna로 RF 하이퍼파라미터 최적화 (10 trials)\n",
    "2. 최적 RF + LR + GB로 Stacking 앙상블 구성\n",
    "3. TreeExplainer로 SHAP 계산\n",
    "4. 평균 절대 SHAP로 상위 특성 식별\n",
    "\n",
    "**핵심 개념**:\n",
    "- Optuna: 효율적인 하이퍼파라미터 탐색\n",
    "- Stacking: 최고 성능 앙상블\n",
    "- SHAP: 모델 불가지론적 해석\n",
    "\n",
    "**실무 팁**:\n",
    "1. Optuna trials 수는 시간과 성능 트레이드오프\n",
    "2. Stacking의 메타 모델은 간단한 것이 좋음\n",
    "3. SHAP은 계산 비용이 크므로 샘플링 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 학습 정리\n",
    "\n",
    "### 퀴즈별 핵심 개념\n",
    "\n",
    "| 퀴즈 | 난이도 | 핵심 개념 |\n",
    "|-----|-------|----------|\n",
    "| Q1 | ⭐ | Hard Voting = 다수결 |\n",
    "| Q2 | ⭐⭐ | Soft Voting = 확률 평균 |\n",
    "| Q3 | ⭐⭐ | VotingClassifier 구성 |\n",
    "| Q4 | ⭐⭐⭐ | Stacking vs Voting 비교 |\n",
    "| Q5 | ⭐⭐⭐ | 가중 Voting 최적화 |\n",
    "| Q6 | ⭐⭐⭐ | Optuna 기본 사용 |\n",
    "| Q7 | ⭐⭐⭐⭐ | Feature Importance 비교 |\n",
    "| Q8 | ⭐⭐⭐⭐ | SHAP 개별 예측 해석 |\n",
    "| Q9 | ⭐⭐⭐⭐⭐ | PDP + rug plot |\n",
    "| Q10 | ⭐⭐⭐⭐⭐ | 종합 파이프라인 |\n",
    "\n",
    "### Kaggle 대회 적용 팁\n",
    "\n",
    "1. **베이스라인**: 단일 모델로 시작\n",
    "2. **앙상블 순서**: Voting -> Stacking -> Blending\n",
    "3. **Optuna 활용**: timeout 설정으로 시간 관리\n",
    "4. **SHAP 필수**: 발표 시 모델 설명에 활용\n",
    "5. **다양성 확보**: 다른 알고리즘, 다른 전처리 조합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
