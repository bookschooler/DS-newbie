{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day13_0: íšŒê·€ ëª¨ë¸ (Regression Models)\n",
    "\n",
    "## ğŸ“š í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "**Part 1: ê¸°ì´ˆ - ì„ í˜• ëª¨ë¸**\n",
    "1. ì„ í˜• íšŒê·€(Linear Regression)ì˜ ì›ë¦¬ì™€ êµ¬í˜„ ì´í•´í•˜ê¸°\n",
    "2. Ridge Regression (L2 ì •ê·œí™”) í™œìš©ë²• ìµíˆê¸°\n",
    "3. Lasso Regression (L1 ì •ê·œí™”)ë¡œ íŠ¹ì„± ì„ íƒí•˜ê¸°\n",
    "4. ElasticNetìœ¼ë¡œ L1+L2 ì¡°í•© í™œìš©í•˜ê¸°\n",
    "5. íšŒê·€ í‰ê°€ ì§€í‘œ(MSE, RMSE, MAE, R2) ì´í•´í•˜ê¸°\n",
    "\n",
    "**Part 2: ì‹¬í™” - ë¹„ì„ í˜• ëª¨ë¸ & íŠœë‹**\n",
    "1. Decision Tree Regressorë¡œ ë¹„ì„ í˜• íŒ¨í„´ í•™ìŠµí•˜ê¸°\n",
    "2. Random Forest Regressorë¡œ ì•™ìƒë¸” íšŒê·€ êµ¬í˜„í•˜ê¸°\n",
    "3. XGBoost/LightGBMìœ¼ë¡œ ê³ ì„±ëŠ¥ íšŒê·€ ë‹¬ì„±í•˜ê¸°\n",
    "4. GridSearchCV/RandomizedSearchCVë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹í•˜ê¸°\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ì™œ ì´ê²ƒì„ ë°°ìš°ë‚˜ìš”?\n",
    "\n",
    "| ê°œë… | ì‹¤ë¬´ í™œìš© | ì˜ˆì‹œ |\n",
    "|------|----------|------|\n",
    "| ì„ í˜• íšŒê·€ | ê¸°ë³¸ ì˜ˆì¸¡, í•´ì„ ê°€ëŠ¥í•œ ëª¨ë¸ | ë§¤ì¶œ ì˜ˆì¸¡, ê°€ê²© ì‚°ì • |\n",
    "| Ridge/Lasso | ê³¼ì í•© ë°©ì§€, íŠ¹ì„± ì„ íƒ | ë‹¤ì¤‘ê³µì„ ì„± ì²˜ë¦¬, í•µì‹¬ ë³€ìˆ˜ ì¶”ì¶œ |\n",
    "| ì•™ìƒë¸” ëª¨ë¸ | ê³ ì„±ëŠ¥ ì˜ˆì¸¡ | ì£¼íƒ ê°€ê²©, ìˆ˜ìš” ì˜ˆì¸¡ |\n",
    "| í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ | ëª¨ë¸ ìµœì í™” | Kaggle ê²½ì§„ëŒ€íšŒ, ì‹¤ë¬´ ë°°í¬ |\n",
    "\n",
    "**ë¶„ì„ê°€ ê´€ì **: íšŒê·€ ë¶„ì„ì€ ë°ì´í„° ë¶„ì„ì˜ í•µì‹¬ì…ë‹ˆë‹¤. ë¶€ë™ì‚° ê°€ê²© ì˜ˆì¸¡, ë§¤ì¶œ ì˜ˆì¸¡, ìˆ˜ìš” ì˜ˆì¸¡ ë“± ë¹„ì¦ˆë‹ˆìŠ¤ì˜ ê±°ì˜ ëª¨ë“  ì˜ˆì¸¡ ë¬¸ì œê°€ íšŒê·€ë¡œ ì‹œì‘ë©ë‹ˆë‹¤!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel '.venv (Python 3.13.9)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. listen EFAULT: bad address in system call argument 0.0.0.0:9000"
     ]
    }
   ],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# sklearn ëª¨ë¸\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# sklearn ìœ í‹¸ë¦¬í‹°\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Gradient Boosting ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    print(\"XGBoost ë²„ì „:\", xgb.__version__)\n",
    "except ImportError:\n",
    "    print(\"XGBoost ì„¤ì¹˜ í•„ìš”: pip install xgboost\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    print(\"LightGBM ë²„ì „:\", lgb.__version__)\n",
    "except ImportError:\n",
    "    print(\"LightGBM ì„¤ì¹˜ í•„ìš”: pip install lightgbm\")\n",
    "\n",
    "try:\n",
    "    import catboost as cb\n",
    "    print(\"CatBoost ë²„ì „:\", cb.__version__)\n",
    "except ImportError:\n",
    "    print(\"CatBoost ì„¤ì¹˜ í•„ìš”: pip install catboost\")\n",
    "\n",
    "# ê²½ê³  ë¬´ì‹œ\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ëœë¤ ì‹œë“œ ê³ ì •\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„°ì…‹ ì¤€ë¹„: California Housing\n",
    "\n",
    "ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ê°€ê²© ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. (Boston Housingì€ ìœ¤ë¦¬ì  ë¬¸ì œë¡œ sklearnì—ì„œ ì œê±°ë¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "df['MedHouseVal'] = housing.target  # ì¤‘ê°„ ì£¼íƒ ê°€ê²© (ë‹¨ìœ„: $100,000)\n",
    "\n",
    "print(\"ë°ì´í„° í¬ê¸°:\", df.shape)\n",
    "print(\"\\nì»¬ëŸ¼ ì„¤ëª…:\")\n",
    "print(\"- MedInc: ì¤‘ê°„ ì†Œë“\")\n",
    "print(\"- HouseAge: ì£¼íƒ ì—°ì‹\")\n",
    "print(\"- AveRooms: í‰ê·  ë°© ê°œìˆ˜\")\n",
    "print(\"- AveBedrms: í‰ê·  ì¹¨ì‹¤ ê°œìˆ˜\")\n",
    "print(\"- Population: ì§€ì—­ ì¸êµ¬\")\n",
    "print(\"- AveOccup: í‰ê·  ê±°ì£¼ì ìˆ˜\")\n",
    "print(\"- Latitude: ìœ„ë„\")\n",
    "print(\"- Longitude: ê²½ë„\")\n",
    "print(\"- MedHouseVal: ì¤‘ê°„ ì£¼íƒ ê°€ê²© (íƒ€ê²Ÿ, $100,000 ë‹¨ìœ„)\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ í†µê³„\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬ í™•ì¸\n",
    "fig = px.histogram(df, x='MedHouseVal', nbins=50, \n",
    "                   title='ì£¼íƒ ê°€ê²© ë¶„í¬ (ë‹¨ìœ„: $100,000)',\n",
    "                   labels={'MedHouseVal': 'ì¤‘ê°„ ì£¼íƒ ê°€ê²©'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬\n",
    "X = df.drop('MedHouseVal', axis=1)\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {X_train.shape[0]}ê°œ\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤ì¼€ì¼ë§ (ì„ í˜• ëª¨ë¸ìš©)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: ê¸°ì´ˆ - ì„ í˜• ëª¨ë¸\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 ì„ í˜• íšŒê·€ (Linear Regression)\n",
    "\n",
    "ì„ í˜• íšŒê·€ëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ íšŒê·€ ëª¨ë¸ë¡œ, íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ê°„ì˜ ì„ í˜• ê´€ê³„ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "$$y = w_1x_1 + w_2x_2 + ... + w_nx_n + b$$\n",
    "\n",
    "**ì¥ì **: í•´ì„ ê°€ëŠ¥, ë¹ ë¥¸ í•™ìŠµ  \n",
    "**ë‹¨ì **: ë¹„ì„ í˜• ê´€ê³„ í•™ìŠµ ë¶ˆê°€, ì´ìƒì¹˜ì— ë¯¼ê°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ í˜• íšŒê·€ ëª¨ë¸ í•™ìŠµ\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# ì„±ëŠ¥ í‰ê°€\n",
    "print(\"=== ì„ í˜• íšŒê·€ ì„±ëŠ¥ ===\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lr)):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_lr):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íšŒê·€ ê³„ìˆ˜ í™•ì¸ (íŠ¹ì„± ì¤‘ìš”ë„)\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': lr_model.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "fig = px.bar(coef_df, x='Coefficient', y='Feature', orientation='h',\n",
    "             title='ì„ í˜• íšŒê·€ ê³„ìˆ˜ (íŠ¹ì„± ì˜í–¥ë„)',\n",
    "             color='Coefficient', color_continuous_scale='RdBu')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: íšŒê·€ ê³„ìˆ˜ í•´ì„\n",
    "\n",
    "- **ì–‘ìˆ˜ ê³„ìˆ˜**: íŠ¹ì„±ì´ ì¦ê°€í•˜ë©´ ì£¼íƒ ê°€ê²©ë„ ì¦ê°€\n",
    "- **ìŒìˆ˜ ê³„ìˆ˜**: íŠ¹ì„±ì´ ì¦ê°€í•˜ë©´ ì£¼íƒ ê°€ê²© ê°ì†Œ\n",
    "- **ì ˆëŒ€ê°’ í¬ê¸°**: ì˜í–¥ë ¥ì˜ í¬ê¸° (ìŠ¤ì¼€ì¼ë§ í›„ ë¹„êµ ê°€ëŠ¥)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 Ridge Regression (L2 ì •ê·œí™”)\n",
    "\n",
    "RidgeëŠ” ê³„ìˆ˜ì˜ í¬ê¸°ì— í˜ë„í‹°ë¥¼ ë¶€ì—¬í•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•©ë‹ˆë‹¤.\n",
    "\n",
    "$$Loss = MSE + \\alpha \\sum w_i^2$$\n",
    "\n",
    "**alpha**: ì •ê·œí™” ê°•ë„ (í´ìˆ˜ë¡ ê³„ìˆ˜ê°€ ì‘ì•„ì§)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge ëª¨ë¸ í•™ìŠµ\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"=== Ridge Regression ì„±ëŠ¥ ===\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_ridge):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_ridge)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha ê°’ì— ë”°ë¥¸ ê³„ìˆ˜ ë³€í™” ì‹œê°í™”\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "coef_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train_scaled, y_train)\n",
    "    for i, col in enumerate(X.columns):\n",
    "        coef_results.append({\n",
    "            'alpha': alpha,\n",
    "            'Feature': col,\n",
    "            'Coefficient': ridge.coef_[i]\n",
    "        })\n",
    "\n",
    "coef_df = pd.DataFrame(coef_results)\n",
    "\n",
    "fig = px.line(coef_df, x='alpha', y='Coefficient', color='Feature',\n",
    "              title='Ridge: Alphaì— ë”°ë¥¸ ê³„ìˆ˜ ë³€í™”',\n",
    "              log_x=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: Ridge í™œìš© ì‹œì \n",
    "\n",
    "- **ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œ**: íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ê°€ ë†’ì„ ë•Œ\n",
    "- **ê³¼ì í•© ë°©ì§€**: í•™ìŠµ ë°ì´í„°ì— ê³¼í•˜ê²Œ ë§ì¶œ ë•Œ\n",
    "- **ì•ˆì •ì ì¸ ì˜ˆì¸¡**: ëª¨ë“  íŠ¹ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ê³„ìˆ˜ë§Œ ì¶•ì†Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 Lasso Regression (L1 ì •ê·œí™”)\n",
    "\n",
    "LassoëŠ” ê³„ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆì–´ **ìë™ íŠ¹ì„± ì„ íƒ** íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "$$Loss = MSE + \\alpha \\sum |w_i|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso ëª¨ë¸ í•™ìŠµ\n",
    "lasso_model = Lasso(alpha=0.01)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "y_pred_lasso = lasso_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"=== Lasso Regression ì„±ëŠ¥ ===\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_lasso):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lasso)):.4f}\")\n",
    "\n",
    "# 0ì´ ì•„ë‹Œ ê³„ìˆ˜ í™•ì¸\n",
    "non_zero = np.sum(lasso_model.coef_ != 0)\n",
    "print(f\"\\nì„ íƒëœ íŠ¹ì„± ìˆ˜: {non_zero}/{len(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso ê³„ìˆ˜ ì‹œê°í™”\n",
    "lasso_coef_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': lasso_model.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "fig = px.bar(lasso_coef_df, x='Coefficient', y='Feature', orientation='h',\n",
    "             title='Lasso ê³„ìˆ˜ (0ì¸ íŠ¹ì„± = ì„ íƒë˜ì§€ ì•ŠìŒ)',\n",
    "             color='Coefficient', color_continuous_scale='RdBu')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: Lassoë¡œ í•µì‹¬ ë³€ìˆ˜ ì¶”ì¶œ\n",
    "\n",
    "- 100ê°œ íŠ¹ì„± ì¤‘ í•µì‹¬ 10ê°œë§Œ ì„ íƒ\n",
    "- ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ ìë™ ì œê±°\n",
    "- ëª¨ë¸ í•´ì„ ìš©ì´ì„± ì¦ê°€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 ElasticNet (L1 + L2)\n",
    "\n",
    "Ridgeì™€ Lassoì˜ ì¥ì ì„ ê²°í•©í•©ë‹ˆë‹¤.\n",
    "\n",
    "$$Loss = MSE + \\alpha \\cdot l1\\_ratio \\cdot \\sum|w_i| + \\alpha \\cdot (1-l1\\_ratio) \\cdot \\sum w_i^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet ëª¨ë¸ í•™ìŠµ\n",
    "elastic_model = ElasticNet(alpha=0.01, l1_ratio=0.5)  # l1_ratio: L1 ë¹„ìœ¨\n",
    "elastic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "y_pred_elastic = elastic_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"=== ElasticNet ì„±ëŠ¥ ===\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_elastic):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_elastic)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.5 íšŒê·€ í‰ê°€ ì§€í‘œ ì •ë¦¬\n",
    "\n",
    "| ì§€í‘œ | ìˆ˜ì‹ | í•´ì„ |\n",
    "|------|------|------|\n",
    "| MSE | $\\frac{1}{n}\\sum(y_i - \\hat{y}_i)^2$ | í‰ê·  ì œê³± ì˜¤ì°¨ (ì´ìƒì¹˜ì— ë¯¼ê°) |\n",
    "| RMSE | $\\sqrt{MSE}$ | ì›ë˜ ë‹¨ìœ„ë¡œ í•´ì„ ê°€ëŠ¥ |\n",
    "| MAE | $\\frac{1}{n}\\sum|y_i - \\hat{y}_i|$ | í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (ì´ìƒì¹˜ì— ê°•ê±´) |\n",
    "| R2 | $1 - \\frac{SS_{res}}{SS_{tot}}$ | ì„¤ëª…ë ¥ (0~1, ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‰ê°€ ì§€í‘œ í•¨ìˆ˜ ì •ì˜\n",
    "def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"íšŒê·€ ëª¨ë¸ í‰ê°€ ì§€í‘œ ê³„ì‚°\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2\n",
    "    }\n",
    "\n",
    "# ì„ í˜• ëª¨ë¸ ë¹„êµ\n",
    "linear_results = [\n",
    "    evaluate_model(y_test, y_pred_lr, \"Linear Regression\"),\n",
    "    evaluate_model(y_test, y_pred_ridge, \"Ridge\"),\n",
    "    evaluate_model(y_test, y_pred_lasso, \"Lasso\"),\n",
    "    evaluate_model(y_test, y_pred_elastic, \"ElasticNet\")\n",
    "]\n",
    "\n",
    "linear_df = pd.DataFrame(linear_results)\n",
    "linear_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: ì‹¬í™” - ë¹„ì„ í˜• ëª¨ë¸ & íŠœë‹\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 Decision Tree Regressor\n",
    "\n",
    "íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì€ ë¹„ì„ í˜• ê´€ê³„ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree ëª¨ë¸ (ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”)\n",
    "dt_model = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "print(\"=== Decision Tree ì„±ëŠ¥ ===\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_dt):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_dt)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': dt_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "fig = px.bar(importance_df, x='Importance', y='Feature', orientation='h',\n",
    "             title='Decision Tree íŠ¹ì„± ì¤‘ìš”ë„')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 Random Forest Regressor\n",
    "\n",
    "ì—¬ëŸ¬ íŠ¸ë¦¬ì˜ ì•™ìƒë¸”ë¡œ ë” ì•ˆì •ì ì¸ ì˜ˆì¸¡ì„ ì œê³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest ëª¨ë¸\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,  # íŠ¸ë¦¬ ê°œìˆ˜\n",
    "    max_depth=15,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # ë³‘ë ¬ ì²˜ë¦¬\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"=== Random Forest ì„±ëŠ¥ ===\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rf)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest íŠ¹ì„± ì¤‘ìš”ë„\n",
    "rf_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "fig = px.bar(rf_importance_df, x='Importance', y='Feature', orientation='h',\n",
    "             title='Random Forest íŠ¹ì„± ì¤‘ìš”ë„')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: Random Forest ì¥ì \n",
    "\n",
    "- **ê³¼ì í•© ë°©ì§€**: ì—¬ëŸ¬ íŠ¸ë¦¬ì˜ í‰ê· ìœ¼ë¡œ ë¶„ì‚° ê°ì†Œ\n",
    "- **íŠ¹ì„± ì„ íƒ ë¶ˆí•„ìš”**: ìë™ìœ¼ë¡œ ì¤‘ìš” íŠ¹ì„± í•™ìŠµ\n",
    "- **ì´ìƒì¹˜ì— ê°•ê±´**: íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ íŠ¹ì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 Gradient Boosting (XGBoost, LightGBM)\n",
    "\n",
    "ìˆœì°¨ì ìœ¼ë¡œ íŠ¸ë¦¬ë¥¼ í•™ìŠµí•˜ë©° ì´ì „ ëª¨ë¸ì˜ ì˜¤ì°¨ë¥¼ ë³´ì™„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost ëª¨ë¸\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"=== XGBoost ì„±ëŠ¥ ===\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_xgb)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM ëª¨ë¸\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "print(\"=== LightGBM ì„±ëŠ¥ ===\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_lgb):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lgb)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ XGBoost vs LightGBM ë¹„êµ\n",
    "\n",
    "| íŠ¹ì„± | XGBoost | LightGBM |\n",
    "|------|---------|----------|\n",
    "| íŠ¸ë¦¬ ì„±ì¥ | Level-wise | Leaf-wise |\n",
    "| ì†ë„ | ë¹ ë¦„ | ë” ë¹ ë¦„ |\n",
    "| ë©”ëª¨ë¦¬ | ë³´í†µ | íš¨ìœ¨ì  |\n",
    "| ëŒ€ìš©ëŸ‰ | ì í•© | ë§¤ìš° ì í•© |\n",
    "| ì •í™•ë„ | ë†’ìŒ | ë†’ìŒ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 CatBoost (Categorical Boosting)\n",
    "\n",
    "**CatBoost**ëŠ” Yandexì—ì„œ ê°œë°œí•œ Gradient Boosting ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, **ë²”ì£¼í˜• íŠ¹ì„±ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬**í•˜ëŠ” ê²ƒì´ íŠ¹ì§•ì…ë‹ˆë‹¤.\n",
    "\n",
    "### CatBoostì˜ í•µì‹¬ íŠ¹ì§•\n",
    "\n",
    "1. **Ordered Target Statistics**: ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”© ì‹œ íƒ€ê²Ÿ ëˆ„ìˆ˜(Target Leakage) ë°©ì§€\n",
    "2. **ë²”ì£¼í˜• ìë™ ì²˜ë¦¬**: ì›-í•« ì¸ì½”ë”© ì—†ì´ `cat_features` ì§€ì •ë§Œìœ¼ë¡œ ì²˜ë¦¬\n",
    "3. **ëŒ€ì¹­ íŠ¸ë¦¬(Oblivious Trees)**: ëª¨ë“  ë…¸ë“œê°€ ë™ì¼ ì¡°ê±´ìœ¼ë¡œ ë¶„í•  â†’ ë¹ ë¥¸ ì˜ˆì¸¡ ì†ë„\n",
    "4. **ê³¼ì í•© ë°©ì§€**: ê¸°ë³¸ì ìœ¼ë¡œ ê°•ë ¥í•œ ì •ê·œí™” ë‚´ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost ëª¨ë¸\n",
    "cat_model = cb.CatBoostRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    verbose=0  # ì¶œë ¥ ìˆ¨ê¹€\n",
    ")\n",
    "cat_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cat = cat_model.predict(X_test)\n",
    "\n",
    "print(\"=== CatBoost ì„±ëŠ¥ ===\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_cat):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_cat)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ë¶€ìŠ¤íŒ… 3ëŒ€ì¥ ë¹„êµ: XGBoost vs LightGBM vs CatBoost\n",
    "\n",
    "| íŠ¹ì„± | XGBoost | LightGBM | CatBoost |\n",
    "|------|---------|----------|----------|\n",
    "| **ê°œë°œì‚¬** | DMLC | Microsoft | Yandex |\n",
    "| **íŠ¸ë¦¬ ì„±ì¥** | Level-wise | Leaf-wise | Symmetric (Oblivious) |\n",
    "| **ë²”ì£¼í˜• ì²˜ë¦¬** | ì§ì ‘ ì¸ì½”ë”© í•„ìš” | ì§ì ‘ ì¸ì½”ë”© í•„ìš” | **ìë™ ì²˜ë¦¬** |\n",
    "| **ì†ë„** | ë¹ ë¦„ | **ê°€ì¥ ë¹ ë¦„** | ë³´í†µ |\n",
    "| **ê³¼ì í•© ë°©ì§€** | ì •ê·œí™” íŒŒë¼ë¯¸í„° | ì •ê·œí™” íŒŒë¼ë¯¸í„° | **ê¸°ë³¸ ë‚´ì¥** |\n",
    "| **GPU ì§€ì›** | âœ… | âœ… | âœ… |\n",
    "| **í•µì‹¬ ì¥ì ** | ì•ˆì •ì„±, ë²”ìš©ì„± | ì†ë„, ë©”ëª¨ë¦¬ íš¨ìœ¨ | ë²”ì£¼í˜• ìë™ ì²˜ë¦¬ |\n",
    "| **ì¶”ì²œ ìƒí™©** | ì¼ë°˜ì  ì„ íƒ | ëŒ€ìš©ëŸ‰ ë°ì´í„° | ë²”ì£¼í˜• íŠ¹ì„± ë§ì„ ë•Œ |\n",
    "\n",
    "> **ì‹¤ë¬´ íŒ**: \n",
    "> - ë²”ì£¼í˜• íŠ¹ì„±ì´ ë§ë‹¤ë©´ â†’ **CatBoost** ìš°ì„  ì‹œë„\n",
    "> - ë°ì´í„°ê°€ ë§¤ìš° í¬ë‹¤ë©´ â†’ **LightGBM** ì¶”ì²œ\n",
    "> - ì•ˆì •ì ì¸ ì„±ëŠ¥ì´ í•„ìš”í•˜ë‹¤ë©´ â†’ **XGBoost** ì„ íƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.5 í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "\n",
    "### GridSearchCV: ëª¨ë“  ì¡°í•© íƒìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV ì˜ˆì œ (Random Forest)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "rf_base = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    rf_base,\n",
    "    param_grid,\n",
    "    cv=3,  # 3-fold CV\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nìµœì  íŒŒë¼ë¯¸í„°:\", grid_search.best_params_)\n",
    "print(f\"ìµœì  CV RMSE: {np.sqrt(-grid_search.best_score_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch ê²°ê³¼ ì‹œê°í™”\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results['RMSE'] = np.sqrt(-cv_results['mean_test_score'])\n",
    "\n",
    "fig = px.scatter(cv_results, \n",
    "                 x='param_max_depth', \n",
    "                 y='RMSE',\n",
    "                 color='param_n_estimators',\n",
    "                 size='param_min_samples_split',\n",
    "                 title='GridSearchCV ê²°ê³¼: íŒŒë¼ë¯¸í„°ë³„ RMSE',\n",
    "                 labels={'param_max_depth': 'max_depth', 'param_n_estimators': 'n_estimators'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV: ë¬´ì‘ìœ„ íƒìƒ‰ (ëŒ€ê·œëª¨ íƒìƒ‰ì— íš¨ìœ¨ì )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# RandomizedSearchCV (XGBoost)\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': randint(3, 15),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "xgb_base = xgb.XGBRegressor(random_state=42, verbosity=0)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb_base,\n",
    "    param_dist,\n",
    "    n_iter=20,  # íƒìƒ‰ íšŸìˆ˜\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nìµœì  íŒŒë¼ë¯¸í„°:\", random_search.best_params_)\n",
    "print(f\"ìµœì  CV RMSE: {np.sqrt(-random_search.best_score_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì  ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡\n",
    "best_xgb = random_search.best_estimator_\n",
    "y_pred_best = best_xgb.predict(X_test)\n",
    "\n",
    "print(\"=== íŠœë‹ëœ XGBoost ì„±ëŠ¥ ===\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_best):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_best)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.6 ëª¨ë¸ ë¹„êµ ì¢…í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  ëª¨ë¸ ê²°ê³¼ ì¢…í•©\n",
    "all_results = [\n",
    "    evaluate_model(y_test, y_pred_lr, \"Linear Regression\"),\n",
    "    evaluate_model(y_test, y_pred_ridge, \"Ridge\"),\n",
    "    evaluate_model(y_test, y_pred_lasso, \"Lasso\"),\n",
    "    evaluate_model(y_test, y_pred_elastic, \"ElasticNet\"),\n",
    "    evaluate_model(y_test, y_pred_dt, \"Decision Tree\"),\n",
    "    evaluate_model(y_test, y_pred_rf, \"Random Forest\"),\n",
    "    evaluate_model(y_test, y_pred_xgb, \"XGBoost\"),\n",
    "    evaluate_model(y_test, y_pred_lgb, \"LightGBM\"),\n",
    "    evaluate_model(y_test, y_pred_cat, \"CatBoost\"),\n",
    "    evaluate_model(y_test, y_pred_best, \"XGBoost (Tuned)\")\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(all_results).sort_values('RMSE')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ë¹„êµ ì‹œê°í™”\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['RMSE (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)', 'R2 Score (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)'])\n",
    "\n",
    "# RMSE ë°” ì°¨íŠ¸\n",
    "fig.add_trace(\n",
    "    go.Bar(x=results_df['Model'], y=results_df['RMSE'], name='RMSE',\n",
    "           marker_color='indianred'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# R2 ë°” ì°¨íŠ¸\n",
    "fig.add_trace(\n",
    "    go.Bar(x=results_df['Model'], y=results_df['R2'], name='R2',\n",
    "           marker_color='seagreen'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(title='íšŒê·€ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ', height=500, showlegend=False)\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ vs ì‹¤ì œ ì‚°ì ë„ (ìµœê³  ì„±ëŠ¥ ëª¨ë¸)\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "\n",
    "# ì˜ˆì¸¡ê°’ ì„ íƒ\n",
    "pred_map = {\n",
    "    'Linear Regression': y_pred_lr,\n",
    "    'Ridge': y_pred_ridge,\n",
    "    'Lasso': y_pred_lasso,\n",
    "    'ElasticNet': y_pred_elastic,\n",
    "    'Decision Tree': y_pred_dt,\n",
    "    'Random Forest': y_pred_rf,\n",
    "    'XGBoost': y_pred_xgb,\n",
    "    'LightGBM': y_pred_lgb,\n",
    "    'CatBoost': y_pred_cat,\n",
    "    'XGBoost (Tuned)': y_pred_best\n",
    "}\n",
    "\n",
    "best_pred = pred_map[best_model_name]\n",
    "\n",
    "fig = px.scatter(x=y_test, y=best_pred, opacity=0.3,\n",
    "                 title=f'{best_model_name}: ì‹¤ì œ vs ì˜ˆì¸¡',\n",
    "                 labels={'x': 'ì‹¤ì œ ê°€ê²©', 'y': 'ì˜ˆì¸¡ ê°€ê²©'})\n",
    "\n",
    "# ëŒ€ê°ì„  ì¶”ê°€ (ì™„ë²½í•œ ì˜ˆì¸¡ ì„ )\n",
    "fig.add_trace(go.Scatter(x=[0, 5], y=[0, 5], mode='lines',\n",
    "                         line=dict(color='red', dash='dash'),\n",
    "                         name='Perfect'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ íŒ: ëª¨ë¸ ì„ íƒ ê¸°ì¤€\n",
    "\n",
    "1. **ì„±ëŠ¥ ìš°ì„ **: RMSE/R2ê°€ ê°€ì¥ ì¤‘ìš”í•˜ë©´ XGBoost/LightGBM\n",
    "2. **í•´ì„ í•„ìš”**: ë¹„ì¦ˆë‹ˆìŠ¤ ì´í•´ í•„ìš”í•˜ë©´ ì„ í˜• íšŒê·€\n",
    "3. **ì†ë„ ì¤‘ìš”**: ì‹¤ì‹œê°„ ì˜ˆì¸¡ì´ë©´ ê°„ë‹¨í•œ ëª¨ë¸\n",
    "4. **ê· í˜•ì **: Random Forestê°€ ì¢‹ì€ ì„ íƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ ì‹¤ìŠµ í€´ì¦ˆ\n",
    "\n",
    "**ë‚œì´ë„**: â­ (ì‰¬ì›€) ~ â­â­â­â­â­ (ì–´ë ¤ì›€)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. ì„ í˜• íšŒê·€ ê¸°ë³¸ â­\n",
    "\n",
    "**ë¬¸ì œ**: LinearRegression ëª¨ë¸ì„ í•™ìŠµí•˜ê³  R2 ìŠ¤ì½”ì–´ë¥¼ ê³„ì‚°í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# X_train, X_test, y_train, y_testëŠ” ì´ë¯¸ ì¤€ë¹„ë¨\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Ridge ì •ê·œí™” â­\n",
    "\n",
    "**ë¬¸ì œ**: alpha=10ì¸ Ridge ëª¨ë¸ì„ í•™ìŠµí•˜ê³  RMSEë¥¼ ê³„ì‚°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Lasso íŠ¹ì„± ì„ íƒ â­â­\n",
    "\n",
    "**ë¬¸ì œ**: alpha=0.1ì¸ Lasso ëª¨ë¸ì„ í•™ìŠµí•˜ê³ , 0ì´ ì•„ë‹Œ ê³„ìˆ˜ì˜ ê°œìˆ˜ë¥¼ ì¶œë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Random Forest í•™ìŠµ â­â­\n",
    "\n",
    "**ë¬¸ì œ**: n_estimators=50, max_depth=10ì¸ Random Forestë¥¼ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ í‰ê°€í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. íŠ¹ì„± ì¤‘ìš”ë„ ì¶”ì¶œ â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Random Forestì˜ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ DataFrameìœ¼ë¡œ ë§Œë“¤ê³  ìƒìœ„ 3ê°œë¥¼ ì¶œë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. XGBoost í•™ìŠµ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: learning_rate=0.05, max_depth=8ì¸ XGBoost ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ í‰ê°€í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. LightGBM í•™ìŠµ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: n_estimators=200, num_leaves=31ì¸ LightGBM ëª¨ë¸ì„ í•™ìŠµí•˜ê³  R2ë¥¼ ê³„ì‚°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. GridSearchCV ì‹¤ìŠµ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Ridgeì˜ alphaë¥¼ [0.01, 0.1, 1, 10, 100] ì¤‘ì—ì„œ GridSearchCVë¡œ ìµœì í™”í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. RandomizedSearchCV ì‹¤ìŠµ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Random Forestì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ RandomizedSearchCVë¡œ ìµœì í™”í•˜ì„¸ìš”.\n",
    "- n_estimators: 50~200\n",
    "- max_depth: 5~20\n",
    "- n_iter=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. ëª¨ë¸ ë¹„êµ ì¢…í•© â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: 3ê°œ ì´ìƒì˜ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  RMSEì™€ R2ë¥¼ ë¹„êµí•˜ëŠ” DataFrameì„ ë§Œë“  í›„, Plotlyë¡œ ì‹œê°í™”í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11. CatBoost ê¸°ë³¸ í•™ìŠµ â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: CatBoostRegressorë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒê·€ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.\n",
    "- n_estimators=100, max_depth=6, learning_rate=0.1\n",
    "- R2 ìŠ¤ì½”ì–´ì™€ RMSEë¥¼ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "from catboost import CatBoostRegressor\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q12. ë¶€ìŠ¤íŒ… 3ëŒ€ì¥ ë¹„êµ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: XGBoost, LightGBM, CatBoost ì„¸ ê°€ì§€ ëª¨ë¸ì„ ëª¨ë‘ í•™ìŠµí•˜ê³ , ì„±ëŠ¥(RMSE, R2)ì„ ë¹„êµí•˜ëŠ” DataFrameì„ ë§Œë“œì„¸ìš”.\n",
    "- ë™ì¼í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‚¬ìš©: n_estimators=100, max_depth=6, learning_rate=0.1\n",
    "- ì–´ë–¤ ëª¨ë¸ì´ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ë‚˜ìš”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "### Part 1: ì„ í˜• ëª¨ë¸ í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ëª¨ë¸ | íŠ¹ì§• | ì–¸ì œ ì‚¬ìš©? |\n",
    "|------|------|------------|\n",
    "| Linear Regression | ê°€ì¥ ê¸°ë³¸, í•´ì„ ìš©ì´ | ê¸°ì¤€ ëª¨ë¸, ì„ í˜• ê´€ê³„ |\n",
    "| Ridge (L2) | ê³„ìˆ˜ ì¶•ì†Œ | ë‹¤ì¤‘ê³µì„ ì„±, ê³¼ì í•© ë°©ì§€ |\n",
    "| Lasso (L1) | íŠ¹ì„± ì„ íƒ | í•µì‹¬ ë³€ìˆ˜ ì¶”ì¶œ |\n",
    "| ElasticNet | L1+L2 ì¡°í•© | Ridgeì™€ Lasso ì¥ì  ê²°í•© |\n",
    "\n",
    "### Part 2: ë¹„ì„ í˜• ëª¨ë¸ & íŠœë‹ ìš”ì•½\n",
    "\n",
    "| ëª¨ë¸ | íŠ¹ì§• | í•µì‹¬ íŒŒë¼ë¯¸í„° |\n",
    "|------|------|---------------|\n",
    "| Decision Tree | ë¹„ì„ í˜• í•™ìŠµ | max_depth, min_samples_split |\n",
    "| Random Forest | ì•™ìƒë¸”, ì•ˆì •ì  | n_estimators, max_depth |\n",
    "| XGBoost | ê³ ì„±ëŠ¥, Kaggle ì¸ê¸° | learning_rate, max_depth |\n",
    "| LightGBM | ë¹ ë¥¸ ì†ë„, ëŒ€ìš©ëŸ‰ | num_leaves, learning_rate |\n",
    "| CatBoost | ë²”ì£¼í˜• ìë™ ì²˜ë¦¬ | cat_features, learning_rate |\n",
    "\n",
    "### ğŸ’¡ ë¶€ìŠ¤íŒ… 3ëŒ€ì¥ ì„ íƒ ê°€ì´ë“œ\n",
    "\n",
    "| ìƒí™© | ì¶”ì²œ ëª¨ë¸ |\n",
    "|------|----------|\n",
    "| ë²”ì£¼í˜• íŠ¹ì„±ì´ ë§ì„ ë•Œ | **CatBoost** |\n",
    "| ëŒ€ìš©ëŸ‰ ë°ì´í„° | **LightGBM** |\n",
    "| ì•ˆì •ì ì¸ ì„±ëŠ¥ í•„ìš” | **XGBoost** |\n",
    "| ë¹ ë¥¸ ì‹œì‘/ì¼ë°˜ì ì¸ ê²½ìš° | XGBoost ë˜ëŠ” LightGBM |\n",
    "\n",
    "### ğŸ’¡ ì‹¤ë¬´ íŒ\n",
    "\n",
    "1. **ê¸°ì¤€ ëª¨ë¸ë¶€í„°**: Linear Regressionìœ¼ë¡œ ì‹œì‘í•˜ì—¬ baseline ì„¤ì •\n",
    "2. **ìŠ¤ì¼€ì¼ë§ ì£¼ì˜**: ì„ í˜• ëª¨ë¸ì€ ìŠ¤ì¼€ì¼ë§ í•„ìˆ˜, íŠ¸ë¦¬ ëª¨ë¸ì€ ë¶ˆí•„ìš”\n",
    "3. **ê³¼ì í•© ë°©ì§€**: ì •ê·œí™”(Ridge/Lasso) ë˜ëŠ” íŠ¸ë¦¬ ê¹Šì´ ì œí•œ\n",
    "4. **êµì°¨ ê²€ì¦**: GridSearchCV/RandomizedSearchCV í•„ìˆ˜\n",
    "5. **ì•™ìƒë¸” íš¨ê³¼**: ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ Random Forest, Boostingì´ ëŒ€ì²´ë¡œ ìš°ìˆ˜\n",
    "6. **CatBoost í™œìš©**: ë²”ì£¼í˜• íŠ¹ì„± ë§ìœ¼ë©´ ì¸ì½”ë”© ì—†ì´ ë°”ë¡œ ì‚¬ìš©"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
