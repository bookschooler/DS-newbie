{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day12_1: ë°ì´í„° ì „ì²˜ë¦¬ for ML - ì •ë‹µ ë…¸íŠ¸ë¶\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ Day12_1 ì‹¤ìŠµ í€´ì¦ˆì˜ ì •ë‹µê³¼ ìƒì„¸ í•´ì„¤ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, MinMaxScaler, RobustScaler,\n",
    "    LabelEncoder, OneHotEncoder, PolynomialFeatures\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Titanic ë°ì´í„° ë¡œë“œ\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    titanic = sns.load_dataset('titanic')\n",
    "except:\n",
    "    url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "    titanic = pd.read_csv(url)\n",
    "    titanic.columns = titanic.columns.str.lower()\n",
    "\n",
    "print(\"í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q1. ë°ì´í„° ë¶„í•  â­\n",
    "\n",
    "### ë¬¸ì œ\n",
    "ë‹¤ìŒ ë°ì´í„°ë¥¼ 70% í›ˆë ¨, 30% í…ŒìŠ¤íŠ¸ë¡œ ë¶„í• í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "X = np.arange(100).reshape(50, 2)\n",
    "y = np.random.randint(0, 2, 50)\n",
    "```\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**: random_state=42, stratify ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "np.random.seed(42)  # ì¬í˜„ì„±ì„ ìœ„í•´ ê³ ì •\n",
    "X = np.arange(100).reshape(50, 2)\n",
    "y = np.random.randint(0, 2, 50)\n",
    "\n",
    "# train_test_splitìœ¼ë¡œ 70:30 ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,       # 30% í…ŒìŠ¤íŠ¸\n",
    "    random_state=42,     # ì¬í˜„ì„±\n",
    "    stratify=y           # í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(f\"ì „ì²´ ë°ì´í„°: {len(X)}ê°œ\")\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°: {len(X_train)}ê°œ ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ ({len(X_test)/len(X)*100:.0f}%)\")\n",
    "print(f\"\\ní´ë˜ìŠ¤ ë¹„ìœ¨ í™•ì¸:\")\n",
    "print(f\"  ì „ì²´: {y.mean():.3f}\")\n",
    "print(f\"  í›ˆë ¨: {y_train.mean():.3f}\")\n",
    "print(f\"  í…ŒìŠ¤íŠ¸: {y_test.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert len(X_train) == 35, \"í›ˆë ¨ ë°ì´í„°ëŠ” 35ê°œì—¬ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert len(X_test) == 15, \"í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” 15ê°œì—¬ì•¼ í•©ë‹ˆë‹¤\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- `train_test_split()`ì€ sklearnì˜ ë°ì´í„° ë¶„í•  í•¨ìˆ˜ì…ë‹ˆë‹¤\n",
    "- `test_size=0.3`ì€ ì „ì²´ì˜ 30%ë¥¼ í…ŒìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•œë‹¤ëŠ” ì˜ë¯¸\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- `random_state`: ë™ì¼í•œ ë¶„í•  ê²°ê³¼ë¥¼ ì¬í˜„í•˜ê¸° ìœ„í•œ ì‹œë“œê°’\n",
    "- `stratify`: íƒ€ê²Ÿ ë³€ìˆ˜ì˜ í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©° ë¶„í• \n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- `train_size=0.7`ë¡œë„ ê°™ì€ ê²°ê³¼\n",
    "- `shuffle=True`ê°€ ê¸°ë³¸ê°’ (ë°ì´í„° ì„ê¸°)\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- stratifyì— Xë¥¼ ë„£ëŠ” ì‹¤ìˆ˜ (yë¥¼ ë„£ì–´ì•¼ í•¨)\n",
    "- random_stateë¥¼ ìƒëµí•˜ë©´ ë§¤ë²ˆ ë‹¤ë¥¸ ê²°ê³¼\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë¶ˆê· í˜• ë°ì´í„°ì—ì„œëŠ” ë°˜ë“œì‹œ stratify ì‚¬ìš©\n",
    "- ì¼ë°˜ì ìœ¼ë¡œ 70:30 ë˜ëŠ” 80:20 ë¶„í• "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q2. StandardScaler ì ìš© â­\n",
    "\n",
    "### ë¬¸ì œ\n",
    "ë‹¤ìŒ ë°ì´í„°ì— StandardScalerë¥¼ ì ìš©í•˜ê³ , ë³€í™˜ í›„ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "data = np.array([[10, 1000], [20, 2000], [30, 3000], [40, 4000]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "data = np.array([[10, 1000], [20, 2000], [30, 3000], [40, 4000]])\n",
    "\n",
    "# StandardScaler ìƒì„± ë° ì ìš©\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(\"ì›ë³¸ ë°ì´í„°:\")\n",
    "print(data)\n",
    "print(f\"\\nì›ë³¸ í‰ê· : {data.mean(axis=0)}\")\n",
    "print(f\"ì›ë³¸ í‘œì¤€í¸ì°¨: {data.std(axis=0)}\")\n",
    "\n",
    "print(\"\\në³€í™˜ëœ ë°ì´í„°:\")\n",
    "print(data_scaled.round(3))\n",
    "print(f\"\\në³€í™˜ í›„ í‰ê· : {data_scaled.mean(axis=0).round(10)}\")\n",
    "print(f\"ë³€í™˜ í›„ í‘œì¤€í¸ì°¨: {data_scaled.std(axis=0).round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert np.allclose(data_scaled.mean(axis=0), [0, 0]), \"í‰ê· ì´ 0ì´ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert np.allclose(data_scaled.std(axis=0), [1, 1]), \"í‘œì¤€í¸ì°¨ê°€ 1ì´ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- StandardScalerëŠ” z-score í‘œì¤€í™”ë¥¼ ìˆ˜í–‰\n",
    "- ê° íŠ¹ì„±ì—ì„œ í‰ê· ì„ ë¹¼ê³  í‘œì¤€í¸ì°¨ë¡œ ë‚˜ëˆ”\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ê³µì‹: z = (x - mean) / std\n",
    "- ê²°ê³¼: í‰ê·  0, í‘œì¤€í¸ì°¨ 1\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- ìˆ˜ë™ ê³„ì‚°: `(data - data.mean(axis=0)) / data.std(axis=0)`\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- fitê³¼ transformì„ ë¶„ë¦¬í•˜ì§€ ì•ŠìŒ (í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë¬¸ì œ)\n",
    "- ì „ì²´ ë°ì´í„°ë¡œ fití•˜ê³  í›ˆë ¨/í…ŒìŠ¤íŠ¸ ëª¨ë‘ transform (Data Leakage)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë¡œì§€ìŠ¤í‹± íšŒê·€, SVM ë“±ì— í•„ìˆ˜\n",
    "- íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì€ ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q3. MinMaxScaler ë²”ìœ„ ì§€ì • â­â­\n",
    "\n",
    "### ë¬¸ì œ\n",
    "MinMaxScalerë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ -1 ~ 1 ë²”ìœ„ë¡œ ë³€í™˜í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "values = np.array([[0], [25], [50], [75], [100]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "values = np.array([[0], [25], [50], [75], [100]])\n",
    "\n",
    "# MinMaxScalerë¡œ -1 ~ 1 ë²”ìœ„ ì§€ì •\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "values_scaled = scaler.fit_transform(values)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(\"ì›ë³¸ -> ë³€í™˜:\")\n",
    "for orig, scaled in zip(values.flatten(), values_scaled.flatten()):\n",
    "    print(f\"  {orig:3d} -> {scaled:6.2f}\")\n",
    "\n",
    "print(f\"\\nìµœì†Ÿê°’: {values_scaled.min():.2f}\")\n",
    "print(f\"ìµœëŒ“ê°’: {values_scaled.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert values_scaled.min() == -1, \"ìµœì†Ÿê°’ì´ -1ì´ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert values_scaled.max() == 1, \"ìµœëŒ“ê°’ì´ 1ì´ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert values_scaled[2][0] == 0, \"ì¤‘ê°„ê°’(50)ì´ 0ì´ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- MinMaxScalerì˜ `feature_range` íŒŒë¼ë¯¸í„°ë¡œ ë³€í™˜ ë²”ìœ„ ì§€ì •\n",
    "- ê¸°ë³¸ê°’ì€ (0, 1)\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ê³µì‹: x_scaled = (x - min) / (max - min) * (max_range - min_range) + min_range\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- ìˆ˜ë™ ê³„ì‚° ê°€ëŠ¥í•˜ë‚˜ ì½”ë“œê°€ ë³µì¡í•´ì§\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- feature_rangeë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬ (íŠœí”Œì´ì–´ì•¼ í•¨)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì‹ ê²½ë§ì—ì„œ tanh í™œì„±í™” í•¨ìˆ˜ ì‚¬ìš© ì‹œ -1~1 ë²”ìœ„ ìœ ìš©\n",
    "- ì´ë¯¸ì§€ ë°ì´í„°ëŠ” ë³´í†µ 0~1 ë²”ìœ„ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q4. LabelEncoder ì ìš© â­â­\n",
    "\n",
    "### ë¬¸ì œ\n",
    "ë‹¤ìŒ ë“±ê¸‰ ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ì¸ì½”ë”©í•˜ê³ , ì—­ë³€í™˜ë„ í•´ë³´ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "grades = ['Bronze', 'Silver', 'Gold', 'Silver', 'Bronze', 'Gold']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "grades = ['Bronze', 'Silver', 'Gold', 'Silver', 'Bronze', 'Gold']\n",
    "\n",
    "# LabelEncoder ìƒì„± ë° ì ìš©\n",
    "le = LabelEncoder()\n",
    "grades_encoded = le.fit_transform(grades)\n",
    "\n",
    "print(\"í´ë˜ìŠ¤ ëª©ë¡:\", le.classes_)\n",
    "print(\"\\nì¸ì½”ë”© ê²°ê³¼:\")\n",
    "for orig, enc in zip(grades, grades_encoded):\n",
    "    print(f\"  {orig} -> {enc}\")\n",
    "\n",
    "# ì—­ë³€í™˜\n",
    "decoded = le.inverse_transform([0, 1, 2])\n",
    "print(f\"\\nì—­ë³€í™˜ [0,1,2] -> {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert len(le.classes_) == 3, \"3ê°œì˜ í´ë˜ìŠ¤ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert grades_encoded[0] == 0, \"BronzeëŠ” 0ì´ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert le.inverse_transform([1])[0] == 'Gold', \"1ì€ Goldë¡œ ì—­ë³€í™˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- LabelEncoderëŠ” ë¬¸ìì—´ì„ ì•ŒíŒŒë²³ ìˆœì„œë¡œ 0ë¶€í„° ì •ìˆ˜ ë§¤í•‘\n",
    "- Bronze(0) < Gold(1) < Silver(2)\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- í´ë˜ìŠ¤ê°€ ì•ŒíŒŒë²³ ìˆœìœ¼ë¡œ ì •ë ¬ë¨\n",
    "- `classes_` ì†ì„±ìœ¼ë¡œ ë§¤í•‘ í™•ì¸ ê°€ëŠ¥\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- OrdinalEncoder: ìˆœì„œë¥¼ ì§ì ‘ ì§€ì • ê°€ëŠ¥\n",
    "- ë”•ì…”ë„ˆë¦¬ ë§¤í•‘: `{'Bronze': 0, 'Silver': 1, 'Gold': 2}`\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ìˆœì„œê°€ ì¤‘ìš”í•œ ê²½ìš° ì•ŒíŒŒë²³ ìˆœ ì¸ì½”ë”©ì´ ì˜ë¯¸ ì—†ìŒ\n",
    "- ìƒˆë¡œìš´ ì¹´í…Œê³ ë¦¬ê°€ ë“±ì¥í•˜ë©´ ì—ëŸ¬ ë°œìƒ\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- íƒ€ê²Ÿ ë³€ìˆ˜ë‚˜ ì´ì§„ ë²”ì£¼ì— ì£¼ë¡œ ì‚¬ìš©\n",
    "- ìˆœì„œê°€ ìˆëŠ” ë²”ì£¼ëŠ” OrdinalEncoder ê¶Œì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q5. OneHotEncoder ì ìš© â­â­\n",
    "\n",
    "### ë¬¸ì œ\n",
    "ë‹¤ìŒ ìƒ‰ìƒ ë°ì´í„°ë¥¼ ì›-í•« ì¸ì½”ë”©í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "colors = np.array([['Red'], ['Blue'], ['Green'], ['Blue'], ['Red']])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "colors = np.array([['Red'], ['Blue'], ['Green'], ['Blue'], ['Red']])\n",
    "\n",
    "# OneHotEncoder ì ìš©\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "colors_encoded = ohe.fit_transform(colors)\n",
    "\n",
    "print(\"ì¹´í…Œê³ ë¦¬:\", ohe.categories_)\n",
    "print(\"íŠ¹ì„± ì´ë¦„:\", ohe.get_feature_names_out(['color']))\n",
    "print(\"\\nì›-í•« ì¸ì½”ë”© ê²°ê³¼:\")\n",
    "result_df = pd.DataFrame(\n",
    "    colors_encoded,\n",
    "    columns=ohe.get_feature_names_out(['color'])\n",
    ")\n",
    "result_df['ì›ë³¸'] = colors.flatten()\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert colors_encoded.shape == (5, 3), \"ê²°ê³¼ shapeì€ (5, 3)ì´ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert colors_encoded.sum() == 5, \"ê° í–‰ì— 1ì´ í•˜ë‚˜ì”© ìˆì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- OneHotEncoderëŠ” ê° ì¹´í…Œê³ ë¦¬ë¥¼ ë³„ë„ì˜ ì´ì§„ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜\n",
    "- sparse_output=Falseë¡œ ë°€ì§‘ ë°°ì—´ ë°˜í™˜\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- 3ê°œ ì¹´í…Œê³ ë¦¬ -> 3ê°œ ì»¬ëŸ¼\n",
    "- í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë§Œ 1, ë‚˜ë¨¸ì§€ 0\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- pandas: `pd.get_dummies(colors.flatten())`\n",
    "- drop='first'ë¡œ ë‹¤ì¤‘ê³µì„ ì„± ë°©ì§€ ê°€ëŠ¥\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- 2D ë°°ì—´ì´ ì•„ë‹Œ 1D ë°°ì—´ ì…ë ¥\n",
    "- sparse_output=Trueì¼ ë•Œ dense ì—°ì‚° ì‹œë„\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì„ í˜• ëª¨ë¸ì—ì„œëŠ” drop='first' ê¶Œì¥\n",
    "- íŠ¸ë¦¬ ëª¨ë¸ì€ ì›-í•«ë³´ë‹¤ íƒ€ê²Ÿ ì¸ì½”ë”©ì´ íš¨ê³¼ì ì¼ ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q6. PolynomialFeatures ìƒì„± â­â­â­\n",
    "\n",
    "### ë¬¸ì œ\n",
    "2ê°œì˜ íŠ¹ì„±ì—ì„œ 2ì°¨ ë‹¤í•­ íŠ¹ì„±ì„ ìƒì„±í•˜ê³ , íŠ¹ì„± ì´ë¦„ì„ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "```\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**: bias í•­ ì œì™¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# 2ì°¨ ë‹¤í•­ íŠ¹ì„± ìƒì„± (bias ì œì™¸)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# íŠ¹ì„± ì´ë¦„\n",
    "feature_names = poly.get_feature_names_out(['x1', 'x2'])\n",
    "print(\"íŠ¹ì„± ì´ë¦„:\", feature_names)\n",
    "print(f\"íŠ¹ì„± ìˆ˜: {len(feature_names)}\")\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(\"\\në‹¤í•­ íŠ¹ì„± ê²°ê³¼:\")\n",
    "result_df = pd.DataFrame(X_poly, columns=feature_names)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert X_poly.shape == (3, 5), \"ê²°ê³¼ shapeì€ (3, 5)ì—¬ì•¼ í•©ë‹ˆë‹¤: x1, x2, x1^2, x1*x2, x2^2\"\n",
    "assert 'x1 x2' in feature_names, \"ìƒí˜¸ì‘ìš© íŠ¹ì„± x1*x2ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- degree=2: ìµœëŒ€ 2ì°¨ ë‹¤í•­ì‹\n",
    "- include_bias=False: ìƒìˆ˜í•­(1) ì œì™¸\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- 2ê°œ íŠ¹ì„±, degree=2ì¼ ë•Œ: x1, x2, x1^2, x1*x2, x2^2 (5ê°œ)\n",
    "- ìƒí˜¸ì‘ìš© íŠ¹ì„±(x1*x2)ìœ¼ë¡œ ë¹„ì„ í˜• ê´€ê³„ í¬ì°©\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- interaction_only=True: ìƒí˜¸ì‘ìš©ë§Œ (x1, x2, x1*x2)\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- bias í¬í•¨ ì‹œ ìƒìˆ˜í•­ 1ì´ ì¶”ê°€ë¨ (ëŒ€ë¶€ë¶„ ë¶ˆí•„ìš”)\n",
    "- íŠ¹ì„± ìˆ˜ê°€ ê¸‰ê²©íˆ ì¦ê°€ (ì°¨ì›ì˜ ì €ì£¼)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë‹¤í•­ íšŒê·€ì—ì„œ ë¹„ì„ í˜• ê´€ê³„ ëª¨ë¸ë§\n",
    "- íŠ¹ì„±ì´ ë§ìœ¼ë©´ degree=2ë„ í­ë°œì  ì¦ê°€ ì£¼ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q7. ìˆ˜ì¹˜í˜• Pipeline êµ¬ì¶• â­â­â­\n",
    "\n",
    "### ë¬¸ì œ\n",
    "ê²°ì¸¡ì¹˜ ëŒ€ì¹˜(ì¤‘ì•™ê°’) -> í‘œì¤€í™” íŒŒì´í”„ë¼ì¸ì„ ë§Œë“¤ê³  ì ìš©í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "data_with_nan = np.array([[1, 10], [2, np.nan], [np.nan, 30], [4, 40]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "data_with_nan = np.array([[1, 10], [2, np.nan], [np.nan, 30], [4, 40]])\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # ì¤‘ì•™ê°’ ëŒ€ì¹˜\n",
    "    ('scaler', StandardScaler())                     # í‘œì¤€í™”\n",
    "])\n",
    "\n",
    "# ì ìš©\n",
    "data_transformed = numeric_pipeline.fit_transform(data_with_nan)\n",
    "\n",
    "print(\"ì›ë³¸ ë°ì´í„° (ê²°ì¸¡ì¹˜ í¬í•¨):\")\n",
    "print(data_with_nan)\n",
    "\n",
    "print(\"\\në³€í™˜ëœ ë°ì´í„°:\")\n",
    "print(data_transformed.round(3))\n",
    "\n",
    "print(f\"\\në³€í™˜ í›„ í‰ê· : {data_transformed.mean(axis=0).round(10)}\")\n",
    "print(f\"ë³€í™˜ í›„ í‘œì¤€í¸ì°¨: {data_transformed.std(axis=0).round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert not np.isnan(data_transformed).any(), \"ê²°ì¸¡ì¹˜ê°€ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert np.allclose(data_transformed.mean(axis=0), [0, 0], atol=1e-10), \"í‰ê· ì´ 0ì´ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- Pipelineì€ ì—¬ëŸ¬ ë³€í™˜ê¸°ë¥¼ ìˆœì„œëŒ€ë¡œ ì—°ê²°\n",
    "- (ì´ë¦„, ë³€í™˜ê¸°) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ìˆœì°¨ ì‹¤í–‰: imputer -> scaler\n",
    "- fit_transform()ìœ¼ë¡œ í•œ ë²ˆì— ì ìš©\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- make_pipeline(): ì´ë¦„ ìë™ ìƒì„±\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ìˆœì„œ ì˜ëª» (ìŠ¤ì¼€ì¼ë§ í›„ ê²°ì¸¡ì¹˜ ëŒ€ì¹˜ ë¶ˆê°€)\n",
    "- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— fit_transform ì‚¬ìš©\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- íŒŒì´í”„ë¼ì¸ì€ ì½”ë“œ ì¬ì‚¬ìš©ê³¼ ì‹¤ìˆ˜ ë°©ì§€ì— íš¨ê³¼ì \n",
    "- êµì°¨ ê²€ì¦ ì‹œ ìë™ìœ¼ë¡œ ê° Foldë§ˆë‹¤ fit/transform ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q8. K-Fold êµì°¨ ê²€ì¦ â­â­â­â­\n",
    "\n",
    "### ë¬¸ì œ\n",
    "Titanic ë°ì´í„°ë¡œ 5-Fold êµì°¨ ê²€ì¦ì„ ìˆ˜í–‰í•˜ê³ , ê° Foldì˜ ì •í™•ë„ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "- age, fare íŠ¹ì„± ì‚¬ìš© (ê²°ì¸¡ì¹˜ ì œê±°)\n",
    "- LogisticRegression ëª¨ë¸\n",
    "- StratifiedKFold ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "# ë°ì´í„° ì¤€ë¹„\n",
    "X_cv = titanic[['age', 'fare']].dropna()\n",
    "y_cv = titanic.loc[X_cv.index, 'survived']\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§ ì ìš©\n",
    "scaler = StandardScaler()\n",
    "X_cv_scaled = scaler.fit_transform(X_cv)\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# ë°©ë²• 1: cross_val_score ì‚¬ìš©\n",
    "cv_scores = cross_val_score(model, X_cv_scaled, y_cv, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"cross_val_score ê²°ê³¼:\")\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(f\"\\ní‰ê· : {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°©ë²• 2: StratifiedKFold ì§ì ‘ ì‚¬ìš©\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = []\n",
    "print(\"\\nStratifiedKFold ì§ì ‘ êµ¬í˜„:\")\n",
    "for fold, (train_idx, val_idx) in enumerate(skfold.split(X_cv_scaled, y_cv), 1):\n",
    "    X_train_fold = X_cv_scaled[train_idx]\n",
    "    X_val_fold = X_cv_scaled[val_idx]\n",
    "    y_train_fold = y_cv.iloc[train_idx]\n",
    "    y_val_fold = y_cv.iloc[val_idx]\n",
    "    \n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    score = model.score(X_val_fold, y_val_fold)\n",
    "    scores.append(score)\n",
    "    print(f\"  Fold {fold}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\ní‰ê· : {np.mean(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert len(cv_scores) == 5, \"5ê°œ Fold ê²°ê³¼ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert all(0 <= s <= 1 for s in cv_scores), \"ì •í™•ë„ëŠ” 0~1 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- cross_val_score: ê°„í¸í•œ êµì°¨ ê²€ì¦\n",
    "- StratifiedKFold: í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¶„í• \n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- 5-Fold: ë°ì´í„°ë¥¼ 5ë“±ë¶„, 1ê°œì”© ê²€ì¦ìš©ìœ¼ë¡œ ìˆœí™˜\n",
    "- í‰ê·  +/- 2*stdë¡œ ì‹ ë¢° êµ¬ê°„ í‘œí˜„\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- KFold: í´ë˜ìŠ¤ ë¹„ìœ¨ ë¬´ì‹œ (ê· í˜• ë°ì´í„°ìš©)\n",
    "- RepeatedStratifiedKFold: ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ì „ì²´ ë°ì´í„°ë¡œ ìŠ¤ì¼€ì¼ë§ í›„ êµì°¨ ê²€ì¦ (Data Leakage)\n",
    "- shuffle=Falseì¼ ë•Œ ìˆœì°¨ ë°ì´í„° ë¬¸ì œ\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ë¶ˆê· í˜• ë°ì´í„°ëŠ” ë°˜ë“œì‹œ StratifiedKFold\n",
    "- ë°ì´í„°ê°€ ì ìœ¼ë©´ 10-Fold ê¶Œì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q9. ColumnTransformer êµ¬ì¶• â­â­â­â­\n",
    "\n",
    "### ë¬¸ì œ\n",
    "ë‹¤ìŒ ë°ì´í„°í”„ë ˆì„ì— ëŒ€í•´ ìˆ˜ì¹˜í˜•/ë²”ì£¼í˜•ì„ ë™ì‹œì— ì²˜ë¦¬í•˜ëŠ” ColumnTransformerë¥¼ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'age': [25, 30, np.nan, 40],\n",
    "    'salary': [50000, 60000, 70000, np.nan],\n",
    "    'department': ['IT', 'HR', 'IT', 'Sales'],\n",
    "    'gender': ['M', 'F', 'M', 'F']\n",
    "})\n",
    "```\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "- ìˆ˜ì¹˜í˜•: ì¤‘ì•™ê°’ ëŒ€ì¹˜ + í‘œì¤€í™”\n",
    "- ë²”ì£¼í˜•: ìµœë¹ˆê°’ ëŒ€ì¹˜ + ì›-í•« ì¸ì½”ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "df = pd.DataFrame({\n",
    "    'age': [25, 30, np.nan, 40],\n",
    "    'salary': [50000, 60000, 70000, np.nan],\n",
    "    'department': ['IT', 'HR', 'IT', 'Sales'],\n",
    "    'gender': ['M', 'F', 'M', 'F']\n",
    "})\n",
    "\n",
    "# ì»¬ëŸ¼ ì •ì˜\n",
    "numeric_cols = ['age', 'salary']\n",
    "categorical_cols = ['department', 'gender']\n",
    "\n",
    "# ìˆ˜ì¹˜í˜• íŒŒì´í”„ë¼ì¸\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# ë²”ì£¼í˜• íŒŒì´í”„ë¼ì¸\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# ColumnTransformer êµ¬ì„±\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_cols),\n",
    "        ('cat', categorical_pipeline, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ì ìš©\n",
    "df_transformed = preprocessor.fit_transform(df)\n",
    "\n",
    "print(\"ì›ë³¸ ë°ì´í„°:\")\n",
    "print(df)\n",
    "\n",
    "print(f\"\\në³€í™˜ í›„ shape: {df_transformed.shape}\")\n",
    "print(\"\\në³€í™˜ëœ íŠ¹ì„± ì´ë¦„:\")\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "for i, name in enumerate(feature_names):\n",
    "    print(f\"  {i}: {name}\")\n",
    "\n",
    "print(\"\\në³€í™˜ëœ ë°ì´í„°:\")\n",
    "print(pd.DataFrame(df_transformed, columns=feature_names).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert df_transformed.shape[0] == 4, \"í–‰ ìˆ˜ëŠ” 4ê°œì—¬ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert not np.isnan(df_transformed).any(), \"ê²°ì¸¡ì¹˜ê°€ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "- ColumnTransformerë¡œ ì„œë¡œ ë‹¤ë¥¸ íŒŒì´í”„ë¼ì¸ì„ ì»¬ëŸ¼ë³„ë¡œ ì ìš©\n",
    "- transformers: (ì´ë¦„, íŒŒì´í”„ë¼ì¸, ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸) íŠœí”Œ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ìˆ˜ì¹˜í˜•ê³¼ ë²”ì£¼í˜•ì„ ë™ì‹œì— ì²˜ë¦¬\n",
    "- ê° íŒŒì´í”„ë¼ì¸ì´ ë…ë¦½ì ìœ¼ë¡œ fit/transform\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- remainder='passthrough': ì§€ì • ì•ˆ í•œ ì»¬ëŸ¼ ìœ ì§€\n",
    "- remainder='drop': ì§€ì • ì•ˆ í•œ ì»¬ëŸ¼ ì œê±° (ê¸°ë³¸ê°’)\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ì»¬ëŸ¼ ì´ë¦„ì´ ì¸ë±ìŠ¤ë¡œ ë³€ê²½ë¨ (get_feature_names_outìœ¼ë¡œ ë³µêµ¬)\n",
    "- ì»¬ëŸ¼ ìˆœì„œê°€ ì›ë³¸ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ ê±°ì˜ í•„ìˆ˜ë¡œ ì‚¬ìš©\n",
    "- ëª¨ë¸ê³¼ í•¨ê»˜ Pipelineìœ¼ë¡œ ë¬¶ìœ¼ë©´ ì™„ì „í•œ ML íŒŒì´í”„ë¼ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q10. ì¢…í•©: Titanic ML íŒŒì´í”„ë¼ì¸ â­â­â­â­â­\n",
    "\n",
    "### ë¬¸ì œ\n",
    "Titanic ë°ì´í„°ë¡œ ì™„ì „í•œ ML íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ê³ , í…ŒìŠ¤íŠ¸ ì •í™•ë„ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "1. ì‚¬ìš© íŠ¹ì„±: age, fare, pclass, sex, embarked\n",
    "2. ìˆ˜ì¹˜í˜•(age, fare): ì¤‘ì•™ê°’ ëŒ€ì¹˜ + StandardScaler\n",
    "3. ë²”ì£¼í˜•(pclass, sex, embarked): ìµœë¹ˆê°’ ëŒ€ì¹˜ + OneHotEncoder\n",
    "4. ëª¨ë¸: LogisticRegression\n",
    "5. ë°ì´í„° ë¶„í• : 80/20, stratify, random_state=42\n",
    "6. 5-Fold êµì°¨ ê²€ì¦ ì ìˆ˜ë„ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë‹µ ì½”ë“œ\n",
    "\n",
    "# 1. íŠ¹ì„± ì •ì˜\n",
    "numeric_features = ['age', 'fare']\n",
    "categorical_features = ['pclass', 'sex', 'embarked']\n",
    "all_features = numeric_features + categorical_features\n",
    "\n",
    "# 2. ìˆ˜ì¹˜í˜• íŒŒì´í”„ë¼ì¸\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 3. ë²”ì£¼í˜• íŒŒì´í”„ë¼ì¸\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# 4. ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5. ì „ì²´ íŒŒì´í”„ë¼ì¸ (ì „ì²˜ë¦¬ + ëª¨ë¸)\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# 6. ë°ì´í„° ì¤€ë¹„\n",
    "X = titanic[all_features]\n",
    "y = titanic['survived']\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ìˆëŠ” íƒ€ê²Ÿ ì œê±°\n",
    "mask = y.notna()\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "print(f\"ì „ì²´ ë°ì´í„°: {len(X)}ê°œ\")\n",
    "print(f\"ìƒì¡´ìœ¨: {y.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. ë°ì´í„° ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°: {len(X_train)}ê°œ\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ\")\n",
    "\n",
    "# 8. í•™ìŠµ ë° í‰ê°€\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "train_score = full_pipeline.score(X_train, y_train)\n",
    "test_score = full_pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f\"\\ní›ˆë ¨ ì •í™•ë„: {train_score:.4f}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 5-Fold êµì°¨ ê²€ì¦\n",
    "cv_scores = cross_val_score(full_pipeline, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"\\n5-Fold êµì°¨ ê²€ì¦ ê²°ê³¼:\")\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(f\"\\ní‰ê· : {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. ê²°ê³¼ ì‹œê°í™”\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['ëª¨ë¸ ì„±ëŠ¥', 'êµì°¨ ê²€ì¦ ê²°ê³¼'])\n",
    "\n",
    "# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ì •í™•ë„\n",
    "fig.add_trace(\n",
    "    go.Bar(x=['í›ˆë ¨', 'í…ŒìŠ¤íŠ¸'], y=[train_score, test_score],\n",
    "           marker_color=['steelblue', 'coral'],\n",
    "           text=[f'{train_score:.3f}', f'{test_score:.3f}'],\n",
    "           textposition='outside'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# êµì°¨ ê²€ì¦ ê²°ê³¼\n",
    "fig.add_trace(\n",
    "    go.Bar(x=[f'Fold {i}' for i in range(1, 6)], y=cv_scores,\n",
    "           marker_color='mediumseagreen',\n",
    "           text=[f'{s:.3f}' for s in cv_scores],\n",
    "           textposition='outside'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(title='Titanic ML íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥', showlegend=False, height=400)\n",
    "fig.update_yaxes(range=[0.6, 0.9])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "assert test_score > 0.7, \"í…ŒìŠ¤íŠ¸ ì •í™•ë„ê°€ 70% ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert len(cv_scores) == 5, \"5ê°œ Fold ê²°ê³¼ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert cv_scores.mean() > 0.7, \"CV í‰ê· ì´ 70% ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í’€ì´ ì„¤ëª…\n",
    "\n",
    "**ì ‘ê·¼ ë°©ë²•**:\n",
    "1. ìˆ˜ì¹˜í˜•/ë²”ì£¼í˜• ì»¬ëŸ¼ ë¶„ë¦¬\n",
    "2. ê°ê°ì— ë§ëŠ” íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\n",
    "3. ColumnTransformerë¡œ í†µí•©\n",
    "4. ëª¨ë¸ê³¼ í•¨ê»˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬ì„±\n",
    "5. í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í•  ë° í‰ê°€\n",
    "6. êµì°¨ ê²€ì¦ìœ¼ë¡œ ì‹ ë¢°ì„± í™•ì¸\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- ì „ì²˜ë¦¬ì™€ ëª¨ë¸ì„ í•˜ë‚˜ì˜ ê°ì²´ë¡œ ê´€ë¦¬\n",
    "- Data Leakage ìë™ ë°©ì§€ (êµì°¨ ê²€ì¦ ì‹œ ê° Foldë§ˆë‹¤ fit/transform ë¶„ë¦¬)\n",
    "\n",
    "**ëŒ€ì•ˆ**:\n",
    "- ë‹¤ë¥¸ ëª¨ë¸ (RandomForest, XGBoost ë“±)\n",
    "- GridSearchCVë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "\n",
    "**í”í•œ ì‹¤ìˆ˜**:\n",
    "- ì „ì²´ ë°ì´í„°ë¡œ ì „ì²˜ë¦¬ í›„ ë¶„í•  (Data Leakage)\n",
    "- pclassë¥¼ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ì²˜ë¦¬ (ìˆœì„œ ì—†ëŠ” ë²”ì£¼í˜•)\n",
    "\n",
    "**ì‹¤ë¬´ íŒ**:\n",
    "- ì´ íŒ¨í„´ì´ ì‹¤ì œ ML í”„ë¡œì íŠ¸ì˜ ê¸°ë³¸ ê³¨ê²©\n",
    "- joblib.dump()ë¡œ íŒŒì´í”„ë¼ì¸ ì €ì¥, ë°°í¬ ì‹œ ê·¸ëŒ€ë¡œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š ì „ì²´ ìš”ì•½\n",
    "\n",
    "### í•µì‹¬ ê°œë… ì •ë¦¬\n",
    "\n",
    "| ë‹¨ê³„ | ë„êµ¬ | í•µì‹¬ í¬ì¸íŠ¸ |\n",
    "|------|------|------------|\n",
    "| ë°ì´í„° ë¶„í•  | train_test_split | stratifyë¡œ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€ |\n",
    "| êµì°¨ ê²€ì¦ | StratifiedKFold | ì—¬ëŸ¬ ë²ˆ í‰ê°€ë¡œ ì‹ ë¢°ì„± í™•ë³´ |\n",
    "| ìŠ¤ì¼€ì¼ë§ | StandardScaler, MinMaxScaler | í›ˆë ¨ ë°ì´í„°ë¡œë§Œ fit |\n",
    "| ì¸ì½”ë”© | LabelEncoder, OneHotEncoder | ë²”ì£¼í˜•ì„ ìˆ«ìë¡œ ë³€í™˜ |\n",
    "| íŒŒì´í”„ë¼ì¸ | Pipeline, ColumnTransformer | ì „ì²˜ë¦¬ ìë™í™” |\n",
    "\n",
    "### ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "- [ ] Data Leakage ë°©ì§€: í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ fit ê¸ˆì§€\n",
    "- [ ] ë¶ˆê· í˜• ë°ì´í„°: stratify, StratifiedKFold ì‚¬ìš©\n",
    "- [ ] ê²°ì¸¡ì¹˜ ì²˜ë¦¬: SimpleImputer í™œìš©\n",
    "- [ ] ìŠ¤ì¼€ì¼ë§: ëª¨ë¸ íŠ¹ì„±ì— ë§ê²Œ ì„ íƒ\n",
    "- [ ] íŒŒì´í”„ë¼ì¸: ì „ì²˜ë¦¬+ëª¨ë¸ í†µí•© ê´€ë¦¬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
