{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day12_1: ë°ì´í„° ì „ì²˜ë¦¬ for ML (Preprocessing)\n",
    "\n",
    "## ğŸ“š í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "**Part 1: ê¸°ì´ˆ**\n",
    "1. MLì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ ê³¼ì • ì´í•´í•˜ê¸°\n",
    "2. train_test_splitìœ¼ë¡œ ë°ì´í„° ë¶„í• í•˜ê¸°\n",
    "3. ê³„ì¸µì  ìƒ˜í”Œë§(stratify) ê°œë… ì´í•´í•˜ê¸°\n",
    "4. StandardScalerë¡œ íŠ¹ì„± í‘œì¤€í™”í•˜ê¸°\n",
    "5. MinMaxScalerë¡œ íŠ¹ì„± ì •ê·œí™”í•˜ê¸°\n",
    "\n",
    "**Part 2: ì‹¬í™”**\n",
    "1. ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ LabelEncoder/OneHotEncoderë¡œ ë³€í™˜í•˜ê¸°\n",
    "2. PolynomialFeaturesë¡œ ë‹¤í•­ íŠ¹ì„± ìƒì„±í•˜ê¸°\n",
    "3. sklearn Pipelineìœ¼ë¡œ ì „ì²˜ë¦¬ ìë™í™”í•˜ê¸°\n",
    "4. ColumnTransformerë¡œ ë³µí•© íŒŒì´í”„ë¼ì¸ êµ¬ì¶•í•˜ê¸°\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ì™œ ì´ê²ƒì„ ë°°ìš°ë‚˜ìš”?\n",
    "\n",
    "| ê°œë… | ì‹¤ë¬´ í™œìš© | ì˜ˆì‹œ |\n",
    "|------|----------|------|\n",
    "| train_test_split | ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ìš© ë°ì´í„° ë¶„ë¦¬ | 80% í•™ìŠµ, 20% í…ŒìŠ¤íŠ¸ |\n",
    "| StandardScaler | íŠ¹ì„± ìŠ¤ì¼€ì¼ í†µì¼ | ë‚˜ì´(0-100) vs ì—°ë´‰(0-1ì–µ) |\n",
    "| OneHotEncoder | ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬ | ì„±ë³„(ë‚¨/ì—¬) -> [1,0]/[0,1] |\n",
    "| Pipeline | ì „ì²˜ë¦¬ ìë™í™” | ìŠ¤ì¼€ì¼ë§ -> ì¸ì½”ë”© -> ëª¨ë¸ í•™ìŠµ |\n",
    "\n",
    "**ë¶„ì„ê°€ ê´€ì **: ML ëª¨ë¸ì˜ ì„±ëŠ¥ì€ 80%ê°€ ì „ì²˜ë¦¬ì—ì„œ ê²°ì •ë©ë‹ˆë‹¤. ì˜ ì •ì œëœ ë°ì´í„°ê°€ ì¢‹ì€ ëª¨ë¸ì„ ë§Œë“­ë‹ˆë‹¤!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: ê¸°ì´ˆ\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 ML ë°ì´í„° ì „ì²˜ë¦¬ ê°œìš”\n",
    "\n",
    "### ì™œ ì „ì²˜ë¦¬ê°€ í•„ìš”í•œê°€?\n",
    "\n",
    "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ **ìˆ«ì ë°ì´í„°**ë§Œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œ ë°ì´í„°ëŠ”:\n",
    "- ê²°ì¸¡ì¹˜ê°€ ìˆê³ \n",
    "- ìŠ¤ì¼€ì¼ì´ ë‹¤ë¥´ê³  (ë‚˜ì´: 0-100, ì—°ë´‰: ì²œë§Œ~ì–µ)\n",
    "- ë²”ì£¼í˜• ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤ (ì„±ë³„, ì§€ì—­ ë“±)\n",
    "\n",
    "ì „ì²˜ë¦¬ëŠ” ì´ëŸ° ë¬¸ì œë“¤ì„ í•´ê²°í•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# sklearn ì „ì²˜ë¦¬ ë„êµ¬\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, MinMaxScaler, RobustScaler,\n",
    "    LabelEncoder, OneHotEncoder, OrdinalEncoder,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# ê²½ê³  ë¬´ì‹œ\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanic ë°ì´í„° ë¡œë“œ (seaborn ë‚´ì¥ ë˜ëŠ” URL)\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    titanic = sns.load_dataset('titanic')\n",
    "except:\n",
    "    url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "    titanic = pd.read_csv(url)\n",
    "    # ì»¬ëŸ¼ëª… ì†Œë¬¸ìë¡œ í†µì¼\n",
    "    titanic.columns = titanic.columns.str.lower()\n",
    "    titanic = titanic.rename(columns={'sex': 'sex', 'pclass': 'pclass'})\n",
    "\n",
    "print(f\"ë°ì´í„° í¬ê¸°: {titanic.shape}\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì •ë³´ í™•ì¸\n",
    "print(\"=\" * 50)\n",
    "print(\"ë°ì´í„° íƒ€ì…ë³„ ì»¬ëŸ¼ ìˆ˜\")\n",
    "print(\"=\" * 50)\n",
    "print(titanic.dtypes.value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ê²°ì¸¡ì¹˜ í˜„í™©\")\n",
    "print(\"=\" * 50)\n",
    "print(titanic.isnull().sum()[titanic.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: ML ì „ì²˜ë¦¬ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "1. **ê²°ì¸¡ì¹˜ ì²˜ë¦¬**: ì‚­ì œ or ëŒ€ì¹˜\n",
    "2. **ì´ìƒì¹˜ ì²˜ë¦¬**: ì œê±° or ë³€í™˜\n",
    "3. **ìŠ¤ì¼€ì¼ë§**: ìˆ˜ì¹˜í˜• íŠ¹ì„± ì •ê·œí™”/í‘œì¤€í™”\n",
    "4. **ì¸ì½”ë”©**: ë²”ì£¼í˜• -> ìˆ«ìí˜•\n",
    "5. **íŠ¹ì„± ìƒì„±**: íŒŒìƒ ë³€ìˆ˜ ë§Œë“¤ê¸°\n",
    "6. **ë°ì´í„° ë¶„í• **: í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 ë°ì´í„° ë¶„í•  (train_test_split)\n",
    "\n",
    "### ì™œ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ë‚˜ìš”?\n",
    "\n",
    "- **í›ˆë ¨ ë°ì´í„°**: ëª¨ë¸ì´ í•™ìŠµí•˜ëŠ” ë°ì´í„°\n",
    "- **í…ŒìŠ¤íŠ¸ ë°ì´í„°**: ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë°ì´í„°\n",
    "\n",
    "ê°™ì€ ë°ì´í„°ë¡œ í•™ìŠµ+í‰ê°€í•˜ë©´ **ê³¼ì í•©(Overfitting)** ë°œìƒ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°„ë‹¨í•œ ë°ì´í„°ë¡œ ë¶„í•  ì—°ìŠµ\n",
    "# íŠ¹ì„±(X)ê³¼ íƒ€ê²Ÿ(y) ë¶„ë¦¬\n",
    "X = titanic[['age', 'fare']].dropna()  # ê²°ì¸¡ì¹˜ ì œê±°\n",
    "y = titanic.loc[X.index, 'survived']\n",
    "\n",
    "print(f\"ì „ì²´ ë°ì´í„°: {len(X)}ê°œ\")\n",
    "print(f\"íŠ¹ì„± shape: {X.shape}\")\n",
    "print(f\"íƒ€ê²Ÿ shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ë¶„í• : 80% í›ˆë ¨, 20% í…ŒìŠ¤íŠ¸\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,      # í…ŒìŠ¤íŠ¸ ë¹„ìœ¨\n",
    "    random_state=42     # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ\n",
    ")\n",
    "\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°: {len(X_train)}ê°œ ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ ({len(X_test)/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íƒ€ê²Ÿ ë¶„í¬ í™•ì¸ (ë¶ˆê· í˜• ì²´í¬)\n",
    "print(\"ì „ì²´ ë°ì´í„° ìƒì¡´ìœ¨:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\ní›ˆë ¨ ë°ì´í„° ìƒì¡´ìœ¨:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\ní…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì¡´ìœ¨:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê³„ì¸µì  ìƒ˜í”Œë§ (stratify)\n",
    "\n",
    "íƒ€ê²Ÿ í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ ë¶„í• í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratify ì˜µì…˜ìœ¼ë¡œ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # íƒ€ê²Ÿ ë¹„ìœ¨ ìœ ì§€\n",
    ")\n",
    "\n",
    "print(\"=== stratify ì ìš© í›„ ===\")\n",
    "print(f\"ì „ì²´ ìƒì¡´ìœ¨: {y.mean():.4f}\")\n",
    "print(f\"í›ˆë ¨ ìƒì¡´ìœ¨: {y_train_s.mean():.4f}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ìƒì¡´ìœ¨: {y_test_s.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”: stratify ì „í›„ ë¹„êµ\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['ì¼ë°˜ ë¶„í• ', 'Stratify ë¶„í• '])\n",
    "\n",
    "# ì¼ë°˜ ë¶„í• \n",
    "fig.add_trace(\n",
    "    go.Bar(x=['ì „ì²´', 'í›ˆë ¨', 'í…ŒìŠ¤íŠ¸'],\n",
    "           y=[y.mean(), y_train.mean(), y_test.mean()],\n",
    "           marker_color=['blue', 'green', 'orange'],\n",
    "           text=[f'{v:.3f}' for v in [y.mean(), y_train.mean(), y_test.mean()]],\n",
    "           textposition='outside'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Stratify ë¶„í• \n",
    "fig.add_trace(\n",
    "    go.Bar(x=['ì „ì²´', 'í›ˆë ¨', 'í…ŒìŠ¤íŠ¸'],\n",
    "           y=[y.mean(), y_train_s.mean(), y_test_s.mean()],\n",
    "           marker_color=['blue', 'green', 'orange'],\n",
    "           text=[f'{v:.3f}' for v in [y.mean(), y_train_s.mean(), y_test_s.mean()]],\n",
    "           textposition='outside'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(title='ë°ì´í„° ë¶„í•  ë°©ì‹ ë¹„êµ: ìƒì¡´ìœ¨', showlegend=False, height=400)\n",
    "fig.update_yaxes(range=[0, 0.5])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: ë¶ˆê· í˜• ë°ì´í„° ë¶„í• \n",
    "\n",
    "- ì‚¬ê¸° íƒì§€ (ì‚¬ê¸° 1%, ì •ìƒ 99%)\n",
    "- ì§ˆë³‘ ì§„ë‹¨ (ì–‘ì„± 5%, ìŒì„± 95%)\n",
    "- ê³ ê° ì´íƒˆ (ì´íƒˆ 10%, ìœ ì§€ 90%)\n",
    "\n",
    "ì´ëŸ° ê²½ìš° **ë°˜ë“œì‹œ stratify** ì‚¬ìš©!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 êµì°¨ ê²€ì¦ (Cross-Validation)\n",
    "\n",
    "í•œ ë²ˆ ë¶„í• ë¡œëŠ” ìš°ì—°íˆ ì¢‹ì€/ë‚˜ìœ ê²°ê³¼ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "**K-Fold êµì°¨ ê²€ì¦**ìœ¼ë¡œ ì—¬ëŸ¬ ë²ˆ í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# 5-Fold êµì°¨ ê²€ì¦ ì˜ˆì‹œ\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"5-Fold ë¶„í•  ê²°ê³¼:\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X), 1):\n",
    "    print(f\"Fold {fold}: í›ˆë ¨ {len(train_idx)}ê°œ, ê²€ì¦ {len(val_idx)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold: í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Stratified 5-Fold ë¶„í•  - ê° Foldë³„ ìƒì¡´ìœ¨:\")\n",
    "for fold, (train_idx, val_idx) in enumerate(skfold.split(X, y), 1):\n",
    "    train_ratio = y.iloc[train_idx].mean()\n",
    "    val_ratio = y.iloc[val_idx].mean()\n",
    "    print(f\"Fold {fold}: í›ˆë ¨ ìƒì¡´ìœ¨ {train_ratio:.3f}, ê²€ì¦ ìƒì¡´ìœ¨ {val_ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ (Feature Scaling)\n",
    "\n",
    "### ì™œ ìŠ¤ì¼€ì¼ë§ì´ í•„ìš”í•œê°€?\n",
    "\n",
    "| íŠ¹ì„± | ë²”ìœ„ | ë¬¸ì œì  |\n",
    "|------|------|--------|\n",
    "| ë‚˜ì´ | 0-100 | ì‘ì€ ê°’ |\n",
    "| ì—°ë´‰ | 0-1ì–µ | í° ê°’ |\n",
    "| í‚¤ | 140-200 | ì¤‘ê°„ ê°’ |\n",
    "\n",
    "ìŠ¤ì¼€ì¼ì´ ë‹¤ë¥´ë©´ **í° ê°’ì˜ íŠ¹ì„±ì´ ëª¨ë¸ì— ê³¼ë„í•œ ì˜í–¥**ì„ ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanicì˜ ageì™€ fare ë¹„êµ\n",
    "print(\"ì›ë³¸ ë°ì´í„° í†µê³„:\")\n",
    "print(titanic[['age', 'fare']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤ì¼€ì¼ ì°¨ì´ ì‹œê°í™”\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['Age ë¶„í¬', 'Fare ë¶„í¬'])\n",
    "\n",
    "fig.add_trace(go.Histogram(x=titanic['age'].dropna(), name='Age', nbinsx=30), row=1, col=1)\n",
    "fig.add_trace(go.Histogram(x=titanic['fare'].dropna(), name='Fare', nbinsx=30), row=1, col=2)\n",
    "\n",
    "fig.update_layout(title='íŠ¹ì„±ë³„ ìŠ¤ì¼€ì¼ ì°¨ì´', showlegend=False, height=350)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler (í‘œì¤€í™”)\n",
    "\n",
    "- **ê³µì‹**: z = (x - mean) / std\n",
    "- **ê²°ê³¼**: í‰ê·  0, í‘œì¤€í¸ì°¨ 1\n",
    "- **ì í•©**: ì •ê·œë¶„í¬ ê°€ì • ëª¨ë¸ (ë¡œì§€ìŠ¤í‹± íšŒê·€, SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler ì ìš©\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„ (ê²°ì¸¡ì¹˜ ì œê±°)\n",
    "sample_data = titanic[['age', 'fare']].dropna()\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ëŸ¬ ìƒì„± ë° ì ìš©\n",
    "scaler_std = StandardScaler()\n",
    "scaled_std = scaler_std.fit_transform(sample_data)\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "scaled_std_df = pd.DataFrame(scaled_std, columns=['age_scaled', 'fare_scaled'])\n",
    "\n",
    "print(\"StandardScaler ì ìš© í›„:\")\n",
    "print(scaled_std_df.describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler (ì •ê·œí™”)\n",
    "\n",
    "- **ê³µì‹**: x_scaled = (x - min) / (max - min)\n",
    "- **ê²°ê³¼**: 0 ~ 1 ì‚¬ì´ ê°’\n",
    "- **ì í•©**: ì‹ ê²½ë§, ì´ë¯¸ì§€ ë°ì´í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler ì ìš©\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_mm = MinMaxScaler()\n",
    "scaled_mm = scaler_mm.fit_transform(sample_data)\n",
    "\n",
    "scaled_mm_df = pd.DataFrame(scaled_mm, columns=['age_scaled', 'fare_scaled'])\n",
    "\n",
    "print(\"MinMaxScaler ì ìš© í›„:\")\n",
    "print(scaled_mm_df.describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RobustScaler (ì´ìƒì¹˜ ê°•ê±´)\n",
    "\n",
    "- **ê³µì‹**: x_scaled = (x - median) / IQR\n",
    "- **ê²°ê³¼**: ì¤‘ì•™ê°’ 0, IQR 1\n",
    "- **ì í•©**: ì´ìƒì¹˜ê°€ ë§ì€ ë°ì´í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RobustScaler ì ìš©\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler_robust = RobustScaler()\n",
    "scaled_robust = scaler_robust.fit_transform(sample_data)\n",
    "\n",
    "scaled_robust_df = pd.DataFrame(scaled_robust, columns=['age_scaled', 'fare_scaled'])\n",
    "\n",
    "print(\"RobustScaler ì ìš© í›„:\")\n",
    "print(scaled_robust_df.describe().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¸ ìŠ¤ì¼€ì¼ëŸ¬ ë¹„êµ ì‹œê°í™”\n",
    "fig = make_subplots(rows=2, cols=2,\n",
    "                    subplot_titles=['ì›ë³¸', 'StandardScaler', 'MinMaxScaler', 'RobustScaler'])\n",
    "\n",
    "# ì›ë³¸\n",
    "fig.add_trace(go.Scatter(x=sample_data['age'], y=sample_data['fare'],\n",
    "                         mode='markers', marker=dict(size=5, opacity=0.5)), row=1, col=1)\n",
    "\n",
    "# StandardScaler\n",
    "fig.add_trace(go.Scatter(x=scaled_std_df['age_scaled'], y=scaled_std_df['fare_scaled'],\n",
    "                         mode='markers', marker=dict(size=5, opacity=0.5)), row=1, col=2)\n",
    "\n",
    "# MinMaxScaler\n",
    "fig.add_trace(go.Scatter(x=scaled_mm_df['age_scaled'], y=scaled_mm_df['fare_scaled'],\n",
    "                         mode='markers', marker=dict(size=5, opacity=0.5)), row=2, col=1)\n",
    "\n",
    "# RobustScaler\n",
    "fig.add_trace(go.Scatter(x=scaled_robust_df['age_scaled'], y=scaled_robust_df['fare_scaled'],\n",
    "                         mode='markers', marker=dict(size=5, opacity=0.5)), row=2, col=2)\n",
    "\n",
    "fig.update_layout(title='ìŠ¤ì¼€ì¼ëŸ¬ë³„ ë³€í™˜ ê²°ê³¼ ë¹„êµ', showlegend=False, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: ìŠ¤ì¼€ì¼ëŸ¬ ì„ íƒ ê¸°ì¤€\n",
    "\n",
    "| ìƒí™© | ì¶”ì²œ ìŠ¤ì¼€ì¼ëŸ¬ | ì´ìœ  |\n",
    "|------|-------------|------|\n",
    "| ì •ê·œë¶„í¬ ê°€ì • ëª¨ë¸ | StandardScaler | í‰ê·  0, í‘œì¤€í¸ì°¨ 1 |\n",
    "| ì‹ ê²½ë§, ì´ë¯¸ì§€ | MinMaxScaler | 0-1 ë²”ìœ„ í•„ìš” |\n",
    "| ì´ìƒì¹˜ ë§ìŒ | RobustScaler | ì¤‘ì•™ê°’/IQR ê¸°ë°˜ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âš ï¸ ì£¼ì˜: Data Leakage ë°©ì§€\n",
    "\n",
    "**ì ˆëŒ€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ fit í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜¬ë°”ë¥¸ ë°©ë²•: í›ˆë ¨ ë°ì´í„°ë¡œë§Œ fit\n",
    "X_train_demo = sample_data.iloc[:600]\n",
    "X_test_demo = sample_data.iloc[600:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# í›ˆë ¨ ë°ì´í„°ë¡œ fit + transform\n",
    "X_train_scaled = scaler.fit_transform(X_train_demo)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” transformë§Œ!\n",
    "X_test_scaled = scaler.transform(X_test_demo)\n",
    "\n",
    "print(\"í›ˆë ¨ ë°ì´í„° í‰ê· :\", X_train_scaled.mean(axis=0).round(3))\n",
    "print(\"í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê· :\", X_test_scaled.mean(axis=0).round(3))  # ì •í™•íˆ 0ì´ ì•„ë‹˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: ì‹¬í™”\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "\n",
    "### LabelEncoder (ìˆœì„œí˜•/íƒ€ê²Ÿìš©)\n",
    "\n",
    "ë¬¸ìì—´ì„ ì •ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. **íƒ€ê²Ÿ ë³€ìˆ˜**ë‚˜ **ìˆœì„œê°€ ìˆëŠ”** ë²”ì£¼ì— ì‚¬ìš©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ì„±ë³„ ì¸ì½”ë”©\n",
    "le = LabelEncoder()\n",
    "sex_encoded = le.fit_transform(titanic['sex'])\n",
    "\n",
    "print(\"í´ë˜ìŠ¤ ëª©ë¡:\", le.classes_)\n",
    "print(\"ì¸ì½”ë”© ê²°ê³¼ (ì²˜ìŒ 10ê°œ):\", sex_encoded[:10])\n",
    "\n",
    "# ì—­ë³€í™˜\n",
    "print(\"ì—­ë³€í™˜:\", le.inverse_transform([0, 1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoder (ëª…ëª©í˜• íŠ¹ì„±ìš©)\n",
    "\n",
    "ìˆœì„œê°€ ì—†ëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ëŠ” **ì›-í•« ì¸ì½”ë”©**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# ìŠ¹ì„  í•­êµ¬ ì›-í•« ì¸ì½”ë”©\n",
    "embarked_data = titanic[['embarked']].dropna()\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first')  # ë‹¤ì¤‘ê³µì„ ì„± ë°©ì§€\n",
    "embarked_encoded = ohe.fit_transform(embarked_data)\n",
    "\n",
    "print(\"ì¹´í…Œê³ ë¦¬:\", ohe.categories_)\n",
    "print(\"\\nì¸ì½”ë”© ê²°ê³¼ (ì²˜ìŒ 5ê°œ):\")\n",
    "print(embarked_encoded[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas get_dummies: ë” ê°„ë‹¨í•œ ë°©ë²•\n",
    "embarked_dummies = pd.get_dummies(titanic['embarked'], prefix='embarked', drop_first=True)\n",
    "print(embarked_dummies.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: ì¸ì½”ë”© ì„ íƒ ê¸°ì¤€\n",
    "\n",
    "| ë³€ìˆ˜ ìœ í˜• | ì˜ˆì‹œ | ì¶”ì²œ ë°©ë²• |\n",
    "|----------|------|----------|\n",
    "| ìˆœì„œí˜• | ë“±ê¸‰(ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ) | OrdinalEncoder |\n",
    "| ëª…ëª©í˜• | ìƒ‰ìƒ(ë¹¨ê°•/íŒŒë‘/ë…¹ìƒ‰) | OneHotEncoder |\n",
    "| ì´ì§„í˜• | ì„±ë³„(ë‚¨/ì—¬) | LabelEncoder |\n",
    "| íƒ€ê²Ÿ | ìƒì¡´(0/1) | LabelEncoder |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§\n",
    "\n",
    "### PolynomialFeatures (ë‹¤í•­ íŠ¹ì„±)\n",
    "\n",
    "íŠ¹ì„± ê°„ì˜ **ìƒí˜¸ì‘ìš©**ê³¼ **ë‹¤í•­ ê´€ê³„**ë¥¼ í¬ì°©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# ìƒ˜í”Œ ë°ì´í„°\n",
    "X_sample = np.array([[2, 3], [4, 5], [6, 7]])\n",
    "print(\"ì›ë³¸:\\n\", X_sample)\n",
    "\n",
    "# 2ì°¨ ë‹¤í•­ íŠ¹ì„± ìƒì„±\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_sample)\n",
    "\n",
    "print(\"\\níŠ¹ì„± ì´ë¦„:\", poly.get_feature_names_out(['x1', 'x2']))\n",
    "print(\"\\në‹¤í•­ íŠ¹ì„±:\\n\", X_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒí˜¸ì‘ìš© íŠ¹ì„±ë§Œ (degree ì—†ì´)\n",
    "poly_interact = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_interact = poly_interact.fit_transform(X_sample)\n",
    "\n",
    "print(\"ìƒí˜¸ì‘ìš© íŠ¹ì„± ì´ë¦„:\", poly_interact.get_feature_names_out(['x1', 'x2']))\n",
    "print(\"ê²°ê³¼:\\n\", X_interact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¡œê·¸ ë³€í™˜\n",
    "\n",
    "**ì˜¤ë¥¸ìª½ ê¼¬ë¦¬ê°€ ê¸´ ë¶„í¬**ë¥¼ ì •ê·œë¶„í¬ì— ê°€ê¹ê²Œ ë§Œë“­ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fareì˜ ë¡œê·¸ ë³€í™˜\n",
    "fare_data = titanic['fare'].dropna()\n",
    "fare_log = np.log1p(fare_data)  # log(1+x)ë¡œ 0 ì²˜ë¦¬\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['ì›ë³¸ Fare', 'ë¡œê·¸ ë³€í™˜ Fare'])\n",
    "\n",
    "fig.add_trace(go.Histogram(x=fare_data, nbinsx=50), row=1, col=1)\n",
    "fig.add_trace(go.Histogram(x=fare_log, nbinsx=50), row=1, col=2)\n",
    "\n",
    "fig.update_layout(title='ë¡œê·¸ ë³€í™˜ íš¨ê³¼', showlegend=False, height=350)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: Titanic íŒŒìƒ ë³€ìˆ˜\n",
    "\n",
    "- **ê°€ì¡± í¬ê¸°**: sibsp + parch + 1\n",
    "- **í˜¼ì íƒ‘ìŠ¹**: ê°€ì¡± í¬ê¸° == 1\n",
    "- **í˜¸ì¹­ ì¶”ì¶œ**: ì´ë¦„ì—ì„œ Mr/Mrs/Miss ë“±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanic íŒŒìƒ ë³€ìˆ˜ ìƒì„±\n",
    "titanic_fe = titanic.copy()\n",
    "\n",
    "# ê°€ì¡± í¬ê¸°\n",
    "titanic_fe['family_size'] = titanic_fe['sibsp'] + titanic_fe['parch'] + 1\n",
    "\n",
    "# í˜¼ì íƒ‘ìŠ¹ ì—¬ë¶€\n",
    "titanic_fe['is_alone'] = (titanic_fe['family_size'] == 1).astype(int)\n",
    "\n",
    "# ìš”ê¸ˆ êµ¬ê°„ (ì €ë ´/ë³´í†µ/ë¹„ìŒˆ)\n",
    "titanic_fe['fare_band'] = pd.qcut(titanic_fe['fare'].fillna(titanic_fe['fare'].median()),\n",
    "                                   q=4, labels=['ì €ë ´', 'ë³´í†µ', 'ë¹„ìŒˆ', 'í”„ë¦¬ë¯¸ì—„'])\n",
    "\n",
    "print(titanic_fe[['sibsp', 'parch', 'family_size', 'is_alone', 'fare', 'fare_band']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 sklearn Pipeline êµ¬ì¶•\n",
    "\n",
    "**Pipeline**ìœ¼ë¡œ ì—¬ëŸ¬ ì „ì²˜ë¦¬ ë‹¨ê³„ë¥¼ **í•˜ë‚˜ì˜ ê°ì²´**ë¡œ ë¬¶ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# ìˆ˜ì¹˜í˜• íŒŒì´í”„ë¼ì¸\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # ê²°ì¸¡ì¹˜ -> ì¤‘ì•™ê°’\n",
    "    ('scaler', StandardScaler())                     # í‘œì¤€í™”\n",
    "])\n",
    "\n",
    "# ì ìš©\n",
    "numeric_features = titanic[['age', 'fare']]\n",
    "numeric_transformed = numeric_pipeline.fit_transform(numeric_features)\n",
    "\n",
    "print(\"íŒŒì´í”„ë¼ì¸ ì ìš© ê²°ê³¼:\")\n",
    "print(pd.DataFrame(numeric_transformed, columns=['age', 'fare']).describe().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²”ì£¼í˜• íŒŒì´í”„ë¼ì¸\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # ìµœë¹ˆê°’\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# ì ìš©\n",
    "cat_features = titanic[['sex', 'embarked']]\n",
    "cat_transformed = categorical_pipeline.fit_transform(cat_features)\n",
    "\n",
    "print(\"ë²”ì£¼í˜• íŒŒì´í”„ë¼ì¸ ê²°ê³¼ shape:\", cat_transformed.shape)\n",
    "print(\"ì²˜ìŒ 5í–‰:\\n\", cat_transformed[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColumnTransformer: ë³µí•© íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "**ìˆ˜ì¹˜í˜•ê³¼ ë²”ì£¼í˜•ì„ ë™ì‹œì— ì²˜ë¦¬**í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# ìˆ˜ì¹˜í˜•/ë²”ì£¼í˜• ì»¬ëŸ¼ ì •ì˜\n",
    "numeric_cols = ['age', 'fare']\n",
    "categorical_cols = ['sex', 'embarked', 'pclass']\n",
    "\n",
    "# ColumnTransformer ìƒì„±\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_cols),\n",
    "        ('cat', categorical_pipeline, categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'  # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ ì œê±°\n",
    ")\n",
    "\n",
    "# ì „ì²´ ë°ì´í„° ë³€í™˜\n",
    "X_transformed = preprocessor.fit_transform(titanic)\n",
    "\n",
    "print(f\"ë³€í™˜ ì „ shape: {titanic.shape}\")\n",
    "print(f\"ë³€í™˜ í›„ shape: {X_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³€í™˜ëœ íŠ¹ì„± ì´ë¦„ í™•ì¸\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "print(\"ë³€í™˜ëœ íŠ¹ì„±ë“¤:\")\n",
    "for i, name in enumerate(feature_names):\n",
    "    print(f\"  {i}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì‹¤ë¬´ ì˜ˆì‹œ: ì™„ì „í•œ ML íŒŒì´í”„ë¼ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ì „ì²˜ë¦¬ + ëª¨ë¸ì„ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ!\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# ë°ì´í„° ì¤€ë¹„\n",
    "X = titanic[numeric_cols + categorical_cols]\n",
    "y = titanic['survived']\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ìˆëŠ” íƒ€ê²Ÿ ì œê±°\n",
    "mask = y.notna()\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# í•™ìŠµ ë° í‰ê°€\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "score = full_pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# êµì°¨ ê²€ì¦ìœ¼ë¡œ ë” ì‹ ë¢°ì„± ìˆëŠ” í‰ê°€\n",
    "cv_scores = cross_val_score(full_pipeline, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"5-Fold CV ê²°ê³¼:\")\n",
    "print(f\"  ê° Fold: {cv_scores.round(4)}\")\n",
    "print(f\"  í‰ê· : {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ ì‹¤ìŠµ í€´ì¦ˆ\n",
    "\n",
    "**ë‚œì´ë„**: â­ (ì‰¬ì›€) ~ â­â­â­â­â­ (ì–´ë ¤ì›€)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. ë°ì´í„° ë¶„í•  â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ë°ì´í„°ë¥¼ 70% í›ˆë ¨, 30% í…ŒìŠ¤íŠ¸ë¡œ ë¶„í• í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "X = np.arange(100).reshape(50, 2)\n",
    "y = np.random.randint(0, 2, 50)\n",
    "```\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**: random_state=42, stratify ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(100).reshape(50, 2)\n",
    "y = np.random.randint(0, 2, 50)\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. StandardScaler ì ìš© â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ë°ì´í„°ì— StandardScalerë¥¼ ì ìš©í•˜ê³ , ë³€í™˜ í›„ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "data = np.array([[10, 1000], [20, 2000], [30, 3000], [40, 4000]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[10, 1000], [20, 2000], [30, 3000], [40, 4000]])\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. MinMaxScaler ë²”ìœ„ ì§€ì • â­â­\n",
    "\n",
    "**ë¬¸ì œ**: MinMaxScalerë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ -1 ~ 1 ë²”ìœ„ë¡œ ë³€í™˜í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "values = np.array([[0], [25], [50], [75], [100]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([[0], [25], [50], [75], [100]])\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. LabelEncoder ì ìš© â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ë“±ê¸‰ ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ì¸ì½”ë”©í•˜ê³ , ì—­ë³€í™˜ë„ í•´ë³´ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "grades = ['Bronze', 'Silver', 'Gold', 'Silver', 'Bronze', 'Gold']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = ['Bronze', 'Silver', 'Gold', 'Silver', 'Bronze', 'Gold']\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. OneHotEncoder ì ìš© â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ìƒ‰ìƒ ë°ì´í„°ë¥¼ ì›-í•« ì¸ì½”ë”©í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "colors = np.array([['Red'], ['Blue'], ['Green'], ['Blue'], ['Red']])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array([['Red'], ['Blue'], ['Green'], ['Blue'], ['Red']])\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. PolynomialFeatures ìƒì„± â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: 2ê°œì˜ íŠ¹ì„±ì—ì„œ 2ì°¨ ë‹¤í•­ íŠ¹ì„±ì„ ìƒì„±í•˜ê³ , íŠ¹ì„± ì´ë¦„ì„ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "```\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**: bias í•­ ì œì™¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. ìˆ˜ì¹˜í˜• Pipeline êµ¬ì¶• â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ê²°ì¸¡ì¹˜ ëŒ€ì¹˜(ì¤‘ì•™ê°’) -> í‘œì¤€í™” íŒŒì´í”„ë¼ì¸ì„ ë§Œë“¤ê³  ì ìš©í•˜ì„¸ìš”.\n",
    "\n",
    "```python\n",
    "data_with_nan = np.array([[1, 10], [2, np.nan], [np.nan, 30], [4, 40]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_nan = np.array([[1, 10], [2, np.nan], [np.nan, 30], [4, 40]])\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. K-Fold êµì°¨ ê²€ì¦ â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Titanic ë°ì´í„°ë¡œ 5-Fold êµì°¨ ê²€ì¦ì„ ìˆ˜í–‰í•˜ê³ , ê° Foldì˜ ì •í™•ë„ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "- age, fare íŠ¹ì„± ì‚¬ìš© (ê²°ì¸¡ì¹˜ ì œê±°)\n",
    "- LogisticRegression ëª¨ë¸\n",
    "- StratifiedKFold ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanic ë°ì´í„° ì¤€ë¹„\n",
    "X_cv = titanic[['age', 'fare']].dropna()\n",
    "y_cv = titanic.loc[X_cv.index, 'survived']\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. ColumnTransformer êµ¬ì¶• â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ë°ì´í„°í”„ë ˆì„ì— ëŒ€í•´ ìˆ˜ì¹˜í˜•/ë²”ì£¼í˜•ì„ ë™ì‹œì— ì²˜ë¦¬í•˜ëŠ” ColumnTransformerë¥¼ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'age': [25, 30, np.nan, 40],\n",
    "    'salary': [50000, 60000, 70000, np.nan],\n",
    "    'department': ['IT', 'HR', 'IT', 'Sales'],\n",
    "    'gender': ['M', 'F', 'M', 'F']\n",
    "})\n",
    "```\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "- ìˆ˜ì¹˜í˜•: ì¤‘ì•™ê°’ ëŒ€ì¹˜ + í‘œì¤€í™”\n",
    "- ë²”ì£¼í˜•: ìµœë¹ˆê°’ ëŒ€ì¹˜ + ì›-í•« ì¸ì½”ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'age': [25, 30, np.nan, 40],\n",
    "    'salary': [50000, 60000, 70000, np.nan],\n",
    "    'department': ['IT', 'HR', 'IT', 'Sales'],\n",
    "    'gender': ['M', 'F', 'M', 'F']\n",
    "})\n",
    "\n",
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. ì¢…í•©: Titanic ML íŒŒì´í”„ë¼ì¸ â­â­â­â­â­\n",
    "\n",
    "**ë¬¸ì œ**: Titanic ë°ì´í„°ë¡œ ì™„ì „í•œ ML íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ê³ , í…ŒìŠ¤íŠ¸ ì •í™•ë„ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "1. ì‚¬ìš© íŠ¹ì„±: age, fare, pclass, sex, embarked\n",
    "2. ìˆ˜ì¹˜í˜•(age, fare): ì¤‘ì•™ê°’ ëŒ€ì¹˜ + StandardScaler\n",
    "3. ë²”ì£¼í˜•(pclass, sex, embarked): ìµœë¹ˆê°’ ëŒ€ì¹˜ + OneHotEncoder\n",
    "4. ëª¨ë¸: LogisticRegression\n",
    "5. ë°ì´í„° ë¶„í• : 80/20, stratify, random_state=42\n",
    "6. 5-Fold êµì°¨ ê²€ì¦ ì ìˆ˜ë„ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "### Part 1: ê¸°ì´ˆ í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ê°œë… | í•¨ìˆ˜/í´ë˜ìŠ¤ | í•µì‹¬ íŒŒë¼ë¯¸í„° | ì‚¬ìš© ì‹œì  |\n",
    "|------|------------|--------------|----------|\n",
    "| ë°ì´í„° ë¶„í•  | train_test_split | test_size, stratify, random_state | ëª¨ë¸ í‰ê°€ ì¤€ë¹„ |\n",
    "| êµì°¨ ê²€ì¦ | KFold, StratifiedKFold | n_splits, shuffle | ì‹ ë¢°ì„± ìˆëŠ” í‰ê°€ |\n",
    "| í‘œì¤€í™” | StandardScaler | - | í‰ê·  0, í‘œì¤€í¸ì°¨ 1 |\n",
    "| ì •ê·œí™” | MinMaxScaler | feature_range | 0-1 ë²”ìœ„ ë³€í™˜ |\n",
    "| ì´ìƒì¹˜ ê°•ê±´ | RobustScaler | - | ì´ìƒì¹˜ ë§ì€ ë°ì´í„° |\n",
    "\n",
    "### Part 2: ì‹¬í™” í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| ê°œë… | í•¨ìˆ˜/í´ë˜ìŠ¤ | í•µì‹¬ íŒŒë¼ë¯¸í„° | ì‚¬ìš© ì‹œì  |\n",
    "|------|------------|--------------|----------|\n",
    "| ë ˆì´ë¸” ì¸ì½”ë”© | LabelEncoder | - | íƒ€ê²Ÿ ë³€ìˆ˜, ì´ì§„ ë²”ì£¼ |\n",
    "| ì›-í•« ì¸ì½”ë”© | OneHotEncoder | drop, handle_unknown | ëª…ëª©í˜• íŠ¹ì„± |\n",
    "| ë‹¤í•­ íŠ¹ì„± | PolynomialFeatures | degree, interaction_only | ë¹„ì„ í˜• ê´€ê³„ í¬ì°© |\n",
    "| íŒŒì´í”„ë¼ì¸ | Pipeline | steps | ì „ì²˜ë¦¬ ìë™í™” |\n",
    "| ë³µí•© ë³€í™˜ | ColumnTransformer | transformers | ìˆ˜ì¹˜í˜•+ë²”ì£¼í˜• ë™ì‹œ ì²˜ë¦¬ |\n",
    "\n",
    "### ğŸ’¡ ì‹¤ë¬´ íŒ\n",
    "\n",
    "1. **Data Leakage ì£¼ì˜**: í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì ˆëŒ€ fit í•˜ì§€ ë§ˆì„¸ìš”!\n",
    "2. **stratify ì‚¬ìš©**: ë¶ˆê· í˜• ë°ì´í„°ëŠ” ë°˜ë“œì‹œ ê³„ì¸µì  ìƒ˜í”Œë§\n",
    "3. **Pipeline í™œìš©**: ì „ì²˜ë¦¬ì™€ ëª¨ë¸ì„ ë¬¶ì–´ ì‹¤ìˆ˜ ë°©ì§€\n",
    "4. **êµì°¨ ê²€ì¦ í•„ìˆ˜**: í•œ ë²ˆ ë¶„í• ë³´ë‹¤ ì—¬ëŸ¬ ë²ˆ í‰ê°€ê°€ ì‹ ë¢°ì„± ìˆìŒ\n",
    "5. **ìŠ¤ì¼€ì¼ëŸ¬ ì„ íƒ**: ë°ì´í„° ë¶„í¬ì™€ ëª¨ë¸ íŠ¹ì„±ì— ë§ê²Œ ì„ íƒ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
