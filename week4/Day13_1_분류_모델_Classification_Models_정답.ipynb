{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day13_1: 분류 모델 (Classification Models) - 정답\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    "    VotingClassifier, BaggingClassifier, AdaBoostClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"라이브러리 로드 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q1. Logistic Regression 기본 훈련 ⭐\n",
    "\n",
    "**문제**: 아래 데이터로 Logistic Regression 모델을 훈련하고 정확도를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 로드\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# 훈련/테스트 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=10000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# 정확도 출력\n",
    "accuracy = lr_model.score(X_test, y_test)\n",
    "print(f\"테스트 정확도: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert accuracy > 0.9, \"정확도가 90% 이상이어야 합니다\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. breast_cancer 데이터셋 로드 (이진 분류: 악성/양성)\n",
    "2. train_test_split으로 80:20 분할\n",
    "3. LogisticRegression 모델 훈련\n",
    "4. score() 메서드로 정확도 계산\n",
    "\n",
    "**핵심 개념**:\n",
    "- `load_breast_cancer()`: 569개 샘플, 30개 특성의 이진 분류 데이터\n",
    "- `max_iter=10000`: 수렴을 위한 충분한 반복 횟수\n",
    "- `random_state=42`: 재현성 보장\n",
    "\n",
    "**대안**:\n",
    "- `accuracy_score(y_test, lr_model.predict(X_test))`로 동일 결과\n",
    "- 스케일링 적용 시 더 안정적인 결과\n",
    "\n",
    "**흔한 실수**:\n",
    "- max_iter 미설정으로 수렴 경고 발생\n",
    "- 데이터 분할 없이 전체 데이터로 평가 (과적합)\n",
    "\n",
    "**실무 팁**:\n",
    "- Logistic Regression은 베이스라인 모델로 항상 먼저 시도\n",
    "- 계수(coef_)로 특성 중요도 해석 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q2. KNN 모델 K값 실험 ⭐\n",
    "\n",
    "**문제**: K=3, K=5, K=7로 KNN 모델을 훈련하고 각각의 정확도를 비교하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 데이터 준비 (스케일링 적용)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# K값 실험\n",
    "k_values = [3, 5, 7]\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    # 모델 생성 및 훈련\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 정확도 계산\n",
    "    accuracy = knn.score(X_test_scaled, y_test)\n",
    "    results.append({'K': k, 'Accuracy': accuracy})\n",
    "    print(f\"K={k}: 정확도 {accuracy:.4f}\")\n",
    "\n",
    "# 결과 정리\n",
    "df_knn_results = pd.DataFrame(results)\n",
    "best_k = df_knn_results.loc[df_knn_results['Accuracy'].idxmax(), 'K']\n",
    "print(f\"\\n최적 K: {best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert len(results) == 3, \"3개의 K값에 대한 결과가 있어야 합니다\"\n",
    "assert all(r['Accuracy'] > 0.9 for r in results), \"모든 정확도가 90% 이상이어야 합니다\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. KNN은 거리 기반이므로 스케일링 필수\n",
    "2. 여러 K값으로 반복 실험\n",
    "3. 최적 K값 선택\n",
    "\n",
    "**핵심 개념**:\n",
    "- K가 작으면 과적합, K가 크면 과소적합\n",
    "- 일반적으로 홀수 K 사용 (동점 방지)\n",
    "- StandardScaler로 특성 스케일 통일\n",
    "\n",
    "**대안**:\n",
    "- cross_val_score로 더 안정적인 K값 선택\n",
    "- GridSearchCV로 자동 최적화\n",
    "\n",
    "**흔한 실수**:\n",
    "- 스케일링 없이 KNN 적용 (성능 저하)\n",
    "- 테스트 데이터에도 fit_transform 적용 (데이터 누수)\n",
    "\n",
    "**실무 팁**:\n",
    "- KNN은 소규모 데이터에 적합\n",
    "- 대규모 데이터는 예측 시간이 오래 걸림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q3. Decision Tree 특성 중요도 추출 ⭐⭐\n",
    "\n",
    "**문제**: Decision Tree를 훈련하고 상위 5개 중요 특성을 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 특성 이름\n",
    "feature_names = data.feature_names\n",
    "\n",
    "# Decision Tree 훈련\n",
    "dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# 특성 중요도 추출\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': dt_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# 상위 5개 출력\n",
    "print(\"상위 5개 중요 특성:\")\n",
    "print(importance_df.head(5).to_string(index=False))\n",
    "\n",
    "# 시각화\n",
    "top5 = importance_df.head(5)\n",
    "fig = go.Figure(go.Bar(\n",
    "    x=top5['importance'],\n",
    "    y=top5['feature'],\n",
    "    orientation='h',\n",
    "    marker_color='steelblue'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"Decision Tree 특성 중요도 (Top 5)\",\n",
    "    xaxis_title=\"Importance\",\n",
    "    yaxis=dict(autorange='reversed'),\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert len(importance_df) == 30, \"30개 특성의 중요도가 있어야 합니다\"\n",
    "assert importance_df['importance'].sum() > 0.99, \"중요도 합이 1에 가까워야 합니다\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. Decision Tree 훈련 (max_depth로 과적합 방지)\n",
    "2. feature_importances_ 속성으로 중요도 추출\n",
    "3. DataFrame으로 정리 후 정렬\n",
    "\n",
    "**핵심 개념**:\n",
    "- feature_importances_: 각 특성이 분류에 기여하는 정도\n",
    "- 불순도 감소량 기반 계산 (Gini impurity)\n",
    "- 합이 1이 되도록 정규화됨\n",
    "\n",
    "**대안**:\n",
    "- Random Forest의 feature_importances_가 더 안정적\n",
    "- permutation_importance()로 더 정확한 중요도 계산\n",
    "\n",
    "**흔한 실수**:\n",
    "- max_depth 미설정으로 과적합\n",
    "- 특성 이름과 중요도 매칭 오류\n",
    "\n",
    "**실무 팁**:\n",
    "- 특성 중요도는 특성 선택(feature selection)에 활용\n",
    "- 중요도가 0인 특성은 제거 고려"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q4. Random Forest vs Decision Tree 비교 ⭐⭐\n",
    "\n",
    "**문제**: Random Forest (n_estimators=100)와 Decision Tree의 성능을 비교하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# 성능 비교\n",
    "results = {\n",
    "    'Model': ['Decision Tree', 'Random Forest'],\n",
    "    'Accuracy': [accuracy_score(y_test, y_pred_dt), accuracy_score(y_test, y_pred_rf)],\n",
    "    'F1 Score': [f1_score(y_test, y_pred_dt), f1_score(y_test, y_pred_rf)]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(results)\n",
    "print(\"성능 비교:\")\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# 승자 판정\n",
    "winner = 'Random Forest' if results['F1 Score'][1] > results['F1 Score'][0] else 'Decision Tree'\n",
    "print(f\"\\n승자: {winner}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert results['Accuracy'][1] >= results['Accuracy'][0] * 0.95, \"RF가 DT보다 크게 나쁘면 안됩니다\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. 동일 조건(max_depth)으로 두 모델 훈련\n",
    "2. 동일 지표(Accuracy, F1)로 비교\n",
    "3. 결과 테이블로 정리\n",
    "\n",
    "**핵심 개념**:\n",
    "- Random Forest = Decision Tree의 앙상블\n",
    "- 배깅으로 분산 감소, 과적합 방지\n",
    "- n_estimators: 트리 개수 (많을수록 안정적)\n",
    "\n",
    "**대안**:\n",
    "- cross_val_score로 더 신뢰성 있는 비교\n",
    "- 학습 시간, 예측 시간도 비교 가능\n",
    "\n",
    "**흔한 실수**:\n",
    "- 다른 조건으로 비교 (불공정)\n",
    "- 단일 지표만으로 판단\n",
    "\n",
    "**실무 팁**:\n",
    "- Random Forest는 거의 항상 Decision Tree보다 좋음\n",
    "- 해석이 중요하면 Decision Tree 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q5. Confusion Matrix 계산 ⭐⭐\n",
    "\n",
    "**문제**: 사기 탐지 데이터에서 Random Forest의 Confusion Matrix를 출력하고 TP, FP, TN, FN을 해석하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사기 탐지 데이터 생성\n",
    "np.random.seed(42)\n",
    "\n",
    "# 정상 거래 (95%)\n",
    "n_normal = 9500\n",
    "normal_data = {\n",
    "    'amount': np.random.exponential(scale=100, size=n_normal),\n",
    "    'hour': np.random.randint(6, 23, n_normal),\n",
    "    'distance_from_home': np.random.exponential(scale=10, size=n_normal),\n",
    "    'ratio_to_median': np.random.uniform(0.5, 2.0, n_normal),\n",
    "    'fraud': np.zeros(n_normal)\n",
    "}\n",
    "\n",
    "# 사기 거래 (5%)\n",
    "n_fraud = 500\n",
    "fraud_data = {\n",
    "    'amount': np.random.exponential(scale=500, size=n_fraud),\n",
    "    'hour': np.random.choice([0, 1, 2, 3, 4, 5, 23], n_fraud),\n",
    "    'distance_from_home': np.random.exponential(scale=100, size=n_fraud),\n",
    "    'ratio_to_median': np.random.uniform(3.0, 10.0, n_fraud),\n",
    "    'fraud': np.ones(n_fraud)\n",
    "}\n",
    "\n",
    "df_fraud = pd.concat([pd.DataFrame(normal_data), pd.DataFrame(fraud_data)], ignore_index=True)\n",
    "df_fraud = df_fraud.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X_fraud = df_fraud.drop('fraud', axis=1)\n",
    "y_fraud = df_fraud['fraud']\n",
    "\n",
    "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(\n",
    "    X_fraud, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Random Forest 훈련\n",
    "rf_fraud = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_fraud.fit(X_train_f, y_train_f)\n",
    "y_pred_fraud = rf_fraud.predict(X_test_f)\n",
    "\n",
    "# Confusion Matrix 계산\n",
    "cm = confusion_matrix(y_test_f, y_pred_fraud)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"\\nTN (True Negative): {TN}\")\n",
    "print(f\"  -> 정상 거래를 정상으로 올바르게 예측\")\n",
    "print(f\"FP (False Positive): {FP}\")\n",
    "print(f\"  -> 정상 거래를 사기로 잘못 예측 (허위 경보)\")\n",
    "print(f\"FN (False Negative): {FN}\")\n",
    "print(f\"  -> 사기 거래를 정상으로 잘못 예측 (놓친 사기!)\")\n",
    "print(f\"TP (True Positive): {TP}\")\n",
    "print(f\"  -> 사기 거래를 사기로 올바르게 예측\")\n",
    "\n",
    "# 비용 관점 해석\n",
    "print(f\"\\n[비용 관점 해석]\")\n",
    "print(f\"FN({FN}건)이 가장 위험: 실제 사기를 놓치면 금전적 손실 발생\")\n",
    "print(f\"FP({FP}건)는 고객 불편: 정상 거래 차단으로 고객 이탈 우려\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert TN + FP + FN + TP == len(y_test_f), \"CM 합이 테스트 데이터 수와 같아야 합니다\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. confusion_matrix()로 CM 계산\n",
    "2. ravel()로 TN, FP, FN, TP 추출\n",
    "3. 각 값의 의미를 비즈니스 관점에서 해석\n",
    "\n",
    "**핵심 개념**:\n",
    "- TN: 실제 음성을 음성으로 예측 (정상->정상)\n",
    "- FP: 실제 음성을 양성으로 예측 (정상->사기)\n",
    "- FN: 실제 양성을 음성으로 예측 (사기->정상) **위험!**\n",
    "- TP: 실제 양성을 양성으로 예측 (사기->사기)\n",
    "\n",
    "**대안**:\n",
    "- ConfusionMatrixDisplay로 시각화\n",
    "- Plotly로 히트맵 시각화\n",
    "\n",
    "**흔한 실수**:\n",
    "- TN/FP/FN/TP 순서 혼동 (sklearn은 [[TN,FP],[FN,TP]])\n",
    "- 양성/음성 기준 혼동\n",
    "\n",
    "**실무 팁**:\n",
    "- 사기 탐지에서 FN 비용 >> FP 비용\n",
    "- Recall을 높이는 것이 중요 (FN 최소화)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q6. Voting Classifier 구현 ⭐⭐⭐\n",
    "\n",
    "**문제**: LogisticRegression, RandomForest, GradientBoosting을 결합한 Soft Voting Classifier를 구현하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "from sklearn.ensemble import VotingClassifier, GradientBoostingClassifier\n",
    "\n",
    "# 개별 모델 정의\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "gb = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Voting Classifier (Soft Voting)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr),\n",
    "        ('rf', rf),\n",
    "        ('gb', gb)\n",
    "    ],\n",
    "    voting='soft'  # 확률 평균\n",
    ")\n",
    "\n",
    "# 개별 모델 훈련 및 평가\n",
    "models = {'Logistic Regression': lr, 'Random Forest': rf, 'Gradient Boosting': gb}\n",
    "individual_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_f, y_train_f)\n",
    "    score = model.score(X_test_f, y_test_f)\n",
    "    individual_scores[name] = score\n",
    "    print(f\"{name}: {score:.4f}\")\n",
    "\n",
    "# Voting Classifier 훈련 및 평가\n",
    "voting_clf.fit(X_train_f, y_train_f)\n",
    "voting_score = voting_clf.score(X_test_f, y_test_f)\n",
    "print(f\"\\nVoting Classifier: {voting_score:.4f}\")\n",
    "\n",
    "# 비교\n",
    "best_individual = max(individual_scores.values())\n",
    "improvement = voting_score - best_individual\n",
    "print(f\"\\n앙상블 효과: {improvement:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert voting_score > 0.9, \"Voting 정확도가 90% 이상이어야 합니다\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. 서로 다른 특성의 모델 3개 선택 (선형, 트리, 부스팅)\n",
    "2. VotingClassifier로 결합\n",
    "3. soft voting으로 확률 평균 사용\n",
    "\n",
    "**핵심 개념**:\n",
    "- Hard Voting: 다수결 (예측 클래스 투표)\n",
    "- Soft Voting: 확률 평균 (일반적으로 더 좋음)\n",
    "- 다양한 모델 결합이 성능 향상에 유리\n",
    "\n",
    "**대안**:\n",
    "- weights 파라미터로 모델별 가중치 조정\n",
    "- 더 다양한 모델 추가 (SVM, KNN 등)\n",
    "\n",
    "**흔한 실수**:\n",
    "- Hard voting에서 probability=True 미설정\n",
    "- 비슷한 모델만 결합 (다양성 부족)\n",
    "\n",
    "**실무 팁**:\n",
    "- Voting은 간단하면서 효과적인 앙상블\n",
    "- 모델 다양성이 핵심"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q7. class_weight 효과 분석 ⭐⭐⭐\n",
    "\n",
    "**문제**: 사기 탐지 데이터에서 class_weight 적용 전후의 Recall을 비교하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_f)\n",
    "X_test_scaled = scaler.transform(X_test_f)\n",
    "\n",
    "# class_weight 없음\n",
    "lr_no_weight = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_no_weight.fit(X_train_scaled, y_train_f)\n",
    "y_pred_no_weight = lr_no_weight.predict(X_test_scaled)\n",
    "recall_no_weight = recall_score(y_test_f, y_pred_no_weight)\n",
    "\n",
    "# class_weight='balanced'\n",
    "lr_balanced = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "lr_balanced.fit(X_train_scaled, y_train_f)\n",
    "y_pred_balanced = lr_balanced.predict(X_test_scaled)\n",
    "recall_balanced = recall_score(y_test_f, y_pred_balanced)\n",
    "\n",
    "# 비교\n",
    "print(\"Recall 비교 (사기 클래스):\")\n",
    "print(f\"  class_weight 없음: {recall_no_weight:.4f}\")\n",
    "print(f\"  class_weight='balanced': {recall_balanced:.4f}\")\n",
    "print(f\"\\n개선: {recall_balanced - recall_no_weight:+.4f} ({(recall_balanced/recall_no_weight - 1)*100:+.1f}%)\")\n",
    "\n",
    "# Precision도 확인\n",
    "precision_no_weight = precision_score(y_test_f, y_pred_no_weight)\n",
    "precision_balanced = precision_score(y_test_f, y_pred_balanced)\n",
    "print(f\"\\n[참고] Precision:\")\n",
    "print(f\"  class_weight 없음: {precision_no_weight:.4f}\")\n",
    "print(f\"  class_weight='balanced': {precision_balanced:.4f}\")\n",
    "print(f\"\\n-> Recall 증가, Precision 감소 (트레이드오프)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert recall_balanced >= recall_no_weight, \"balanced가 Recall이 더 높거나 같아야 합니다\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. class_weight 없이 기본 모델 훈련\n",
    "2. class_weight='balanced'로 모델 훈련\n",
    "3. Recall과 Precision 비교\n",
    "\n",
    "**핵심 개념**:\n",
    "- class_weight='balanced': n_samples / (n_classes * np.bincount(y))\n",
    "- 소수 클래스에 높은 가중치 -> 오분류 페널티 증가\n",
    "- Recall 증가, Precision 감소 (트레이드오프)\n",
    "\n",
    "**대안**:\n",
    "- class_weight={0: 1, 1: 10}으로 수동 설정\n",
    "- SMOTE로 오버샘플링\n",
    "\n",
    "**흔한 실수**:\n",
    "- Recall만 보고 Precision 무시\n",
    "- 모든 모델에 class_weight 적용 가능하다고 가정\n",
    "\n",
    "**실무 팁**:\n",
    "- 사기 탐지: Recall 중시 (FN 비용 높음)\n",
    "- 스팸 필터: Precision 중시 (FP 비용 높음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q8. ROC 곡선 Plotly 시각화 ⭐⭐⭐\n",
    "\n",
    "**문제**: Logistic Regression과 Random Forest의 ROC 곡선을 Plotly로 시각화하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# 모델 준비 (앞서 훈련한 모델 사용)\n",
    "# LR 확률 예측\n",
    "y_proba_lr = lr_balanced.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# RF 확률 예측\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_f, y_train_f)\n",
    "y_proba_rf = rf_model.predict_proba(X_test_f)[:, 1]\n",
    "\n",
    "# ROC 곡선 계산\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test_f, y_proba_lr)\n",
    "auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test_f, y_proba_rf)\n",
    "auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "# Plotly 시각화\n",
    "fig = go.Figure()\n",
    "\n",
    "# Logistic Regression\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=fpr_lr, y=tpr_lr,\n",
    "    mode='lines',\n",
    "    name=f'Logistic Regression (AUC={auc_lr:.3f})',\n",
    "    line=dict(color='blue', width=2)\n",
    "))\n",
    "\n",
    "# Random Forest\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=fpr_rf, y=tpr_rf,\n",
    "    mode='lines',\n",
    "    name=f'Random Forest (AUC={auc_rf:.3f})',\n",
    "    line=dict(color='green', width=2)\n",
    "))\n",
    "\n",
    "# 대각선 (랜덤 분류기)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 1], y=[0, 1],\n",
    "    mode='lines',\n",
    "    name='Random (AUC=0.5)',\n",
    "    line=dict(color='gray', dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ROC Curve: LR vs RF',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    template='plotly_white',\n",
    "    legend=dict(x=0.6, y=0.1)\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nAUC 비교:\")\n",
    "print(f\"  Logistic Regression: {auc_lr:.4f}\")\n",
    "print(f\"  Random Forest: {auc_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert auc_lr > 0.5, \"LR AUC가 0.5보다 커야 합니다\"\n",
    "assert auc_rf > 0.5, \"RF AUC가 0.5보다 커야 합니다\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. predict_proba()로 확률 예측\n",
    "2. roc_curve()로 FPR, TPR 계산\n",
    "3. auc()로 AUC 계산\n",
    "4. Plotly로 시각화\n",
    "\n",
    "**핵심 개념**:\n",
    "- ROC: 임계값 변화에 따른 TPR vs FPR\n",
    "- AUC: ROC 곡선 아래 면적 (1에 가까울수록 좋음)\n",
    "- 대각선(AUC=0.5)은 랜덤 분류기 기준선\n",
    "\n",
    "**대안**:\n",
    "- sklearn의 RocCurveDisplay 사용\n",
    "- matplotlib으로 시각화\n",
    "\n",
    "**흔한 실수**:\n",
    "- predict() 대신 predict_proba() 사용해야 함\n",
    "- 클래스 1의 확률만 사용 ([:, 1])\n",
    "\n",
    "**실무 팁**:\n",
    "- AUC는 임계값에 독립적인 평가 지표\n",
    "- 불균형 데이터에서는 PR 곡선이 더 유용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q9. Stacking Ensemble 구현 ⭐⭐⭐⭐\n",
    "\n",
    "**문제**: 3개의 기본 모델과 메타 모델을 사용한 Stacking Classifier를 구현하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 기본 모델 정의\n",
    "base_models = [\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('dt', DecisionTreeClassifier(max_depth=5, random_state=42)),\n",
    "    ('svm', SVC(probability=True, random_state=42))\n",
    "]\n",
    "\n",
    "# 메타 모델\n",
    "meta_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Stacking Classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5  # 교차 검증으로 메타 특성 생성\n",
    ")\n",
    "\n",
    "# 훈련 (스케일링된 데이터 사용)\n",
    "stacking_clf.fit(X_train_scaled, y_train_f)\n",
    "\n",
    "# 예측\n",
    "y_pred_stacking = stacking_clf.predict(X_test_scaled)\n",
    "\n",
    "# 평가\n",
    "print(\"Stacking Classifier 결과:\")\n",
    "print(f\"정확도: {accuracy_score(y_test_f, y_pred_stacking):.4f}\")\n",
    "print(\"\\n\" + classification_report(y_test_f, y_pred_stacking, target_names=['정상', '사기']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 모델과 비교\n",
    "print(\"\\n개별 모델 vs Stacking 비교:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "individual_f1 = []\n",
    "for name, model in base_models:\n",
    "    model.fit(X_train_scaled, y_train_f)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    f1 = f1_score(y_test_f, y_pred)\n",
    "    individual_f1.append(f1)\n",
    "    print(f\"{name}: F1={f1:.4f}\")\n",
    "\n",
    "stacking_f1 = f1_score(y_test_f, y_pred_stacking)\n",
    "print(f\"\\nStacking: F1={stacking_f1:.4f}\")\n",
    "print(f\"최고 개별 모델 대비: {stacking_f1 - max(individual_f1):+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert accuracy_score(y_test_f, y_pred_stacking) > 0.9, \"Stacking 정확도가 90% 이상이어야 합니다\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. 서로 다른 특성의 기본 모델 3개 정의\n",
    "2. 메타 모델로 Logistic Regression 사용\n",
    "3. StackingClassifier로 결합\n",
    "4. cv=5로 교차 검증 기반 메타 특성 생성\n",
    "\n",
    "**핵심 개념**:\n",
    "- Stacking: 기본 모델의 예측을 새로운 특성으로 사용\n",
    "- 메타 모델이 최종 예측 수행\n",
    "- cv로 데이터 누수 방지\n",
    "\n",
    "**대안**:\n",
    "- 메타 모델로 더 강력한 모델 사용 (GradientBoosting)\n",
    "- passthrough=True로 원본 특성도 포함\n",
    "\n",
    "**흔한 실수**:\n",
    "- cv 미설정으로 데이터 누수\n",
    "- SVM에 probability=True 미설정\n",
    "\n",
    "**실무 팁**:\n",
    "- Stacking은 Kaggle 대회에서 자주 사용\n",
    "- 학습 시간이 오래 걸리므로 최종 단계에서 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q10. 종합: 최적 분류 모델 파이프라인 ⭐⭐⭐⭐⭐\n",
    "\n",
    "**문제**: 사기 탐지 데이터에 대해 최적의 분류 파이프라인을 구축하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드 - Part 1: 모델 훈련 및 비교\n",
    "\n",
    "# 데이터 준비 (앞서 생성한 사기 탐지 데이터 사용)\n",
    "print(\"=\" * 60)\n",
    "print(\"사기 탐지 최적 분류 파이프라인 구축\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 모델 정의 (불균형 처리 적용)\n",
    "models = {\n",
    "    'LR (balanced)': LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n",
    "    'RF (balanced)': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "    'GB': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 결과 저장\n",
    "all_results = []\n",
    "all_probas = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # 스케일링 필요 여부 판단\n",
    "    if 'LR' in name:\n",
    "        model.fit(X_train_scaled, y_train_f)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train_f, y_train_f)\n",
    "        y_pred = model.predict(X_test_f)\n",
    "        y_proba = model.predict_proba(X_test_f)[:, 1]\n",
    "    \n",
    "    all_probas[name] = y_proba\n",
    "    \n",
    "    all_results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test_f, y_pred),\n",
    "        'Precision': precision_score(y_test_f, y_pred),\n",
    "        'Recall': recall_score(y_test_f, y_pred),\n",
    "        'F1': f1_score(y_test_f, y_pred),\n",
    "        'AUC': auc(*roc_curve(y_test_f, y_proba)[:2]),\n",
    "        'AP': average_precision_score(y_test_f, y_proba)\n",
    "    })\n",
    "\n",
    "# 결과 테이블\n",
    "df_results = pd.DataFrame(all_results).sort_values('F1', ascending=False)\n",
    "print(\"\\n[모델 성능 비교]\")\n",
    "print(df_results.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드 - Part 2: ROC 곡선 시각화\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "colors = {'LR (balanced)': 'blue', 'RF (balanced)': 'green', 'GB': 'red'}\n",
    "\n",
    "for name, y_proba in all_probas.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test_f, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=fpr, y=tpr,\n",
    "        mode='lines',\n",
    "        name=f\"{name} (AUC={roc_auc:.3f})\",\n",
    "        line=dict(color=colors[name], width=2)\n",
    "    ))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 1], y=[0, 1],\n",
    "    mode='lines',\n",
    "    name='Random',\n",
    "    line=dict(color='gray', dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ROC Curves - 모델 비교',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    template='plotly_white',\n",
    "    width=700, height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드 - Part 3: PR 곡선 시각화\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for name, y_proba in all_probas.items():\n",
    "    precision, recall, _ = precision_recall_curve(y_test_f, y_proba)\n",
    "    ap = average_precision_score(y_test_f, y_proba)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=recall, y=precision,\n",
    "        mode='lines',\n",
    "        name=f\"{name} (AP={ap:.3f})\",\n",
    "        line=dict(color=colors[name], width=2)\n",
    "    ))\n",
    "\n",
    "# 베이스라인\n",
    "baseline = y_test_f.mean()\n",
    "fig.add_hline(y=baseline, line_dash=\"dash\", line_color=\"gray\",\n",
    "              annotation_text=f\"Baseline ({baseline:.2%})\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Precision-Recall Curves - 모델 비교',\n",
    "    xaxis_title='Recall',\n",
    "    yaxis_title='Precision',\n",
    "    template='plotly_white',\n",
    "    width=700, height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 코드 - Part 4: 최종 추천 및 설명\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"최종 추천 모델 및 이유\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 최고 성능 모델 찾기\n",
    "best_model = df_results.iloc[0]['Model']\n",
    "best_metrics = df_results.iloc[0]\n",
    "\n",
    "print(f\"\\n추천 모델: {best_model}\")\n",
    "print(f\"\\n성능 지표:\")\n",
    "print(f\"  - Accuracy: {best_metrics['Accuracy']:.4f}\")\n",
    "print(f\"  - Precision: {best_metrics['Precision']:.4f}\")\n",
    "print(f\"  - Recall: {best_metrics['Recall']:.4f}\")\n",
    "print(f\"  - F1 Score: {best_metrics['F1']:.4f}\")\n",
    "print(f\"  - AUC-ROC: {best_metrics['AUC']:.4f}\")\n",
    "print(f\"  - Average Precision: {best_metrics['AP']:.4f}\")\n",
    "\n",
    "print(f\"\\n선택 이유:\")\n",
    "print(f\"  1. F1 Score가 가장 높음 ({best_metrics['F1']:.4f})\")\n",
    "print(f\"  2. Recall이 높아 사기 탐지에 적합 ({best_metrics['Recall']:.4f})\")\n",
    "print(f\"  3. class_weight='balanced'로 불균형 처리 적용\")\n",
    "print(f\"  4. 앙상블로 안정적인 성능\")\n",
    "\n",
    "print(f\"\\n실무 적용 시 고려사항:\")\n",
    "print(f\"  - 임계값 조정으로 Recall/Precision 균형 조절 가능\")\n",
    "print(f\"  - 정기적인 재훈련으로 새로운 사기 패턴 학습\")\n",
    "print(f\"  - 실시간 모니터링으로 모델 성능 추적\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "assert len(all_results) >= 3, \"최소 3개 모델 비교가 필요합니다\"\n",
    "assert df_results['F1'].max() > 0.5, \"최고 F1이 0.5 이상이어야 합니다\"\n",
    "print(\"테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀이 설명\n",
    "\n",
    "**접근 방법**:\n",
    "1. 불균형 처리 적용한 모델 3개 이상 훈련\n",
    "2. 다양한 지표로 성능 평가\n",
    "3. ROC, PR 곡선으로 시각화\n",
    "4. 비즈니스 관점에서 최적 모델 선택\n",
    "\n",
    "**핵심 개념**:\n",
    "- 사기 탐지는 불균형 문제 -> Recall 중시\n",
    "- class_weight로 불균형 처리\n",
    "- PR 곡선이 ROC보다 불균형 데이터에 유용\n",
    "- F1 Score로 Precision-Recall 균형 평가\n",
    "\n",
    "**대안**:\n",
    "- SMOTE 오버샘플링 적용\n",
    "- XGBoost/LightGBM 사용\n",
    "- 앙상블(Voting, Stacking) 적용\n",
    "\n",
    "**흔한 실수**:\n",
    "- Accuracy만으로 평가 (불균형에서 부적합)\n",
    "- 불균형 처리 미적용\n",
    "- 단일 지표만 고려\n",
    "\n",
    "**실무 팁**:\n",
    "- 사기 탐지: FN 비용 > FP 비용 -> Recall 우선\n",
    "- 임계값 조정으로 운영 환경에 맞게 조절\n",
    "- A/B 테스트로 실제 비즈니스 영향 측정\n",
    "- 모델 해석(SHAP, 특성 중요도)으로 신뢰성 확보"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 학습 정리\n",
    "\n",
    "### 퀴즈 난이도 분포\n",
    "\n",
    "| 난이도 | 퀴즈 번호 | 핵심 개념 |\n",
    "|--------|-----------|----------|\n",
    "| ⭐ | Q1, Q2 | 기본 모델 훈련, KNN K값 실험 |\n",
    "| ⭐⭐ | Q3, Q4, Q5 | 특성 중요도, 모델 비교, Confusion Matrix |\n",
    "| ⭐⭐⭐ | Q6, Q7, Q8 | Voting, class_weight, ROC 시각화 |\n",
    "| ⭐⭐⭐⭐ | Q9 | Stacking Ensemble |\n",
    "| ⭐⭐⭐⭐⭐ | Q10 | 종합 파이프라인 |\n",
    "\n",
    "### 핵심 학습 포인트\n",
    "\n",
    "1. **기본 분류기**: LR, KNN, NB, SVM - 각각의 장단점 이해\n",
    "2. **트리 기반**: DT, RF, GB - 특성 중요도 활용\n",
    "3. **앙상블**: Voting, Bagging, Boosting, Stacking - 성능 극대화\n",
    "4. **불균형 처리**: class_weight, SMOTE - 실무 필수\n",
    "5. **시각화**: ROC, PR 곡선 - Plotly로 인터랙티브\n",
    "\n",
    "### 다음 단계\n",
    "\n",
    "- Day 14-0: 군집화 (Clustering)\n",
    "- Day 14-1: 차원 축소 (Dimensionality Reduction)\n",
    "- Week 4 Kaggle 미니 대회 준비"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
